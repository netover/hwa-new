IBM® Workload Scheduler

Administration

Version 10.2.5

# Note

Before using this information and the product it supports, read the information in Notices on page cdIxxviii.

This edition applies to version 10, release 2, modification level 5 of IBM® Workload Scheduler (program number 5698-T09) and to all subsequent releases and modifications until otherwise indicated in new editions.

# Contents

List of Figures. VIII  
List of Tables ix  
About this publication. xi  
What is new in this release.  
Accessibility xi  
Technical training. xi  
Support information. xi

# Chapter 1. Customizing and configuring IBM Workload Scheduler 13

Setting global options. 13  
Global options - summary. 15  
Global options - detailed description. 27

Setting local options. 48

Locopts summary. 49  
Localoptsdetails. 52  
Local options file example. 66

Setting user options. 70  
Multiple product instances. 71  
Configuring the agent. 71  
Configuring general properties [ITA]. 74  
Configuring log message properties [JobManager Logging.cblog] 75  
Configuring trace properties when the agent is stopped [JobManager Logging.ccclog] 77  
Trace configuration for the agent. 78  
Configuring common launchers properties [Launchers] 81  
Configuring properties of the native job launcher [NativeJobLauncher]. 83  
Configuring properties of the Java™ job launcher [JavaJobLauncher] 86  
Configuring properties of the Resource advisor agent [ResourceAdvisorAgent]. 87  
Configuring properties of the System scanner [SystemScanner]. 89  
Configuring environment variables [Env] 90  
Configuring the agent to work with a password vault. 90  
Configuring the agent to work with Kerberos.... 98  
Regular agent maintenance. 101

Configuring the dynamic workload broker server on the master domain manager and dynamic domain manager. 102

Maintaining the dynamic workload broker server on the master domain manager and dynamic domain manager 103  
Enabling unsecure communication with the dynamic workload broker server. 104  
ResourceAdvisor.Config.properties file............ 105  
JobDispatcherConfig.properties file............ 107

BrokerWorkstation.properties file 109  
Archiving job data. 112  
Configuring to schedule J2EE jobs 112  
Configuring to schedule job types with advanced options 120  
Configuring security roles for users and groups 121

Configuring command-line client access authentication. 123

Connection parameters. 124  
Entering passwords. 126

An active-active high availability scenario. 127

IBM Workload Scheduler console messages and prompts. 132

Setting sysloglocal on UNIX™ 132  
console command. 133

Automatic encryption for key product files. 133  
Encryption key rotation. 134  
Modifying jobmon service rights for Windows™ 135

# Chapter 2. Configuring the Dynamic Workload Console. 136

Launching in context with the Dynamic Workload Console. 136

Scenarios. 136  
Advanced optional parameters 137

Configuring access to the Dynamic Workload Console. 145

Configuring a user registry. 146  
Configuring roles to access the Dynamic Workload Console 146

Configuring the Dynamic Workload Console for Single Sign-On. 149

How to configure the Dynamic Workload Console and the master domain manager for Single SignOn 150  
How to configure the Dynamic Workload Console 10.2.5 and a master domain manager 9.4.x for Single Sign-On............ 151

Configuring Dynamic Workload Console to connect to a remote SAP system 154

Customizing your global settings 155  
Customize video URLs 157

Override graphical view limits. 158  
Plan View in new window. 158  
Plan View auto refresh interval 159  
Disable and customize NewsFeed function..... 159

Disable and customize the creation of predefined tasks. 161

Add customized URL to job and job streams.... 162  
User registry. 164

z/OS http connections. 165

Limit the number of objects retrieved by queries. 165

Limit task and engine sharing. 166

Show all dependencies. 167

Auditing mobile app activity. 167

Modifying the number of archived plans displayed in the Dynamic Workload Console 168

Show or hide predecessors from What-if Analysis Gantt view 169

TdwcGlobalSettings.xml sample. 169

Disable the What-if Analysis 173

Configuring High Availability. 174

Configuring Dynamic Workload Console to view reports. 175

Configuring for an Oracle database. 175

Configuring for a Db2 database in HADR. 176

# Chapter 3. Configuring user authorization (Security file) 178

Getting started with security 178

Role-based security model. 179

Configuring role-based security from Dynamic Workload Console. 180

Configuring role-based security with composer command-line 186

Actions on security objects. 194

Attributes for object types. 200

Specifying object attribute values. 201

Classic security model. 205

Security management overview. 205

Updating the security file. 206

Centralized security management. 210

Configuring the security file. 211

Sample security file. 252

# Chapter 4. Configuring authentication.. 262

Where to configure authentication. 262

Available configurations. 262

Rules for using a Federated User Registry with IBM Workload Scheduler 263

Completing the LDAP configuration 263

Configuring an IBM Tivoli Directory Server 265

Example configurations of LDAP servers for IDS 266

Configuring Microsoft Active Directory. 268

Example configurations of LDAP servers for Microsoft Active Directory. 269

Configuring an OpenID Connect Client 272

# Chapter 5. Network administration. 274

Network overview. 274

Network definition 275

Network communications. 276

Network links. 276

Working across firewalls. 277

Configuring dynamic agent communications through a gateway 278

Enabling Ports. 282

Network operation 284

Network processes. 285

Optimizing the network 289

Data volumes. 289

Connectivity 290

Planning space for queues. 291

Tuning mailman servers 300

Netman configuration file. 301

Determining internal Symphony table size. 302

Defining access methods for agents 303

UNIXTM access methods. 304

IP address validation. 307

Support for Internet Protocol version 6. 307

Operating system configuration (UNIX™ only)...308

IP address validation messages 308

Impact of network changes 309

# Chapter 6. Configuring secure communications.. 311

Managing certificates using Certman 311

Generate new certificates and a Certificate Authority (CA). 311

Generate new certificates from an existing Certificate Authority (CA). 313

Extract certificates from the keystore and trustore. 314

Verify the validity of certificates. 317

Import certificates into the trustore. 318

Remove an alias from the keystore or truststore. 320

Certificate rotation. 321

Scenario: SSL Communication across the fault-tolerant agent network 323

Using SSL for netman and conman 324

# Chapter 7. Data maintenance 331

Backing up and restoring the database 331

Reorganizing the DB2 database 333

Maintaining the file system. 334

Avoiding full file systems. 334

Log files and archived files. 340

Temporary files. 345

Managing event message queue file sizes.....346

Administrative tasks - DB2 346

Changing DB2® passwords 347

Locating the DB2® tools. 347

User permissions for running the DB2® tools....347

Running DB2® maintenance manually. 348

Reorganizing the DB2® database. 349

Monitoring the lock list memory 350

Administrative tasks - Oracle 352

Customizing your RDBMS server 353

Connecting the master domain manager to a new database 354

Connecting the master domain manager to a new database when using pools. 358

Auditing facilities 363

Database and plan audit. 364

Enabling audit for authentication events. 372

Keeping track of database changes using audit reports. 373

Collecting job metrics 378

Job metrics queries for DB2. 378

Job metrics queries for DB2 for zOS. 379

Job metrics queries for Oracle database. 379

Chapter 8.Administrative tasks. 380

Switching a domain manager 381

Simplified procedure for switching a domain manager 382

Complete procedure for switching a domain manager 383

Switching the master to a backup. 387

Selecting a workstation for the backup master domain manager 388

Automatic failover 390

Manually switching the master 396

Switching a dynamic domain manager for a Z controller 399

Cloning scheduling definitions from one environment to another. 400

Changing key IBM Workload Scheduler passwords 402

Changing the WebSphere Application Server Liberty password. 404

Change password used by command-line clients to access the master domain manager. 406

Change password used by fault-tolerant agent systems to access the master domain manager (for conman). 406

Update the engine connection parameters in the GUIs. 406

WindowsTM -update WindowsTM services. 407

Change the IBM Workload Scheduler user definition 407

Unlinking and stopping IBM Workload Scheduler.....407

Changing the properties for the database. 408

Changing the workstation host name or IP address 411

Reporting the changes in the WebSphere Application Server Liberty configuration file.....411

Reporting the changed host name or IP address in the workstation definition. 413

Reporting the changed host name or IP address of the dynamic workload broker server. 413

Reporting the changed host name or IP address of the dynamic agent 415

Changing the security settings. 415

Managing the event processor. 416

Automatically initializing IBM Workload Scheduler instances 417

Configuring IBM Workload Scheduler using templates. 418

WebSphere Application Server Liberty tasks. 423

Application server - starting and stopping .....423

Application server - automatic restart after failure 424

Application server - encrypting the profile properties files. 427

Application server - configuration files backup and restore. 428

Application server - changing the host name or TCP/IP ports. 428

Application server - changing the trace properties 428

Chapter 9. Administering IBM i dynamic environment... 430

Configuring the agent on IBM i systems. 430

Configuring log message properties [JobManager Logging.cclog] 431

Configuring trace properties when the agent is stopped [JobManager Logging.ccclog] 432

Trace configuration for the agent 434

Configuring common launchers properties [Launchers] 437

Configuring properties of the native job launcher [NativeJobLauncher] 439

Configuring properties of the Java™ job launcher [JavaJobLauncher] 442

Configuring properties of the Resource advisor agent [ResourceAdvisorAgent] 443

Configuring properties of the System scanner [SystemScanner]. 445

Configuring to schedule job types with advanced options 445

Chapter 10. Performance 447

Network traffic. 447

Tracing 447

Logging. 447

Symphony file sizing. 447

Tuning a UNIX™ domain manager to handle large numbers of fault-tolerant agents. 447

Tuning job processing on a workstation. 448

Tuning plan replication. 449

Tuning the database. 450

Optimizing the replication of the Symphony file in

the database. 450

Too many manual job submissions. 450

Too many file dependency checks. 450

Network configuration availability. 451

Workload spreading 451

Improving job-processing performance. 451

Mailbox caching - advantages and disadvantages....452

Setting the synch level parameter. 453

The fault-tolerant switch manager - impact on performance. 453

Network Traffic 454

Disk Space. 454

Scalability 454

Impact on JnextPlan. 455

Impact on reporting. 455

Impact on event rule deployment. 456

Increasing application server heap size. 456

Increasing maximum DB2® log capacity. 457

Oracle tablespace size. 460

Multiple Dynamic Workload Console production plan reports. 460

Dynamic Workload Console - adjusting session timeout settings 461

Dynamic Workload Console - Increasing application server heap size. 462

Dynamic Workload Console graphical views 463

Using Google Chrome might reduce the Dynamic

Workload Console performance 463

Chapter 11. Availability 464

Resolving user ID account on Windows® operating systems. 464

Using a temporary directory on UNIX<sup>TM</sup> 465

Chapter 12. License Management in IBM License Metric

Tool 466

Processor Value Unit license model. 466

Per Job license model. 470

Using per job queries when upgrading from a version earlier than 9.4 Fix Pack 2 476

Notices. cdlxxviii

Index 482

# List of Figures

Figure 1: And end-to-end environment configured for high availability. 128  
Figure 2: Realm name in the WebSphere administrative console. 152  
Figure 3: Export of the ltpa keys file. 152  
Figure 4: Realm name in the authentication template.....153  
Figure 5: Password in XOR format. 154  
Figure 6: IBM Workload Scheduler network domain structure. 274  
Figure 7: Symphony file synchronization. 285  
Figure 8: Process creation on domain manager and fault-tolerant agent. 286  
Figure 9: Typical IBM Workload Scheduler network flows. 291

# List of Tables

Table 1: Workload service assurance feature. 17  
Table 2: Condition-based workflow automation.17  
Table 3: Event-driven workload automation feature - general. 18  
Table 4: Event-driven workload automation feature - event mailing. 18  
Table 5: Event-driven workload automation feature - IBM Z  
Workload Scheduler plug-in. 19  
Table 6: SSL. 20  
Table 7: Job management. 20  
Table 8: Job stream management. 20  
Table 9: Stageman. 21  
Table 10: Planman. 21  
Table 11: Logging and auditing. 22  
Table 12: Cross dependencies. 22  
Table 13: ServiceNow. 23  
Table 14: Automatic failover. 23  
Table 15: Licensing configuration. 24  
Table 16: General. 26  
Table 17: Valid internal job states. 29  
Table 18: Agent configuration parameters. 101  
Table 19: J2EEJobExecutorConfig.properties file keywords. 113  
Table 20: Configuration files for job types with advanced options. 120  
Table 21: Menu and Group Permissions. 148  
Table 22: Syntax for special characters. 163  
Table 23: Variables used in the URL definition. 163  
Table 24: Interaction between enWorkloadServiceAssurance and enWhatIf global options. 174  
Table 25: Security object types. 191

Table 26: Actions that users or groups can perform on the different objects. 193  
Table 27: Actions that users or groups can perform when designing and monitoring the workload. 195  
Table 28: Actions that users or groups can perform when modifying current plan. 195  
Table 29: Actions that users or groups can perform when submitting workload 196  
Table 30: Actions that users or groups can perform when managing the workload environment. 197  
Table 31: Actions that users or groups can perform when managing event rules. 198  
Table 32: Administrative tasks that users or groups can perform 199  
Table 33: Actions that users or groups can perform on workload reports. 199  
Table 34: Actions that users or groups can perform on folders. 200  
Table 35: Attributes for security object types. 201  
Table 36: Object attribute types for each object type.....223  
Table 37: Access keywords for composer actions. 231  
Table 38: Actions - access keywords. 233  
Table 39: Calendar - additional access keywords. 234  
Table 40: Cpus - additional access keywords. 235  
Table 41: Events - access keywords. 237  
Table 42: Files - access keywords. 237  
Table 43: folders - access keywords. 239  
Table 44: Jobs - additional access keywords. 241  
Table 45: Parameters - additional access keywords......245  
Table 46: Prompts - additional access keywords. 245  
Table 47: Files- access keywords. 246  
Table 48: Resources - additional access keywords.247  
Table 49: Run cycle groups- access keywords. 247

Table 50: Job streams - additional access keywords......248  
Table 51: Users - additional access keywords. 249  
Table 52: Variable tables - access keywords. 250  
Table 53: Workload applications - access keywords...... 251  
Table 54: Configuration settings. 280  
Table 55:Critical flow errors. 291  
Table 56: Queue sizing conditions. 293  
Table 57: Example for the ge operator. 295  
Table 58: Example for the le operator. 296  
Table 59: Calculation of internal Symphony table. 303  
Table 60: Type of communication depending on the security level value. 326  
Table 61: Algorithm for calculating the approximate size of the plan data in the Symphony file. 334  
Table 62: Algorithm for calculating the approximate size of the database data in the Symphony file. 335  
Table 63: Example for the ge operator. 337  
Table 64: Example for the le operator. 338  
Table 65: Log and trace file maintenance. 340  
Table 66: Complete procedure for switching a domain manager in case of a planned outage. 383  
Table 67: Complete procedure for switching a domain manager after an unplanned outage. 385  
Table 68: Configurable properties for automatic switch broker process. 398  
Table 69: If and where password changes are required....404  
Table 70: Correspondence between wastools and templates. 420  
Table 71: Configuration files for job types with advanced options. 446  
Table 72: Options for tuning job processing on a workstation. 448  
Table 73: Chargeable software components automatically detected by License Metric Tool. 466

Table 74: Chargeable software components that require software tag deployment on managed nodes. 467  
Table 75: IBM Workload Scheduler chargeable access methods and application plug-ins. 469

# About this publication

IBM Workload Scheduler: Administration Guide provides information about the administration of the main components of IBM Workload Scheduler (often called the engine).

# What is new in this release

Learn what is new in this release.

For information about the new or changed functions in this release, see IBM Workload Automation: Overview, section Summary of enhancements.

For information about the APARs that this release addresses, see the IBM Workload Scheduler Release Notes and the Dynamic Workload Console Release Notes. For information about the APARs addressed in a fix pack, refer to theREADME file for the fix pack.

New or changed content is marked with revision bars.

# Accessibility

Accessibility features help users with a physical disability, such as restricted mobility or limited vision, to use software products successfully.

With this product, you can use assistive technologies to hear and navigate the interface. You can also use the keyboard instead of the mouse to operate all features of the graphical user interface.

For detailed information, see the appendix about accessibility in the IBM Workload Scheduler User's Guide and Reference.

# Technical training

Cloud & Smarter Infrastructure provides technical training.

For Cloud & Smarter Infrastructure technical training information, see: http://www.ibm.com/software/tivoli/education

# Support information

IBM provides several ways for you to obtain support when you encounter a problem.

If you have a problem with your IBM software, you want to resolve it quickly. IBM provides the following ways for you to obtain the support you need:

- Searching knowledge bases: You can search across a large collection of known problems and workarounds, Technotes, and other information.  
- Obtaining fixes: You can locate the latest fixes that are already available for your product.  
- Contacting IBM Software Support: If you still cannot solve your problem, and you need to work with someone from IBM, you can use a variety of ways to contact IBM Software Support.

For more information about these three ways of resolving problems, see the appendix about support information in IBM Workload Scheduler: Troubleshooting Guide.

# Chapter 1. Customizing and configuring IBM Workload Scheduler

After installing the product you can customize it to fit your operational requirements. You can also change the customized values at any time. This chapter describes the optional customization steps for IBM Workload Scheduler. It is divided into the following sections:

- Setting global options on page 13  
- Setting local options on page 48  
- Setting user options on page 70  
- Configuring the dynamic workload broker server on the master domain manager and dynamic domain manager on page 102  
- Configuring the agent on page 71  
- Configuring command-line client access authentication on page 123  
- IBM Workload Scheduler console messages and prompts on page 132

For more information, see the sections about automating production plan processing and managing the production cycle in User's Guide and Reference.

# Setting global options

Manages the IBM Workload Scheduler global options. You can list, show and change them.

# Authorization

You must have the following security permissions for the global options file in the IBM Workload Scheduler security file to work with this command:

- For optman ls or optman show:

```txt
FILE NAME=GLOBALOPTS ACCESS=DISPLAY
```

For optmanchg:

```txt
FILE NAME=GLOBALOPTS ACCESS=MODIFY
```

See Configuring user authorization (Security file) on page 178 for more information on the security file.

# Syntax

optman [-u | -v]

optman [connectionParams] chg {option | shortName} = value

optman [connectionParams] Is

optman [connectionParams] show {option | shortName}

# Arguments

# connectionParams

If you are using optman from the master domain manager, the connection parameters were configured at installation and do not need to be supplied, unless you do not want to use the default values.

If you are using optman from the command line client on another workstation, the connection parameters might be supplied by one or more of these methods:

- Stored in the locallypts file  
- Stored in the useropts file  
- Supplied to the command in a parameter file  
- Supplied to the command as part of the command string

For full details of the connection parameters see Configuring command-line client access authentication on page 123.

# chg {option | shortName} = value

Change the value of an option to the new value supplied. The option can either be identified by its full or its short name. See Global options - summary on page 15 for a table showing all of the options with their full and short names, value ranges and default values. See Global options - detailed description on page 27 for a full description of each option.

# Is

Lists the current values of all global options.

# show{option|shortName}

Displays the current value of the indicated option. The option can either be identified by its full or its short name. See Global options - summary on page 15 for a table showing all of the options with their full and short names, value ranges and default values. See Global options - detailed description on page 27 for a full description of each option.

# Comments

Some of the changes are effective immediately, but others require a specific action, such as running JnextPlan, restarting the WebSphere Application Server Liberty. These actions are indicated in the option descriptions. See User's Guide and Reference for more information on the JnextPlan command.

Users can decide to maintain an audit trail recording any changes they perform and the related justifications. To enable the justification option, set up in a system shell the IBM Workload Scheduler environment variables listed below before running any optman commands:

# IWS DESCRIPTION

Specify the description to be recorded for each change performed by commands in the shell. The maximum length for this value is 512 characters. A warning message displays if you exceed the maximum and excess characters are truncated.

# IWS_CATEGORY

Specify the category to be recorded for each change performed by commands in the shell. The maximum length for this value is 128 characters. A warning message displays if you exceed the maximum and excess characters are truncated.

# IWS_TICKET

Specify the ticket to be recorded for each change performed by commands in the shell. The maximum length for this value is 128 characters. A warning message displays if you exceed the maximum and excess characters are truncated.

For more information about the justification option, see the section about keeping track of changes in Dynamic Workload Console User's Guide.

# Example

# Examples

# Example 1: list the global options

To list all of the global options, when your connection parameters are supplied via the localoptions and useropts files, give the following command:

```txt
optman ls
```

# Example 2: show the value of a global option

To show the current value of the enCarryForward global option, identifying it by its short name, give the following command:

```txt
optman show cf
```

# Example 3: change the value of a global option

To change the current value of the enCarryForward global option, identifying it by its full name, give the following command:

```txt
optman chg enCarryForward no
```

# Global options - summary

This section summarizes the global options that are managed by optman. The columns in the tables have the following meanings:

# Description

The brief description of the option

# Name

The option as used in the optman commands.

# Short name

The shortName as used in the optman commands.

# Default

The default value that is applied to the option at installation (if present).

# Range

The range or choice of values you can supply (where appropriate).

# Units

The units that apply to the default and range.

# Effect

How to make any changes effective. The following codes have been used:

# E

If you are enabling the option, start the Event Processor. If you are disabling the option, stop the Event Processor.

# Imm

The change is effective immediately

# Imm (DB)

The change is effective immediately in the database only.

# J

Run JnextPlan.

# J (Plan)

Run JnextPlan - it makes the change effective in the plan only.

# NSJ

The change is effective on the next submit job stream action.

# NSM

The change is effective on the next send mail action.

# NOC

The change is effective on the next change performed on a security object.

# W

Restart WebSphere Application Server Liberty.

The following tables summarize the global options for managing the features and functions of IBM Workload Scheduler:

Table 1. Workload service assurance feature  

<table><tr><td>Description</td><td>Name</td><td>Sh or n ame</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Enable workload service assurance</td><td>enWorkloadServiceAssurance</td><td>wa</td><td>yes</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>Approaching late offset</td><td>approachingLateOffset</td><td>al</td><td>120</td><td>&gt;=0</td><td>seconds</td><td>J or W</td></tr><tr><td>Deadline offset</td><td>deadlineOffset</td><td>do</td><td>2</td><td>&gt;=0</td><td>minutes</td><td>J or W</td></tr><tr><td>Promotion offset</td><td>promotionOffset</td><td>po</td><td>120</td><td>&gt;=0</td><td>seconds</td><td>J</td></tr><tr><td>Enable forecast start time calculation</td><td>enForecastStartTime</td><td>st</td><td>no</td><td>yes, no</td><td>boolean</td><td>imm</td></tr></table>

Table 2. Condition-based workflow automation  

<table><tr><td>Description</td><td>Name</td><td>Short name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Name of the job which is automatically added to the plan to run the file monitoring task.</td><td>fileStartConditionJobName</td><td>fc</td><td>file_StartCond</td><td>40 bytes</td><td></td><td>Imm</td></tr><tr><td>Name of the job which is automatically added to the plan to resubmit a new instance of the job stream where the start condition is defined.</td><td>resubmitJobName</td><td>rj</td><td>restart_SstartCond</td><td>40 bytes</td><td></td><td>Imm</td></tr><tr><td>Default offset set for the start condition deadline.</td><td>startConditionDeadlineOffset</td><td>cd</td><td>2400</td><td>0001 - 9959</td><td>hhmm</td><td>Imm</td></tr><tr><td>Prevent job streams from completing in error when the start condition is not met</td><td>enStartCondSuccOnDeadline</td><td>od</td><td>Freshinstallationyes</td><td>yes - no</td><td>boolean</td><td>J</td></tr></table>

Table 2. Condition-based workflow automation (continued)  

<table><tr><td>Description</td><td>Name</td><td>Short name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td></td><td></td><td></td><td>Upgrade</td><td>no</td><td></td><td></td></tr></table>

Table 3. Event-driven workload automation feature - general  

<table><tr><td>Description</td><td>Name</td><td>Shornt name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Enable event driven workload automation</td><td>enEventDrivenWorkloadAutomation</td><td>ed</td><td>yes</td><td>yes, no</td><td>boolean</td><td>J or E</td></tr><tr><td>Rules deployment frequency</td><td>deploymentFrequency</td><td>df</td><td>5</td><td>0-60</td><td>minutes</td><td>Imm</td></tr><tr><td>Enable event processor HTTPS protocol</td><td>enEventProcessorHttpsProtocol</td><td>eh</td><td>yes</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>IBM event integration facility port for SSL</td><td>eventProcessorEIFSsslPort</td><td>ef</td><td>31131</td><td>0 - 65535</td><td>port number</td><td>W and J</td></tr><tr><td>IBM event integration facility port</td><td>eventProcessorEIFPort</td><td>ee</td><td>31131</td><td>0 - 65535</td><td>port number</td><td>W and J</td></tr><tr><td>EIF Probe server name (used both for events in TEC and TBSM formats)</td><td>TECServerName</td><td>th</td><td>localhost</td><td></td><td>name</td><td>J</td></tr><tr><td>EIF Probe server port (used both for events in TEC and TBSM formats)</td><td>TECServerPort</td><td>tp</td><td>5529</td><td>0 65535</td><td>port number</td><td>J</td></tr></table>

Table 4. Event-driven workload automation feature - event mailing  

<table><tr><td>Description</td><td>Name</td><td>Shornt name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Mail sender name</td><td>mailSenderName</td><td>ms</td><td>TWS</td><td></td><td>name</td><td>NSM</td></tr><tr><td>SMTP server name</td><td>smtpServerName</td><td>sn</td><td>localhost</td><td></td><td>name</td><td>Imm</td></tr></table>

Table 4. Event-driven workload automation feature - event mailing (continued)  

<table><tr><td>Description</td><td>Name</td><td>Short name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>SMTP Server port</td><td>smtpServerPort</td><td>sp</td><td>25</td><td>065535</td><td>port number</td><td>NSM</td></tr><tr><td>Mail plug-in uses SMTP authentication</td><td>smtpUseAuthentication</td><td>ua</td><td>no</td><td>yes, no</td><td>boolean</td><td>Imm</td></tr><tr><td>SMTP user name</td><td>smtpUserName</td><td>un</td><td></td><td></td><td>name</td><td>Imm</td></tr><tr><td>SMTP user password</td><td>smtpUserPassword</td><td>up</td><td></td><td></td><td></td><td>Imm</td></tr><tr><td>Mail plug-in uses SSL</td><td>smtpUseSSL</td><td>us</td><td>no</td><td>yes, no</td><td>boolean</td><td>Imm</td></tr><tr><td>Mail plug-in uses TLS protocol</td><td>smtpUseTLS</td><td>tl</td><td>no</td><td>yes, no</td><td>boolean</td><td>Imm</td></tr></table>

Table 5. Event-driven workload automation feature - IBM Z Workload Scheduler plug-in  

<table><tr><td>Description</td><td>Name</td><td>Short name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>IBM Z Workload Scheduler connector remote server name</td><td>zOSRemoteServerName</td><td>zt</td><td></td><td></td><td>name</td><td>NSJ</td></tr><tr><td>IBM Z Workload Scheduler connector server name</td><td>zOSServerName</td><td>zs</td><td>localhost</td><td></td><td>name</td><td>NSJ</td></tr><tr><td>IBM Z Workload Scheduler connector server port</td><td>zOSServerPort</td><td>zp</td><td>31217</td><td>065535</td><td>port number</td><td>NSJ</td></tr><tr><td>IBM Z Workload Scheduler connector user name</td><td>zOSUserName</td><td>zu</td><td></td><td></td><td>name</td><td>NSJ</td></tr><tr><td>IBM Z Workload Scheduler connector user password</td><td>zOSUserPassword</td><td>zw</td><td></td><td></td><td></td><td>NSJ</td></tr></table>

Table 6. SSL  

<table><tr><td>Description</td><td>Name</td><td>Sh
ort n
ame</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Enable strong password encryption</td><td>enStrEncrypt</td><td>se</td><td>no</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>Enable the SSL full connection</td><td>enSSLFullConnection</td><td>sf</td><td>no</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>Defines the encryption algorithm used by IBM® Workload Scheduler</td><td>useAESEncryptionAlgorithm</td><td>ea</td><td>N/A</td><td>yes, no</td><td>boolean</td><td>N/A</td></tr></table>

Table 7. Job management  

<table><tr><td>Description</td><td>Name</td><td>Short name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Maximum prompts after abound</td><td>baseRecPrompt</td><td>bp</td><td>1000</td><td>0 65535</td><td>prompts</td><td>J</td></tr><tr><td>Additional prompts after abound</td><td>extRecPrompt</td><td>xp</td><td>1000</td><td>0 65535</td><td>prompts</td><td>J</td></tr><tr><td>Concurrent access to resources</td><td>enExpandedResources</td><td>er</td><td>yes</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>Automatically grant logon as batch</td><td>enLogonBatch</td><td>lb</td><td>no</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>Long duration job threshold</td><td>longDurationThreshold</td><td>Id</td><td>150</td><td>100 - 1000</td><td>seconds</td><td>J or W</td></tr><tr><td>User for binding to remote jobs from shadow job</td><td>bindUser</td><td>bu</td><td></td><td></td><td></td><td>Imm</td></tr></table>

Table 8. Job stream management  

<table><tr><td>Description</td><td>Name</td><td>Short name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Job streams without jobs policy</td><td>enEmptySchedulesAreSucc</td><td>es</td><td>no</td><td>yes, no</td><td>boolean</td><td>J</td></tr></table>

Table 8. Job stream management (continued)  

<table><tr><td>Description</td><td>Name</td><td>Sh
ort n
ame</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Prevent job stream without &quot;at&quot; dependency from starting</td><td>enPreventStart</td><td>ps</td><td>yes</td><td>yes, no</td><td>boolean</td><td>J</td></tr></table>

Table 9. Stageman  

<table><tr><td>Description</td><td>Name</td><td>Sho-rt n ame</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Carry job states</td><td>carryStates</td><td>cs</td><td>null</td><td></td><td>list of states</td><td>J</td></tr><tr><td>Enable carry forward</td><td>enCarryForward</td><td>cf</td><td>all</td><td>all, no</td><td>boolean</td><td>J</td></tr><tr><td>Enable carry forward for internetwork dependencies</td><td>enCFinterNetworkDeps</td><td>ci</td><td>yes</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>Enable carry forward resource quantity</td><td>enCFResourceQuantity</td><td>rq</td><td>yes</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>Retain rerun job name</td><td>enRetainNameOnRerunFrom</td><td>rr</td><td>no</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>Remove obsolete job streams</td><td>untilDays</td><td>ud</td><td>0</td><td>&gt;=0</td><td>days</td><td>J</td></tr></table>

Table 10. Planman  

<table><tr><td>Description</td><td>Name</td><td>Sho rtn ame</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Maximum preproduction plan length</td><td>maxLen</td><td>x1</td><td>8</td><td>8 - 365</td><td>days</td><td>J</td></tr><tr><td>Minimum preproduction plan length</td><td>minLen</td><td>ml</td><td>8</td><td>7 - 365</td><td>days</td><td>J</td></tr></table>

Table 11. Logging and auditing  

<table><tr><td>Description</td><td>Name</td><td>Sh or n ame</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Log cleanup frequency</td><td>logCleanupFrequency</td><td>Ic</td><td>5</td><td>0 - 60</td><td>minutes</td><td>J</td></tr><tr><td>Log history period</td><td>logHistory</td><td>Ih</td><td>10</td><td>&gt;=0</td><td>days</td><td>J</td></tr><tr><td>Logman minimum and maximum run time policy</td><td>logmanMinMaxPolicy</td><td>Im</td><td>both</td><td></td><td>literal</td><td>J</td></tr><tr><td>Logman normal run time calculation policy</td><td>logmanSmoothPolicy</td><td>It</td><td>-1</td><td>-1 - 100</td><td>factor</td><td>J</td></tr><tr><td>Enable database auditing</td><td>enDbAudit</td><td>da</td><td>0</td><td>0, 1</td><td>boolean</td><td>Imm</td></tr><tr><td>Type of store to be used to log database audit records</td><td>auditStore</td><td>as</td><td>both</td><td>db, file, both</td><td></td><td>Imm</td></tr><tr><td>Audit history period</td><td>auditHistory</td><td>ah</td><td>180</td><td>&gt;=1</td><td>days</td><td>Imm</td></tr><tr><td>Enable auditing of database GET operations</td><td>enDbGetOpsAudit</td><td>dg</td><td>1</td><td>0, 1</td><td>boolean</td><td>Imm</td></tr></table>

Table 12. Cross dependencies  

<table><tr><td>Description</td><td>Name</td><td>Sho-rt n-ame</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Number of days for retrying to send notifications about job status changes to the remote engine if the notification fails</td><td>notificationTimeout</td><td>nt</td><td>5</td><td>1-90</td><td>Number</td><td>Imm</td></tr></table>

Table 13. ServiceNow  

<table><tr><td>Description</td><td>Name</td><td>Short name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Address of the ServiceNow server</td><td>servicenowUrl</td><td>nu</td><td></td><td></td><td>name</td><td>Imm</td></tr><tr><td>User who connects to the ServiceNow server</td><td>servicenowUserName</td><td>nn</td><td></td><td></td><td>name</td><td>Imm</td></tr><tr><td>Password associated with the user who connects to the ServiceNow server</td><td>servicenowUserPassword</td><td>np</td><td></td><td></td><td>name</td><td>Imm</td></tr></table>

Table 14. Automatic failover  

<table><tr><td>Description</td><td>Name</td><td>Short name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Enables or disables the automatic failover feature which invokes an automatic switch from the master domain manager, event manager, or both, to a backup.</td><td>enAutomaticFailover</td><td>af</td><td>yes</td><td>yes, no</td><td>boolean</td><td>W</td></tr><tr><td>Enables or disables automatic failover actions, such as, the automatic switch of the master or automatic restart of the fault-tolerant agent. This option takes effect only if the enAutomaticFailover option is set to yes</td><td>enAutomaticFailoverActions</td><td>aa</td><td>yes</td><td>yes, no</td><td>boolean</td><td>W</td></tr><tr><td>A comma-separated list of workstation names, including the current event manager workstation, that serve as backups for the event manager workstation when the automatic failover feature is enabled. If an eligible workstation is defined in a folder, use the composer li ws @;showid command to retrieve the ID</td><td>workstationEventMgrListInAutomatic Failover</td><td>we</td><td></td><td>comma-separatedlist ofworkstationnames.The</td><td>name</td><td>W</td></tr></table>

Table 14. Automatic failover (continued)  

<table><tr><td>Description</td><td>Name</td><td>Short name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>of the workstation you plan to define as backup.</td><td></td><td></td><td></td><td>maxi mum length is 256 bytes.</td><td></td><td></td></tr><tr><td>A comma-separated list of workstations, including the current master domain manager, that serve as backups for the master domain manager when the automatic failover feature is enabled. If an eligible workstation is defined in a folder, use the composer li ws @;showid command to retrieve the ID of the workstation you plan to define as backup.</td><td>workstationMasterListInAutomaticFailover</td><td>wm</td><td></td><td>com ma-separate listed of workstation names. The maximum length is 256 bytes.</td><td>name</td><td>W</td></tr></table>

Table 15. Licensing configuration  

<table><tr><td>Description</td><td>Name</td><td>Short name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Type of accepted license for IBM Workload Scheduler</td><td>licenseType</td><td>In</td><td>ws</td><td>ws, wa, byworkstation</td><td></td><td>J</td></tr></table>

Table 15. Licensing configuration (continued)  

<table><tr><td>Description</td><td>Name</td><td>Shorth name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Specify the default license type for IBM Workload Scheduler workstations.</td><td>defaultWksLicenseType</td><td>wn</td><td>In aDockerenvonmentPeeJobinamfrreshiinnssstalalatctionandpeersseserever</td><td></td><td></td><td>J</td></tr></table>

Table 15. Licensing configuration (continued)  

<table><tr><td>Description</td><td>Name</td><td>Short name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td></td><td></td><td></td><td>u</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>p</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>g</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>r</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>a</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>de.</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>In an</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>on-</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>premi</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>ses</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>envir</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>onm</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>ent</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>p</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>e</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>r</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>s</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>e</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>r</td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td>ver</td><td></td><td></td><td></td></tr></table>

Table 16. General  

<table><tr><td>Description</td><td>Name</td><td>Short name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Company name</td><td>companyName</td><td>cn</td><td></td><td></td><td>name</td><td>J</td></tr><tr><td>Delete folders</td><td>folderDays</td><td>fd</td><td>10</td><td>0 - 10</td><td>days</td><td>J</td></tr><tr><td>Enable centralized security in the classic security model</td><td>enCentSec</td><td>ts</td><td>no</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>Evaluate start-of-day</td><td>enLegacyStartOfDayEvaluation</td><td>le</td><td>no</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>Enable list security check</td><td>enListSecChk</td><td>sc</td><td>no</td><td>yes, no</td><td>boolean</td><td>J (Plan) 
Imm 
(DB)</td></tr></table>

Table 16. General (continued)  

<table><tr><td>Description</td><td>Name</td><td>Sh orn name</td><td>Default</td><td>Range</td><td>Units</td><td>Effect</td></tr><tr><td>Enable plan auditing</td><td>enPlanAudit</td><td>pa</td><td>0</td><td>0,1</td><td>boolean</td><td>Imm</td></tr><tr><td>Enable security file creation in the role-based security model</td><td>enRoleBasedSecurityFileCreation</td><td>rs</td><td>no</td><td>yes,no</td><td>boolean</td><td>Imm</td></tr><tr><td>Enable extended field support in the security file.</td><td>enSecFileExtendedFields</td><td>sl</td><td>no</td><td>yes, no</td><td>boolean</td><td>NOC</td></tr><tr><td>Enable the fault-tolerant switch manager</td><td>enSwfaultTol</td><td>sw</td><td>no</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>Enable time zones</td><td>enTimeZone (deprecated)</td><td>tz</td><td>yes</td><td>yes, no</td><td>boolean</td><td>J (Plan) Imm (DB)</td></tr><tr><td>Enable What-if Analysis</td><td>enWhatIfAnalysis</td><td>wi</td><td>yes</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>Ignore calendars</td><td>ignoreCals</td><td>ic</td><td>no</td><td>yes, no</td><td>boolean</td><td>J</td></tr><tr><td>Start time of processing day</td><td>startOfDay</td><td>sd</td><td>0000</td><td>0000 2359</td><td>hhmm</td><td>J</td></tr><tr><td>Job statistics history period</td><td>statsHistory</td><td>sh</td><td>10</td><td>&gt;=0</td><td>days</td><td>J (Plan) Imm (DB)</td></tr><tr><td>Critical Jobs Risk Confidence</td><td>riskConfidence</td><td>rc</td><td>80% in fresh installation, 50% in upgrade</td><td>1-99</td><td>Number</td><td>Imm</td></tr></table>

# Global options - detailed description

This section gives full descriptions of the global options managed by optman:

# approachingLateOffset | al

Approaching late offset. Used in workload service assurance. The critical start time of a job in the critical network is the latest time that the job can start without causing the critical job to finish after the deadline. In most cases, a job will start well before the critical start time so that if the job runs longer than its estimated duration, the situation does not immediately become critical. Therefore, if a job has not started and the critical

start time is only a few minutes away, the timely completion of the critical job is considered to be potentially at risk.

The approachingLateOffset option allows you to determine the length of time before the critical start time of a job in the critical network at which you are to alerted to this potential risk. If a job has still not started the specified number of seconds before the critical start time, the job is added to a hot list that can be viewed on the Dynamic Workload Console.

![](images/587e069292323b357ba2743a4d4f888d88fd7726e78d2c2032eaa6d6dfc348f6.jpg)

Note: To qualify for addition to the hot list, all time and follow dependencies must have been resolved.

This option is only active if enWorkloadServiceAssurance is set to yes.

The default is 120 seconds.

![](images/67dc085570f346abd65ade400e7f2cb59e091fb7ce79d37636a2012d29b1c69c.jpg)

Note: Whatever value you set for this option, if IBM Workload Scheduler loses the connection with its database, the default value is applied to critical job processing, and the warning message AWSJCO135W is issued to tell you what has happened.

Run JnextPlan or restart WebSphere Application Server Liberty (stopappserver and startappserver) to make this change effective.

# auditHistory | ah

Audit history period. Used in audit management. This setting applies only when the auditStore option is set to db. Enter the number of days for which you want to save audit record data. Audit records are discarded on a FIFO (first-in first-out) basis.

The default value is 400 days. This option takes effect immediately.

For more information about auditing, see Auditing facilities on page 363.

# auditStore | as

Type of store to be used to log database and plan audit records. Enter one of the following:

file

To specify that a flat file in the <install_dir>/TWSDATA/audit/database directory on the master domain manager and backup master domain manager is used to store the audit records.

db

To specify that the IBM Workload Scheduler database itself is used to store the audit records.

both

To have audit records logged in both the file and the database.

The default value is both. Any change of this value is effective immediately.

![](images/fa7a2434ed43dc04d9c597bdbdb6fe6165a23b8b16fe1f100df13b6d035a3995.jpg)

Note: When you upgrade the master domain manager from a previous release, the default value for this global option is changed. The default value is now both. The reason for this change is to support the auditing feature which introduces reporting, versioning and rollback functions for database objects. If you customized the default value in the previous release, the value is overwritten with the new value with the exception of the auditStore option with the DB value assigned. If the auditStore option was set to DB, this value is maintained and is not overwritten.

For more information about auditing, see Auditing facilities on page 363.

# baseRecPrompt | bp

Maximum prompts after abend. Specify the maximum number of prompts that can be displayed to the operator after a job abends.

The default value is 1000. Run JnextPlan to make this change effective.

# bindUser | bu

User for binding to remote jobs from shadow job. Specify the user ID that is used to bind a shadow job to a remote job during the security check for "cross dependencies". This user must be given at least the following authorizations in the security file:

- Display access to the job and schedule objects that need to be bound  
- List access to job objects that need to be bound

However, the ID does not need to be in the user registry of the engine, nor have a password, as it is only required for authorization purposes.

The default value is the<TWS_user>. Any change of this value is effective immediately.

# carryStates | cs

**Carry job states.** A preproduction option that affects the operation of the stageman command. Specify the jobs, by state, to be included in job streams that are carried forward. Enclose the job states in parentheses, double quotation marks, or single quotation marks. Commas can be replaced by spaces. The valid internal job states are as follows:

Table 17. Valid internal job states  

<table><tr><td>abend</td><td>abenp</td><td>add</td><td>bound</td><td>done</td><td>error</td><td>exec</td></tr><tr><td>fail</td><td>hold</td><td>intro</td><td>pend</td><td>ready</td><td>rjob</td><td>sched</td></tr><tr><td>skel</td><td>succ</td><td>succp</td><td>suppr</td><td>susp</td><td>wait</td><td>waitd</td></tr></table>

Some examples of the option are as follows:

```txt
carryStates="abend, exec, hold, intro"  
carryStates='abend, exec, hold, intro'  
carryStates="abend, exec, hold, intro"  
carryStates='abend, exec, hold, intro'
```

An empty list is entered as follows:

carryStates  $\equiv$  null

The default value is null, which corresponds to selecting all states. Run JnextPlan to make this change effective.

# companyName|cn

Company name. Specify the name of your company. The maximum length is 40 bytes. If the name contains spaces, enclose the name in double quotation marks ("). If you use the Japanese-Katakana language set, enclose the name within single or double quotation marks.

Run JnextPlan to make this change effective.

# deadlineOffset | do

Deadline offset. Used in workload service assurance. Used to calculate the critical start of a critical job in the case where a deadline has not been specified neither for the job nor its job stream. In this case the deadline is defaulted to the plan end date and time, plus this offset, expressed in minutes.

This option is only active if enWorkloadServiceAssurance is set to yes.

The default is 2 minutes.

![](images/dabfc140032e4e36013e0a5db1900adfa40faf5447a3dc3105705b6a0226ef16.jpg)

# Note:

1. Important: When the plan is extended, the start time of critical jobs with a deadline calculated with this mechanism is automatically changed as a consequence of the fact that it must now match the new plan finishing time.  
2. Whatever value you set for this option, if IBM Workload Scheduler loses the connection with its database, the default value is applied to critical job processing, and the warning message AWSJCO135W is issued to tell you what has happened.

Run JnextPlan or restart WebSphere Application Server Liberty (stopappserver and startappserver) to make this change effective.

# defaultWksLicenseType / wn

Specify the default licensing model for IBM Workload Scheduler workstations. This option is supported only if thelicenseType option is set to byWorkstation and a specific value was not specified at creation time for each workstation. For more information, see licenseType | In on page 40. Supported values are as follows:

# perServer

to specify the IBM Workload Scheduler Processor Value Unit (PVU) pricing.

# perJob

to specify the IBM Workload Scheduler Per Job (PJ) pricing.

The default value varies, depending on the environment type:

# In a Docker environment

By default, the defaultWksLicenseType option is set to perJob in a fresh installation and to perServer during product upgrade. By default, the licenseType option is set to byWorkstation in a fresh installation. This setting is not modified during product upgrade. As a result, the value of the defaultWksLicenseType option is applied to the creation of all workstation types.

# In an on-premises environment

By default, thelicenseType option is set to perServer, and also defaultWksLicenseType option is set to perServer. Before changing this value, contact your sales representative.

# deploymentFrequency | df

Rules deployment frequency. Used in event rule management. Specify the frequency, in minutes, with which rules are to be checked to detect if there are changes to deploy. All active rules (active rules have the isDraft property set to no in their definition) that have been changed or added since the last deployment are deployed.

Valid values are in the 0-60 minutes range. If you specify 0, the changes are not deployed automatically and you must use the planman deploy command.

The default value is 5 minutes. The change is effective immediately.

# enAddUser | au

Enable the automatic user addition into the Symphony file. This option enables the automatic addition of a user into the Symphony file after you create or modify the user in the database. If you specify "yes", the user is automatically added to the Plan. If you specify "no", the user is not automatically added to the Plan.

The default value is "yes". Changes to this parameter are effective immediately.

For more information about how to use this feature, see "IBM Workload Scheduler: User's Guide and Reference".

# enAddWorkstation | aw

Enable the automatic dynamic agent, pool, and dynamic pool workstation addition into the Symphony file.

This option enables the automatic addition of a dynamic agent, pool, or dynamic pool workstation into the Symphony file after you created the workstation in the database. If you specify "yes", the workstation is automatically added to the Plan. If you specify "no", the workstation is not automatically added to the Plan.

The default is "no". Changes to this parameter are effective immediately.

For more information about how to use this feature, see IBM Workload Scheduler: User's Guide and Reference.

# enAutomaticFailover | af

Enable or disable the automatic failover feature. This option enables or disables the automatic failover feature which invokes an automatic switch from the master domain manager, event manager, or

both, to a backup workstation. Eligible backups for both the master domain manager and the event manager can be specified using the optman options, workstationMasterListInAutomaticFailover and workstationEventMgrListInAutomaticFailover, respectively. For more information about this feature, see Automatic failover on page 390.

A fresh installation of IBM® Workload Scheduler V9.5FP2 or later enables this feature by default (yes). This feature is disabled (no) when you upgrade to IBM® Workload Scheduler V9.5FP2 or later. Changes to this parameter require restarting WebSphere Application Server Liberty.

# enAutomaticFailoverActions | aa

Enable or disable the automatic failover actions. This option enables or disables automatic failover actions, such as, the automatic switch of the master or the automatic restart of the fault-tolerant agent. This option takes effect only if the enAutomaticFailover option is set to yes. You can set this option to no in the case of a planned maintenance window.

By default, this option is set to yes. Changes to this parameter require restarting WebSphere Application Server Liberty.

# enCarryForward | cf

Enable carry forward. A preproduction option that affects the operation of the stageman command. Specify if job streams that did not complete are carried forward from the old to the new production plan (Symphony). Enter yes to have incomplete job streams carried forward only if the Carry Forward option is enabled in the Job Scheduler definition. Enter all to have all incomplete job streams carried forward, regardless of the Carry Forward option. Enter no to completely disable the Carry Forward function. If you run the JnextPlan -for 0000 command and the Carry Forward option is set to either yes or no, a message is displayed informing you that incompletel job streams might not be carried forward. When the stageman -carryforward command is used, it overrides enCarryForward. See IBM Workload Scheduler: User's Guide and Reference for more information. If this option is set to no, running jobs are moved to the USERJOBS job stream.

The default value is all. Run JnextPlan to make this change effective.

# enCentSec | ts

Enable centralized security. In the classic security model, determine, how the security file is used within the network. Centralized security is not relevant to an end-to-end scheduling environment.

If set to yes, the security files of all the workstations of the network can be created and modified only on the master domain manager. In this case, the IBM Workload Scheduler administrator is responsible for their production, maintenance, and distribution.

If set to no, the security file of each workstation can be managed by the root user or administrator of the system. The local user can run the makesec command to create or update the file.

See Centralized security management on page 210 for more information about centralized security.

The default value is no. Run JnextPlan to make this change effective.

![](images/ff8ead93765671d3c40c1f15a08622fa6be0210f3104b9c81b1d6767ac74e46f.jpg)

Note: This option does not apply to role-based security model.

# enCFinterNetworkDeps | ci

Enable carry forward for internetwork dependencies. A preproduction option that affects the way stageman handles internetwork dependencies. It specifies if external job streams are carried forward from the old to the new production plan (Symphony file). Enter yes to have all external job streams carried forward. Enter no to have no external job streams carried forward.

The default value is yes. Run JnextPlan to make this change effective.

# enCFResourceQuantity | rq

Enable carry forward resource quantity. A preproduction option that affects the way stageman handles resources. Enter yes to carry forward the resource quantity from the old production file to the new. Enter no to not carry forward the resource quantity. Stageman carries forward resource quantities only if the resource is needed by a job or job stream that is also being carried forward. Otherwise the resource quantities are set to the original value. See IBM Workload Scheduler: User's Guide and Reference for details on using this feature.

The default value is yes. Run JnextPlan to make this change effective.

# enDbAudit | da

Enable auditing on information available in the database. Enable or disable auditing on information available in the database. To enable auditing on information available in the database, specify 1. To disable auditing on information available in the database, specify 0. Auditing information is logged to a flat file in the TWA_home/TWS/audit/database directory, to the IBM Workload Scheduler database itself, or to both. To choose which, set the optman property auditStore. Each IBM Workload Scheduler workstation maintains its own log. Only actions are logged, not the success or failure of the action. Installation of dynamic domain managers and agents is not recorded in audit logs.

The default value is 1. Changes to this parameter are effective immediately.

![](images/933f703b49369f1c8c67773773f57e8e9dbf0eb72024ab50baf3ba51961ca035.jpg)

Note: When you upgrade the master domain manager from a previous release, the default value for this global option is changed. The default value is now 1. The reason for this change is to support the auditing feature which introduces reporting, versioning and rollback functions for database objects. If you customized the default value in the previous release, the value is overwritten with the new value.

For more information about auditing, see Auditing facilities on page 363.

# enDbGetOpsAudit

Enable auditing of GET database operations. Enable or disable auditing on database GET operations. Disabling this auditing feature might improve performance. All other database operations are not affected. To disable auditing on database GET operations, specify 0. To enable auditing on database GET operations, specify 1. This parameter is effective only if general database audit is enabled. enDbAudit=1).

The default value is 1. Changes to this parameter are effective immediately.

# workstationEventMgrListInAutomaticFailover | we

A list of workstations eligible to serve as a backup for the event manager. A comma-separated list of

workstations that serve as backups for the event manager, including the current event manager itself, when the automatic failover feature is enabled. The maximum length is 256 bytes. If an eligible workstation is defined in a folder, use the composer li ws @;showid command to retrieve the ID of the workstation you plan to define as backup.

If no workstations are specified in this list, then all backup master domain managers in the domain are eligible backups. Changes to this parameter require restarting WebSphere Application Server Liberty.

# ```bash
workstationMasterListInAutomaticFailover | wc

A list of workstations eligible to serve as a backup for the master. A comma-separated list of workstations that serve as backups for the master domain manager, including the current master domain manager itself, when the automatic failover feature (enAutomaticFailover) is enabled. The maximum length is 256 bytes. If an eligible workstation is defined in a folder, use the composer li ws @;showid command to retrieve the ID of the workstation you plan to define as backup.

If no workstations are specified in this list, then all backup master domain managers in the domain are considered eligible backups. Changes to this parameter require restarting WebSphere Application Server Liberty.

# useAESEncryptionAlgorithm | ea

AES algorithm used for passwords Specify whether or not the AES encryption algorithm is used for encrypting passwords. The AES encryption algorithm is a widely adopted encryption algorithm used to secure digital data. It is fast, reliable, and considered one of the most secure symmetric encryption methods available today. It is compliant with FIPS. If set to yes, it indicates that user passwords are encrypted with the AES algorithm. If set to no, it indicates that a different encryption algorithm is used.

# enEmptySchedsAreSucc | es

Job streams without jobs policy. Specify the behavior of job streams without any jobs. If set to yes, the job streams that contain no jobs are set to SUCC after their dependencies are resolved. If set to no, the job streams are left in READY status.

The default value is no. Run JnextPlan to make this change effective.

# enEventDrivenWorkloadAutomation | ed

Enable event-driven workload automation. Enable or disable the event-driven workload automation feature. To enable, specify yes. To disable, specify no.

The default value is yes.

After disabling, you must run JnextPlan and stop the event processing server (with the conman stopevtp command).

After enabling, you must run JnextPlan and start the event processing server (with the conman startevtp command).

# enEventDrivenWorkloadAutomationProxy | pr

Enable event-driven workload automation proxy. Enable or disable the event-driven workload automation proxy feature. To enable, specify yes. To disable, specify no.

The default value is no. Run JnextPlan to make this change effective.

# enEventProcessorHttpsProtocol | eh

Enable event processor HTTPS protocol. Used in event rule management. Enables or disables the use of the HTTPS protocol to connect to the event processor server. To enable, enter yes. To disable, enter no.

The default value is yes. Run JnextPlan to make this change effective.

# enExpandedResources

Enables up to 60 concurrent holders for an IBM Workload Scheduler resource. Enter yes to enable up to 60 concurrent holders for a resource. Enter no to disable the feature and use only 32 holders for a resource.

The default value is yes. Run JnextPlan to make this change effective.

# enForecastStartTime | st

Enable forecast start time. Only applicable when workload service assurance is enabled (see

enWorkloadServiceAssurance). Enter yes to enable the calculation of the predicted start time of each job when running a forecast plan: this option is recommended if you want to take advantage of the enhanced forecast capability that calculates the start time of each job considering the estimated duration of its predecessor jobs. Enabling this feature could negatively impact the time taken to generate the forecast plan. Enter no to disable the calculation of the predicted start time of each job when running a forecast plan.

The default value is no. Any change of this value is effective immediately.

When this option is set to yes, the enPreventStart global option is ignored during the creation of forecast plans.

# enLegacyStartOfDayEvaluation | le

Evaluate start-of-day. Specify how the startOfDay option is to be managed across the IBM Workload Scheduler network. This is a legacy setting and should always be set to no starting from release 9.4.0 and later. If you set this option to yes, the startOfDay value on the master domain manager is converted to the local time zone set on each workstation across the network. If you set this option to no, the startOfDay value on the master domain manager is applied as is on each workstation across the network. This option requires that the enTimeZone option is set to yes to become operational.

The default value is no. Run JnextPlan to make this change effective.

# enListSecChk | sc

Enable list security check. Control the objects in the database and the plan that a user is permitted to list when running a query on the Dynamic Workload Console or IBM® Workload Scheduler database, for example running

a composer list, or a conman show command. If set to yes, objects in the plan returned from a query or show command are shown to the user only if the user has been granted the list permission in the security file. If set to no, all objects are shown, regardless of the settings in the security file.

![](images/4995934796b2c6d8397954efedf2adfc0b2c66b375aa3092bd0d311f6fa0bcae.jpg)

Note: Setting this option to yes affects how the graphical user interfaces function for the users defined in the security file.

The default value is no. Run JnextPlan to make this change effective for the plan. For the database, this option takes immediate effect.

# enLogonBatch | Ib

Automatically grant logon as batch. This is for Windows® jobs only. If set to yes, the logon users for

Windows® jobs are automatically granted the right to Logon as batch job. If set to no, or omitted, the right must be granted manually to each user or group. The right cannot be granted automatically for users running jobs on a backup domain manager, so you must grant those rights manually.

The default value is no. Run JnextPlan to make this change effective.

# enPlanAudit | pa

Enable plan auditing. Enable or disable auditing on information available in the plan. To enable auditing on information available in the plan, specify 1. To disable auditing on information available in the plan, specify 0. Auditing information is logged to a flat file, to the IBM Workload Scheduler database itself, or to both. To define the logging location, set the auditStore global option. For more information, see auditStore | as on page 28.

The audit file is located in the following path on the master domain manager and backup master domain manager:

TWA_home\TWS\audit\database

TWA_DATA_DIR/audit/database

For the plan, only actions are logged in the auditing file, not the success or failure of any action.

For more information about auditing, see Auditing facilities on page 363.

The default value is 1. Changes to this parameter are effective immediately.

![](images/ee99db1d15a00dea613a6b7eec6b437d3c85f1d42ce1f0bec34ad8df3e5c2202.jpg)

Note: When you upgrade the master domain manager from a previous release, the default value for this global option is changed. The default value is now 1. The reason for this change is to support the

![](images/e667e21e1d29c1e8a1867de6dcf1e317afaf821c057d18cba00bbb73b84d78f6.jpg)

auditing feature which introduces reporting, versioning and rollback functions for database objects. If you customized the default value in the previous release, the value is overwritten with the new value.

# enPreventStart | ps

Prevent job stream without "at" dependency from starting. Specify if job streams without an at dependency are to be prevented from starting immediately, without waiting for the beginning of the day the run cycle specified in the Job Scheduler identifies. Valid values are yes and no.

The default value is yes. Run JnextPlan to make this change effective.

When the enForecastStartTime option is set to yes, this option is ignored during the creation of forecast plans.

# enRetainNameOnRerunFrom | rr

Retain rerun job name. A production option that affects the operation of Batchman, the production control process of IBM Workload Scheduler. Its setting determines if jobs that are rerun with the Conman rerun command retain their original job names. To have rerun jobs retain their original job names, enter yes. Enter no to assign the rerun from name to rerun jobs.

The default value is no. Run JnextPlan to make this change effective.

![](images/28636638c437ed81b546233b689203b51c1b640efcb5d1b6538cf70345ee33d1.jpg)

Note: Starting from version 10.1, this option is deprecated and must not be modified. By default, its value is set to no.

# enRoleBasedSecurityFileCreation | rs

Enable the role-based security model. This option enables the automatic creation of the security file using the role-based security model. You define the role-based security model in the master domain manager database by using the Manage Workload Security interface from Dynamic Workload Console or the composer command-line program.

The default value is yes, which means that the role-based security model is enabled for your installation.

At any time, specify no if you want to disable the role-based security model and replace your current security file. You can then continue to use the classic security model, that allows you to update your security file by using dumpsec and makesec commands from the command line.

For more information about user authorization and classic and role-based security models, Configuring user authorization (Security file) on page 178.

Changes to this parameter are effective immediately.

# enSecFileExtendedFields

Enable extended fields support in the security file. Enable long attribute values for all scheduling objects in the security file. When this option is enabled, it permits the use of the extended version of the security file with the attribute field value length set to 64K rather than 255 bytes.

The default value is no. This change becomes effective the first time you edit a security object.

# enSSLFullConnection | sf

Enable the SSL full connection. Specify that IBM Workload Scheduler uses a higher level of SSL connection than the standard level. For full details see Configuring full SSL security on page 327. Valid values are yes to enable the SSL full connection or no to disable the SSL full connection.

The default value is no. Run JnextPlan to make this change effective.

# enStartCondSuccOnDeadline | od

Prevent job streams from completing in error when the start condition is not met Specify the behavior of the job stream when the start condition is not met and the Start once option is not selected. If you set the Start once option, this option is ignored. If you set the option to yes, when the deadline for the start condition is met, the monitoring job is confirmed in Successful status and the job stream is canceled. If you set the option to no, the monitoring job is killed, so both the monitoring job and the job stream change to Error status.

The default value is yes in a fresh installation and no in upgrade to maintain compatibility with previous versions. Run JnextPlan to make this change effective.

# enSwfaultTol | sw

Enable the fault-tolerant switch manager. Enable or disable the fault-tolerant switch manager feature. Valid values are yes to enable the fault tolerant switch manager, and no to disable it. This option has not dynamic capabilities and is not designed to work with broker agents. It applies to fault-tolerant agents. See the IBM Workload Scheduler: User's Guide and Reference for more details.

The default value is no. Run JnextPlan to make this change effective.

![](images/d22b5b3ca5361cf66989bfa71d43dce11ca2c4cb73ca8af4639cbc436428c411.jpg)

Note: Starting from version 10.1, this option is deprecated and must not be modified. By default, its value is set to no.

# enTimeZone|tz

Enable time zones. Enables the time zone option.

![](images/dbf7e10326baa6534159eca0b3e15f95a1fa45ca1db52c33a0216f37c4932b9f.jpg)

Note: Starting from version 10.1, this option is deprecated and must not be modified. By default, its value is set to yes.

# enWhatIfAnalysis | wi

Enable What-if Analysis. Enables or disables What-if Analysis, which is the feature that shows plan activities displayed against time and give you a visual representation of your plan at a glance in real time. To enable What-if Analysis, specify yes. To disable What-if Analysis, specify no. See Dynamic Workload Console User's Guide for details on using this feature..

The default value is yes. Run JnextPlan to make this change effective.

# enWorkloadServiceAssurance | wa

Enable workload service assurance. Enables or disables workload service assurance, which is the feature that manages the privileged processing of mission critical jobs and their predecessors. Specify yes to enable or no to disable.

![](images/90b2c49832455badde8fa75d6ac2b6728bdbd49936b091aafc0ccafb3e51e215.jpg)

Note: Before starting to use workload service assurance you must set up the<TWS_user> in the security file to have the appropriate access to the objects that this feature will modify - see The <TWS_user> - special security file considerations on page 251

The default value is yes. Run JnextPlan to make this change effective.

# eventProcessorEIFSsIPort | ef

Tivoli® event integration facility port. Used in event rule management. Specify the port number for SSL where the event processor server receives events from the Tivoli® Event Integration Facility (EIF). Valid values are in the 0-65535 range.

The default value is 31131. If you change the value, restart WebSphere Application Server Liberty (stopappserver and startappserver) and run JnextPlan to make this change effective.

# eventProcessorEIFPort | ee

Tivoli® event integration facility port. Used in event rule management. Specify the port number where the event processor server receives events from the Tivoli® Event Integration Facility (EIF). Valid values are in the 0-65535 range.

The default value is 31131. If you change the value, restart WebSphere Application Server Liberty (stopappserver and startappserver) and run JnextPlan to make this change effective.

If you use a security firewall, make sure this port is open for incoming and outgoing connections.

# extRecPrompt | xp

Additional prompts after abend. Specify an additional number of prompts for the value defined in baseRecPropmt. This applies when a job is rerun after abending and the limit specified in baseRecPropmt has been reached.

The default value is 1000. Run JnextPlan to make this change effective.

# fileStartConditionJobName | fc

Name of the job in charge of running the file monitoring task. Applicable only if you select file as the start condition type. Specify the name of the job which is automatically added to the plan to run the file monitoring task. This value is used by default if you do not specify any value for the job name when defining the start condition. If you specify a value for the job name, this value is ignored.

The default value is FILE_STARTCOND. The maximum supported length is 40 bytes. Changes to this parameter are effective immediately.

# folderDays | fd

Remove deleted folders, prompts, resources, and workstations from the database. When deleting a folder, a prompt, or resource, if there are still objects in the plan that reference these objects, then another folder, prompt, or resource cannot be renamed with the name of the deleted folder, prompt or resource for the number of days specified by "folderDays?. However, a brand new folder, prompt, or resource can be created with the name of the deleted object.

When deleting a workstation, if the workstation is still in the plan, then another workstation cannot be renamed with the name of the deleted workstation for the number of days specified by the global option folderDays. However, a brand new workstation can be created with the name of the deleted workstation. This behavior applies only to dynamic agents, pools, and dynamic pools.

The default value is 10 days.

# ignoreCals | ic

Ignore calendars. A preproduction option that affects the operation of the planman command. Its setting determines if user calendars are copied into the new production plan (Symphony) file. To prevent user calendars from being copied into the new production plan, enter yes.

The default value is no. See IBM Workload Scheduler: User's Guide and Reference. Run JnextPlan to make this change effective.

![](images/f128963682d36f804eeff35039aaed82a8e4964d3e38bf2401ae6d9f9151d3e3.jpg)

Note: Starting from version 10.1, this option is deprecated and must not be modified. By default, its value is set to yes.

# licenseType | In

Type of accepted license for IBM Workload Scheduler.

Supported values are:

WS

perServer

to specify the IBM Workload Scheduler Processor Value Unit (PVU) pricing.

wa

perJob

to specify the IBM Workload Scheduler Per Job (PJ) pricing.

# byWorkstation

to specify that the licensing type (either perServer or perJob) is specified at creation time for each workstation. When you specify this value, you can define the default type of license for each workstation by setting the defaultWksLicenseType option. For more information, see defaultWksLicenseType / wn on page 30. For more information about defining workstations, see the section about workstation definition in User's Guide and Reference.

The default value is perServer. Run JnextPlan to make this change effective. For additional information about license management and metrics, see License Management in IBM License Metric Tool on page 466.

You can define this option for the following workstation types:

- master domain manager  
- fault-tolerant agent  
standard agent  
dynamic agent

# logCleanupFrequency | lc

Log cleanup frequency. Used in event rule and audit management. Specify how often the automatic cleanup of log instances is run. Valid values are in the 0-60 minutes range. If you specify 0, the automatic cleanup feature is disabled.

The default value is 5 minutes. This option takes effect immediately.

# logHistory | Ih

Log history period. Used in event rule management. Enter the number of days for which you want to save rule instance, action run, and message log data. Log instances are discarded on a FIFO (first-in first-out) basis.

The default value is 10 days. This option takes effect immediately.

# logmanMinMaxPolicy | Im

Logman minimum and maximum run times policy. Specify how the minimum and maximum job run times are logged and reported by logman. Possible values are:

# elapsedtime

The minimum and maximum elapsed runtimes are logged and reported.

# cptime

The minimum and maximum CPU run times are logged and reported.

# both

Both the minimum and maximum job runtimes are logged and reported.

See IBM Workload Scheduler: User's Guide and Reference for details on using this feature.

The default value is both. Run JnextPlan to make this change effective.

# logmanSmoothPolicy | It

Logman normal run time calculation policy. Set the weighting factor that favors the most recent job run when calculating the normal (average) run time for a job. This is expressed as a percentage. For example, specify 40 to apply a weighting factor of  $40\%$  to the most recent job run, and  $60\%$  to the existing average. See the topic about customizing plan management using global options in IBM Workload Scheduler: User's Guide and Reference for more information about how to use this option.

The default value is -1. Run JnextPlan to make this change effective.

# longDurationThreshold | Id

Long duration job threshold. Specify, when comparing the actual duration of a job to the estimated duration, the threshold over which the job is considered to be of "long duration." The threshold value is expressed as a percentage with respect to the estimated duration. For example, if the threshold is set to 150, and the actual duration is more than  $150\%$  of the estimated duration (it is  $50\%$  greater), the job is considered to be a "long duration" job.

If you have the workload service assurance feature enabled, the effect of a "critical" job satisfying the long duration criteria is that the job is inserted automatically into the hot list.

Valid values are between:

100

The minimum value. All jobs that exceed the estimated duration are considered long duration jobs 1000

The maximum value. Only those jobs that last ten times as long as their estimated duration are considered as long duration jobs

The default is 150.

![](images/5023e4e91b165a3f66bac09044021e90eeedd525621f9272243edb1aa05c0430.jpg)

Note: Whatever value you set for this option, if you have the workload service assurance feature enabled, and IBM Workload Scheduler loses the connection with its database, the default value is applied to critical job processing, and the warning message AWSJC0135W is issued to tell you what has happened.

Run JnextPlan or restart WebSphere Application Server Liberty (stopappserver and startappserver) to make this change effective.

# mailSenderName | ms

Mail sender name. Used in event rule management. If you deploy rules implementing an action that sends emails via an SMTP server, specify a string to be used as the sender of the emails.

The default value is TWS. Changes to this parameter are effective for the next mail send action performed.

# maxLen | x1

Maximum preproduction plan length. Specify the maximum length of the preproduction plan in days after it is automatically extended or created. The value for maxLen must be greater than or equal to the value for minLen and must be in the range of 8 to 365.

The default is 14 days. Run JnextPlan to make this change effective.

# minLen | ml

Minimum preproduction plan length. Specify the minimum length in days of the preproduction plan that can pass after the production plan is created or extended, without extending the preproduction plan. If the days left in the preproduction plan after a JnextPlan are less than the value of this option, the preproduction plan is automatically extended. The value for minLen must be less than or equal to the value for maxLen and must be in the range of 7 to 365.

The default is 8 days. Run JnextPlan to make this change effective.

# notificationTimeout | nt

Notification timeout. Used in cross dependencies. Specify how many days IBM Workload Scheduler must retry sending notifications about job status changes to the remote engine if the notification fails. When this timeout expires, the job request subscription and the status notifications associated to this job are discarded.

Valid values are in the range of 1 to 90. The default is 5 days. Changes to this parameter are effective immediately.

# promotionOffset | po

Promotion offset. Used in workload service assurance. Specify when a job become eligible for promotion in terms of the number of seconds before its critical start time is reached. Applies only to jobs that are flagged as critical in a job stream definition and to their predecessor jobs. A critical job and its predecessors make up a critical network.

When a predecessor jeopardizes the timely completion of the critical job, it is promoted; that is, it is assigned additional resources and its submission is prioritized with respect to other jobs that are out of the critical network. Also critical jobs might be promoted.

The scheduler calculates the critical start time of a critical job by subtracting its estimated duration from its deadline. It calculates the critical start time of a critical predecessor by subtracting its estimated duration from the critical start time of its next successor. Within a critical network the scheduler calculates the critical start time of the critical job first and then works backwards along the chain of predecessors. These calculations are reiterated as many times as necessary until the critical job has run.

This option is only active if enWorkloadServiceAssurance is set to yes.

The default is 120 seconds.

Run JnextPlan to make this change effective.

# resubmitJobName | rj

Name of the job in charge of resubmitting the job stream. Specify the name of the Job Stream Submission job which is automatically added to the plan to resubmit a new instance of the job stream where the start condition is defined.

The default value is MASTERAGENTS#restart_StartCond, where MASTERAGENTS is the name of the pool workstation on which the Job Stream Submission job runs. The maximum length for the workstation name

is 16 bytes, and the maximum length for the job name is 40 bytes. Changes to this parameter are effective immediately.

# resubmitJobUserName | rw

Name of the user in charge of resubmitting the job stream. Specify the user name which owns the Job Stream Submission job. The Job Stream Submission job is automatically added to the plan to resubmit a new instance of the job stream where the start condition is defined.

The default value is TWS 用户。Changes to this parameter are effective immediately. If the user defined in the resubmitJobUserName property does not exist, the user name and password defined on WebSphere Application Server Liberty installed on the master domain manager or backup master domain manager are used. This implies that the user defined in the resubmitJobUserName property must be the same both on the master domain manager and on the backup master domain manager, or must be changed immediately after switching the master domain manager.

# riskConfidence | rc

Critical Jobs Risk Confidence Specifies when a critical job must be set as High Risk, comparing the confidence factor of completing before deadline and the percentage specified in this parameter. If the probability of completing before the deadline is below riskConfidence, then the critical job is considered at high risk. Valid values are in the range 1-99. The default value is  $80\%$  when you perform a fresh installation. If you upgrade a previous version to the current version, the default value is  $50\%$  for maintaining backward compatibility. This option is effective immediately.

# servicenowUrl | nu

ServiceNow URL. Used in event rule management. If you use rules that implement an action that opens an incident in ServiceNow (or any other application that can open an incident in the ServiceNow format), specify the ServiceNow URL. You can change this value when you define the action if you want to use a different ServiceNow URL.

The default value is "http://localhost:8080/api/now/v1/table/incident". Changes to this parameter are effective immediately.

# servicenowUserName|nn

ServiceNow user name. Used in event rule management. If you use rules that implement an action that opens an incident in ServiceNow, specify the identifier of the user connecting to the ServiceNow server.

The default value is the IBM Workload Scheduler user on the master domain manager. Changes to this parameter are effective immediately.

# servicenowUserPassword|np

ServiceNow user password. Used in event rule management. If you use rules that implement an action that opens an incident in ServiceNow, specify the password associated with the user connecting to the ServiceNow server.

Changes to this parameter are effective immediately.

# smtpServerName|sn

SMTP server name. Used in event rule management. If you deploy rules implementing an action that sends emails via an SMTP server, specify the name of the SMTP server to be used by the mail plug-in.

The default value is localhost. Changes to this parameter are effective immediately.

# smtpServerPort | sp

SMTP Server port. Used in event rule management. If you deploy rules implementing an action that sends emails via an SMTP server, specify the port number used to connect to the SMTP server by the mail plug-in. Valid values are in the range 0-65535.

The default value is 25. Changes to this parameter are effective for the next mail send action performed.

# smtpUseAuthentication | ua

Mail plug-in uses SMTP authentication. Used in event rule management. If you deploy rules implementing an action that sends emails via an SMTP server, specify if the SMTP connection needs to be authenticated. Values are yes or no.

The default is no. Changes to this parameter are effective immediately.

# smtpUserName|un

SMTP server user name. Used in event rule management. If you deploy rules implementing an action that sends emails via an SMTP server, specify the SMTP server user name.

The default value is the name of the IBM Workload Scheduler user (the <TWS_user>) on the master domain manager. Changes to this parameter are effective immediately.

# smtpUserPassword | up

SMTP server user password. Used in event rule management. If you deploy rules implementing an action that sends emails via an SMTP server, specify the SMTP server user password. The password is stored in an encrypted form.

Changes to this parameter are effective immediately.

# smtpUseSSL|us

Mail plug-in uses SSL. Used in event rule management. If you deploy rules implementing an action that sends emails via an SMTP server, specify if the SMTP connection is to be authenticated via SSL. Values are yes or no.

The default is no. Changes to this parameter are effective immediately.

# smtpUseTLS | tl

Mail plug-in uses TLS protocol. Used in event rule management. If you deploy rules implementing an action that sends emails via an SMTP server, specify if the SMTP connection is to be authenticated via the Transport Layer Security (TLS) protocol. Values are yes or no.

The default is no. Changes to this parameter are effective immediately.

# startOfDay | sd

Start time of processing day. Specify the start time of the IBM Workload Scheduler processing day in 24-hour format: hhmm (0000-2359).

The default value is 0000 (0:00 a.m.), but if you upgraded your environment to version 10.2.5 starting from a version earlier than version 8.6, the default value is 0600 (6:00 a.m.). If you change this option, you must also change the launch time of the final Job Scheduler, which is usually set to one minute before the start time. Run JnextPlan to make the change of startOfDay effective.

If you need to modify in a production environment the start of day and the FINAL job stream launch time, run the following command twice:

```txt
JnextPlan -to tomorrowTZ customerTimezone
```

For example, if yourtimezone is America/Chicago and on the 30th of August you want to modify the start of day from 0400 to 0700, perform the following steps:

1. Verify the current start of day using the optman Is command:

```txt
optman ls startOfDay / sd=0400
```

2. Modify the startOfDay global option using optman:

```txt
optman chg sd=0700
```

3. Validate all the job stream definitions to make sure they are compatible with the new startOfDay time running the composer command:

```txt
composer validate <extracted schedule definition>
```

4. Modify the launch time of the FINAL and FINALPOSTREPORTS job streams modifying the at keyword from 0359 to 0659.  
5. Run the command planman showinfo and look for the production plan end time, for example:

```txt
production plan end time: 06/22/2024 03:59 tz CST6CDT
```

6. Run the following command twice:

```txt
JnextPlan -to 06/22/2024 0700 tz America/Chicago
```

![](images/2889c8ef64088387dc6e9b1dfa92763326f39345282105e13ee415e98b738050.jpg)

Note: The -to value must be later than the production plan end time

7. Cancel the previous FINAL and FINALPOSTREPORTS job streams. This final step prevents the production plan from extending an additional 24 hours.

# statsHistory | sh

Job statistics history period. Specify the number of days for which you want to maintain job statistics. Statistics are discarded on a FIFO (first-in first-out) basis. For example, if you leave the default value of 400, statistics are maintained for the last 400 days. This has no effect on job standard list files, which must be

removed with the rmstdlist command. See the IBM Workload Scheduler: User's Guide and Reference for information about the rmstdlist command.

The default value is 400. Run JnextPlan to make this change effective in the plan. For the database, this option takes effect immediately.

# startConditionDeadlineOffset | cd

Start condition deadline offset. The default offset set for the start condition deadline in 24 hour format:

"hhmm" (0001-9959). Specify the time range during which the start condition is active.

The default value is 2400 and the range is 0001 - 9959. Changes to this parameter are effective immediately.

# untilDays | ud

Remove obsolete job and job stream instances from the plan. If an until time (latest start time) has not

been specified for a job or job stream, then the default until time is calculated adding the value of this option, expressed in number of days, to the scheduled time of the job or job stream. If the enCarryForward option is set to all, and the number of days specified for untilDays is reached, then any job or job stream instance in the plan that ended in error is automatically removed from the plan and not added to the new production plan.

The default value is 0. If the default value is used, then for jobs, no default time is set for the until time (latest start time). For job streams, if the default is used, then the default until time is 2 days.

Run JnextPlan to make this change effective.

# workstationLimit | wl

# The workstation limit.

Used in the automatic dynamic agent registration. This parameter specifies the dynamic agent workstation limit value that the dynamic agent workstation assumes after the workstation is added to the plan. You can later modify the dynamic agent workstation limit value by using the conman command line or the Dynamic Workload Console.

Valid values are in the 0-1024 range.

The default is 100. Changes to this parameter are effective immediately.

# zOSRemoteServerName | zr

IBM Z Workload Scheduler connector remote server name. Used in event rule management. If you deploy rules implementing an action that submits job streams to the IBM Z Workload Scheduler controller, enter the name of the controller specified as the engine to the Z connector. It must exactly match the Z connector engine name and is case sensitive.

After changing the value of this parameter, the change becomes effective when the next submit action is run.

# zOSServerName | zs

IBM Z Workload Scheduler connector server name. Used in event rule management. If you deploy rules implementing an action that submits job streams to the IBM Z Workload Scheduler controller, specify the

name or the hostname of the system where the IBM Z Workload Scheduler connector runs. The default value is localhost.

After changing the value of this parameter, the change becomes effective when the next submit action is run.

# zOSServerPort | zp

IBM Z Workload Scheduler connector server port. Used in event rule management. If you deploy rules implementing an action that submits job streams to the IBM Z Workload Scheduler controller, specify the bootstrap port number of the IBM Z Workload Scheduler connector server. Valid values are in the range 0-65535. The default value is 31217.

After changing the value of this parameter, the change becomes effective when the next submit action is run.

# zOSUserName|zu

IBM Z Workload Scheduler connector user name. Used in event rule management. If you deploy rules implementing an action that submits job streams to the IBM Z Workload Scheduler controller, specify the IBM Z Workload Scheduler connector user name required to access the IBM Z Workload Scheduler engine.

After changing the value of this parameter, the change becomes effective when the next submit action is run.

# zOSUserPassword | zw

IBM Z Workload Scheduler connector user password. Used in event rule management. If you deploy rules implementing an action that submits job streams to the IBM Z Workload Scheduler controller, specify the IBM Z Workload Scheduler connector user password required to access the IBM Z Workload Scheduler engine. The password is stored in encrypted form.

After changing the value of this parameter, the change becomes effective when the next submit action is run.

# Setting local options

Set local options, such as general attributes of the workstation for the IBM Workload Scheduler processes, in the locallypts file. Changes do not take effect until netman is stopped (conman shut;wait) and restarted (StartUp).

During the installation process, a working copy of the local options file is installed as TWA_DATA_DIR/localopts.

The localizepts file is not modified during the agent upgrade process. The file generated by the upgrade process is saved to the /config directory, to maintain your custom values, if any. You can then merge the two files with your customized values and save the resulting file in the TWA_DATA_DIR folder.

A template file containing default settings is located in TWA_DATA_DIR.

![](images/7d9260458fe169d6edb7a07908820c41bc651ef9771ee983d19944ef9ad47160.jpg)

Note: All of the SSL settings in the localopts file relate to the network communications and do not relate to the Dynamic Workload Console.

The options in the localizepts file are described in the following sections:

- Localopts summary on page 49  
- Localopts details on page 52  
- Local options file example on page 66

# Localopts summary

General attributes of the workstation:  
```ini
thiscpu = workstation  
merge stdlists = yes/no  
stdlib width = columns  
syslog local = facility  
restricted stdlists = yes/no
```

The attributes of the workstation for the batchman process:  
```txt
bm check file = seconds  
bm check status = seconds  
bm look = seconds  
bm read = seconds  
bm stats = on/off  
bm verbose = on/off  
bm check until = seconds  
bm check deadline = seconds  
bm late every = minutes
```

The attributes of the workstation for the jobman process:  
The attributes of the workstation for the mailman process:  
```txt
jm job table size = entries  
jm look = seconds  
jm nice = value  
jm promoted nice = UNIX® and Linux® critical job priority  
jm promoted priority = Windows® critical job priority  
jm no root = yes/no  
jm file no root = yes/no  
jm read = seconds  
jm loaduserprofile = on/off
```

```txt
mm response = seconds  
mm retrylink = seconds  
mm sound off = yes/no  
mm unlink = seconds  
mm cache mailbox = yes/no
```

mm cache size = bytes

mm resolve master = yes/no

```python
autostart monman = yes/no

The attributes of the workstation for the netman process:

nm mortal = yes/no

nm port = port number

nm read = seconds

nm retry = seconds

The attributes of the workstation for the writer process:

wr read = seconds

wr unlink = seconds

wr enable compression = yes/no

Optional attributes of the workstation for remote database files

mozart directory = mozart_share

parameters directory  $=$  parms_share

unison network directory = unison_share

The attributes of the workstation for the custom formats

date format  $=$  integer

composer prompt = key

conman prompt = key

switch sym prompt = key

The attributes of the workstation for the customization of I/O on mailbox files

sync level = low|medium|high

The attributes of the workstation for networking

tcp timeout = seconds

tcp connect timeout = seconds

The attributes of the workstation for SSL - General

ssl auth mode = caonly|string|cpu

ssl auth string = string

SSL FIPS compliance=yes/no

SSL config file  $\equiv$  SSL_configuration_file

nm ssl full port = value

nm ssl port = value

OpenSSL attributes of the workstation

SSL key = *:perm

SSL certificate = *.perm

SSL key pwd = *.sth

SSL CA certificate = *.crt

SSL random seed = *.rmd

SSL cert type  $=$  certificate_type

SSL ciphers = SSL_ciphers

SSL cipher suites = encryption_algorithms

SSL version  $=$  ssl_version

CLI SSL server auth = yes/no

CLI SSL ciphers = ssl_ciphers

CLI SSL cipher suites = encryption_algorithms

CLI SSL version=

CLI SSL server certificate = file_name

CLI SSL trusted dir = directory_name

# Encryption options

encrypt keystore file = keystore_file

encrypt keystore pwd = keystore_password

encrypt label = default

encrypt label list =

# The IBM Workload Scheduler instance is a command line client

is remote cli = yes/no

# Attributes for CLI connections

host = host_name

protocol  $=$  protocol

port = port number

proxy  $=$  proxy server

proxy port = proxy server port number

timeout = seconds

defaultws = master_workstation

useropts  $=$  useropts_file

![](images/ef2417134ed15d11e493e06f15bad0157e543e7ccc00c89a40c0cbc3d615521a.jpg)

# Note:

![](images/80ced64f543e1f300f59705b801ccec40d23458ed03fe9ee28d213da8724f127.jpg)

1. The SSL attributes for the command line client connection will depend on which SSL method is in use. They are included in the relevant section and all commence with "cli".  
2. The command lines for the dynamic domain manager and backup dynamic domain manager will work only if you configure the host and port attributes.

Event Management parameters

can be event processor  $=$  yes/no

Centralized Agent Update parameters

DownloadDir = directory_name

Current Folder

current folder = /foldername>

The attributes of the workstation for the Appserver Watchdog ( WebSphere Application Server Liberty)

Application server check attributes on the workstation

appserver check interval  $=$  minutes

appserver auto restart = on/off

appserver min restart time = minutes

appserver max restarts = number

appserver count reset interval  $=$  hours

![](images/280e15701ae8058e3c0a8d88f2b6fb84f22582a3eadfbe9083418cd33486871f.jpg)

Note: The localopts file syntax is not case-sensitive, and the spaces between words in the option names are ignored. For example, you can validly write is remote cli as:

- is remote cli  
Is Remote CLI  
- isremotecli  
- ISREMOTECLI  
- isRemoteCLI  
...IBM

# Localopts details

comment

Treats everything from the indicated character (#) to the end of the line as a comment.

appserver auto restart = yes|no

Requests the appservman process to automatically start WebSphere Application Server Liberty if it is found down. The default is Yes.

# appserver check interval  $=$  minutes

Specifies the frequency in minutes that the appservman process is to check that WebSphere Application Server Liberty is still running. The default is 3 minutes.

# appserver count reset interval  $=$  hours

- Specifies the time interval in hours after which the restart count is reset from the last WebSphere Application Server Liberty start. The default is 24 hours.

# appserver max restarts = number

Specifies the maximum number of restarting attempts the appservman process can make before giving up and exiting without restarting WebSphere Application Server Liberty. The counter is reset if WebSphere Application Server Liberty runs for longer than the appserver count reset interval value. The default is 5.

# appserver min restart time = minutes

Specifies in minutes the minimum elapsed time the appservman process must wait between each attempt to restart the WebSphere Application Server Liberty if it is down. If this value is less than the appserver check interval, the WebSphere Application Server Liberty is restarted as soon as it is found down. If it is found down before this time interval (min restart time) has elapsed, appservman exits without restarting it. The default is 2 minutes.

# ```python
autostart monman = yes|no

Used in event rule management. Restarts the monitoring engine automatically when the next production plan is activated (on Windows® also when IBM Workload Scheduler is restarted). The default is Yes.

# bm check deadline = seconds

Specify the minimum number of seconds Batchman waits before checking if a job has missed its deadline. The check is performed on all jobs and job streams included in the Symphony file, regardless of the workstation where the jobs and job streams are defined. Jobs and job streams with expired deadlines are marked as late in the local Symphony file. To obtain up-to-date information about the whole environment, define this option on the master domain manager. Deadlines for critical jobs are evaluated automatically, independently of the bm check deadline option. To disable the option and not check deadlines, enter a value of zero, the default value.

# bm check file = seconds

Specify the minimum number of seconds Batchman waits before checking for the existence of a file that is used as a dependency. The default is 120 seconds.

# bm check status = seconds

Specify the number of seconds Batchman waits between checking the status of an internetwork dependency. The default is 300 seconds.

# bm check until = seconds

Specify the maximum number of seconds Batchman waits before reporting the expiration of an Until time for job or Job Scheduler. Specifying a value below the default setting (300) might overload the system. If it is set below the value of Local Option bm read, the value of bm read is used in its place. The default is 300 seconds.

# bm late every = minutes

When an every job does not start at its expected start time, bm late every specifies the maximum number of minutes that elapse before IBM Workload Scheduler skips the job. This option applies only to jobs defined with every option together with the at time dependency, it has no impact on jobs that have only the every option.

# bm look = seconds

Specify the minimum number of seconds Batchman waits before scanning and updating its production control file. If you install the 9.4, FP1 version as a fresh installation, the default value is automatically set to 5 for improving product performance. The previous default value was 15 seconds and is maintained if you perform a product upgrade.

# bm read = seconds

Specify the maximum number of seconds Batchman waits for a message in the intercom.msg message file. If no messages are in queue, Batchman waits until the timeout expires or until a message is written to the file. If you install the 9.4, FP1 version as a fresh installation, the default value is automatically set to 3 for improving product performance. The previous default value was 10 seconds and is maintained if you perform a product upgrade.

# bm stats = on|off

To have Batchman send its startup and shut down statistics to its standard list file, specify on. To prevent Batchman statistics from being sent to its standard list file, specify off. The default is off.

# bm verbose = on|off

To have Batchman send all job status messages to its standard list file, specify on. To prevent the extended set of job status messages from being sent to the standard list file, specify off. The default is off.

# can be event processor  $=$  yes|no

Specify if this workstation can act as event processing server or not. It is set by default to yes for master domain managers and backup masters, otherwise it is set to no.

# CLI SSL ciphers = cipher_class

Specify the cipher class to be used when the command-line client and the server are using SSL authentication. The default is MD5.

If you want to use an OpenSSL cipher class, use the following command to determine the list of available classes:

openssl ciphers

For a full list of supported ciphers, see SSL Ciphers and OpenSSL.

# CLI SSL cipher suites suites

Specify one or more supported algorithms for TLS version 1.3, This option does not apply to TLS version 1.2 or earlier.

# CLI SSL server auth = yes|no

Specify yes if server authentication is to be used in SSL communications with the command line client. The default is no.

# CLI SSL server certificate = file_name

Specify the file, including its full directory path, that contains the SSL certificate when the command-line client and the server use SSL authentication in their communication. There is no default. See Configuring SSL attributes on page 325.

# CLI SSL trusted dir = directory_name

Specify the directory that contains an SSL trusted certificate contained in files with hash naming (#) when the command-line client and the server are using SSL authentication in their communication. When the directory path contains blanks, enclose it in double quotation marks ("). There is no default.

# CLI SSL version version

Specify the SSL version to be used. Supported values are:

- atleast.TLSv1.0  
- atleast.TLSv1.1  
atleast.TLSv1.2  
atleast.TLSv1.3

where you specify the minimum version of the TLS protocol to be used. In this case, IBM® Workload Scheduler uses the specified version of the protocol or a higher version, if supported.

max.TLSv1.0  
max.TLSv1.1  
max.TLSv1.2  
max.TLSv1.3

where you specify the maximum version of the TLS protocol to be used. In this case, IBM® Workload Scheduler uses the specified version of the protocol or a lower version.

TLSv1.0  
TLSv1.1  
TLSv1.2  
TLSv1.3

where you specify the exact version of the TLS protocol to be used. In this case, IBM® Workload Scheduler uses the specified version of the protocol.

# composer prompt = prompt

Specify the prompt for the composer command line. The prompt can be of up to 10 characters in length. The default is dash (-).

conman prompt = prompt

Specify the prompt for the conman command line. The prompt can be of up to 8 characters in length. The default is percent  $(\%)$ .

current folder = /foldername>

When submitting commands that involve folders from either the composer or conman command line, you can change the default folder or working directory from the root (/) to another folder path so that you can submit commands from the composer or conman command line using relative folder paths.

date format  $= 0|1|2|3$

Specify the value that corresponds to the date format you require. The values can be:

- 0 corresponds to yy/mm/dd  
- 1 corresponds to mm/dd/yy  
- 2 corresponds to dd/mm/yy  
- 3 indicates usage of Native Language Support variables

The default is 1.

# encrypt label list

The list of previously used aliases for key encryption. When you modify a key alias for key rotation, store the previous alias in this property. This storage method is useful if the obsolete key is still used in the product. Separate each value with a comma ".". Note that this property is commented. This property is case insensitive. For more information about encryption and key rotation, see Automatic encryption for key product files on page 133.

defaultws  $=$  manager_workstation

The default workstation when you are accessing using a command line client. Specify the domain manager workstation.

jm file no root = yes|no

For UNIX® and Linux® operating systems only, specify yes to prevent Jobman from executing commands in file dependencies as root. Specify no to allow Jobman to execute commands in file dependencies as root. The default is no.

DownloadDir = directory_name

Defines the name of the directory where the fix pack installation package or upgrade elmage is downloaded during the centralized agent update process. If not specified, the following default directory is used:

On Windows operating systems:

TWA_home\TWS\stdlib\JMPowerload

On UNIX operating systems:

TWA_home/TWS/stdlist/JM/download

# encrypt keystore file file_name

The path to the keystore PKCS12 file, containing the AES-256 or AES-128 key. The keystore is created automatically at installation time and the related path is inserted in this parameter. If you want to use a different keystore, you can create it and add the path in this option.

# encrypt keystore pwd password

The path to the keystore stash file.

# encrypt label label

The label of the key in the keystore. When you modify a key label for key rotation, store the previous label in the decrypt label list property, so it can be retrieved if it is still used in the product. This property is case insensitive. For more information about encryption and key rotation, see Automatic encryption for key product files on page 133.

# host = hostname_or_IP_address

The name or IP address of the host when accessing using a command line client. For Agents, the host or ip address of the master is used. For Backup Master Domain Manager the value is the default: 127.0.0.1

# is remote cli = yes|no

Specify if this instance of IBM Workload Scheduler is installed as a command line client (yes).

# jm job table size = entries

Specify the size, in number of entries, of the job table used by Jobman. The default is 1024 entries.

# jm loaduserprofile = on|off

Only on Windows operating systems. Specify if the jobman process loads the user profile and its environment variables for the user specified in the logon field of each job, before starting the job on the workstation. Specify on to load the user profile on the workstation before running jobs for the logon user; otherwise specify off. Roaming profiles are not supported. The default is on.

# jm look = seconds

Specify the minimum number of seconds Jobman waits before looking for completed jobs and performing general job management tasks. The default is 300 seconds.

# jm nice = nice_value

For UNIX® and Linux® operating systems only, specify the nice value to be applied to jobs launched by Jobman to change their priority in the kernel's scheduler. The default is zero.

The nice boundary values vary depending upon each specific platform, but generally lower values correspond to higher priority levels and vice versa. The default depends upon the operating system.

Applies to jobs scheduled by the root user only. Jobs submitted by any other user inherit the same nice value of the Jobman process.

See also jm promoted nice on page 58.

jm no root = yes|no

For UNIX® and Linux® operating systems only, specify yes to prevent Jobman from launching root jobs.

Specify no to allow Jobman to launch root jobs. The default is yes.

jm promoted nice = nice_value

Used in workload service assurance. For UNIX® and Linux® operating systems only, assigns the priority value to a critical job that needs to be promoted so that the operating system processes it before others. Applies to critical jobs or predecessors that need to be promoted so that they can start at their critical start time.

Boundary values vary depending upon each specific platform, but generally lower values correspond to higher priority levels and vice versa. The default is -1.

Be aware that:

- The promotion process is effective with negative values only. If you set a positive value, the system runs it with the -1 default value and logs a warning message every time Jobman starts.  
- An out of range value (for example -200), prompts the operating system to automatically promote the jobs with the lowest allowed nice value. Note that in this case no warning is logged.  
- Overusing the promotion mechanism (that is, defining an exceedingly high number of jobs as mission critical and setting the highest priority value here) might overload the operating system, negatively impacting the overall performance of the workstation.

You can use this and the jm nice on page 57 options together. If you do, remember that, while jm nice applies only to jobs submitted by the root user, jm promoted nice applies only to jobs that have a critical start time. When a job matches both conditions, the values set for the two options add up. For example, if on a particular agent the local options file has:

```txt
jm nice  $= -2$   
jm promoted nice  $= -4$
```

when a critical job submitted by the root user needs to be promoted, it is assigned a cumulative priority value of -6.

jm promoted priority  $=$  value

Used in workload service assurance. For Windows® operating systems only, sets to this value the priority by which the operating system processes a critical job when it is promoted.

Applies to critical jobs or predecessors that need to be promoted so that they can start at their critical start time.

The possible values are:

High  
- AboveNormal (the default)  
Normal

BelowNormal  
Low Or Idle

Note that if you a set a lower priority value than the one non-critical jobs might be assigned, no warning is given and no mechanism like the one available for jm promoted nice sets it back to the default.

# jm read = seconds

Specify the maximum number of seconds Jobman waits for a message in the courier.msg message file. The default is 10 seconds.

# merge stdlists = yes|no

Specify yes to have all of the IBM Workload Scheduler control processes, except Netman, send their console messages to a single standard list file. The file is given the name TWSmerge. Specify no to have the processes send messages to separate standard list files. The default is yes.

# mm cache mailbox = yes|no

Use this option to enable Mailman to use a reading cache for incoming messages. In this case, only messages considered essential for network consistency are cached. The default is yes.

# mm cache size = messages

Specify this option if you also use mm cache mailbox. The maximum value (default) is 512.

# mm resolve master = yes|no

When set to yes the $MASTER variable is resolved at the beginning of the production day. The host of any extended agent is switched after the next JnextPlan (long term switch). When it is set to no, the $MASTER variable is not resolved at JnextPlan and the host of any extended agent can be switched after a conman switchmgr command (short- and long-term switch). Starting from Version 9.5 Fix Pack 2, the default is no (for previous releases, it was set to yes. When you switch a master domain manager and the original has mm resolve master set to no and the backup has mm resolve master set to yes, after the switch any extended agent that is hosted by $MASTER switches to the backup master domain manager. When the backup master domain manager restarts, the keyword $MASTER is locally expanded by Mailman. You should keep the mm resolve master value the same for master domain managers and backup domain managers.

# mm response = seconds

Specify the maximum number of seconds Mailman waits for a response before reporting that a workstation is not responding. The minimum wait time for a response is 90 seconds. The default is 600 seconds.

# mm retrylink = seconds

Specify the maximum number of seconds Mailman waits after unlinking from a non-responding workstation before it attempts to link to the workstation again. The default is 600 seconds. The tomserver optional mailman servers do not unlink non-responding agents. The link is repetitively checked every 60 seconds, which is the default retrylink for these servers.

mm sound off = yes|no

Specify how Mailman responds to a conman tellop? command. Specify yes to have Mailman display information about every task it is performing. Specify no to have Mailman send only its own status. The default is no.

mm symphony download timeout = seconds

Specify the maximum number of minutes Mailman waits after attempting to initialize a workstation on a slow network. If the timeout expires without the workstation being initialized successfully, Mailman initializes the next workstation in the sequence. The default is no timeout (0).

mm unlink = seconds

Specify the maximum number of seconds Mailman waits before unlinking from a workstation that is not responding. The wait time should not be less than the response time specified for the Local Option nm response. The default is 960 seconds.

nm mortal = yes|no

Specify yes to have Netman quit when all of its child processes have stopped. Specify no to have Netman keep running even after its child processes have stopped. The default is no.

nm port  $=$  port

Specify the TCP port number that Netman responds to on the local computer. This must match the TCP/IP port in the computers workstation definition. It must be an unsigned 16-bit value in the range 1- 65535 (values between 0 and 1023 are reserved for services such as, FTP, TELNET, HTTP, and so on). The default is the value supplied during the product installation. If you disable this port at installation time using the port parameter, this option is automatically set to 0.

If you run event-driven workload automation and you have a security firewall, make sure this port is open for incoming and outgoing connections.

nm read = seconds

Specify the maximum number of seconds Netman waits for a connection request before checking its message queue for stop and start commands. The default is 10 seconds.

nm retry = seconds

Specify the maximum number of seconds Netman waits before retrying a connection that failed. The default is 800 seconds.

nm SSL full port = port

The port used to listen for incoming SSL connections when full SSL is configured by setting global option enSSLFullConnection to yes (see Configuring full SSL security on page 327 for more details). This value must match the one defined in the secureaddr attribute in the workstation definition in the database. It must be different from the nm port local option that defines the port used for normal communication.

![](images/b43df279f6993dffc0f7098053272805807cabeb373341bcaa2695262e1be844.jpg)

Note:

![](images/f3cc8ca41265cfd4ea72f358790bca7ff8413749edf819722b70e20a646ce371.jpg)

1. If you install multiple instances of IBM Workload Scheduler on the same computer, set all SSL ports to different values.  
2. If you plan not to use SSL, set the value to 0.

The default value is 31113.

```txt
nm SSL port = port
```

The port used to listen for incoming SSL connections, when full SSL is not configured (see Configuring full SSL security on page 327 for more details). This value must match the one defined in the secureaddr attribute in the workstation definition in the database. It must be different from the nm port local option that defines the port used for normal communication.

![](images/7c5398de1263337763e8c2280b20da9a918ab3a5b562098be43e362de682cd87.jpg)

# Note:

1. If you install multiple instances of IBM Workload Scheduler on the same computer, set all SSL ports to different values.  
2. If you plan not to use SSL, set the value to 0.

The default value is 0.

```python
port = port
```

The TCP/IP port number of the protocol used when accessing using a command line client. The default is 31116.

```txt
protocol = http://https
```

The protocol used to connect to the host when accessing using a command line client.

```txt
proxy = proxy_server_hostname_or_IP_address
```

The name of the proxy server used when accessing using a command line client.

```batch
proxy port  $=$  proxy_server_port
```

The TCP/IP port number of the proxy server used when accessing using a command line client.

```txt
restricted stdlists = yes|no
```

Use this option to set a higher degree of security to the stdlist directory (and to its subdirectories) allowing only selected users to create, modify, or read files.

This option is available for UNIX workstations only. After you define it, make sure you erase your current stdlist directory (and subdirectories) and that you restart IBM Workload Scheduler. The default is no.

If the option is not present or if it is set to no, the newly created stdlist directory and its subdirectories are unaffected and their rights are as follows:

```txt
drwxrwxr-x 22 twsmdm staff 4096 Nov 09 12:12  
drwxrwxr-x 2 twsmdm staff 256 Nov 09 11:40 2009.11.09
```

```txt
drwxrwxr-x 2 twsmdm staff 4096 Nov 09 11:40 logs  
drwxr-xr-x 2 twsmdm staff 4096 Nov 09 11:40 traces
```

If the option is set to yes, these directories have the following rights:

```txt
drwxr-x--x 5 twsmdm staff 256 Nov 13 18:15  
rwxr-x--x 2 twsmdm staff 256 Nov 13 18:15 2009.11.13  
rwxr-x--x 2 twsmdm staff 256 Nov 13 18:15 logs  
rwxr-x--x 2 twsmdm staff 256 Nov 13 18:15 traces
```

Do the following to define and activate this option:

1. Change the line restricted stdlists = no to restricted stdlists = yes in your local options file.  
2. Stop IBM Workload Scheduler.  
3. Stop WebSphere Application Server Liberty if present.  
4. Remove the stdlist directory (or at least its files and subdirectories).  
5. Start IBM Workload Scheduler.  
6. Start WebSphere Application Server Liberty if present.

# SSL auth mode = caonly|string|cpu

The behavior of IBM Workload Scheduler during an SSL handshake is based on the value of the SSL authentication mode option as follows:

# caonly

IBM Workload Scheduler checks the validity of the certificate and verifies that the peer certificate has been issued by a recognized CA. Information contained in the certificate is not examined. The default value.

# string

IBM Workload Scheduler checks the validity of the certificate and verifies that the peer certificate has been issued by a recognized CA. It also verifies that the Common Name (CN) of the Certificate Subject matches the string specified into the SSL auth string option. See SSL auth string = string on page 62.

# cpu

IBM Workload Scheduler checks the validity of the certificate and verifies that the peer certificate has been issued by a recognized CA. It also verifies that the Common Name (CN) of the Certificate Subject matches the name of the workstation that requested the service.

# SSL auth string = string

Used in conjunction with the SSL auth mode option when the "string" value is specified. The SSL auth string (ranges from 1 - 64 characters) is used to verify the certificate validity. The default string is "tws".

# SSL CA certificate = file_name

Specify the name of the file containing the trusted certification authority (CA) certificates required for SSL authentication. The CAs in this file are also used to build the list of acceptable client CAs passed to the client

when the server side of the connection requests a client certificate. This file is the concatenation, in order of preference, of the various PEM-encoded CA certificate files.

The default is /TWS_DATA_DIR/ssl/certs/TWSClientTrustStore.pem. This file is part of the SSL configuration distributed with the product to all customers. It is thus not secure and should be replaced with your own secure SSL configuration. See Configuring SSL attributes on page 325.

SSL certificate = file_name

Specify the name of the local certificate file used in SSL communication.

The default is /TWS_DATA_DIR/ssl/certs/TWSCClientTrustStore.pem. This file is part of the SSL configuration distributed with the product to all customers. It is thus not secure and should be replaced with your own secure SSL configuration. See Configuring SSL attributes on page 325.

SSL cert type  $=$  certificate_type

Specify the type of the local certificate file used in SSL communication. The default value is P12.

SSL ciphers = cipher_class

Define the ciphers that the workstation supports during an SSL connection.

If you want to use an OpenSSL cipher class, use the following command to find out the list of available classes:

openssl ciphers

For a full list of supported ciphers, see SSL Ciphers and OpenSSL.

SSL cipher suites suites

Specify one or more supported algorithms for TLS version 1.3, This option does not apply to TLS version 1.2 or earlier.

SSL config file file_name

Specify the name and path of the OpensSLS configuration file. See OpensSLS documentation for details about the file format and options. If you modify this file, ensure the changes are consistent with the security configuration in your environment.

SSL FIPS compliance= yes|no

Specifies whether to enable FIPS compliance. In the current release, FIPS is not supported, so this option must not be changed.

SSL key = file_name

The full path to the private key file in pem format.

This file is part of the SSL configuration distributed with the product to all customers. It is thus not secure and should be replaced with your own secure SSL configuration. See Configuring SSL attributes on page 325.

SSL key pwd = file_name

The full path to the file containing the password encoded in Base64 for the private key.

The default is <TWS_DATA_DIR>/ssl/certs/tls.sth. This file is part of the SSL configuration distributed with the product to all customers. It is thus not secure and should be replaced with your own secure SSL configuration. See Configuring SSL attributes on page 325.

# SSL random seed = file_name

Specify the pseudo random number file used by OpenSSL on some operating systems. Without this file, SSL authentication might not work correctly.

The default is <TWS_DATA_DIR>/ssl/certs/tls.rnd. This file is part of the SSL configuration distributed with the product to all customers. It is thus not secure and should be replaced with your own secure SSL configuration. See Configuring SSL attributes on page 325.

# SSL version version

Specify the SSL version to be used. Supported values are:

- atleast.TLSv1.0  
atleast.TLSv1.1  
- atleast.TLSv1.2  
- atleast.TLSv1.3

where you specify the minimum version of the TLS protocol to be used. In this case, IBM® Workload Scheduler uses the specified version of the protocol or a higher version, if supported.

max.TLSv1.0  
max.TLSv1.1  
max.TLSv1.2  
max.TLSv1.3

where you specify the maximum version of the TLS protocol to be used. In this case, IBM® Workload Scheduler uses the specified version of the protocol or a lower version.

TLSv1.0  
TLSv1.1  
TLSv1.2  
TLSv1.3

where you specify the exact version of the TLS protocol to be used. In this case, IBM® Workload Scheduler uses the specified version of the protocol.

# stdlist width = columns

Specify the maximum width of the IBM Workload Scheduler console messages. You can specify a column number in the range 1 to 255. Lines are wrapped at or before the specified column, depending on the presence of imbedded carriage control characters. Specify a negative number or zero to ignore line width. On UNIX®

and Linux® operating systems, you should ignore line width if you enable system logging with the syslog local option. The default is 0 columns.

# switch sym prompt = prompt

Specify a prompt for the conman command line after you have selected a different Symphony file with the setsym command. The maximum length is 8 characters. The default is  $n\%$ .

# sync level = low|medium|high

Specify the rate at which IBM Workload Scheduler synchronizes information written to disk. This option affects all mailbox agents and is applicable to UNIX® and Linux® operating systems only. Values can be:

low

Allows the operating system to handle it.

medium

Flashes the updates to disk after a transaction has completed.

high

Flashes the updates to disk every time data is entered.

The default is low.

# syslog local = value

Enables or disables IBM Workload Scheduler system logging for UNIX® and Linux® operating systems only. Specify -1 to turn off system logging for IBM Workload Scheduler. Specify a number from 0 to 7 to turn on system logging and have IBM Workload Scheduler use the corresponding local facility (LOCAL0 through LOCAL7) for its messages. Specify any other number to turn on system logging and have IBM Workload Scheduler use the USER facility for its messages. The default is -1. See IBM Workload Scheduler console messages and prompts on page 132.

# tcp connect timeout = seconds

Specify the maximum number of seconds that can be waited to establish a connection through non-blocking socket. The default is 15 seconds.

# tcp timeout = seconds

Specify the maximum number of seconds that can be waited for the completion of a request on a connected workstation that is not responding. The default is 300 seconds.

# this cpu = workstation_name

The unique identifier of the workstation. Even when the workstation is subsequently moved to a different folder, the unique identifier remains the same. The name can be a maximum of 16 alphanumeric characters in length and must start with a letter. When a switch is made between the master domain manager and a backup domain manager, using the switchmgr command, the Symphony header value for this cpu is overwritten by the this cpu value in the localopts file. The default is the host name of the computer.

timeout = seconds

The timeout in seconds to await for the server operation completion was reached. The command continues to run on the server until its completion. The default value is 3600 seconds.

unison network directory = directory_name

This parameter applies only to versions of IBM Workload Scheduler prior to version 8.3. Defines the name of the Unison network directory. The default is TWA_home>/../unison/network.

userargs = file_name

If you have multiple instances of IBM Workload Scheduler on a system, use this to identify the useropts file that is to be used to store the connection parameters for the instance in which this localops file is found. See Multiple product instances on page 71 for more details.

wre enable compression  $=$  yes|no

Use this option on fault-tolerant agents. Specify if the fault-tolerant agent can receive the Symphony file in compressed form from the master domain manager. The default is no.

wr read = seconds

Specify the number of seconds the Writer process waits for an incoming message before checking for a termination request from Netman. The default is 600 seconds.

wr unlink = seconds

Specify the number of seconds the Writer process waits before exiting if no incoming messages are received. The minimum is 120 seconds. The default is 180 seconds.

# Local options file example

The following is an example of a default localizepts file:

![](images/e7ffbc9c45c9ac5b0afddc5e8410ea088c3cb274b077881ad487d2e9bd3fd577.jpg)

Note: Some parameters might not be present depending upon your version and configuration.

# Example

```python
########## Properties of IBM* and HCL**
# Licensed Materials - Property of IBM* and HCL**
# 5698-WSH
# (c) Copyright IBM Corp. 1998, 2016 All rights reserved.
# (c) Copyright HCL Technologies Ltd. 2016, 2024 All rights reserved.
# * Trademark of International Business Machines
# ** Trademark of HCL Technologies Limited
#### # The IBM Workload Scheduler localots file defines the attributes of this
# workstation, for various processes.
# General attributes of this workstation:
# thiscpu=GF-UTN-OKG117
```

```txt
merge stdlists  $=$  yes  
stderr width  $=0$    
syslog local  $=-1$    
restricted stdlists  $\equiv$  no  
#  
#  
# The attributes of this workstation for the batchman process:  
#  
bm check file  $=120$   
bm check status  $=300$   
bm look  $=5$   
bm read  $=3$   
bm stats  $=off$   
bm verbose  $=off$   
bm check until  $=300$   
bm check deadline  $=0$   
bm late every  $=0$   
#  
#  
# The attributes of this workstation for the jobman process:  
#  
jm job table size  $=1024$   
jm look  $=300$   
jm nice  $=0$   
jm promoted nice  $=-1$  #UNIX  
jm promoted priority  $=$  AboveNormal #WINDOWS  
jm no root  $=$  yes  
jm file no root  $=$  no  
jm read  $=10$   
jm loaduserprofile  $=$  on  
#  
#  
# The attributes of this workstation for the TWS mailman process:  
#  
mm response  $=600$   
mm retrylink  $=600$   
mm sound off  $=$  no  
mm unlink  $=960$   
mm cache mailbox  $=$  yes  
mm cache size  $=512$   
mm resolve master  $=$  no  
autostart monman  $=$  yes  
mm symphony download timeout  $=0$   
#  
#  
# The attributes of this workstation for the netman process:  
#  
nm mortal  $=$  no  
nm port  $=3111$   
nm read  $=10$   
nm retry  $=800$   
#  
#  
# The attributes of this workstation for the writer process:  
#  
wr read  $=600$   
wr unlink  $=180$   
wr enable compression  $=$  no
```

```txt
#  
#  
#  
# Optional attributes of this Workstation for remote database files  
#  
#  
#  
# bazart directory = /opt/IBM/TWA/TWS/mozart  
# parameters directory = /opt/IBM/TWA  
# unison network directory = /opt/IBM/TWA/TWS/../unison/network  
#  
#  
#  
# The attributes of this workstation for custom formats  
#  
date format =1 # The possible values are 0-yyyy/mm/dd, 1-mm/dd/yyyy, 2-dd/mm/yyyy, 3-NLS.  
composer prompt =-  
conman prompt =%  
switch sym prompt =<n>  
#  
#  
# The attributes of this workstation for the customization of I/O on mailbox files  
#  
sync level =low  
#  
#  
# The attributes of this workstation for networking  
#  
tcp timeout =300  
tcp connect timeout =15  
#  
#  
# General Secure options  
#  
SSL auth mode =caonly  
#  
# Use "SSL auth string" only if "SSL auth mode" is set to "string"  
#  
SSL auth string =tws  
#  
## This flag set to "yes" require the FIPS 140-2 policies. The default value is "no".  
#  
SSL FIPS compliance =no  
#  
# This property specify the path to the file containing OpenSSL configuration properties.  
#  
SSL config file="/opt/IBM/TWA/TWSDATA/ssl/openssl.cnf"  
#  
# Netman full SSL port, use "nm SSL full port"it on if "enSSLFullConnection" is set to "yes"  
# the value "@" means port close  
#  
nm SSL full port =31113  
#  
# Netman SSL port  
# the value "@" means port close  
#  
nm SSL port =0  
#  
End General Secure options
```

```ini
# OpenSSL options
# 
# This section is ignored for agent dynamic only
# 
# when custom certificate are provided in SSL folder by the user,
# these lines are substituted by the installation with correct datadir path
# pointing to the following files: "tls.crt", "tls.sth", "tls.key", "tls.rnd", "ca.crt"
SSL key = ""
SSL certificate = "/opt/IBM/TWA/TWSDATA_SSL/certs/TWSClientKeyStore.p12"
SSL key pwd = "/opt/IBM/TWA/TWSDATA_SSL/certs/tls.sth"
SSL CA certificate = "/opt/IBM/TWA/TWSDATA_SSL/certs/TWSCClientTrustStore.pem"
SSL random seed = "/opt/IBM/TWA/TWSDATA_SSL/certs/tls.rnd"
SSL cert type = P12
SSL Ciphers =
SSL Version = atleast.TLSv1.2
# 
# CLI SSL server auth =
CLI SSL Ciphers =
CLI SSL cipher suites =
CLI SSL Version = atleast.TLSv1.2
# CLI SSL server certificate =
# CLI SSL trusted dir =
End OpenSSL options
#
# Encryption options
#
encrypt keystore file = "/opt/IBM/TWA/TWSDATA_SSL/aes/key.p12"
encrypt keystore pwd = "/opt/IBM/TWA/TWSDATA_SSL/aes/key.sth"
encrypt label = "default"
# decrypt label list =
End Encryption options
#
The TWS instance has been installed as REMOTE CLI
IS REMOTE CLI = no # yes for a REMOTE CLI installation, no otherwise
#
# Attributes for CLI connections
#
# General attributes for CLI connections
#
HOST = 127.0.0.1 # Master hostname used when attempting a connection.
PROTOCOL = https # Protocol used to establish a connection with the Master.
PORT = 31116 # Protocol port
# PROXY =
# PROXYPORT =
TIMEOUT = 3600 # Timeout in seconds to wait a server response.
# CLI SSL SERVER AUTH = yes
DEFAULTS = GF-UTN-OKG117
USEROPTS = useropts_twsuser
#
# Event Management parameters
#
```

```txt
CAN BE EVENT PROCESSOR = yes # yes for MDM and BKM, no otherwise  
#  
# Centralized Agent Update  
#  
#DownloadDir =  
#  
# Current Folder  
#  
#current folder = /  
#  
# Appserver Watchdog default settings  
#  
Appserver check interval = 3 #minutes  
Appserver auto restart = yes #yes/no  
Appserver min restart time = 2 #minutes  
Appserver max restarts = 5 #restarts number  
Appserver count reset interval = 24 #hours
```

![](images/fb2746ee79a11e7b4f40aafd216938c1e7917211fcb53112ad2c20114096dcc1.jpg)

Note: The "REMOTE CLI" term indicates the command line client.

# Setting user options

Set the user options you require for each user on a workstation in the useropts file. Changes do not take effect until IBM Workload Scheduler is stopped and restarted.

The useropts file contains values for localopts parameters that must be customized for an individual user. Both files are located in the user_home/.TWS directory of the user. When IBM Workload Scheduler needs to access data from the localopts file, it looks first to see if the property it requires is stored also in the useropts file for the current user. The value specified in the useropts file always takes precedence over the value in the localopts file. If a property is not specified when invoking the command that requires it, or in the useropts and localopts files, an error is displayed.

The main use of the useroptions file is to store the user-specific connection parameters for accessing the command line client, for example conman or composer.

You can define authentication using either the username and password parameters or the JWT parameter:

# username

User name used to access the master domain manager. The user must be defined in the security file on the master domain manager. For more information, see the section about configuring user authorization in Administration Guide.

# password

Password used to access the master domain manager. The presence of the ENCRYPT or AES label in the password field indicates that the specified setting has been encrypted; if this label is not present, you must exit and access the interface program again to allow the encryption of that field.

# JWT

JSON Web Token (JWT) used to access the master domain manager. The JWT parameter always takes precedence over the username and password parameters. If it is incorrect, the connection does not take place, even if the username and password parameters are present and correct. You retrieve the JWT from the Dynamic Workload Console.

Note that these parameters are not stored in the localopts file.

For more information, see Configuring command-line client access authentication on page 123.

A useropts file is created for the <TWS_user> during the installation, but you must create a separate file for each user that needs to use user-specific parameters on a workstation.

# Multiple product instances

Because IBM Workload Scheduler supports multiple product instances installed on the same computer, there can be more than one instance of the useroptions file per user. This is achieved by giving the useroptions files for a user different names for each instance.

In the `localargs` file of each instance the option named `userargs` identifies the file name of the `userargs` file that has to be accessed in the `user_home/.TWS` directory to connect to that installation instance.

This means that, for example, if two IBM Workload Scheduler instances are installed on a computer and the user operator is a user of both instances, you could define the useropts credentials as follows:

- In the `localopts` file of the first instance the local option `useropts = useroptsl` identifies the `operator_home/.TWS/`, `useroptsl` file containing the connection parameters settings that user `operator` needs to use to connect to the first IBM Workload Scheduler instance.  
- In the `localargs` file of the second IBM Workload Scheduler instance the local option `userargs = userargs2` identifies the `operator_home/.TWS/userargs2` file containing the connection parameters settings that user `operator` needs to use to connect to the second IBM Workload Scheduler instance.

# Configuring the agent

The configuration settings of the agent are stored in the JobManager.ini file. Starting with version 10.2.4, if you are integrating with a password vault tool, the related configuration is no longer saved in the JobManager.ini file. Instead, it is now stored in a profile and, optionally, in a configuration file. For more information, see Configuring the agent to work with a password vault on page 90.

In a distributed environment, if a gateway is configured to allow the master domain manager or dynamic domain manager to communicate with a dynamic agent located behind a network boundary, then the gateway configuration settings of the agent are contained in the JobManagerGW.ini file. This file is almost identical to the JobManager.ini file, however, only parameters in the [ITA], [Env], and [ResourceAdvisorAgent] sections require configuration. For these parameters, definitions are given for both the JobManager.ini and JobManagerGW.ini files.

To find out where these files are located, see the section about installation paths in IBM Workload Scheduler: Planning and Installation.

Only a subset of the available parameters is documented, because some parameters are reserved for internal use.

These files are made up of many different sections. Each section name is enclosed between square brackets and each section includes a sequence of variable = value statements.

You can customize properties for the following:

- Event-driven workload automation properties  
- Log properties  
- Trace properties when the agent is stopped. You can also customize traces when the agent is running using the procedure described in Configuring trace properties when the agent is running on page 78.  
- Native job executor  
- Java™ job executor  
Resource advisor agent  
- System scanner

The log messages are written in the following file:

On Windows operating systems:

```txt
<TWA_home>\TWS\stdlib\JM\JobManager_message.log
```

On UNIX and Linux operating systems:

```txt
<TWA_DATA_DIR>/stdlib/JobManager_message.log
```

The trace messages are written in the following file:

On Windows operating systems:

```batch
<TWA_home>\TWS\stdlib\JM\ITA_trace.log
```

```batch
<TWA_home>\TWS\stdlib\JM\JobManager_trace.log
```

```batch
<TWA_home>\TWS\JavaExt\logs\javaExecutor0.log
```

On UNIX and Linux operating systems:

```txt
<TWA_DATA_DIR>/stderr/JM/ITA_trace.log
```

```txt
<TWA_DATA_DIR>/stderr/JM/JobManager_trace.log
```

```txt
<TWA_DATA_DIR>/JavaExt/logs/javaExecutor0.log
```

Logging information about job types with advanced options

You can use the logging.properties file to configure the logging process for job types with advanced options, with the exception of the Executable and Access Method job types.

The logging.properties file is located on the IBM Z Workload Scheduler Agent, located in the following path:

# On Windows operating systems:

<TWA_home>/TWS/JavaExtcfg/logging.properties

# On UNIX and Linux operating systems:

<TWA_DATA_DIR>/JavaExtcfg/logging.properties

After installation, this file is as follows:  
```ini
# Specify the handlers to create in the root logger
# (all loggers are children of the root logger)
# The following creates two handlers
handlers = java.utillogging|xMLE績Handler,
		// Set the default logging level for the root logger
_.level = INFO
# Set the default logging level for new ConsoleHandler instances
java.utillogging|xMLE績Handler.level = INFO
# Set the default logging level for new FileHandler instances
java.utillogging|xMLE績Handler.level
		= ALL
java.utillogging|xMLE績Handler-pattern
		= C:\\TWA_home\\TWS\\JavaExt\\logs\\javaExecutor%g.log
java.utillogging|xMLE績Handler limit
		= 1000000
java.utillogging|xMLE績Handler.count
		= 10
# Set the defaultformatter for new ConsoleHandler instances
java.utillogging|xMLE績Handlerformatter =
		// Set the default logging level for the logger named com.mycompany
```

You can customize:

- The logging level (from INFO to WARNING, ERROR, or ALL) in the following keywords:

.level

Defines the logging level for the internal logger.

com.ibm.scheduling

Defines the logging level for the job types with advanced options. To log information about job types with advanced options, set this keyword to ALL.

- The path where the logs are written, specified by the following keyword:

```txt
java.utillogging.FileHandler-pattern
```

Not all the properties in the JobManager.ini and JobManagerGW.ini files can be customized. For a list of the configurable properties, see the following sections:

- Configuring log message properties [JobManager Logging.cclog] on page 75  
- Configuring trace properties when the agent is stopped [JobManager Logging.cclog] on page 77.  
- Configuring common launchers properties [Launchers] on page 81  
- Configuring properties of the native job launcher [NativeJobLauncher] on page 83.  
- Configuring properties of the Java job launcher [JavaJobLauncher] on page 86.  
- Configuring properties of the Resource advisor agent [ResourceAdvisorAgent] on page 87.  
- Configuring properties of the System scanner [SystemScanner] on page 89  
- Configuring environment variables [Env] on page 90  
- The section about configuring properties of event-driven workload automation [EventDrivenWorkload] in IBM Z Workload Scheduler: Scheduling End-to-end with z-centric Capabilities

# Configuring general properties [ITA]

# About this task

In the JobManager.ini or JobManagerGW.ini file, you can add some general properties to the following section:

```txt
[ITA]
```

You can add or modify the following properties:

# ActionPollers

The number of the thread processes started on the gateway workstation to communicate with the broker server installed on the master domain manager or dynamic domain manager. The default value is 1. Specify this value if you have more than 100 dynamic agents that communicate with the broker server installed on the master domain manager or dynamic domain manager by using the same gateway. Restart the agent after the property change.

# http-proxy

The URL of the proxy configured in a distributed environment through which agents or gateways communicate to the broker server installed on the master domain manager or dynamic domain manager. The value is

```txt
https-proxy =http://<proxy_workstation>:\<proxy_workstation_port>, where:
```

- <proxy_workstation> is the fully qualified host name of the workstation where the proxy is configured.  
- <proxy_workstation_port> is the port number of the workstation where the proxy is configured.

Restart the agent after the property change.

# DebugDir

You can use this parameter to enable tracing for the dynamic agent to help determine what information is being sent to and from a dynamic agent workstation. Perform the following steps:

1. Create a directory to dump the files sent and received by the dynamic agent, for example /tmp/DA_DD. This directory needs to be writable by the user owning the dynamic agent.  
2. Add the DebugDir parameter to the path of the directory you created, for example:

```txt
DebugDir = /tmp/DA_DD
```

3. Restart the dynamic agent using the following commands:

```txt
ShutdownLwa StartUpLwa
```

Remember to monitor the debug directory on a regular basis to ensure it does not become too large. No automatic check is performed on the debug director. For more information, see Enable packet tracing for dynamic agent using ITA parameter DebugDir.

# Configuring log message properties [JobManager Logging.cclog]

# About this task

To configure the logs, edit the [JobManager Logging.cclog] section in the JobManager.ini file. This procedure requires that you stop and restart the IBM Workload Scheduler agent

The section containing the log properties is named:

```json
[JobManager Logging.cclog]
```

You can change the following properties:

# JobManager/loggerhd.fileName

The name of the file where messages are to be logged. the default value is

# On Windows operating systems

```batch
TWA_home\stdlib\JM\JOBMANAGER-FFDC
```

# On UNIX operating systems

```txt
$\S$  (TWA_DATA_DIR)/stdlib/JM/JobManager_message.log
```

# JobManager/loggerhd.maxFileBytes

The maximum size that the log file can reach. The default is 1024000 bytes.

# JobManager/loggerhd.maxFiles

The maximum number of log files that can be stored. The default is 3.

# JobManager/loggerhd.fileEncoding

By default, log files for the agent are coded in UTF-8 format. If you want to produce the log in a different format, add this property and specify the required codepage.

# JobManager/loggerfl.level

The amount of information to be provided in the logs. The value ranges from 3000 to 7000. Smaller numbers correspond to more detailed logs. The default is 3000.

# JobManager.ddc.maxDiskSpace

Exceeding this maximum disk space, log files collected by the first failure data capture mechanism are removed, beginning with the oldest files first.

# JobManager.ddc.baseDir

The directory to which log and trace files collected by the ffdc tool are copied. The default directory is

# On Windows operating systems

TWA_home\stdlib\JM\JobManager_message.log

# On UNIX operating systems

$\S$  (TWA_DATA_DIR)/stdlib/JM/JobManager_message.log

# JobManager.ffdc.filesToCopy

Log and trace files (JobManager_message.log and JobManager_trace.log) collected by the ffdc tool located in <TWA_home>\TWS\stdlib>JM. The files are available in the following paths:

# On Windows operating systems

- TWA_home/TWS/stdlist/JM/JobManager_message.log  
- TWA_home/TWS/stdlist/JM/JobManager_trace.log

# On UNIX operating systems

$\cdot \S$  (TWA_DATA_DIR)/stdlib/JM/JobManager_message.log  
$\S$  (TWA_DATA_DIR)/stdlib/PM/JobManager_trace.log

When a message is logged (JobManager.ffdc_triggerFilter = JobManager.msgIdFilter) that has an ID that matches the pattern "AWSITA*E" (JobManager.msgIdFilter.msglds = AWSITA*E), which corresponds to all error messages, then the log and trace files (JobManager.ffdc.filesToCopy = "/opt/IBM/TWA_<TWS_user>/TWS/stdlist/JM/JobManager_message.log" "/opt/IBM/TWA_<TWS_user>/TWS/stdlist/JM/JobManager_trace.log") are copied (JobManager.ffdcClassName = ccg_ffdc_filecopy_handler) to the directory JOBMANAGER-FFDC (JobManager.ffdc.baseDir = /opt/IBM/TWA_<TWS_user>/TWS/stdlist/JM/JobMANAGER-FFDC). If the files copied exceed 10 MB (JobManager.ffdc.maxDiskSpace = 10000000), then the oldest files are removed first (JobManager.ffdc.quotaPolicy = QUOTA_AUTODELETE).

After installing the z-centric agent or dynamic agent on Windows 2012, the JobManager_message.log might not be created. In this case, perform the following procedure:

1. Stop the agent.  
2. Create a backup copy of JobManager.ini, and edit the original file by changing the row:

```txt
JobManager/loggerhd.className = ccgMULTIProc_filehandler
```

to

```txt
JobManager/loggerhd.className = ccg_filehandler
```

3. Restart the agent.

# Configuring trace properties when the agent is stopped [JobManager Logging.cclog]

How to configure the trace properties when the agent is stopped.

To configure the trace properties when the agent is stopped, edit the [JobManager Logging] section in the JobManager.ini file and then restart the IBM Workload Scheduler agent.

The section containing the trace properties is named:

```json
[JobManager Logging.cclog]
```

You can change the following properties:

# JobManager.trhd.fileName

The name of the trace file. the default path is as follows:

# On Windows operating systems

```txt
TWA_home/TWS/stdlist/JM/JobManager_trace.log
```

# On UNIX operating systems

```txt
$\S$  (TWA_DATA_DIR)/stdlib/JM/JobManager_trace.log
```

# JobManager.trhd.maxFileBytes

The maximum size that the trace file can reach. The default is 10240000 bytes.

# JobManager.trhd.maxFiles

The maximum number of trace files that can be stored. The default is 5.

# JobManager.trfl.level

Determines the type of trace messages that are logged. Change this value to trace more or fewer events, as appropriate, or on request from IBM Software Support. Valid values are:

# DEBUG_MAX

Maximum tracing. Every trace message in the code is written to the trace logs.

# INFO

All informational, warning, error and critical trace messages are written to the trace. The default value.

# WARNING

All warning, error and critical trace messages are written to the trace.

# ERROR

All error and critical trace messages are written to the trace.

# CRITICAL

Only messages which cause the agent to stop are written to the trace.

The output trace (JobManager_trace.log) is provided in XML format.

After installing the z-centric agent or dynamic agent on Windows 2012, the JobManager_trace.log might not be created. In this case, perform the following procedure:

1. Stop the agent.  
2. Create a backup copy of JobManager.ini, and edit the original file by changing the row:

```txt
JobManager.trhd.className = ccgMULTIProc_filehandler
```

to

```txt
JobManager.trhd.className = ccg_filehandler
```

3. Restart the agent.

# Configuring trace properties when the agent is running

Use the twstrace command to set the trace on the agent when it is running.

Using the twstrace command, you can perform the following actions on the agent when it is running:

See command usage and verify version on page 79.  
- Enable or disable trace on page 79.  
- Set the traces to a specific level, specify the number of trace files you want to create, and the maximum size of each trace file. See Set trace information on page 79.  
Show trace information on page 80.  
- Collect trace files, message files, and configuration files in a compressed file using the command line. See Collect trace information on page 80.  
- Collect trace files, message files, and configuration files in a compressed file using the Dynamic Workload Console. See the section about retrieving agent traces from the Dynamic Workload Console in Troubleshooting Guide.

You can also configure the traces when the agent is not running by editing the [JobManager Logging] section in the JobManager.ini file as described in Configuring the agent on page 71. This procedure requires that you stop and restart the agent.

# twstrace command

Use the twstrace command to configure traces, and collect logs, traces, and configuration files (ita.ini and jobManager.ini) for agents. You collect all the information in a compressed file when it is running without stopping and restarting it.

# See command usage and verify version

To see the command usage and options, use the following syntax.

# Syntax

twstrace -u | -v

# Parameters

-u

Shows the command usage.

-v

Shows the command version.

# Enable or disable trace

To set the trace to the maximum or minimum level, use the following syntax.

# Syntax

twstrace -enable | -disable

# Parameters

-enable

Sets the trace to the maximum level. The maximum level is 1000.

-disabled

Sets the trace to the minimum level. The minimum level is 3000.

# Set trace information

To set the trace to a specific level, specify the number of trace files you want to create, and the maximum size the trace files can reach, use the following syntax.

# Syntax

twstrace [-level <level_number>] [-maxFiles <files_number>] [-maxFileBytes <bytes_number>]

# Parameters

-level<level_number>

Sets the trace level. Specify a value in the range from 1000 to 3000, which is also the default value. Note that if you set this parameter to 3000, you have the lowest morbidity level and the fewest trace messages. To have a better trace level, with the most verbose trace messages and the maximum trace level, set it to 1000.

-maxFiles <files_number>

Specify the number of trace files you want to create.

-maxFileBytes <bytes_number>

Set the maximum size in bytes that the trace files can reach. The default is 1024000 bytes.

# Show trace information

To display the current trace level, the number of trace files, and the maximum size the trace files can reach, use the following syntax.

# Syntax

twstrace -level | -maxFiles | -maxFileBytes

# Parameters

-level

See the trace level you set.

-maxFiles

See the number of trace files you create.

-maxFileBytes

See the maximum size you set for each trace file

# Example

# Sample

The example shows the information you receive when you run the following command:

```batch
twstrace -level -maxFiles -maxFileBytes
```

```txt
AWSITA176I The trace properties are: level="1000", max files="3", file size="1024000".
```

# Collect trace information

To collect the trace files, the message files, and the configuration files in a compressed file, use the following syntax.

# Syntax

twstrace -getLogs [-zipFile <compressed_file_name>] [-host <host_name>] [-protocol {http | https} [-port <port_number>] [-iniFile <ini_file_name>]

# Parameters

-zipFile <compressed_file_name>

Specify the name of the compressed file that contains all the information, that is logs, traces, and configuration files (ita.ini and jobManager.ini) for the agent. The default is logs.zip.

-host <host_name>

Specify the host name or the IP address of the agent for which you want to collect the trace. The default is localhost.

# -protocol http?https

Specify the protocol of the agent for which you are collecting the trace. The default is the protocol specified in the .ini file of the agent.

# -port <port_number>

Specify the port of the agent. The default is the port number of the agent where you are running the command line.

# -iniFile <ini_file_name>

Specify the name of the .ini file that contains the SSL configuration of the agent for which you want to collect the traces. If you are collecting the traces for a remote agent for which you customized the security certificates, you must import the certificate on the local agent and specify the name of the .ini file that contains this configuration. To do this, perform the following actions:

1. Extract the certificate from the keystore of the remote agent.  
2. Import the certificate in a local agent keystore. You can create an ad hoc keystore whose name must be TWSClientKeyStore.kdb.

3. Create an .ini file in which you specify:

0 in the tcp_port property as follows:

```txt
tcp_port=0
```

- The port of the remote agent in the ssl_port property as follows:

```txt
ssl_port=<ssl_port>
```

- The path to the keystore you created in Step 2 on page 81 in the keyrepository_path property as follows:

```xml
key/repository_path=<local_agent_keystore_path>
```

# Configuring common launchers properties [Launchers]

# About this task

In the JobManager.ini file, the section containing the properties common to the different launchers (or executors) is named:

```json
[Launchers]
```

The following properties are available:

# BaseDir

The installation path of the IBM Workload Scheduler agent. Do not modify this value.

# CommandHandlerMinThreads

Indicates the maximum number of commands that can be run on the agent concurrently. Limits to the number of jobs vary depending on the resources of your workstation, however consider that operations on command are usually short. The default is 20. Usually, there is no need to modify this setting, even if you plan a very high

workload on the agent. You might want to change it if many commands are run concurrently on the agent, for example, many concurrent requests to retrieve job logs.

# CommandHandlerMaxThreads

Indicates the maximum number of commands that can be run on the agent concurrently. Limits to the number of jobs vary depending on the resources of your workstation, however consider that operations on commander are usually short. The default is 100. Usually, there is no need to modify this setting, even if you plan a very high workload on the agent. You might want to change it if many commands are run concurrently on the agent, for example, many concurrent requests to retrieve job logs.

# CpaHeartBeatTimeSeconds

The polling interval in seconds used to verify if the agent process is still up and running. If the agent process is inactive the product stops also the JobManager process. The default is 30. Modify only if you use dynamic pools with CPU-based requirements or optimization policies. With a lower value, the agent reacts quickly to CPU modifications, but this might cause unstable values in case of CPU spikes. Lower values causes a higher use of resources on the agent.

# DirectoryPermissions

The access rights assigned to the agent for creating directories when running jobs. The default is 0755.

Supported values are UNIX-format entries in hexadecimal notation.

# DownloadDir

The name of the directory where the fix pack installation package or upgrade elmage for IBM Workload Scheduler fault-tolerant agents or dynamic agents is downloaded during the centralized agent update process. If not specified, the following default directory is used:

On Windows operating systems:

TWA_home\TWS\stdlib\JM\download

On UNIX operating systems:

TWA_DATA_DIR/TWS/stdlist/JM/download

The centralized agent update process does not apply to z-centric agents.

# ExecutorsMaxThreads

Specifies the maximum number of jobs the dynamic agent can run concurrently. For example, to allow the dynamic agent to run a maximum of 500 jobs concurrently, set this parameter to 500. The default is 400.

# ExecutorsMinThreads

Specifies the minimum number of jobs the dynamic agent can run concurrently. For example, to allow the dynamic agent to run a minimum of 500 jobs concurrently, set this parameter to 500. The default is 38. Modify if the number of expected concurrent jobs is much higher than 38. The agent dynamically allocates more threads if necessary, until it reaches the value specified in ExecutorsMaxThreads.

# FilePermissions

The access rights assigned to the agent for creating files when running jobs. The default is 0755. Supported values are UNIX-format entries in hexadecimal notation.

# MaxAge

The number of days that job logs are kept (in path TWA_home/TWS/stdlidst/JM) before being deleted. The default is 30. Possible values range from a minimum of 1 day.

# NotifierMaxThreads

Notifier threads are in charge of notifying the dynamic workload broker of each status change in a job. This parameter specifies the maximum number of job status changes that can be notified to the dynamic workload broker.

# NotifierMinThreads

Notifier threads are in charge of notifying the dynamic workload broker of each status change in a job. This parameter specifies the minimum number of job status changes that can be notified to the dynamic workload broker. The default value is 3. Modify this parameters only in case of unexpected errors and after consulting with software support team.

# SpoolDir

The path to the folder containing the jobstore and outputs. The default is:

# On Windows operating systems

TWA_home/TWS/stdlist/JM

# On UNIX operating systems

$(TWA_DATA_DIR/stdlist/JM

# StackSizeBytes

The size of the operating system stack in bytes. The default is DEFAULT, meaning that the agent uses the default value for the operating system. Do not modify this parameter unless instructed to do so by the software support team. Incorrect values can cause the agent to crash.

# Configuring properties of the native job launcher [NativeJobLauncher]

# About this task

In the JobManager.ini file, the section containing the properties of the native job launcher is named:

[NativeJobLauncher]

You can change the following properties:

# AllowRoot

Applies to UNIX™ systems only. Specifies if the root user can run jobs on the agent. It can be true or false. The default is false. This property does not apply to IBM i, use the AllowQSECOFR option instead

# AllowQECOFR

Applies to IBM i systems only. Specifies if QSECOFR user can run jobs on the agent. It can be true or false.

The default is true. Add a line like AllowQSECOFR = false to the JobManager.ini file to deny job execution to

QSECOFR.

# Exec

If true, before launching the job, the agent checks both the availability and the execution rights of the binary

file. The default is true.

# DefaultWorkingDir

Specifies the working directory of native jobs. You can also specify the value for the working directory when

creating or editing the job definition in the Graphical Designer. When specified in the Graphical Designer, this

value overrides the value specified for the DefaultWorkingDir property. If you do not specify any working

directories, the <TWS_home> \bin directory is used.

# JobUnspecifiedInteractive

Applies to Windows™ operating systems only. Specifies if native jobs are to be launched in interactive mode. It

can be true or false. The default is false.

# KeepCommandTraces

Set to true to store the traces of the method invocation for actions performed on a job definition, for example,

when selecting from a picklist. These files are stored in the path /opt/IBM/TWA_<TWS_user>/TWS/

stderr/JM/r3batch_cmd_exec. The default setting is false.

# KeepJobCommandTraces

Set to true to store the traces of the method invocation for actions performed on a job instance, for example,

viewing a spool list. These files are stored in the .zip file of the job instance. The default setting is true.

# LoadProfile

Applies to agents on Windows servers only. Specifies if the user profile is to be loaded. It can be true or false.

The default is true.

# MonitorQueueName

Specifies the name of the queue where the IBM i jobs are monitored. If you do not specify this property, the

default queue (QBATCH) is used.

# PortMax

The maximum range of the port numbers used by the task launcher to communicate with the Job Manager.

The default is 0, meaning that the operating system assigns the port automatically.

# PortMin

The minimum range of the port numbers used by the task launcher to communicate with the Job Manager. The

default is 0, meaning that the operating system assigns the port automatically.

# PostJobExecScriptPathName

The fully qualified path of the script file that you want to run when the job completes. By default, this property is not present in the JobManager.ini file. If you do not specify any file path or the script file doesn't exist, no action is taken.

This property applies to dynamic agent and z/OS agent. For details about running a script when a job completes, see User's Guide and Reference.

# PromotedNice

Used in workload service assurance. This property is not supported on the Agent for z/OS.

For UNIX and Linux operating systems only, assigns the priority value to a critical job that needs to be promoted so that the operating system processes it before others. Applies to critical jobs or predecessors that need to be promoted so that they can start at their critical start time.

Boundary values vary depending upon each specific platform, but generally lower values correspond to higher priority levels and vice versa. The default is -1.

# Be aware that:

- The promotion process is effective with negative values only. If you set a positive value, the system runs it with the -1 default value.  
- An out of range value (for example -200), prompts the operating system to automatically promote the jobs with the lowest allowed nice value.  
- Overusing the promotion mechanism (that is, defining an exceedingly high number of jobs as mission critical and setting the highest priority value here) might overload the operating system, negatively impacting the overall performance of the workstation.

# PromotedPriority

Used in workload service assurance. This property is not supported on the Agent for z/OS.

For Windows operating systems only, sets to this value the priority by which the operating system processes a critical job when it is promoted. Applies to critical jobs or predecessors that need to be promoted so that they can start at their critical start time. Valid values are:

High  
- AboveNormal (the default)  
Normal  
BelowNormal  
- Low Or Idle

Note that if you a set a lower priority value than the one non-critical jobs might be assigned, no warning is given.

# RequireUserName

When true, requires that you add the user name in the JSDL job definition.

When false, runs with the user name used by job manager, that is:

- TWS_user on UNIX™ and Linux™ systems  
- The local system account on Windows™ systems

The default is false.

# RunExecutablesAsIBMiJobs

If you set this property to true, you can define IBM i jobs as generic jobs without using the XML definition. Generic jobs are automatically converted to IBM i jobs. As a side effect, generic jobs cannot be run when this parameter is enabled (RunExecutablesAsIBMiJobs=true). There is no default value because this property is not listed in the JobManager.ini file after the agent installation.

If you set this property to true, ensure that the user you used to install the agent has been granted the *ALLOBJ special authority.

# RunInteractiveJobOnInvalidSession

Applies only to native and executable jobs starting interactive programs running on dynamic agents installed on Windows operating systems. Interactive programs run only if the job user has an active session open when the job runs. If there is no active session for the job user, the job behavior is defined by this property, as follows. Set the property to true to enable jobs to start interactive programs even if there is no active session for the job user. Set the property to false to prevent jobs from starting interactive programs if there is no active session for the job user.

# ScriptSuffix

The suffix to be used when creating the script files. It is:

```txt
cmd
    For Windows™
    .sh
    For UNIX™
```

# verboseTracing

Enables verbose tracing. It is set to true by default.

# Configuring properties of the Java™ job launcher [JavaJobLauncher]

# About this task

In the JobManager.ini file, the section containing the properties of the Java™ job launcher is named:

```json
[JavaJobLauncher]
```

You can change the following property:

# JVMOptions

The options to provide to the Java™ Virtual Machine used to start job types with advanced options. Supported keywords for establishing a secure connection are:

- https-proxyHost  
- https.protoPort

Supported keywords for establishing a non-secure connection are:

- Dhttp proxyHost  
Dhttp-proxyPort

For example, to set job types with advanced options, based on the default JVM http protocol handler, to the unauthenticated proxy server called with name myproxyserver.mycompany.com, define the following option:

```txt
JVMOptions = -Dhttp-proxyHost=myproxyserver.mycompany.com -Dhttp-proxyPort=80
```

# Configuring properties of the Resource advisor agent [ResourceAdvisorAgent]

# About this task

In the JobManager.ini and JobManagerGW.ini files, the section containing the properties of the Resource advisor agent is named:

```txt
[ResourceAdvisorAgent]
```

You can change the following properties:

# BackupResourceAdvisorUrls

The list of URLs returned by the IBM Workload Scheduler master in a distributed environment or by the dynamic domain manager either in a z/OS or in a distributed environment. The agent uses this list to connect to the master or dynamic domain manager.

# CPUScannerPeriodSeconds

The time interval that the Resource advisor agent collects resource information about the local CPU. The default value is every 10 seconds.

# FullyQualifiedHostname

The fully qualified host name of the agent. It is configured automatically at installation time and is used to connect with the master in a distributed environment or with the dynamic domain manager in a z/OS or in a distributed environment. Edit only if the host name is changed after installation.

# NotifyToResourceAdvisorPeriodSeconds

The time interval that the Resource advisor agent forwards the collected resource information to the Resource advisor. The default value is every 119 seconds.

# ResourceAdvisorUrl

# JobManager.ini

The URL of the master in a distributed environment, or of the dynamic domain manager in a z/OS or in a distributed environment, that is hosting the agent. This URL is used until the server replies with the list of its URLs. The value is https:// $\text{山}$  (tdwb_server):  $\text{山}$  (tdwb_port)/JobManagerRESTWeb/ JobScheduler/resource, where:

#  $(tdwb_server)

is the fully qualified host name of the master in a distributed environment or of the dynamic domain manager either in a z/OS or in a distributed environment.

#  $(tdwb_port)

is the port number of the master in a distributed environment or of the dynamic domain manager either in a z/OS or in a distributed environment.

It is configured automatically at installation time. Edit only if the host name or the port number are changed after installation, or if you do not use secure connection (set to http). If you set the port number to zero, the resource advisor agent does not start. The port is set to zero if at installation time you specify that you will not be using the master in a distributed environment or the dynamic domain manager either in a z/OS or in a distributed environment.

In a distributed environment, if -gateway is set to either local or remote, then this is the URL of the dynamic agent workstation where the gateway resides and through which the dynamic agents communicate. The value is https://\ $(tdwb_server) : \$  (tdwb_port)/ita/JobManagerGW/ JobManagerRESTWeb/JobScheduler/resource, where:

# $(tdwb_server)$

The fully qualified host name of the dynamic agent workstation where the gateway resides and through which the dynamic agent communicates with the dynamic workload broker.

# $(tdwb_port)$

The port number of the dynamic agent workstation where the gateway resides and through which the dynamic agent communicates with the dynamic workload broker.

# JobManagerGW.ini

In a distributed environment, if -gateway is set to local, then ResourceAdvisorUrl is the URL of the master or dynamic domain manager. The value is https://\\( (tdwb_server):

$\S (tdwb\_port)/JobManagerRESTWeb/JobScheduler/resource,$  where:

# $(tdwb_server)$

The fully qualified host name of the master or dynamic domain manager.

#  $(tdwb_port)

The port number of the master or dynamic domain manager.

# ScannerPeriodSeconds

The time interval that the Resource advisor agent collects information about all the resources in the local system other than CPU resources. The default value is every 120 seconds.

The resource advisor agent, intermittently scans the resources of the machine (computer system, operating system, file systems and networks) and periodically sends an update of their status to the master or dynamic domain manager either in a z/OS or in a distributed environment.

The CPU is scanned every CPUScannerPeriodSeconds seconds, while all the other resources are scanned every ScannerPeriodSeconds seconds. As soon as one of the scans shows a significant change in the status of a resource, the resources are synchronized with the master in a distributed environment or the dynamic domain manager either in a z/OS or in a distributed environment. The following is the policy followed by the agent to tell if a resource attribute has significantly changed:

- A resource is added or deleted  
- A string attribute changes its value  
- A CPU value changes by more than DeltaForCPU  
- A file system value changes by more than DeltaForDiskMB megabytes  
- A Memory value changes by more than DeltaForMemoryMB megabytes

If there are no significant changes, the resources are synchronized with the IBM Workload Scheduler master in a distributed environment or with the dynamic domain manager either in a z/OS or in a distributed environment every NotifyToResourceAdvisorPeriodSeconds seconds.

# Configuring properties of the System scanner [SystemScanner]

# About this task

In the JobManager.ini file, the section containing the properties of the System scanner is named:

[SystemScanner]

You can change the following properties:

# CPUSamples

The number of samples used to calculate the average CPU usage. The default value is 3.

# DeltaForCPU

The change in CPU usage considered to be significant when it becomes higher than this percentage (for example, DeltaForCPU is 20 if the CPU usage changes from 10 percent to 30 percent). The default value is 20 percent.

# DeltaForDiskMB

The change in use of all file system resources that is considered significant when it becomes higher than this value. The default value is 100 MB.

# DeltaForMemoryMB

The change in use of all system memory that is considered significant when it becomes higher than this value. The default value is 100 MB.

# Configuring environment variables [Env]

# About this task

Add the section [Env] to the JobManagerGW.ini configuration file and insert the environment variables that you need in your dynamic scheduling environment.

# Configuring the agent to work with a password vault

Configure dynamic agents to work with a password vault by creating a dedicated profile.

# About this task

Enhance your password management by configuring dynamic agents to function as proxies to password vaults. You can use a password vault of your choice. If you prefer to use CyberArk, see Configuring the agent to work with CyberArk on page 91.

Perform the following steps:

# 1. Prerequisites check:

- Ensure all IBM® Workload Scheduler components are at version 10.2.4 or later.  
- Ensure at least one profile is present on each agent acting as a proxy.  
The profile is created automatically if you are upgrading from version 10.2.1 and later, otherwise it must be created manually.  
In a z/OS environment, a dynamic domain manager is required.  
- If you are using pools, make sure all agents within the pool are correctly configured to integrate with CyberArk. Additionally, verify that all profiles on all agents are identical.

2. Create a Profile: On the agent, create a profile located in /home/TWA_DATA_DIR/integrations/vault-profiles using a flat-text editor. If you name the profile default, it is selected automatically if no profile is specified in the job definition. You can create multiple profiles for the same password vault or for different password vaults to meet different requirements.

3. Specify Parameters: The profile must contain the following parameters:

```ini
[VaultProfile.Common]  
Type =  
Description =  
PasswordSolver =  
ConfigFile =
```

where

# Type

Specify the type of password vault to be used. This parameter is a string, and no validations are performed on its contents.

# Description

Optionally write a description for the profile.

# PasswordSolver

Contains the path to the password vault libraries. Alternatively, you can specify the absolute path to a script that retrieves the desired password from the password vault of your choice. This absolute path is consistent and independent of the current working directory, no matter where the file is located within the agent's file system.

If you plan to use a script to integrate with a password vault rather than a library, you have to write a dedicated script and ensure it returns a string containing the value of the password to be used in the job.

# ConfigFile

Specify the name and path of the configuration file for the password vault. Alternatively, you can insert the whole configuration file directly in this parameter.

4. Job definition creation: Specify the desired profile when creating the job definition. If you do not specify a profile in the job definition, the default profile is used. For more information about creating the job definition so that the password is retrieved from a password vault, see the topic about obtaining passwords from password vaults in User's Guide and Reference.

# Configuring the agent to work with CyberArk

Configure dynamic agents to work with CyberArk by creating a dedicated profile.

# About this task

If you plan to use CyberArk as your password vault, configure the profile as follows:

```ini
[VaultProfile.Common]  
Type = CyberArk  
Description =  
PasswordSolver = installation_dir/TWS/integrations/bin/libCyberArkVault.so  
ConfigFile = TWA_DATA_DIR/integrations/config
```

# Type

Specify the type of password vault to be used. This parameter is a string, and no validations are performed on its contents.

# Description

Optionally write a description for the profile.

# PasswordSolver

Contains the path to the password vault libraries. For example, you can point to the CyberArk libraries installed by default with the agent in the following paths:

# On Windows operating systems

installation_dir\TWS\integrations\bin\CyberArkVault.dll

# On UNIX operating systems

installation_dir/TWS/integrations/bin/libCyberArkVault.so

# ConfigFile

Specify the name and full path of the configuration file for the password vault. If you have a CyberArk.ini configuration file from a previous installation, merge the contents of the file with the new configuration file. Alternatively, you can insert the whole configuration file directly in this parameter, for example by copying the whole CyberArk.ini file in this parameter.

For information about configuring secure communication with CyberArk, see Configuring secure communication with CyberArk on page 97.

# What to do next

After the agent is configured, you can proceed to define a job that is designed to securely retrieve passwords from the password vault, as described in the topic about obtaining passwords from password vaults in User's Guide and Reference.

# Defining parameters in the CyberArk.ini file

# About this task

Set up the CyberArk.ini file to configure password retrieval.

To configure CyberArk, you can use the CyberArk.ini template file available in TWS/integrations/config Templ, as follows:

1. Create a copy of the template file to one of the following paths, depending on your operating system:

# On Windows operating systems

installation_directory\integrations\config

# On UNIX operating systems

TWA_DATA_DIR/integrations/config

2. On UNIX operating systems, ensure you apply to the new file the same permissions and ownership settings assigned to the JobManager.ini file.  
3. Fill in the parameters listed below as required.

You can also copy the updated file to a different path and specify the full path in the ConfigFile parameter of the profile you plan to use.

In the CyberArk.ini file, the following sections and parameters are available:

# [CyberArk.Config]

# CPAccessLibrary

The full path to the CyberArk proprietary library file.

# HandlePasswordChangeInProcess

The operation to be performed if another user changes the password while you are requesting it from CyberArk.

Supported values are true and false.

If you set this property to true, the job remains in waiting status and password retrieval is

attempted again, based on the values set for the RetryIntervalForPasswordChangeInProcess and

RetryAttemptsForPasswordChangeInProcess parameters.

# RetryIntervalForPasswordChangeInProcess

The time interval in seconds IBM® Workload Scheduler waits before sending a new password request to

CyberArk.

# RetryAttemptsForPasswordChangeInProcess

The number of times IBM® Workload Scheduler retries to obtain the password from CyberArk. If the specified

number of retries is exceeded, the operation fails.

# [CyberArk.CP.Connection]

This section applies only when you use the Credential Provider (CP) and specify the full path to the CyberArk library file in the CPAccessLibrary property.

Port

The port that is used to connect to the CP.

# ConnectionTimeout

The time interval in seconds IBM® Workload Scheduler waits for the host to answer the connection request.

# [CyberArk.CCP.Connection]

This section applies only when you use the Central Credential Provider (CCP) and is used when you leave the

CPAccessLibrary property empty. These properties are mandatory.

Host

The host name of the workstation where CyberArk Central Credential Provider is installed.

Protocol

The protocol used to connect to the host.

Port

The port used to connect to the host.

# Path

The path where the REST API is located.

# ConnectionTimeout

The time interval in seconds IBM® Workload Scheduler waits for the host to answer the connection request.

# Timeout

The time interval in seconds IBM® Workload Scheduler waits for CyberArk to return the password.

# FollowLocation

Set this property to true to enable the HTTP protocol. You cannot enable the HTTP protocol from the command line. This property instructs the composer command to follow any Location: header that the server sends as part of the HTTP header in a 3xx response. The Location: header can specify a relative or an absolute URL to follow.

# SSLVerifyServer

Specify yes if server authentication is to be used in SSL communications.

# Proxy

The name of the proxy server used when connecting to the specified host.

# ProxyPort

The TCP/IP port number of the proxy server used when connecting to the specified host.

# SSLVersion

Specify the SSL version to be used. Supported values are:

- atleast.TLSv1.0  
- atleast.TLSv1.1  
- atleast.TLSv1.2  
- atleast.TLSv1.3

where you specify the minimum version of the TLS protocol to be used. In this case, IBM® Workload Scheduler uses the specified version of the protocol or a higher version, if supported.

max.TLSv1.0  
max.TLSv1.1  
max.TLSv1.2  
max.TLSv1.3

where you specify the maximum version of the TLS protocol to be used. In this case, IBM® Workload Scheduler uses the specified version of the protocol or a lower version.

TLSv1.0  
TLSv1.1

-TLSv1.2  
TLSv1.3

where you specify the exact version of the TLS protocol to be used. In this case, IBM® Workload Scheduler uses the specified version of the protocol.

# SSLCiphers

Define the ciphers that the workstation supports during an SSL connection.

If you want to use an OpenSSL cipher class, use the following command to find out the list of available classes:

```txt
openssl ciphers
```

For a full list of supported ciphers, see SSL Ciphers and OpenSSL.

# SSLCipherSuites

Specify one or more supported algorithms for TLS version 1.3, This option does not apply to TLS version 1.2 or earlier.

# SSLConfigFile

Specify the name and path of the OpensSLS configuration file. See OpensSLS documentation for details about the file format and options. If you modify this file, ensure the changes are consistent with the security configuration in your environment.

# [CyberArk.CCP.Connection.OpenSSL]

For more information about configuring secure communication with CyberArk, see Configuring secure communication with CyberArk on page 97.

# SSLKey

The full path to the private key file in pem format.

If you use certificates in pem format

Specify the full path to the private key file in pem format. For example, if you use certman to generate the certificates, specify in this parameter the full path to the t1s.key file.

If you use certificates in p12 format

Leave this parameter blank.

# SSLKeyPwd

The full path to the file containing the password encoded in Base64 for the private key.

# SSLCertificate

Specify the full path to the local certificate file used in SSL communication. You can either use the certificates available on the agent or generate brand new certificates using the certman command, as follows:

# you use the certificates available on the agent

Specify in the SSL certificate parameter the full path to the certificates, for example / <TWS_DATA_DIR>/ssl/certs/TWSClientKeyStore.p12. This ensures secure communication without further steps.

# you generate new certificates using certman

1. Generate the certificates using certman, as described in Managing certificates using Certman on page 311  
2. Set the SSL cert type parameter to pem, which is the format used by certman.  
3. Specify in the SSL certificate parameter the full path to the tls.crt file generated by the certman command.  
4. Specify in the SSLKey parameter the full path to the private key file.

# SSLCertificateType

Specify the type of your private key and certificate file used in SSL communication. Supported formats are p12 and pem .

# If the certificate type is in pem format

- Specify the full path to the private key file in the SSLKey parameter.  
- Specify the full path to the local certificate file in the SSLCertificate parameter.

# If the certificate type is in p12 format

- Store both private key and certificate in the p12.  
- Leave the SSLKey parameter blank.  
- Specify the full path to the local certificate file in the SSLCertificate parameter.

# SSLCACertificate

Specify the name of the file containing the trusted certification authority (CA) certificates required for SSL authentication. The CAs in this file are also used to build the list of acceptable client CAs passed to the client when the server side of the connection requests a client certificate. This file is the concatenation, in order of preference, of the various PEM-encoded CA certificate files.

# SSLRandomSeed

Specify the pseudo random number file used by OpenSSL on some operating systems. Without this file, SSL authentication might not work correctly.

# [CyberArk.AppDescs]

# AppID

The unique ID of the application issuing the password request. This parameter is required.

# [CyberArk.Document]

# Safe

The name of the Safe where the password is stored.

# Folder

The name of the folder where the password is stored.

# Object

The name of the password object to retrieve.

# Username

Defines search criteria according to theUserName account property.

# Address

Defines search criteria according to the Address account property.

# PolicyID

Defines the format that will be used in the setPolicyID method.

# Database

Defines search criteria according to the Database account property.

# [CyberArk.Quey. Result]

# NormalizedUsername

Standardized format of a user name.

# What to do next

After the agent is configured, you can proceed to define a job that is designed to securely retrieve passwords from the password vault, as described in the topic about obtaining passwords from password vaults in User's Guide and Reference.

# Configuring secure communication with CyberArk

# About this task

To establish secure communication, you can use several certificate formats. The required configuration varies depending on the format you use, as follows:

# If the certificate type is in pem format

- Specify the full path to the private key file in the SSLKey parameter.  
- Specify the full path to the local certificate file in the SSLCertificate parameter.

# If the certificate type is in p12 format

- Store both private key and certificate in the p12.  
- Leave the SSLKey parameter blank.  
- Specify the full path to the local certificate file in the SSLCertificate parameter.

When establishing secure communication with CyberArk, you can encounter one of the following scenarios:

# You want to use your own certificates and CA

The following steps apply:

1. Provide CyberArk with your CA, which validates your certificate.  
2. CyberArk returns its CA, which validates the certificate from CyberArk.  
3. Depending on whether you use certificates in pem or p12 format, specify the following parameters:

# certificates in pem format

Specify the full path to the private key file in the SSLKey and the full path to the local certificate in the SSLCertificate parameters.

# certificates in p12 format

a. Add private key and certificate into a p12 keystore.  
b. Specify the full path to the p12 keystore you just created in the SSLCertificate parameter.  
c. Leave the SSLKey parameter blank.

4. Import the CyberArk CA into the pem truststore which must be specified in the SSLCACertificate parameter in the CyberArk.ini file.

# You request the certificates from CyberArk

The following steps apply:

1. CyberArk provides you with private key and certificate.  
2. Depending on whether you use certificates in pem or p12 format, specify the following parameters:

# certificates in pem format

Specify the full path to the key in the SSLKey and the full path to the certificate in the SSLCertificate parameters.

# certificates in p12 format

a. Add private key and certificate into a p12 keystore.  
b. Specify the full path to the p12 keystore you just created in the SSLCertificate parameter.  
c. Leave the SSLKey parameter blank.

3. Import the CyberArk CA into the pem truststore which must be specified in the SSLCACertificate parameter in the CyberArk.ini file.

# Configuring the agent to work with Kerberos

With the Kerberos integration, you can communicate securely over an insecure network by leveraging the Kerberos Authentication Protocol for submitting jobs on dynamic agents.

To configure Kerberos on 64-bit Linux Intel (linux-x86_64) operating systems, you can use the Kerberos.ini template file available on dynamic agents in TWS/integrations/config Templ, as follows:

1. Create a copy of the template file to one of the following paths, depending on your operating system:

# On Windows operating systems

```txt
installation_directory\ITA\cpa\config
```

# On UNIX operating systems

```txt
TWA_DATA_DIR/ITA/cpa/config
```

2. Ensure you apply to the new file the same permissions and ownership settings assigned to the JobManager . ini file.  
3. Fill in the parameters listed in Configuring the Kerberos.ini file on page 99 as required.  
4. Browse to the JobManager.ini file, located in one of the following paths, depending on your operating system:

# On Windows operating systems

```txt
installation_directory\ITA\cpa\config
```

# On UNIX operating systems

```txt
TWA_DATA_DIR/ITA/cpa/config
```

5. Add the following keys to the NativeJobLauncher section in the JobManager.ini file:

# AuthMethod

```txt
The full path to the libKerberos.so library file, as follows: installation_directory/TWS/bin/libKerberos.so
```

# IsAuthMethodMandatory

```txt
The behavior in case the authentication fails. The default value is false: if Kerberos authentication fails, the job continues with the authentication methods provided by the service in use, for example, by requesting the user and password required by SSH. If you set this key to true and Kerberos authentication fails, the job fails.
```

6. Start all processes on the dynamic agent by running the StartUpLwa command.

# Configuring the Kerberos. ini file

You can configure the following properties in the Kerberos.ini file:

# Kerberos.Config section

# UseDefaultCCache

The credentials cache to be used for storing intermediate objects. The default value is false: a cache file is automatically assigned by the libKerberos.so library for each job. If you set it to true, Kerberos defines the cache location.

# KDCConnectionRetryAttempts

The number of times IBM® Workload Scheduler retries to authenticate with Kerberos, in case the first attempt fails. The default value is 0, which means the integrations tries to authenticate a single time and performs no further attempts.

# KDCConnectionRetryInterval

The time interval in seconds IBM® Workload Scheduler waits before sending a new authentication request to Kerberos. The default value is 5 seconds.

# Kerberos InitCredits section

The following properties are internal Kerberos properties. If you specify a value, it overrides the corresponding setting on Kerberos. If you leave the property blank, the value defined on Kerberos applies. For more information about these properties, see Kerberos documentation.

# Proxiable

Whether credentials should be proxiable.

# Forwardable

Whether the credentials should be forwardable.

# TicketLifetime

The default lifetime for initial ticket requests.

# Kerberos Logging.ccclog section

Most of the properties in this section are reserved for internal use and should not be changed. You can configure the following properties:

# Kerberos.trfl.level

Determines the type of trace messages that are logged. Change this value to trace more or fewer events, as appropriate, or on request from Software Support. The default value is 3000, which means minimum trace information is captured. To enable maximum level of tracing, set this property to 1000.

# Kerberos.trhd.maxFileBytes

The maximum size that the trace file can reach. The default value is 10240000 bytes.

# Kerberos.trhd.maxFiles

The maximum number of trace files that can be stored. The default value is 5.

# User management

The integration supports two authentication modes:

- You can specify the same user for authenticating to Kerberos and running the job.  
- You can specify a user for authenticating to Kerberos and a different user for running the job. In this case, when you create the job definition from the Workload Designer or Graphical Designer, specify both users in the Credentials tab of the job definition with the following syntax:

```txt
job_user/kerberos_user
```

where

```txt
job_user
```

Is the user running the job

```ignorefile
kerberos_user
```

Is the user authenticating to Kerberos

# What to do next

After configuring Kerberos, you can proceed to create job definitions as usual. When you specify a user in the job definition, the Kerberos Authentication Protocol is applied.

The job can run only on the dynamic agent on which you have configured Kerberos.

# Regular maintenance

Regular maintenance refers to the mechanisms that are used on your dynamic workstation agents to free up storage space and improve performance.

Unlike IBM Workload Scheduler fault-tolerant agents, where maintenance tasks must be performed manually using the rmstdlist utility command, you can have regular maintenance performed on your dynamic agent workstations to keep disk space under control by configuring the following parameters as appropriate.

Table 18. Agent configuration parameters  

<table><tr><td>File</td><td>Parameter</td><td>Description</td></tr><tr><td>JobManager.ini located in the path</td><td>MaxAge</td><td>The number of days that job logs are kept before being deleted. The default is 2. Possible values range from a minimum of 1 day.</td></tr><tr><td>On UNIX™ operating systems</td><td></td><td></td></tr><tr><td>TWA_DATA_DIR/I</td><td>JobManager.log</td><td rowspan="2">The maximum size that the log file can reach. The default is 1024000 bytes.</td></tr><tr><td>TA/cpa/config/J</td><td>gerhd.maxFileBy</td></tr><tr><td>obManager.ini</td><td>tes</td><td></td></tr></table>

Table 18. Agent configuration parameters  
(continued)  

<table><tr><td>File</td><td>Parameter</td><td>Description</td></tr><tr><td rowspan="2">On WindowsTM operating systems</td><td>JobManager.log</td><td rowspan="2">The maximum number of log files that can be stored in the stdlist/JM directory. The default is 3.</td></tr><tr><td>gerhd.maxFiles</td></tr><tr><td rowspan="6">TWA_home\TWS\ITA\cpa\config\JobManager.ini</td><td>JobManager.fffdc</td><td rowspan="2">The maximum disk space reached, by the log files collected by the First Failure Data Capture tool, after which the oldest files are removed.</td></tr><tr><td>.maxDiskSpace</td></tr><tr><td>JobManager.trhd</td><td rowspan="2">The maximum size that the log file can reach. The default is 10240000 bytes.</td></tr><tr><td>.maxFileBytes</td></tr><tr><td>JobManager.trhd</td><td rowspan="2">The maximum number of log files that can be stored. The default is 5.</td></tr><tr><td>.maxFiles</td></tr><tr><td rowspan="2">logging.properties located in the path</td><td>java.util logging.</td><td rowspan="2">The maximum amount to write log messages to a file. Default value is 1000000 (bytes)</td></tr><tr><td>FileHandlerlimit</td></tr><tr><td>On UNIXTM operating systems</td><td>java.util logging.</td><td rowspan="2">The number of output files to cycle through. Default value is 10.</td></tr><tr><td>TWA_DATA_DIR/TWS/JavaExtcfg/</td><td>FileHandler.coont</td></tr><tr><td>On WindowsTM operating systems</td><td></td><td></td></tr><tr><td>TWA_home\TWS\JavaExt.cfg</td><td></td><td></td></tr><tr><td>Logs related to jobs with advanced options.</td><td></td><td></td></tr></table>

# Configuring the dynamic workload broker server on the master domain manager and dynamic domain manager

# About this task

You can perform these configuration tasks after completing the installation of your master domain manager, dynamic domain manager, and dynamic agents, and any time that you want to change or tune specific parameters in your environment.

The configuration parameters for the dynamic workload broker server are defined by default at installation time. You modify a subset of these parameters using the files that are created when you install dynamic workload broker. The following files are created in the path:

# On Windows systems

```txt
<TWA_home>\broker\config
```

# On UNIX systems

```txt
<TWA_DATA_DIR>/broker/config
```

# ResourceAdvisorConfig.properties

Contains configuration information about the Resource Advisor. For more information, see ResourceAdvisorConfig.properties file on page 105.

# JobDispatcherConfig.properties

Contains configuration information about the Job Dispatcher. For more information, see JobDispatcherConfig.properties file on page 107.

# BrokerWorkstation.properties

Contains configuration information about the broker server. BrokerWorkstation.properties file on page 109

# CLConfig.properties

Contains configuration information for the dynamic workload broker command line. This file is described in the section about Command-line configuration file in User's Guide and Reference.

You can modify a subset of the parameters in these files to change the following settings:

- Heartbeat signal from the agents.  
- Time interval for job allocation to resources  
- Time interval for notifications on resources  
- Polling time when checking the status of remote engine workstations  
Maximum number of results when allocating jobs to global resources  
- Encryption of any passwords sent in the JSDL definitions  
- Time interval for retrying the operation after a Job Dispatcher failure  
- Time interval for retrying the operation after a client notification failure  
- Archive settings for job data  
Job history settings  
Command line properties

The editable parameters are listed in the following sections. If you edit any parameters that are not listed, the product might not work. After modifying the files, you must stop and restart WebSphere Application Server Liberty.

# Maintaining the dynamic workload broker server on the master domain manager and dynamic domain manager

# About this task

Because one dynamic workload broker server is installed with your master domain manager and dynamic domain manager, and one server with every backup manager, you have at least two servers present in your IBM Workload Scheduler network.

The server running with the master domain manager is the only one active at any time. The servers installed in the backup managers are idle until you switch managers, and the server in the new manager becomes the active server. To have a smooth transition from one server to another, when you switch managers, it is important that you keep the same configuration settings in the ResourceAdvisorConfig.properties and JobDispatcherConfig.properties files in all your servers. When you make a change in any of these files of your running dynamic workload broker server, remember to apply the same change also in the dynamic workload broker server idling on your backup manager.

Some of the settings for the dynamic workload broker server are stored in the local BrokerWorkstation.properties file and also in the IBM Workload Scheduler database. When you switch to the backup master domain manager or dynamic domain manager, the dynamic workload broker server settings are automatically updated on the backup workstation. For more information about the BrokerWorkstation.properties file, see BrokerWorkstation.properties file on page 109.

![](images/00390a40b87659be073d7c1d2f4bb200b0177c34c5e6675e237eb0b12aff16e7.jpg)

Note: The database is automatically populated with the information from the active workstation, regardless of whether it is the manager or the backup workstation. For example, if you modify the dynamic workload broker server settings on the backup master domain manager or dynamic domain manager, this change is recorded in the database. When you switch back to the manager workstation, the change is applied to the master domain manager or dynamic domain manager and the related local settings are overwritten.

It is important that you also keep the data pertinent to every dynamic workload broker server up-to-date. If you change the host name or port number of any of your dynamic workload broker servers, use the exportserverdata and importserverdata commands from the dynamic workload broker command line to record these changes in the IBM Workload Scheduler database. For information about these commands, see Scheduling Workload Dynamically.

The database records for your workload broker workstations all have LOCALHOST as the host name of the workstation. Leave the record as-is. Do not replace LOCALHOST with the actual host name or IP address of the workstation. LOCALHOST is used intentionally to ensure that the jobs submitted from IBM Workload Scheduler are successfully sent to the new local dynamic workload broker when you switch the master domain manager or dynamic domain manager.

# Enabling unsecure communication with the dynamic workload broker server

# About this task

By default, the dynamic workload broker server uses secure communication. You might need to enable unsecure communication, even though this type of communication is not recommended.

To enable unsecure communication with the dynamic workload broker server, perform the following steps on the master domain manager:

1. Run the exportserverdata command located in TWA_home/TDWB/bin:

exportserverdata -dbUsr db_instance_admin -dbPwd db_instance_admin pwd

2. Open the resulting server.properties file in a flat-text editor.  
3. Copy the following line:

https://hostname:port/JobManagerRESTWeb/JobScheduler

4. Change the copied line by replacing https with http:

```txt
http://hostname:port/JobManagerRESTWeb/JobScheduler
```

The file now contains two lines specifying the connection mode, one line specifying the https mode and one line specifying the http mode.

5. Save the file.  
6. Import the new data with the importserverdata command located in TWA_home/TDWB/bin:

```batch
importserverdata -dbUsr db_instance_admin -dbPwd db_instance_admin pwd
```

For more information about the exportserverdata and importserverdata commands, see IBM Workload Scheduler:

Scheduling Workload Dynamically.

# ResourceAdvisorConfig.properties file

The parameters in this file affect the following dynamic workload broker server settings:

- Heartbeat signal from the agents  
- Time interval for job allocation to resources  
- Time interval for notifications on resources  
- Polling time when checking the status of remote engine workstations  
Maximum number of results when allocating jobs to global resources

You can modify the following parameters in the ResourceAdvisorConfig.properties file:

# DatabaseCheckInterval

Specifies the time interval within which the dynamic workload broker server checks the availability of the database. The default value is 180 seconds.

# ResourceAdvisorURL

Specifies the URL of the Resource Advisor.

# RaaHeartBeatInterval

Specifies the time interval within which the Resource Advisor expects a heartbeat signal from the dynamic agent. The default value is 200 seconds. After the maximum number of retries (specified in the MissedHeartBeatCount parameter) is exceeded, the Resource Advisor reports the related computer as unavailable. In a slow network, you might want to set this parameter to a higher value. However, defining a higher value might delay the updates on the availability status of computer systems. If, instead, you decrease this value together with the value defined for the NotifyToResourceAdvisorPeriodSeconds parameter, this might generate network traffic and increase CPU usage when updating cached data. The value defined in this parameter must be consistent with the NotifyToResourceAdvisorPeriodSeconds parameter defined in the JobManager.ini file, which defines the time interval for each dynamic agent to send the heartbeat signal to the Resource Advisor.

# MissedHeartBeatCount

Specifies the number of missed heartbeat signals after which the computer is listed as not available. The default value is 2. In a slow network, you might want to set this parameter to a higher value.

# MaxWaitingTime

Specifies the maximum time interval that a job must wait for a resource to become available. If the interval expires before a resource becomes available, the job status changes to Resource Allocation Failure. The default value is 600 seconds. You can override this value for each specific job by using the Maximum Resource Waiting Time parameter defined in the Dynamic Workload Console. For more information about the Maximum Resource Waiting Time parameter, see the Dynamic Workload Console online help. If you set this parameter to -1, no waiting interval is applied for the jobs. If you set this parameter to 0, the Resource Advisor tries once to find the matching resources and, if it does not find any resource, the job changes to the ALLOCATION Failed status. If you increase this value, all submitted jobs remain in WAITING status for a longer time and the Resource Advisor tries to find matching resources according to the value defined for the CheckInterval parameter.

# CheckInterval

Specifies how long the Resource Advisor waits before retrying to find matching resources for a job that did not find any resource in the previous time slot. The default value is 60 seconds.

# TimeSlotLength

Specifies the time slot interval during which the Resource Advisor allocates resources to each job. Jobs submitted after this interval has expired are considered in a new time slot. The default value is 15 seconds. The default value is adequate for most environments and should not be modified. Setting this parameter to a higher value, causes the Resource Advisor to assign resources to higher priority jobs rather than to lower priority jobs when all jobs are trying to obtain the same resource. It might also, however, cause the job resource matching processing to take longer and the resource state updates from agents to be slowed down. Setting this parameter to a lower value, causes the Resource Advisor to process the resource matching faster and, if you have a high number of agents with frequent updates, to update the resource repository immediately. If job requirements match many resources, lower values ensure a better load balancing. If most jobs use resource allocation, do not lower this value because the allocation evaluation requires many processing resources.

# NotifyTimInterval

Specifies the interval within which the Resource Advisor retries to send notifications on the job status to the Job Dispatcher after a notification failed. The default value is 15 seconds. The default value is adequate for most environments and should not be modified.

# MaxNotificationCount

Specifies the maximum number of attempts for the Resource Advisor to send notifications to the Job Dispatcher. The default value is 100. The default value is adequate for most environments and should not be modified.

# ServersCacheRefreshInterval

Specifies with what frequency (in seconds) the Resource Advisor checks the list of active and backup dynamic workload broker servers for updates. This list is initially created when the master domain manager is installed, and after that it is updated every time a new backup master is installed and connected to the master domain manager database (the master domain manager and every backup master include also a dynamic workload broker server). When the Resource Advisor agents send their data about the resources discovered in each computer, they are able to automatically switch between the servers of this list, so that the dynamic workload broker server that is currently active can store this data in its Resource Repository. For this reason, the Resource Advisor agents must know at all times the list of all dynamic workload broker servers. The possible values range between 300 (5 minutes) and 43200 (12 hours). The default value is 600 seconds.

# StatusCheckInterval

Specifies the time interval in seconds the Resource Advisor waits before polling for the status of a resource. For example this timeout applies when checking the status of a remote engine. The default value is 120 seconds.

After modifying the file, you must stop and restart WebSphere Application Server Liberty.

# JobDispatcherConfig.properties file

The parameters in this file affect the following settings for the dynamic workload broker server installed on a master domain manager or dynamic domain manager:

- Encryption of any passwords sent in the JSDL definitions  
- Time interval for retrying the operation after a Job Dispatcher failure  
- Time interval for retrying the operation after a client notification failure  
- Archive settings for job data  
Job history settings  
- Gateways and dynamic workload broker server connection settings.

After modifying the file, you must stop and restart the IBM® WebSphere® server.

During the upgrade from version 8.5.1 the values you set for the properties for version 8.5.1 are preserved. The default values for the properties for version 8.6 are different from those in version 8.5.1. If you want to use the version 8.6 defaults, change them manually.

In the JobDispatcherConfig.properties file, the following parameters are available:

# DatabaseCheckInterval

Specifies the time interval within which the dynamic workload broker server checks the availability of the database. The default value is 180 seconds.

# EnablePasswordEncryption

Specifies that any user passwords contained in the JSDL definitions are to be encrypted when the definitions are sent to the agents. The default is true. Setting this property to false forces the dynamic workload broker server to send the passwords in plain text. This applies to any password field.

# RAEndpointAddress

Specifies the URL of the Resource Advisor.

# JURL

Specifies the URL of the Job Dispatcher.

# FailQInterval

Specifies the numbers of seconds for retrying the operation after the following failures:

- Client notification.  
- Allocation, Reallocate, Cancel Allocation requests to Resource Advisor.  
- Any database operation failed for connectivity reasons.

The default value is 30 seconds. Increasing this value improves recovery speed after a failure but can use many system resources if the recovery operation is complex. For example, if the workload broker workstation is processing a new Symphony file, this operation might require some time, so you should set this parameter to a high value. If you are not using workload broker workstation, this parameter can be set to a lower value.

# MaxCancelJobAttemptsCount

The maximum number of times the Job Dispatcher attempts to cancel a shadow job or a job running on a dynamic agent when a request to kill the job is made and the kill request cannot be immediately processed. The default is 1440 attempts. The Job Dispatcher attempts to cancel the job every 30 seconds for a maximum number of times specified by this parameter.

# MaxNotificationCount

Specifies the maximum number of retries after a client notification failure. The default value is 1440. For example, if the workload broker workstation is processing a new Symphony file, this operation might require some time, so you should set this parameter to a high value. If you are not using the workload broker workstation, this parameter can be set to a lower value.

# MoveHistoryDataFrequencyInMins

Specifies how often job data must be deleted. The unit of measurement is minutes. The default value is 60 minutes. Increasing this value causes the Job Dispatcher to check less frequently for jobs to be deleted. Therefore, the volume of jobs in the Job Repository might increase and all queries might take longer to complete. Dynamic workload broker servers with high job throughput might require lower values, while low job throughputs might require higher values.

# SuccessfulJobsMaxAge

Specifies how long successfully completed or canceled jobs must be kept in the Job Repository database before being archived. The unit of measurement is hours. The default value is 240 hours, that is ten days.

# UnsuccessfulJobsMaxAge

Specifies how long unsuccessfully completed jobs or jobs in unknown status must be kept in the Job Repository database before being archived. The unit of measurement is hours. The default value is 720 hours, that is 30 days.

# AgentConnectTimeout

Specifies the number of minutes that the dynamic workload broker server waits for a scheduling agent response after it first attempts to establish a connection with that agent. If the agent does not reply within this time, the server does not open the connection. Values range from 0 to 60 (use 0 to wait indefinitely). The default is 3.

# AgentReadTimeout

Specifies the number of minutes that the dynamic workload broker server waits to receive data from established connections with a scheduling agent or a gateway. If no data arrives within the specified time, the server closes the connection with the agent. Values range from 0 to 60 (use 0 to wait indefinitely). The default is 3.

# GatewayPollingTimeout

Add this parameter to specify the number of minutes that the gateway waits to receive data from established connections with a dynamic workload broker. If no data arrives within the specified time, the gateway closes the connection with the dynamic workload broker. Values range from 1 to 60. The default is 1 minute.

# GatewayConnectionTimeout

Add this parameter to specify the number of seconds that the dynamic workload broker server waits for a gateway receiving data after the dynamic workload broker first attempts to send data to the gateway. If the gateway does not reply within this time, the dynamic workload broker does not open the connection. Values range from 1 to 60. The default is 10 seconds.

# MaxNumberOfParallelGateways

Add this parameter to specify the number of gateways that dynamic workload broker server can manage without lack of performances. Values range from 3 to 100. The default is 3.

![](images/b32bc78322a299b2bb59ceaf4045019633f6b039735f6e47b824443c7f56dc95.jpg)

# Note:

If an unexpected job workload peak occurs and a cleanup of the database is required earlier than the value you specified in the MoveHistoryDataFrequencyInMins parameter, you can use the movehistorydata command to perform a cleanup before the scheduled cleanup is performed.

# BrokerWorkstation.properties file

If you need to make configuration changes to the broker server after the installation has completed, you can edit the BrokerWorkstation.properties file. The BrokerWorkstation.properties file contains the following configuration properties:

# Broker.AuthorizedCNs

The list of prefixes of common names authorized to communicate with the broker server.

# Broker.CertificateExpirationInterval

The number of days before the certificate on the agent expires. During this interval, the certificate is set in expiring status and the agent tries to download a new version of the certificate from the master domain manager, if available. Supported values are any integer greater than zero. The default value is 15 days.

# Broker.fileproxy.urls

If you defined a stand-alone file proxy using the fileproxyinst command, you can optionally use this property to specify the URL of an alternate stand-alone file proxy for high availability configuration. You can implement one of the following configurations:

- Specify one or more proxy servers, separated by commas. If one of the file proxies stops unexpectedly, the other file proxy takes over.  
- Specify a load balancer. If one of the file proxies stops unexpectedly, the load balancer switches the workload to one of the available file proxies.

Use the following syntax:

```txt
[http/https]://[fileproxy host]:[file proxy port]
```

This procedure does not apply if you use the default file proxy installed with each master domain manager.

For more information about the File Transfer integration, see the File Transfer integration on Automation Hub.

For more information about installing the file proxy as a stand-alone component, see the section about the fileproxyinst script in IBM Workload Scheduler: Planning and Installation.

# Broker.jobLog.corePoolSize

The size of the thread pool that serves core services and job log requests. The maximum supported number of concurrent job log requests corresponds to the value set for Broker.jobLog.corePoolSize minus 5. For example, if Broker.jobLog.corePoolSize is set to 20, the maximum supported number of concurrent job log requests is 15. Issuing a number of concurrent job log requests higher than this value (15 in the example) causes the dynamic domain manager to hang and requires a restart of the application server. The default value, when the property is not specified in the BrokerWorkstation.properties file or empty, is 50.

# Broker.Workstation.CpuType

The workstation type assigned to the broker server. Supported values are:

- master domain manager (master)  
- backup master domain manager (fta)  
dynamic domain manager (fta, broker, agent)  
- backup dynamic domain manager (fta, broker, agent)

# Broker.Workstation.Enabled

A switch that enables or disables the broker server. The value can be true or false. The default value is true.

Set this value to false if you decide not to use a broker server. Not using the broker server means that you can submit jobs dynamically on the dynamic workload broker directly (using either the Dynamic Workload Console or the dynamic workload broker command line) without using the scheduling facilities of IBM Workload Scheduler.

# Broker.Workstation.Name

The name of the broker server in the IBM Workload Scheduler production plan. This name is first assigned at installation time.

# Broker.Workstation.PortSSL

The port used by the broker server to listen to the incoming traffic (equivalent to the Netman port) in SSL mode. It is first assigned at installation time. This port number must always be the same for all the broker servers that you define in your IBM Workload Scheduler network (one with the master domain manager and one with every backup master you install) to ensure consistency when you switch masters.

# Broker.Workstation.Port

The port used by the broker server to listen to the incoming traffic (equivalent to the Netman port). It is first assigned at installation time. This port number must always be the same for all the broker servers that you define in your IBM Workload Scheduler network (one with the master domain manager and one with every backup master you install) to ensure consistency when you switch masters.

# Broker.Workstation.RetryLink

The number of seconds between consecutive attempts to link to the broker server. The default is 600.

# DomainManager.Workstation.Domain

The name of the domain where the broker server is registered.

# DomainManager.Workstation.Name

The name of the domain manager workstation.

# DomainManager.Workstation.Port

The port of the domain manager workstation.

# MasterDomainManager.HostName

The host name of the master domain manager workstation.

# MasterDomainManager.HttpsPort

The HTTPS port of the master domain manager workstation.

# MasterDomainManager.Name

The name of the master domain manager workstation.

If you need to modify the event processor server, for example to use a load balancer, add the following two keywords in the file:

Broker.Workstation.evtprocprevious_hostname  $\equiv$  new_hostname

Specify the previous hostname and the new hostname of the event processor.

Broker.Workstation.evtprocprevious_port  $\equiv$  new_port

Specify the previous and new port of the event processor.

After stopping and restarting WebSphere Application Server Liberty, the dynamic domain manager sends the updated information to the dynamic agents.

# Archiving job data

Job definitions created using the Dynamic Workload Console are stored in the Job Repository database. The Job Repository database stores also the jobs created when the job definitions are submitted to the dynamic workload broker.

Job information is archived on a regular basis. By default, successful jobs are archived every 24 hours. Jobs in failed or unknown status are archived by default every 72 hours.

You can configure the time interval after which job data is archived using the following parameters:

- MoveHistoryDataFrequencylnMins  
- SuccessfulJobsMaxAge  
- UnsuccessfulJobsMaxAge

These parameters are available in the JobDispatcherConfig.properties file, as described in JobDispatcherConfig.properties file on page 107. You can also use the movehistorydata command to perform a cleanup before the scheduled cleanup is performed.

# Configuring to schedule J2EE jobs

# About this task

Using the dynamic workload broker component you can schedule J2EE jobs. To do this you must complete the following configuration tasks:

- Configure the J2EE executor on page 112 on every agent on which you submit J2EE jobs.  
- Configure the J2EE Job Executor Agent on page 117 on an external WebSphere® Application Server

# Configuring the J2EE executor

# About this task

To dynamically schedule J2EE jobs, you must configure the following property files on every agent on which you submit J2EE jobs:

- J2EEJobExecutorConfig.properties  
- logging.properties  
- soap.client props

These files are configured with default values at installation time. The values that you can customize are indicated within the description of each file.

# J2EEJobExecutorConfig.properties file

Use the J2EEJobExecutorConfig.properties file to configure the J2EE executor

The file is located in:

On Windows operating systems

```txt
TWA_home>JavaExtversion_number> \cfg
```

On UNIX operating systems

```txt
TWA_DATA_DIR>/JavaExtcfg
```

The keywords of this file are described in the following table:

Table 19. J2EEJobExecutorConfig.properties file keywords

Table 19. J2EEJobExecutorConfig.properties file keywords (continued)  

<table><tr><td>Keyword</td><td>Specifies...</td><td>Default value</td><td>Must be customized</td></tr><tr><td></td><td>invoker means that dynamic workload broker uses an existing WebSphere® Application Server scheduling infrastructure that is already configured on a target external WebSphere® Application Server.</td><td>·indirect keyword
·Name of the scheduler: sch/MyScheduler
·soap keyword
·Host name of the external WebSphere® Application Server instance: washost.mydomain.com
·SOAP port of the WebSphere® Application Server instance: 8880
·Path to the soap.client props file: TWA_home/TWS/JavaExt/cfg/soap.client props
·Credentials keyword: mycred</td><td>·The scheduler name. Replace the sch/MyScheduler string with the JNDI name of the IBM® WebSphere® scheduler that you plan to use.
·The host name of the external WebSphere® Application Server instance.
·The SOAP port of the external WebSphere® Application Server instance.</td></tr><tr><td>connector.direct</td><td>The name of the direct communication channel without using the WebSphere® Application Server scheduler. Select a direct invoker to have dynamic workload brokerimmediately forward the job to the external WebSphere® Application Server instance components (EJB or JMS). When creating the job definition, you can specify if you want to use a direct or indirect connector in the J2EE Application pane in the Application page in the Job Brokering Definition Console, or in the invoker element in the JSDL file. For more</td><td>A single line with the following values separated by commas:</td><td>You must customize the following:
·The host name of the external WebSphere® Application Server instance: washost.mydomain.com
·The RMI port of the external WebSphere® Application Server instance: 2809</td></tr></table>

Table 19. J2EEJobExecutorConfig.properties file keywords (continued)  

<table><tr><td>Keyword</td><td>Specifies...</td><td>Default value</td><td>Must be customized</td></tr><tr><td></td><td>information about the Job Brokering Definition Console, see the online help.</td><td></td><td></td></tr><tr><td>trustStore.path</td><td>The path to the WebSphere® Application Server trustStore file (this file must be copied to this local path from the WebSphere® Application Server instance).</td><td>TWA_home/TWS/JavaExtcfg/Dumm yClientTrustFile</td><td>You can change the path (TWA_home/TWS/JavaExtcfg), if you copy the trustStore path from the external WebSphere® Application Server to this path.</td></tr><tr><td>trustStore-password</td><td>The password for the WebSphere® Application Server trustStore file.</td><td>WebAs</td><td>Yes</td></tr></table>

# The logging.properties file

# About this task

The path to this file is TWA_home/TWS/JavaExtcfg/logging.properties (TWA_home\TWS\JavaExt.cfg\logging.properties) on the agent.

After installation, this file is as follows:

```txt
Set the default logging level for the logger named com.mycompany.com.ibm.scheduling = INFO
```

You can customize:

- The logging level (from INFO to WARNING, ERROR, or ALL) in the following keywords:

.level

Defines the logging level for the internal logger.

com.ibm.scheduling

Defines the logging level for the job types with advanced options. To log information about job types with advanced options, set this keyword to ALL.

- The path where the logs are written, specified by the following keyword:

java.utillogging.FileHandler-pattern

# The soap.client props file

# About this task

The path to this file is as follows:

On Windows operating systems

```batch
<TWA_home>\TWS\JavaExt\fsg\soap.client props
```

On UNIX operating systems

```txt
<TWA_DATA_DIR>/JavaExtcfg/soap.client props
```

After installation, this file is as follows:

```txt
# prompt:GUI dialog box; falls back tostdin if GUI not allowed
# (So to disable auto prompting, set loginSource to nothing)
#
com.ibm.SOAP-loginSource=prompt
#
# SOAP Request Timeout
#
# - timeout (specified in seconds [default 180], 0 implies no timeout)
#
#
com.ibm.SOAP.requestTimeout=180
#
# SSL configuration alias referenced in ssl.client props
#
com.ibm~-DefaultSSLSettings
```

If you want to enable SOAP client security, you must:

1. Change com.ibm.SOAP.securityEnabled to true  
2.Customize:

com.ibm.SOAP loginUserID with the true WebSphere Application Server Liberty administrator user ID.  
com.ibm.SOAP loginPassword with the true WebSphere Application Server Liberty administrator password in {xor} encrypted format. For further details about encrypting and decrypting passwords in xor format, see the documentation, for example WebSphere {xor} password decoder and encoder.

# Configuring the J2EE Job Executor Agent

# About this task

To set up the environment on the external WebSphere® Application Server, Version 7.0 for the J2EE Job Executor Agent, do the following:

# Create a Service Integration Bus

1. Open the WebSphere® Administrative Console (for example, http://localhost:9060/admin, depending on the admin port you configured).  
2. Expand Service Integration and select Buses. The Buses window is displayed.  
3. Click New to display the Buses configuration window.  
4. Type a name for the new bus, for example MyBus and click Next and then Finish to confirm.  
5. Click the MyBus name and the MyBus properties are displayed.  
6. Under Topology, click Bus Members. The Buses  $\rightarrow$  MyBus  $\rightarrow$  Bus members window is displayed.  
7. Click Add, select the Server radio button, choose your.application.server_name, click Next, and then click Finish.  
8. When the Confirm the addition of a new bus member panel is displayed, click Finish.  
9. Select Service Integration  $\rightarrow$  Buses  $\rightarrow$  MyBus  $\rightarrow$  Destinations  $\rightarrow$  New.

10. Select Queue as the type and click Next  
11. Type BusQueue as the identifier and assign the queue to a bus member. Click Next. In the confirmation panel click Finish.

# Configure the Default Messaging Service

1. From the left panel of the WebSphere® Administrative Console, expand Resources  $\rightarrow$  JMS  $\rightarrow$  JMS Providers, then click Default messaging at the server level as scope.  
2. In the Connection Factories section, click New.  
3. On the New JMS connection factory window, type in the following fields:

Name

MyCF

JNDI name

jms/MyCF

Bus name

MyBus

Provider endpoints

<hostname>:_Basic SIB port number>:BootstrapBasicMessaging;<hostname>:_Secure SIB port number>:BootstrapSecureMessaging

4. Select again Resources  $\rightarrow$  JMS-  $\rightarrow$  JMS Providers  $\rightarrow$  Default Messaging at the server level as scope, locate the section Destinations, and click Queues. Click New and type in the following fields as shown:

Name=MyQueue

JNDI name=jms/MyQueue

Bus name=MyBus

Queue name  $=$  BusQueue

Click Ok.

5. Select again Resources  $\rightarrow$  JMS  $\rightarrow$  JMS Providers  $\rightarrow$  Default Messaging at the server level as scope, and locate the section Activation Specifications.  
6. Click JMS activation specification. Click New and type in the following fields as shown:

Name=MyActSpec

JNDI name=eis/MyActSpec

Bus name=MyBus

Destination type=Queue

Destination JNDI name=jms/MyQueue

Click Ok.

# Configure the Java security

1. Select Security  $\rightarrow$  Secure Administration, applications and infrastructure.  
2. Locate the Authentication section, expand the Java Authentication and Authorization Service, and click J2C authentication data.  
3. Click New and type in the following fields as shown:

Alias=usr

User ID  $\equiv$  usr

Password  $\equiv$  pwd

where  $usr$  is the user ID authenticated when using connector security and  $pwd$  is the related password.

4. Click Ok.

# Create an XA DataSource

1. In the left pane, go to Resources  $\rightarrow$  JDBC..  $\rightarrow$  JDBCProviders. In the resulting right pane, check that the scope is pointing to your.application_server_name.  
2. Locate the DERBY JDBC Provider (XA) entry and click it.  
3. Locate the Additional Properties section and click Data Sources.  
4. Click New and type in the following fields as shown:

Name = MySchedulerXADataSource

JNDI name = jdbc/SchedulerXADS

Database name = ${USERInstall_ROOT}/databases/Schedulerulers/$${SERVER}/SchedulerDB;create=true

5. At the top of the page, click Test connection button.  
6. Even if you get a negative result, modify the Database name field, deleting the part ;create=true. Click Ok.

# Create a WorkManager

1. In the left pane, go to Resources  $\rightarrow$  Asynchronous beans  $\rightarrow$  Work managers and click New.  
2. type in the following fields as shown:

Name=SchedulerWM

JNDI name=wm/SchedulerWM

3. Click Ok.

# Create and configure a scheduler

1. In the left pane, go to Resources  $\rightarrow$  Schedulers and click New.  
2. type in the following fields as shown:

Name=MyScheduler

JNDI name=sch/MyScheduler

Data source JNDI name=jdbc/SchedulerXADS

Table prefix=MYSCHED

Work managers JNDI name=wm/SchedulerWM

3. Click Ok.  
4. Select MyScheduler and click Create tables.  
5. Deploy the test application.

# Security order of precedence used for running J2EE tasks

There are three ways of verifying that a task runs with the correct user credentials. Tasks run with specified security credentials using the following methods:

1. Java™ Authentication and Authorization Service (JAAS) security context on the thread when the task was created.  
2. setAuthenticationAlias method on the TaskInfo object.  
3. A specified security identity on a BeanTaskInfo task TaskHandler EJB method.

The authentication methods are performed in the order listed above, so that if an authentication method succeeds, the following checks are ignored. This means that the usr and pwd credentials defined in Configure the Java™ security take precedence over any credentials specified in the tasks themselves.

# Configuring to schedule job types with advanced options

# About this task

You can define job types with advanced options by using the related configuration files. The options you define in the configuration files apply to all job types with advanced options of the same type. You can override these options when defining the job by using the Dynamic Workload Console or, if you are in a distributed environment, the composer command.

Configuration files are available on each dynamic agent in TWA_home/TWS/JavaExtcfg for the following job types with advanced options:

Table 20. Configuration files for job types with advanced options  

<table><tr><td>Job type</td><td>File name</td><td>Keyword</td></tr><tr><td>·Database job type
·MSSQL Job</td><td>DatabaseJobExecutor.properties</td><td>Use the jdbcDriversPath keyword to specify the path to the JDBC drivers. Define the keyword so that it points to the JDBC jar files directory, for example:
jdbcDriversPath=c:\mydir\jars\jdbc
The JDBC jar files must be located in the specified directory or its subdirectories. Ensure you have list permissions on the directory and its sub directories.
Note: For the MSSQL database, use version 4 of the JDBC drivers.</td></tr><tr><td>Java™ job type</td><td>JavaJobExecutor.properties</td><td>Use the jarPath keyword to specify the path to the directory where the jar files are stored.</td></tr></table>

Table 20. Configuration files for job types with advanced options (continued)  

<table><tr><td>Job type</td><td>File name</td><td>Keyword</td></tr><tr><td></td><td></td><td>This includes all jar files stored in the specified directory and all sub directories.</td></tr><tr><td>J2EE job type</td><td>J2EEJobExecutorConfig.properties</td><td>For more information about the J2EE job type, see the topic about configuring to schedule J2EE jobs in the IBM Workload Scheduler: Administration Guide.</td></tr></table>

# Configuring security roles for users and groups

The dynamic workload broker provides two commands for managing resources and job definitions:

# resource

to create, modify, associate, query, or set resources online or offline. For more information, see the section about the resource command in User's Guide and Reference.

# jobstore

to manage job definitions. For more information, see the section about the jobstore command in Scheduling Workload Dynamically.

At master domain manager installation time, the broker_role Mapping.xml template is created to configure in WebSphere Application Server Liberty the users and groups authorized to use the dynamic workload broker commands. For the configuration procedure, see Mapping security roles to users and groups in WebSphere Application Server Liberty on page 121.

# Mapping security roles to users and groups in WebSphere Application Server Liberty

# About this task

When the dynamic workload broker instance is installed on your master domain manager, corresponding roles are set up in WebSphere Application Server Liberty. By default, these roles are not used. However, the authorization required to perform any tasks is always validated by WebSphere Application Server Liberty. Users are required to provide credentials for managing resources and job definitions using the resource and jobstore commands. These credentials correspond to existing users defined in the domain user registry or the LDAP server.

To allow users and groups to access the dynamic workload broker functions, they must be mapped to the security roles in WebSphere Application Server Liberty. This mapping allows those users and groups to access applications defined by the role. At installation time, the IBM® Workload Scheduler administrative user (wauser) is assigned the Administrator role in WebSphere Application Server Liberty. The following roles are also created but they are not assigned to any users nor groups:

# Operator

Monitors and controls the jobs submitted.

# Administrator

Manages the scheduling infrastructure.

# Submitter

Manages the submission of their own jobs and monitors and controls the job lifecycle. This is the typical role for an IBM Workload Scheduler user.

IBM Workload Scheduler acts as a submitter of jobs to the IBM Workload Scheduler dynamic agent.

# Configurator

Is the entity responsible for running the jobs on a local environment.

To map security roles to users and groups on the WebSphere Application Server Liberty, edit the broker-role Mapping.xml file located in <Liberty_installation_directory>/usr/server/ENGINEServer/ configDropins.

You can edit the file to associate users and groups to the Operator, Administrator, Developer, or Submitter roles, as follows:

1. Copy the template file from the templates folder to a working folder.  
2. Edit the template file in the working folder with the desired configuration.  
3. Optionally, create a backup copy of the relevant configuration file present in the overrides directory in a different directory. Ensure you do not copy the backup file in the path where the template files are located.  
4. Copy the updated template file to the overrides folder. Maintaining the original folder structure is not required.  
5. Changes are effective immediately.

To enable all users to use the dynamic workload broker commands, remove the comment from the special-subject string, otherwise, specify the list of users or groups for each role.

# Examples

In the following example, the Operator role is associated to user user1, the Submitter role is associated to all users belonging to group1, and the Configurator role is associated to all users authenticated by the server:

```txt
<server> <enterpriseApplication id="SchedulerEAR"> <application-bnd> <security-role id="adminRole" name="Administrator"> <user access-id="${user.twsuser.id}" name="${user.twsuser.id}" /> <run-asuserid="${user.twsuser.id}" password="${user.twsuser.password}" /> </security-role> <security-role id="operatorRole" name="Operator"> <user name=?user1? /> </security-role> <security-role id="submitRole" name="Submitter"> <group name=?group1? /> </security-role> <security-role id="configuratorRole" name="Configurator">
```

```txt
<special-subject type="ALL_AUTHENTICATED_USERS"/> </security-role> </application-bnd> </enterpriseApplication>
```

# broker_roleMapping.xml file

# Example

```xml
<server> <enterpriseApplication id="SchedulerEAR"> <application-bnd> <security-role id="adminRole" name="Administrator"> <user access-id="${user.twsuser.id}" name="${user.twsuser.id}" /> <run-asuserid="${user.twsuser.id}" password="${user.twsuser.password}" /> </security-role> <security-role id="operatorRole" name="Operator"> </security-role> <security-role id="submitRole" name="Submitter"> </security-role> <security-role id="configuratorRole" name="Configurator"> </security-role> </application-bnd> </enterpriseApplication>
```

# Configuring command-line client access authentication

This section describes how to reconfigure the connection used by the command line client.

The command line client is installed automatically on the master domain manager and on fault-tolerant agents. On the master domain manager you use it to run all of the commands and utilities.

On any other workstation you use it to run one of the following commands:

- composer  
conman  
- evtdef  
- logman  
- optman  
planman  
- sendevent  
- wappman

It is configured automatically by the installation process, but if you need to change the credentials that give access to the server on the master domain manager, or you want to use it to access a different master domain manager, modify the connection parameters as described in Connection parameters on page 124.

![](images/daf5ff6623e43050d64b6d8fe093720da15400c2d0e01bf237bbcc8e5bcab747.jpg)

# Note:

1. The connection parameters are not required to use the local conman program on a fault-tolerant agent.  
2. The command-line client on the master domain manager uses exactly the same mechanism to communicate with the server as it does when it is installed remotely.

# Connection parameters

# About this task

The connection parameters can be provided in one of three ways:

# Define them as local options in the locallyts file

All fields except username and password, can be defined by editing the TWA_home/TWS/localopts properties file on the computer from which the access is required. See Setting local options on page 48 for a full description of the file and the properties.

In localopts there is a section for the general connection properties, which contains the following:

```ini
host = host_name  
protocol = protocol  
port = port number  
proxy = proxy server  
proxyport = proxy server port number  
timeout = seconds  
defaultws = master_workstation  
useropts = useropts_file
```

In addition, there is a separate set of SSL parameters:

```txt
CLI SSL server auth = yes|no  
CLI SSL cipher = cipher_class  
CLI SSL server certificate = certificate_file_name  
CLI SSL trusted dir = trusted_directory
```

# Store some or all of them as user options in the useroptions file

As a minimum, the username and password parameters can be defined in the user_home/.TWS/userscripts file for the user who needs to make the connection. Also, if you need to personalize for a user any of the properties normally found in the localots file, add the properties to the useropts file. The values in the useropts file always take precedence over those in the localots file.

The minimum set of properties you would find in useroptions is as follows:

```txt
username  $\equiv$  user_ID password  $\equiv$  password
```

You can also add the JWT in the useroptions file. See Setting user options on page 70 for a full description of the file and the properties.

# Supply them when you use the command

When you use any of the commands you can add one or more of the connection parameters to the command string. These parameters take precedence over the parameters in localots and userpts. This allows you, for example, to keep the parameters in the localots file and just get users to supply the username and password parameters when they use one of the commands, avoiding the necessity to store this data in the userpts file for each user..

The parameters can either be supplied fully or partially in a file, to which you refer in the command string, or typed directly as part of the command string. The full syntax is as follows:

```txt
[-file <parameter_file>   
|   
[-host <host_name>]   
[-port <port_number>]   
[-protocol {http|https}]   
[-proxy <proxy_name>]   
[-proxyport <proxy_port_number>]   
[-jwt JSON Web Token]   
[-username <username>]   
[-password <user_password>]   
[-timeout <timeout>]
```

-file <parameter_file>

A file containing one or more of the connection parameters. Parameters in the file are superseded if the corresponding parameter is explicitly typed in the command.

-host <host_name>

The host name or IP address of the master domain manager to which you want to connect.

-port <port_number>

The listening port of the master domain manager to which you want to connect.

-protocol{http|https}

Enter either http or https, depending on whether you want to make a secure connection.

- proxy <proxy_name>

The host name or IP address of the proxy server involved in the connection (if any).

-proxyport <proxy_port_number>

The listening port of the proxy server involved in the connection (if any).

[-jwt JSON Web Token]

Specify the JWT to be used for authentication between the master domain manager and agents.

You can retrieve the token from the Dynamic Workload Console. This parameter is mutually exclusive with the username and password parameters. The JWT authentication applies to the commands you launch in the shell where you specify the JWT.

You can use JWT when running the following commands:

- composer  
conman  
- wappman

# [-username user_name]

An IBM Workload Scheduler user with sufficient privileges to perform the operation. This parameter is mutually exclusive with the jwt parameter.

# [-password password]

The password of the IBM Workload Scheduler user. This parameter is mutually exclusive with the jwt parameter.

# -timeout <timeout>

The number of seconds the command line client is to wait to make the connection before giving a timeout error.

![](images/259ad82b5b294c410cc0dc8ab46daa6d512affdf9c40b3e3f5c67799bc869064.jpg)

# Note:

From the command line, neither the default workstation, nor the command line client SSL parameters can be supplied. These must always be supplied in either the localopts (see Setting local options on page 48) or the useropts file for the user (see Setting user options on page 70).

For monitoring commands, such as conman showjobs, conman showresources, and so on, IBM® Workload Scheduler uses the connection parameters of the user logged on to the computer

The command line client needs to assemble a full set of parameters, and it does so as follows:

1. First it looks for values supplied as parameters to the command  
2. Then, for any parameters it still requires, it looks for parameters supplied in the file identified by the -file parameter  
3. Then, for any parameters it still requires, it looks in the useropts file for the user  
4. Finally, for any parameters it still requires, it looks in the localopts file

If a setting for a parameter is not specified in any of these places an error is displayed.

# Entering passwords

# About this task

Password security is handled as follows:

# Password entered in useropts file

You type the connection password into the useropts file in unencrypted form. When you access the interface for the first time it is encrypted. This is the preferred method.

# Password entered in the parameter file used by the command

You type the connection password into the parameter file in unencrypted form. It is not encrypted by using the command. Delete the file after use to ensure password security.

# Password entered using the -password parameter in the command

You type the password in the command string in unencrypted form. It remains visible in the command window until you clear the command window contents.

![](images/ff64ae21fc00e84621a2c43213a79288c5399a79ae7f57e3f4279cfbb3e7d7e7.jpg)

Note: On WindowsTM workstations, when you specify a password that contains double quotation marks (") or other special characters, make sure that the character is escaped. For example, if your password is tws11"tws, write it as "tws11\"tws" in useropts.

# An active-active high availability scenario

Implement active-active high availability between the Dynamic Workload Console and the master domain manager so that a switch to a backup is transparent to Dynamic Workload Console users.

Use a load balancer between the Dynamic Workload Console servers and the master domain manager so that in the event the master needs to switch to a backup, the switch is transparent to console users.

Configure the master domain manager and backup master domain managers behind a second load balancer so that the workload is balanced across all backup master domain managers and the master domain manager. Load balancing distributes workload requests across all configured nodes to avoid any single node from being overloaded and avoids a single point of failure.

You might already have installed and configured a number of backup master domain managers, in addition to your master domain manager, that you use for dedicated operations and to alleviate the load on the master domain manager. For example, you might have one dedicated to monitoring activities, another for event management, and perhaps your scheduling activities are run on the master domain manager. Administrators must create engine connections for each of these and users have to switch between engines to run dedicated operations. Should one of them go down, users need to be notified about which engine to use as a replacement and switch to the replacement engine.

To simply this, configure a load balancer in front of the master domain manager and backup master domain managers so that users are unaware of when a switch occurs and administrators configure a single engine connection in single-sign on that points to the name or IP address and port number of the load balancer and not ever need to know the hostname of the current active master. The load balancer monitors the engine nodes and takes over the task of balancing the workload and the switch to a backup master domain manager is completely transparent to console instance users. Any backup master domain manager can satisfy HTTP requests, even those that can be satisfied only by the active master, such as requests on the plan, because the requests are proxied to and from the active master.

To complete the picture of a full high availability IBM® Workload Scheduler environment, the RDBMS and the Dynamic Workload Console need to be configured in high availability. If your RDBMS includes a high availability disaster recovery (HADR) feature and it is enabled, you can configure the datasource.xml file on the WebSphere Application Server Liberty server of the master and backup components to add failover properties. The key-value pairs to set depend on your specific

RDBMS. As an example, Db2®'s datasource can be configured with the following set of properties in the XML element named properties.db2.jcc:

```txt
<properties.db2.jcc  
databaseName="TWS"  
user="..."  
password="..."  
serverName="MyMaster"  
portNumber="50000"  
clientRerouteAlternateServerName="MyBackup"  
clientRerouteAlternatePortNumber="50000"  
retryIntervalForClientReroute="3000"  
maxRetriesForClientReroute="100"  
/>
```

For the Dynamic Workload Console, replicate it, and link the consoles to a load balancer that supports session affinity so that requests related to the same user session are dispatched to the same console instance.

![](images/5659025abe00e6d6af9333ceb735eabd4d3d363029e6f2462e3ee27a49d85b03.jpg)

Note: If your environment includes the IBM Workload Scheduler Agent for z/OS to schedule jobs (JCL) on the JES2 subsystem of z/OS, ensure that the value for the host.Bootstrap.port.sec parameter specified in the ports_variables.xml file is the same on every workstation hosting the Dynamic Workload Console component in your environment. For more information about the location of the ports_variables.xml file, see Configuring IBM Workload Scheduler using templates on page 418.

The following is a sample of the high-level architecture of an active-active high availability system with two load balancers

![](images/7868ff06624360f5460cdef24b375a81e3ed0997783dd67d8212aaf16e010d1c.jpg)  
Figure 1. And end-to-end environment configured for high availability

This environment configuration offers numerous benefits:

# High availability

The load balancer monitors the nodes and takes care of balancing the workload across the nodes, eliminating the possibility of a node creating a single point of failure.

# Scalability

As client requests increase, you can add additional backup master domain manager nodes to the configuration to support the increased workload.

# User-friendly

Users are unaware of when a switch occurs to a different node. Administrators do not have to worry about creating new engine connections to run workloads on a different node.

# Low overhead

This configuration does not require any manual intervention when nodes become unavailable. Additional flexibility is provided to console instance users who no longer have to run certain operations on dedicated nodes.

# Optimization of hardware

Load balancing distributes session requests across multiple servers thereby utilizing hardware resources equally.

![](images/81782ce43abd42fb2a2702206caa27b7213111332ef0741e8d60aff3c580dd20.jpg)

Note: When there are multiple Dynamic Workload Console servers connected to a load balancer and one of the servers becomes unavailable, load balancing takes place automatically, however, console users need to perform a page refresh and reopen any tabbed pages that were previously opened.

The following is intended to be a high-level view of the steps required to implement a scenario of this kind. It is an example and is not meant to be a verified procedure.

1. Install a load balancer on a workstation either within the IBM® Workload Scheduler environment or external to the environment. Ports must be open between the load balancer and the Dynamic Workload Console nodes and the engine nodes.  
2. Configure multiple Dynamic Workload Console instances in a cluster where the consoles share the same repository settings and a load balancer takes care of dispatching and redirecting connections among the nodes in the cluster. The load balancer must support session affinity. See the topic about configuring high availability across multiple Dynamic Workload Console nodes.  
3. Exchange certificates between the load balancer and the Dynamic Workload Console and between the second load balancer and the master domain manager and backup master domain manager nodes.  
4. Configure the load balancer configuration file with details about the Dynamic Workload Console, master domain manager, and backup master domain managers. The configuration file indicates which nodes (Dynamic Workload Console, master domain manager, and backup master domain managers) are available and the routes to be used to dispatch client calls to the Dynamic Workload Console server nodes.  
5. Configure an engine connection that points to the name or IP address of the load balancer, and specify the incoming port number to the load balancer that corresponds to the outgoing port number to the master (default port number 31116). The load balancer must point to the HTTPS of the Dynamic Workload Console and the HTTPS of the master domain manager.  
6. Configure an RDBMS in high availability and enable the HADR feature.

7. To configure the Dynamic Workload Console nodes in a cluster behind the load balancer, modify the

ports_config.xml file as follows:

```txt
<httpEndpoint host="${httpEndpoint.host}" httpPort="${host.http.port}" httpsPort="${host=https.port"} id="defaultHttpEndpoint">
    <httpOptions removeServerHeader="true"/>
    <remoteIp useRemoteIpInAccessLog="true"/>
</httpEndpoint>
```

This solution requires a load balancer that supports session affinity. Nginx is an example of a load balancer of this kind. The following is an abstract from a configuration file for an Nginx load balancer that demonstrates the configuration settings necessary to implement the high availability use case depicted in Figure 1: And end-to-end environment configured for high availability on page 128.

```txt
user nginx;   
worker_processes 10; #Default: 1   
worker_rlimit_nofile 8192;   
error_log /var/log/nginx-error.log warn;   
pid /var/run/nginx.pid;   
events { worker Connections 4096; Default: 1024 }   
http { include /etc/nginx/mime.types; default_type application/ocet-stream; log_format main 'remote_addr - remote_user [\ $time_local]"\$ request" \ $status \$body_bytes_sent "$ http_referer" "'\"\$http_user_agent''\$http_x.forwarded_for'''; access_log /var/log/nginx/access.log main; sendfile on;   
keepalive_timeout 65;   
upstream waSOLE nolse { ##DWC configuration ip_hash; server DWC1_HOSTNAME:DWC1_PORT max_fails  $= 3$  fail_timeout  $= 300s$  server DWC2_HOSTNAME:DWC2_PORT max_fails  $= 3$  fail_timeout  $= 300s$  keepalive 32; }   
upstream waServer頁backend_htps { server MDM1_HOSTNAME:MDM1_PORT weight  $= 1$  server MDM2_HOSTNAME:MDM2_PORT weight  $= 1$
```

```txt
}   
server{ listen 443 ssl; ssl_certicate /etc/nginx/certs/nginx.crt; ssl_certicate_key /etc/nginx/certs/nginxkey.key; ssl_trusted_certicate /etc/nginx/certs/cca-certificates.crt; location / { proxy_pass https://wa(Console; proxy_cache off; proxy_set_header Host $host; proxy_set_header Forwarded " $proxy_add_x.forwarded_for;proto=$scheme"; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x.forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Port 443; } }   
server{ listen 9443 ssl; ssl_certicate /etc/nginx/certs/nginx.crt; ssl_certicate_key /etc/nginx/certs/nginxkey.key; ssl_trusted_certicate /etc/nginx/certs/ca-certificates.crt; location / { proxy_pass https://wa/server�建立https; proxy_cache off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x.forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Connection "close"; } }
```

where:

# DWCx_HOSTNAME:DWCx_PORT

is the address of the Dynamic Workload Console.

# MDMx_HOSTNAME:MDMx_PORT

is the address of the master domain manager.

# IBM Workload Scheduler console messages and prompts

The IBM Workload Scheduler control processes (Netman, Mailman, Batchman, Jobman, and Writer) write their status messages (referred to as console messages) to standard list files. These messages include the prompts used as job and Job Scheduler dependencies. On UNIX® and Linux® operating systems, the messages can also be directed to the syslog daemon (syslogd) and to a terminal running the IBM Workload Scheduler console manager. These features are described in the following sections.

# Setting sysloglocal on UNIX

# About this task

If you set sysloglocal in the local options file to a positive number, IBM Workload Scheduler's control processes send their console and prompt messages to the syslog daemon. Setting it to -1 turns this feature off. If you set it to a positive number to enable system logging, you must also set the local option stdlistwidth to 0, or a negative number.

IBM Workload Scheduler's console messages correspond to the following syslog levels:

# LOG_ERR

Error messages such as control process abends and file system errors.

# LOG_WARNING

Warning messages such as link errors and stuck job streams.

# LOG_NOTICE

Special messages such as prompts and tellops.

# LOG_INFO

Informative messages such as job launches and job and Job Scheduler state changes.

Setting sysloglocal to a positive number defines the syslog facility used by IBM Workload Scheduler. For example, specifying 4 tells IBM Workload Schedulerto use the local facility LOCAL4. After doing this, you must make the appropriate entries in the /etc/syslog.conf file, and reconfigure the syslog daemon. To use LOCAL4 and have the IBM Workload Scheduler messages sent to the system console, enter the following line in /etc/syslog.conf:

```txt
local4 /dev/console
```

To have the IBM Workload Scheduler error messages sent to the maestro and root users, enter the following command:

```txt
local4.err maestro,root
```

The selector and action fields must be separated by at least one tab. After modifying /etc/syslog.conf, you can configure the syslog daemon by entering the following command:

```batch
kill -HUP `cat /etc/syslog.pid`
```

# console command

# About this task

You can use the conman console command to set the IBM Workload Scheduler message level and to direct the messages to your terminal. The message level setting affects only Batchman and Mailman messages, which are the most numerous. It also sets the level of messages written to the standard list file or files and the syslog daemon. The following command, for example, sets the level of Batchman and Mailman messages to 2 and sends the messages to your computer:

```txt
console sess;level  $= 2$
```

Messages are sent to your computer until you either run another console command, or exit conman. To stop sending messages to your terminal, enter the following conman command:

```txt
console sys
```

# Automatic encryption for key product files

Key product files, such as the Symphony file, are automatically encrypted for all fresh installations using AES-256 or AES-128 cryptography starting from version 10.1.

Data breaches are becoming more and more common and pervasive in today's business world. Encryption is a key feature when it comes to protect sensitive data, such as the data at rest stored in your Symphony plan or message queues. For this reason, all fresh installations starting from this release automatically encrypt key product files using AES-256 or AES-128 cryptography.

Data at rest means data is not being accessed or used but instead stored on your computer, external hard drive, cloud storage, server, or database. Encryption at rest ensures that this data is protected and encrypted.

If you want IBM® Workload Scheduler to encrypt files such as the Symphony file, messages queues, and the useropts file at runtime, you do not need to take any actions. By default, the product is automatically encrypted without your intervention. You can also define the folder containing the certificates and the certificates password using the sslpassword and sslkeysfolder parameters when installing the master domain manager and agents, both fault-tolerant agents and dynamic agents.

The following IBM® Workload Scheduler elements are automatically encrypted:

- Symphony file  
- messages queues  
- useroptsfile  
- jmJobTableDir directory on dynamic agents

You can also optionally encrypt the following IBM® Workload Scheduler elements:

- SAP (r3batch) options file  
- PeopleSoft options file  
- secure command if you set the useaeskeystore argument. For more information, see the topic about the secure command in IBM Workload Scheduler: Planning and Installation.

Information about encryption keys is stored in the following locally properties:

# encrypt keystore file file_name

The path to the keystore PKCS12 file, containing the AES-256 or AES-128 key. The keystore is created automatically at installation time and the related path is inserted in this parameter. If you want to use a different keystore, you can create it and add the path in this option.

# encrypt keystore pwd password

The path to the keystore stash file.

# encrypt label

The label of the key in the keystore. When you modify a key label for key rotation, store the previous label in the decrypt label list property, so it can be retrieved if it is still used in the product. This property is case insensitive.

# encrypt label list

The list of previously used aliases for key encryption. When you modify a key alias for key rotation, store the previous alias in this property. This storage method is useful if the obsolete key is still used in the product. Separate each value with a comma ",". Note that this property is commented. This property is case insensitive.

For more information about the locally files, see Setting local options on page 48.

For more information about rotating the keys, see Encryption key rotation on page 134.

# Encryption key rotation

Procedure to perform a key rotation.

# About this task

You can optionally modify the existing encryption keys by performing a key rotation, for example if the existing keys expire or are no longer secure. Perform the following steps on the master domain manager and on each agent in the environment

1. Generate a new key by running the following keytool command:

```batch
./keytool -densekey -alias new alias name -keyalg AES -keysize 256  
-storepass encrypt_keystore pwd_in_clear -storetype PKCS12 -keystore encrypt_keystore_file
```

2. Change the localopts file as follows:

a. Add the previous value of the encrypt label parameter to the decrypt label list parameter.  
b. Change the value of the encrypt label parameter to new alias_name.

For more information about the locallypts file, see Setting local options on page 48.

# Result

If the keystore does not exist, it is created. If it exists, the new key is added to the keystore.

# Results

The current Symphony plan keeps using the previous key. To apply the new setting to the Symphony plan, run a JnextPlan command. The message boxes are encrypted immediately and the useropts file is encrypted as soon as you save the localopts file and launch a CLI command. Key product files are now encrypted with the new key.

# Modifying jobmon service rights for Windows™

On Windows™ systems, the IBM Workload Scheduler jobmon service runs in the SYSTEM account with the right Allow Service to Interact with Desktop granted to it. You can remove this right for security reasons. However, if you do so, it prevents the service from launching interactive jobs that run in a window on the user's desktop. These jobs will be run, but are not accessible from the desktop or from IBM Workload Scheduler and do not have access to desktop resources. As a result, they may run forever or abend due to lack of resources.

# Chapter 2. Configuring the Dynamic Workload Console

This chapter describes how to configure Dynamic Workload Console. It is divided into the following sections:

- Launching in context with the Dynamic Workload Console on page 136  
- Configuring access to the Dynamic Workload Console on page 145  
- Configuring the Dynamic Workload Console for Single Sign-On on page 149  
- Configuring Dynamic Workload Console to connect to a remote SAP system on page 154  
- Customizing your global settings on page 155  
- Disable the What-if Analysis on page 173  
- Configuring High Availability on page 174  
- Configuring Dynamic Workload Console to view reports on page 175

![](images/558017ce45565c3f2dfd753d1c244463d11f4bc56cd81d60766d1adf57e6659b.jpg)

Note: If, after installing, you have more than one instance of WebSphere Application Server Liberty managing any IBM® Workload Scheduler products, ensure that they share the same LTPA token_keys.

# Launching in context with the Dynamic Workload Console

Create a URL to launch the Dynamic Workload Console and have it directly open the results of a particular query.

By accessing the bookmark icon in the page of your interest, you can copy the URL of that page, and then include the copied URL in an external application, for example, to monitor jobs and job streams that are critical to your business, and to quickly and easily manage them.

Open your Dynamic Workload Console pages and access the information you need in just one click.

Launch in context: your environment at your fingertips.

# Scenarios

The following main scenarios can be identified:

- Obtain the result of a monitor query on:

Jobs  
Critical jobs  
Job streams  
Workstation  
Workload  
Existing tasks

For all the scenarios, you must create a basic URL.

# Creating a basic URL

About this task

To create a basic URL, you need to define the URL to access the Dynamic Workload Console:

https://WebUIHostName:adminSecurePort

console/?pageId=<pageID>

where:

# WebUIHostname

It is the fully qualified hostname or the IP address of the computer where the Dynamic Workload Console is installed.

# adminSecurePort

It is the number of the port on which the Dynamic Workload Console is listening.

pageld

It is the ID of the Dynamic Workload Console page that has to be launched.

# Example

https://mypc:29443 console/?pageId=manage-roles

# Advanced optional parameters

Depending on the query whose results you want to view, you can complete your URL with the following parameters:

# Mandatory parameters

engineName

Specify the name of one or more engines to be used as filter.

objectType

Specify an object type as filter. The following are the supported object types in the Dynamic

Workload Console:

- com.ibm.tws.objects.plan.JobInPlan  
- com.ibm.tws.objects.plan.JobStreamInPlan  
- com.ibm.tws.objects.plan.CriticalJobInPlan  
- com.ibm.tws.objects.plan.WorkstationInPlan  
- com.ibm.tws.objects.plan.PromptlnPlan  
- com.ibm.tws.objects.plan.ResourceInPlan  
- com.ibm.tws.objects.plan.DomainInPlan

plan

Specify a plan name as filter.

query

Specify a query to filter the results.

![](images/2a0126bce952a8db4d06c5d602d5053431c8a4f7b12a55c224da0a8d234dbf91.jpg)

Note: Special characters must be replaced by encoded values. For example, # (number sign) must be replaced by %23, + (plus sign) must be replaced by %2B.

# Example

A query like @!@@state  $\equiv$  #Waiting must be written like this: @!@@%2Bstate= %23Waiting

# Optional parameters

# columns

Specify the columns that you want to display in your result table. The following three options are available:

ALL

Display all columns.

# DEFAULT

Display only the default columns.

# Customized columns

Display the customized column to get a specific column result. For example, "columns": "Status, Internal Status".

If not specified, the default columns for this query are shown.

# encrypt

Specify if you want to encrypt or not the engine name parameter. If true, the engine name has to be encrypted by using Base64 encode.

# taskName

Specify the name of an existing task as filter.

![](images/191207b7df389957f4c32e7ecd3ad1590b10349961d227c1eb129bdf61e3230f.jpg)

Note: it is not recommended to specify both the taskName and query parameters in the URL. If both parameters are specified, the taskName parameter has the priority.

# Monitor Jobs on distributed systems

The following is an example of URL to be launched to directly open the Monitor Workload page and obtain results about jobs on distributed systems.

To create a URL to monitor jobs on a distributed system, specify the following filters:

# engineName

Specify the name of one or more engines to be used as filter.

# objectType

Specify an object type as filter. The following are the supported object types in the Dynamic Workload Console:

- com.ibm.tws.objects.plan.JobInPlan  
- com.ibm.tws.objects.plan.JobStreamInPlan  
- com.ibm.tws.objects.plan.CriticalJobInPlan  
- com.ibm.tws.objects.plan.WorkstationlnPlan  
- com.ibm.tws.objects.plan.PromptInPlan  
- com.ibm.tws.objects.ResourceInPlan  
- com.ibm.tws.objects.plan.DomainInPlan

# plan

Specify a plan name as filter.

# query

Specify a query to filter the results.

![](images/7d49446c56efdf9f27150d5ff2036e3b13d68d2eded276d0874e36ada09fe900.jpg)

Note: Special characters must be replaced by encoded values. For example, # (number sign) must be replaced by %23, + (plus sign) must be replaced by %2B.

# Example

A query like@@.state  $\equiv$  #Waiting must be written like this:@@.@%2Bstate=%23Waiting

# columns

Specify the columns that you want to display in your result table. The following three options are available:

# ALL

Display all columns.

# DEFAULT

Diplay only the default columns.

# Customized columns

Display the customized column to get a specific column result. For example, "columns":

"Status,Internal Status".

If not specified, the default columns for this query are shown.

# encrypt

Specify if you want to encrypt or not the engine name parameter. If true, the engine name has to be encrypted by using Base64 encode.

# Example:

https://mypc:9449/console?pageId  $\equiv$  direct-query&properties  $\equiv$  {"query":"%2F%40%2F%40%23%2F%40%2F%40.%.40","engineName": "eJxzzUvPzEs1BAAKagKI","encrypt":true,"plan":"current-plan","objectType":"com.ibm.tws.objects.plan.JobInPlan"

```csv
,"columns":"Status,Internal Status,Folder (Job Stream),Job,Job Type,Workstation (Job),Job Stream,Workstation (Job Stream),Scheduled Time,Not Satisfied Dependencies,Priority,Job number,Earliest Start,Actual Start,Deadline"}
```

# Monitor Jobs on z/OS® systems

The following is an example of URL to be launched to directly open the Monitor Workload page and obtain results about jobs on z/OS® systems.

To create a URL to monitor jobs on a z/OS® system, specify the following filters:

# engineName

Specify the name of one or more engines to be used as filter.

# objectType

Specify an object type as filter. The following are the supported object types in the Dynamic Workload Console:

- com.ibm.tws.objects.plan.JoblnPlan  
- com.ibm.tws.objects.plan.JobStreamInPlan  
- com.ibm.tws.objects.plan.CriticalJobInPlan  
- com.ibm.tws.objects.plan.WorkstationlnPlan  
- com.ibm.tws.objects.plan.PromptInPlan  
- com.ibm.tws.objects.plan.ResourceInPlan  
- com.ibm.tws.objects.plan.DomainInPlan

# plan

Specify a plan name as filter.

# query

Specify a query to filter the results.

![](images/2db213597c4c66050d26d60a177dde3154e5968c86cce8ae7af6317654d3d3fb.jpg)

Note: Special characters must be replaced by encoded values. For example, # (number sign) must be replaced by %23, + (plus sign) must be replaced by %2B.

# Example

A query like @!@@.state  $\equiv$  #Waiting must be written like this: @!@@.@2Bstate  $=$  %23Waiting

# columns

Specify the columns that you want to display in your result table. The following three options are available:

# ALL

Display all columns.

# DEFAULT

Diplay only the default columns.

# Customized columns

Display the customized column to get a specific column result. For example, "columns":

"Status,Internal Status".

If not specified, the default columns for this query are shown.

# encrypt

Specify if you want to encrypt or not the engine name parameter. If true, the engine name has to be encrypted by using Base64 encode.

# Example:

```json
https:// mypc:9449/console?pageId  $\equiv$  direct-query&properties  $\equiv$  {"query":"%40!%40","engineName":"eJyLyi92zUvPzEsFABGsA5M=","encrypt":true,"plan":"current plan","objectType":"com.ibm.tws.objects.plan.JobInPlan","columns":"Status,Internal Status,Job Number,Job,Workstation,Job stream,Status Details,Scheduled Time,Job Identifier,Error Code,Time Dependent,Earliest Start,Planned Start,Actual Start,Deadline,Critical"}
```

# Monitor Critical Jobs

The following is an example of URL to be launched to directly open the Monitor Workload page and obtain results about critical jobs.

To create a URL to monitor critical jobs, specify the following filters:

# engineName

Specify the name of one or more engines to be used as filter.

# objectType

Specify an object type as filter. The following are the supported object types in the Dynamic Workload Console:

- com.ibm.tws.objects.plan.JoblnPlan  
- com.ibm.tws.objects.plan.JobStreamInPlan  
- com.ibm.tws.objects.plan.CriticalJobInPlan  
- com.ibm.tws.objects.plan.WorkstationlnPlan  
- com.ibm.tws.objects.plan.PromptlnPlan  
- com.ibm.tws.objects.plan.ResourceInPlan  
- com.ibm.tws.objects.plan.DomainInPlan

# plan

Specify a plan name as filter.

# query

Specify a query to filter the results.

![](images/afd5f316534c7565e32f2b364cbcbe731d0ef0c8888e87e29d03b7896670cf57.jpg)

Note: Special characters must be replaced by encoded values. For example, # (number sign) must be replaced by %23, + (plus sign) must be replaced by %2B.

![](images/2c1b9f42d8461f222b74f310bb2d86f5f9453f1d7307eb469df18a6fcfcfce0c.jpg)

# Example

A query like @!@@+state=#Waiting must be written like this: @!@@.@2Bstate=%23Waiting

# columns

Specify the columns that you want to display in your result table. The following three options are available:

ALL

Display all columns.

# DEFAULT

Display only the default columns.

# Customized columns

Display the customized column to get a specific column result. For example, "columns":

"Status,Internal Status".

If not specified, the default columns for this query are shown.

# encrypt

Specify if you want to encrypt or not the engine name parameter. If true, the engine name has to be encrypted by using Base64 encode.

# Example:

```json
https://mypc:9449 console?pageId  $\equiv$  direct-query&properties  $\equiv$  {"query":"%2F%40%2F%40%23%2F%40%2F%40%.40","engineName":"eJxzzUvPzEs1BAAKagKI","encrypt":true,"plan":"current-plan","objectType":"com.ibm.tws.objects.plan.CriticalJobbInPlan","columns":"Risk level,Confidence Factor,Status,Internal Status,Folder (Job Stream),Job,Job Type,Workstation (Job),Job Stream,Workstation (Job Stream),Scheduled Time,Jobs Left on Critical Path,Critical Path Remaining Duration,Estimated Start,Estimated End,Earliest Start,Actual Start,Deadline,Critical LatestStart"}
```

# Monitor Job Streams

The following is an example of URL to be launched to directly open the Monitor Workload page and obtain results about job streams.

To create a URL to monitor job streams, specify the following filters:

# engineName

Specify the name of one or more engines to be used as filter.

# objectType

Specify an object type as filter. The following are the supported object types in the Dynamic Workload Console:

- com.ibm.tws.objects.plan.JoblnPlan  
- com.ibm.tws.objects.plan.JobStreamInPlan  
- com.ibm.tws.objects.plan.CriticalJobInPlan  
- com.ibm.tws.objects.plan.WorkstationlnPlan

- com.ibm.tws.objects.plan.PromptInPlan  
- com.ibm.tws.objects.ResourceInPlan  
- com.ibm.tws.objects.plan.DomainInPlan

# plan

Specify a plan name as filter.

# query

Specify a query to filter the results.

![](images/b9886741b6b9da6e3bed9e92749647b7812431425c8e2f0f8601d4efa657a577.jpg)

Note: Special characters must be replaced by encoded values. For example, # (number sign) must be replaced by %23, + (plus sign) must be replaced by %2B.

# Example

A query like@@.state  $\equiv$  #Waiting must be written like this:@@. $\% 2$ Bstate  $=$  %23Waiting

# columns

Specify the columns that you want to display in your result table. The following three options are available:

# ALL

Display all columns.

# DEFAULT

Display only the default columns.

# Customized columns

Display the customized column to get a specific column result. For example, "columns":

"Status,Internal Status".

If not specified, the default columns for this query are shown.

# encrypt

Specify if you want to encrypt or not the engine name parameter. If true, the engine name has to be encrypted by using Base64 encode.

# Example:

```txt
https://mypc:9449 console?pageId=direct-query&properties={'query":"%2F%40%2F%40%23%2F%40%2F%40","engineName":"eJxzzUvPzEs1BAAKagKI","encrypt":true,"plan":"current-plan","objectType":"com.ibm.tws.objects.plan.JobStreamInPla n","columns":"Status,Internal Status,Folder,Job Stream,Workstation,Scheduled Time,Not Satisfied Dependencies,Total Jobs,Successful Jobs,Jobs Limit,Priority,Earliest Start,Actual Start,Deadline"}
```

# Monitor Workstations

The following is an example of URL to be launched to directly open the Monitor Workload page and obtain results about workstations.

To create a URL to monitor workstations, specify the following filters:

# engineName

Specify the name of one or more engines to be used as filter.

# objectType

Specify an object type as filter. The following are the supported object types in the Dynamic Workload Console:

- com.ibm.tws.objects.plan.JoblnPlan  
- com.ibm.tws.objects.plan.JobStreamInPlan  
- com.ibm.tws.objects.plan.CriticalJobInPlan  
- com.ibm.tws.objects.plan.WorkstationlnPlan  
- com.ibm.tws.objects.plan.PromptInPlan  
- com.ibm.tws.objects.ResourceInPlan  
- com.ibm.tws.objects.plan.DomainInPlan

# plan

Specify a plan name as filter.

# query

Specify a query to filter the results.

![](images/3a8d4c1bb54a944adcd01690fa6b24d38922b662420dccc413b42bde5a9db2a1.jpg)

Note: Special characters must be replaced by encoded values. For example, # (number sign) must be replaced by %23, + (plus sign) must be replaced by %2B.

# Example

A query like @!@@+state=#Waiting must be written like this: @!@@.2Bstate=%23Waiting

# columns

Specify the columns that you want to display in your result table. The following three options are available:

# ALL

Display all columns.

# DEFAULT

Diplay only the default columns.

# Customized columns

Display the customized column to get a specific column result. For example, "columns": "Status,Internal Status".

If not specified, the default columns for this query are shown.

# encrypt

Specify if you want to encrypt or not the engine name parameter. If true, the engine name has to be encrypted by using Base64 encode.

# Example:

```json
https://mypc:9449 console?pageId  $\equiv$  direct-query&properties  $\equiv$  {"query":"%2F%40%2F%40","engineName":"eJxzzUvPzEs1BAAK agKI","encrypt":true,"plan":"current-plan","objectType":"com.ibm.tws.objects.plan.WorkstationInPlan","columns": "Link Status,Folder,Workstation,Agent Running,Writer Running,Start Time,Run Number,Limit,Domain,Type,Version"}
```

# Existing task

The following is an example of URL to be launched to directly open the Monitor Workload page and obtain results about an existing task.

# About this task

To create a URL to monitor an existing task, specify the following filters:

# taskName

Specify the name of an existing task as filter.

![](images/407f2beb91759d6e28d00783ddbd1299b2d1c8114630e18f3d615538fdd824d4.jpg)

Note: it is not recommended to specify both the taskName and query parameters in the URL. If both parameters are specified, the taskName parameter has the priority.

# Example:

```txt
https://mypc:9449 console?groupId  $\equiv$  direct-query&properties  $=$  {"taskName":"MyTask"}
```

# Configuring access to the Dynamic Workload Console

As soon as you finish installing the Dynamic Workload Console, you can launch it by logging in at the following link:

```txt
https://<your_ip_address>:9443 console/login.jsp
```

You can access the Dynamic Workload Console from any computer in your environment using a web browser through the secure HTTPS protocol and using the credentials specified at installation time.

By default, the Dynamic Workload Console is configured to use a local file-based user repository. Users defined in the user registry can log in to the Dynamic Workload Console and need to be associated to a role to be able access the Dynamic Workload Console features (see "Configuring roles to access the Dynamic Workload Console on page 146.)

If you use a central user registry that is based on the Lightweight Directory Access Protocol (LDAP) to manage users and groups and provide single sign-on, then you can set up an LDAP server and create an LDAP user registry to use with the Dynamic Workload Console. You can implement an LDAP user repository in place of the default file-based user registry by configuring the sample authentication templates provided in XML format. The following are the supported LDAP servers and the corresponding sample template that can be configured to replace the configuration file currently in use:

- File-based: auth_basicRegistry_config.xml  
- IBM® Directory Server: auth_IDS_config.xml  
- OpenLDAP: auth_OpenLDAP_config.xml  
- WindowsTMServerActiveDirectory:auth_AD_config.xml

In addition you can also add a line

See Configuring IBM Workload Scheduler using templates on page 418 for more information about the templates and the location.

![](images/9974d96dc02831adda28c59e2552dcaa3461a00cdd9d9aaaee4a1cdb2faf4735.jpg)

Note: If two or more instances of Dynamic Workload Console share the same database repository for their settings, but they are not configured to be in a High Availability configuration, they all must be at the same fix pack level.

# Configuring a user registry

To use LDAP user registry, users and groups must be created by the system administrator in the chosen LDAP server database.

Configuring user registries for the Dynamic Workload Console and all other IBM Workload Scheduler components is described in Configuring LDAP described in Planning and Installation Guide.

# Configuring roles to access the Dynamic Workload Console

During the Dynamic Workload Console installation, new predefined roles are created. They determine which console panels are available to a user, and therefore which activities that user can perform from Dynamic Workload Console. More roles can be created and customized according to business needs. For more information about the creation of customized roles, see the section about customizing roles in Dynamic Workload Console User's Guide

# Tip

It is not necessary to assign a role to every single user. If the user registry already contains groups of users that are properly defined for using the console, it is possible to assign roles to groups too. If groups are not available in the user registry, then the special role all authenticated users can be used to assign roles to all the users at once.

To assign roles to a default groups of users that are properly defined for using the console, add this property to the authentication file in use.

```xml
<jndiEntry jndiName="all.authenticated/users" value="my-group" />
```

Within the Dynamic Workload Console, you can create your own custom views to enable users to see all or a subset of IBM Workload Scheduler pages. To do it, you must have the Administrator role and perform the following steps:

1. Open the authentication_config.xml located in the following path:

# On UNIX operating systems

DWC_DATA_dir/usr/servers/dwcServer/configDropins/overrides

# On Windows operating systems

DWC_home\usr\servers\dwcServer\configDropins\overridden

2. Add the entity specifying username and password in users or groups.  
3. Open Dynamic Workload Console > Administration > Manage Roles  
4. Click Entities to associate the user or the group you have created to one of the roles from the list.  
5. Add the entity and save.

The following lists the predefined roles created in WebSphere Application Server Liberty for accessing the IBM Workload Scheduler environments using Dynamic Workload Console:

# API User

Users in this group can use only the Dynamic Workload Console APIs to perform the available actions. Logging to the Dynamic Workload Console through a Web browser would not give them access to any feature. For more details about the Dynamic Workload Console APIs, see https://<DWC_hostname>:<port>/dwc/api.

# Administrator

Users with this role can see the entire portfolio and use all features of the Dynamic Workload Console.

Users with this group can also access and use all features of the Self-Service Catalog and theSelf-Service Dashboards mobile applications. From the Self-Service Catalog mobile application, these users can create and edit catalogs, create and edit services, add services to catalogs, submit services associated to job streams, and share catalogs and services with other users. From the Self-Service Dashboards mobile application, these users can create and edit dashboards to filter for jobs and workstations, display a dashboard of results, perform recovery actions on a single result.

From the Manage Roles panel, the administrator can add entities, manage pinned pages and shared boards.

# Analyst

Users in this group can manage Dynamic Workload Console reports and user preferences.

# Broker

Users in this group can define Broker settings, create and manage Broker jobs and resources, and monitor Broker computers and resources.

# Developer

Users in this group can create, list, and edit workload definitions, workstations, and event rule definitions in the IBM Workload Scheduler database.

# Mobile User

Users in this group can manage the Self-Service Catalog and theSelf-Service Dashboards mobile applications but the actions they can perform are limited to submitting service requests (job streams) from the Self-Service Catalog and, from the Self-Service Dashboards mobile application, displaying a dashboard of results and performing recovery actions on them.

# Operator

Users in this group can see Dynamic Workload Console:

- All Monitor tasks.  
- Jobs and job streams to be submitted on request  
- Set User Preferences

The following table lists some entries of the navigation toolbar, and some activities that you can perform on the Dynamic Workload Console. Beside each item, the table shows the groups whose users are authorized to access them.

Table 21. Menu and Group Permissions  

<table><tr><td>Menu Item</td><td>Groups with Permission</td></tr><tr><td>Quick Start</td><td>Administrator</td></tr><tr><td>All Configured Tasks</td><td>Administrator, Operator</td></tr><tr><td>Manage Workload Reports</td><td>Administrator, Analyst</td></tr><tr><td>Design -&gt; Workload Definitions</td><td>Administrator, Developer</td></tr><tr><td>Planning &amp; Submission -&gt; Workload Forecast</td><td>Administrator, Operator</td></tr><tr><td>Administration -&gt; Workload Submission</td><td>Administrator, Operator</td></tr><tr><td>Monitoring &amp; Reporting</td><td>Administrator, Operator</td></tr><tr><td>Design -&gt; Workload Definitions</td><td>Administrator</td></tr><tr><td>Reporting</td><td>Administrator, Analyst</td></tr></table>

Table 21. Menu and Group Permissions (continued)  

<table><tr><td>Menu Item</td><td>Groups with Permission</td></tr><tr><td>Security -&gt;Manage Engines</td><td>Administrator</td></tr><tr><td>Security -&gt; Manage Settings</td><td>Administrator</td></tr><tr><td>Administration → Broker Settings; Design → Broker Design; Monitoring &amp; Reporting → Broker Monitoring</td><td>Administrator, Broker</td></tr></table>

# Configuring the Dynamic Workload Console for Single Sign-On

Single Sign-On (SSO) is a method of access control that allows a user to authenticate once and gain access to the resources of multiple applications sharing the same user registry.

This means that using SSO you can run queries on the plan or manage object definitions on the database accessing the engine without authenticating, automatically using the same credentials you used to log in to the Dynamic Workload Console.

The same is true when working with the Self-Service Catalog and Self-Service Dashboards apps from a mobile device. If the Dynamic Workload Console has been configured to use SSO, then these apps automatically use the same credentials used to log in to the Dynamic Workload Console.

After completing the installation or upgrade, you can set up Single Sign-On (SSO) for the Dynamic Workload Console and master domain manager using either an LTPA registry or a basic user registry. To achieve this, Dynamic Workload Console and master domain manager need to use the same user registry. Additionally, ensure that the contents of the ltpa keys file are identical on both the Dynamic Workload Console and the master domain manager. The ltpa keys file is located in the following path:

usr/server/EngineServers/resources/security

The Lightweight Directory Access Protocol (LDAP) is an application protocol for querying and modifying directory services running over TCP/IP - see the information about configuring a common LDAP for both the master and console in the post-installation section of the Planning and Installation Guide for more details.

If you configured Dynamic Workload Console to use Single Sign-On with an engine, then, the following behavior is applied:

# If engine connection has the user credentials specified in its definitions

These credentials are used. This behavior regards also engine connections that are shared along with their user credentials.

# If the user credentials are not specified in the engine connection

The credentials you specified when logging in to Dynamic Workload Console are used. This behavior regards also shared engine connections having unshared user credentials.

For detailed information about how to configure SSO using an LTPA token or an MP-JWT token, see How to configure the Dynamic Workload Console and the master domain manager for Single Sign-On on page 150.

# How to configure the Dynamic Workload Console and the master domain manager for Single Sign-On

Configure the Dynamic Workload Console and the master domain manager for Single Sign-On.

# About this task

You can configure Single Sign-On using a Lightweight Third-Party Authentication (LTPA) token or an MP-JWT token.

![](images/6782e96efa85812c4ea63e22bcb8826d87ade077539064d853a66a4b258c0884.jpg)

Note: When implementing a configuration in Single Sign-On, ensure you have not specified the engine credentials in the Manage Engine section.

# Configuring the Dynamic Workload Console for Single-Sign-On with an LTPA token

# About this task

To enable Single Sign-On between the Dynamic Workload Console and master domain manager, perform the following steps:

1. Configure an authentication provider for the Dynamic Workload Console as explained in the post-installation section of the Planning and Installation Guide.  
2. Create the Access Control list for the authentication provider user or group. For example, to give full access on domain and folders to the LDAP group perform the following steps:

a. From the Dynamic Workload Console open the Manage Workload Security panel and select Give access to users and groups.  
b. Select the LDAP group from the drop-down list and FULLCONTROL in the field Role.  
c. Select Domain and assign ALOBJECTS.  
d. Save and create new  
e. Select the LDAP group from the drop-down list and FULLCONTROL in the field Role.  
f. Select Folder and assign the root by clicking /  
g. Save

3. Ensure that the ltpa . keys file on both the Dynamic Workload Console and the master domain manager are identical, copying the file from one instance to the other. The file is located as follows:

# Dynamic Workload Console

DWC_home/usr/servers/dwcServer/resources/security

# masterdomainmanager

TWA_home/usr/ servers/engineServer/resources/security

4. Restart WebSphere Application Server Liberty on both the master domain manager and the Dynamic Workload Console by running stopAppServer and startAppServer.

# Configuring the Dynamic Workload Console for Single Sign-On with an MP-JWT token

# About this task

Perform the following steps:

1.  
2. Create the Access Control list for the authentication provider user or group. For example, to give full access on folders to an LDAP group perform the following steps:

a. From the Dynamic Workload Console open the Manage Workload Security panel and select Give access to users and groups.  
b. Select the LDAP group from the drop-down list and FULL_CONTROL in the field Role.  
c. Select Folder and assign the root by clicking /  
d. Save

# How to configure the Dynamic Workload Console 10.2.5 and a master domain manager 9.4.x for Single Sign-On

How to configure the Dynamic Workload Console 10.2.5 and a master domain manager 9.4.x for Single Sign-On.

# Before you begin

Ensure that the master domain manager V9.4.x is configured to use a Lightweight Directory Access Protocol (LDAP). The LDAP should be the same one already configured and used by the Dynamic Workload Console 10.2.5. For further information about how to configure an LDAP, see the section about configuring a user registry in IBM Workload Scheduler: Planning and Installation.

# About this task

To configure the Dynamic Workload Console 10.2.5 and the master domain manager V9.4.x for Single Sign-On, perform the following steps:

1. Access the WebSphere administrative console of the master domain manager V9.4.x and go to Global security in the Security section.  
2. In the Global security panel, take note of the value for the Realm name in the User account repository section. The realm name is required later in this section.

![](images/d41cee48538ef06083d9e02050696a8b8aefd1ed0fbadeecdb8771e5b98d626a.jpg)  
Figure 2. Realm name in the WebSphere administrative console

3. In Authentication, select LTPA as the authentication mechanism, and enter a password to export the ltpa keys.

![](images/34905ed7f8e660b5f6ee3ecfda5b71030125c160f3a6b73f6cf5c96ec9739d26.jpg)

Note: Take note of the password. The password you enter is required later during the import.

![](images/c9c4e37dfab671e1f1b98c8f0b433075cf91947c57ec6515839e3e520192aa7a.jpg)  
Figure 3. Export of the ltpa keys file

4. Before replacing the existing ltpa on the Dynamic Workload Console 10.2.5, create a backup copy in a different directory. The existing ltpa keys file can be found in the following path:

DWC_DATA_dir/usr/servers/dwcServer/resources/security/

DWC_home\usr\servers\dwcServer\resources\security

5. Rename the exported ltpa keys file to ltpa_keys and copy it to the same path as the existing file on the Dynamic Workload Console 10.2.5.  
6. Open the authentication configuration file previously customized to enable the LDAP for the Dynamic Workload Console 10.2.5, and ensure that the realm name is the same as the one specified for the master domain manager V9.4.x (see Step 2 on page 151). The authentication configuration file is located in the following path:

```txt
DWC_DATA_dir/usr/servers/dwcServer/configDropins/overrides/
```

```txt
DWC_home\usr\servers\dwcServer\configDropins\overridden\
```

![](images/f057572bc31186e137c34abb8a7e3f50e1856fdabb17be319e90e17b2795104e.jpg)  
Figure 4. Realm name in the authentication template

Where TWSREALM is the default realm name.

7. Add the password in XOR format in the ssl_config.xml as follows:

a. Copy the ssl_config.xml file from the following path:

```txt
DWC_home/usr/servers/dwcServer/configDropins/defaults/
```

```txt
DWC_home\usr\servers\dwcServer\configDropins\ defaults\
```

b. Paste the ssl_config.xml file in the following path:

```txt
DWC_DATA_dir/usr/servers/dwcServer/configDropins/overrides/
```

```txt
DWC_home\usr\servers\dwcServer\configDropins\overridden\
```

c. Open the ssl_config.xml file and enter the password in XOR format. The password is the one you specified for the master domain manager V9.4.x during the export (see Step 3 on page 152).

![](images/fc8867e03d3815d682ab81cac63af443fc2862a10f513b1524c3ac37adf2943d.jpg)  
Figure 5. Password in XOR format

8. Restart the Dynamic Workload Console 10.2.5.

# Results

You successfully configured the Dynamic Workload Console 10.2.5 and the master domain manager V9.4.x for Single Sign-On.

# Configuring Dynamic Workload Console to connect to a remote SAP system

You can create a new SAP connection.

# About this task

The purpose of the following scenario is to show how to create a new SAP connection in the context of an example.

The scope of the scenario is to create a new SAP connection named "S4HANA" with the workstation named "DYN Agents", using an options file named "FILE Agents1_r3batch_opts".

1. Create a new SAP connection as follows:

a. From the Administration menu, click Manage SAP Connections page, and then select the engine.  
b. Click New Connection.  
c. In SAP Connection Name, type S4HANA.  
d. In Workstation, click the lookup icon, search the workstation named "DYN_AGENT", and select it.  
e. In Option file, click the lookup icon, search the option file named "FILE(agent1_r3batch_opts", and select it.  
f. Test the connection.

2. Click Ok to save it.

# Results

You successfully created a SAP connection named "S4HANA", and now you can start creating, scheduling, and control your SAP jobs directly from the IBM® Workload Scheduler.

# Customizing your global settings

How to customize global settings.

# About this task

To customize the behavior of the Dynamic Workload Console, you can optionally configure some advanced settings. These settings are specified in a customizable file named TdwcGlobalSettings.xml.template.

By default, the customizable file is copied into the following path after you install the Dynamic Workload Console:

# On Windows operating systems:

DWC_home\usr\servers\dwcServer\registry\TdwcGlobalSettings.xml.template

# On UNIX and Linux operating systems:

DWC_home/usr/servers/dwcServer/registry/T DWC Global Settings.xml.template

If you have Administrator privileges, you can modify the file to replace default values with customized ones and enable commented sections. To enable commented sections, remove the tags that enclose the section. You then save the file locally with the name TdwcGlobalSettings.xml.

You can add and modify some customizable information, such as:

- The URLs that link to videos in the Dynamic Workload Console. For example, you can link to a company intranet server to view help videos rather than to a public video site.  
- The maximum number of objects to be shown in the graphical views.  
- The setting to display the plan view in a new window.  
- The auto refresh interval for the Show Plan View graphical view.  
- The creation of predefined tasks.  
- The URLs where you can store customized documentation about your jobs or job streams to associate customized documentation to them.  
- The current user registry in use.  
- The timeout to read and write information on a IBM® Z Workload Scheduler engine.  
- The maximum number of objects to be retrieved with a query, the maximum number of rows to display in a table, and the maximum number of direct queries to maintain in history.  
- Allowing or preventing users from sharing tasks and engine connections.  
- The display of all dependencies, both satisfied and unsatisfied.  
- The use of audit files to track activities in the Self-Service Catalog and Self-Service Dashboards mobile applications.  
- Displaying or hiding all predecessors from the What-if Analysis Gantt view.

This file is accessed at each login, and all configurations specified in the file are immediately applied, except for the precannedTaskCreation property. This property is read only when a user logs in for the first time and is then used whenever this user logs in again.

You can use any text or XML editor to edit this file, but ensure that you save it as a valid XML file.

The file is organized into sections that group similar properties. An explanation of each section is available in the file. For more information, see TdwcGlobalSettings.xml sample on page 169.

Sections can also be repeated multiple times in the same file and applied differently to different user roles. To apply a section only to the users belonging to a role, the section must be included within the tags <settings role="user-role"> and </settings>, where:

```txt
<user_role>
```

The user for which the enclosed configuration must be applied. The default value is all users, unless otherwise specified.

Only one settings section can be specified for each role. If a user has more than one role, the settings associated to the higher role are used.

To edit the file, proceed as follows:

1. Stop WebSphere Application Server Liberty Base using the following command:

UNIXTM

Stop the application server

```txt
./stopAppServer.sh [-direct]
```

WindowsTM

Stop the application server

```txt
stopAppServer.bat [-direct [-wlpHome <installation_directory>] [-options <parameters>]
```

as described in the section about starting and stopping WebSphere Application Server Liberty Base in Administration Guide.

2. Log is as root or Administrator to the Dynamic Workload Console.  
3. Browse to

On Windows operating systems:

DWC_home\usr\servers\dwcServer\rregistry\TdwcGlobalSettings.xml.template

On UNIX and Linux operating systems:

```txt
DWC_home/usr/servers/dwcServer/configDropins/template/ TdwcGlobalSettings.xml.template
```

4. Edit the file as necessary, rename it to TdwcGlobalSettings.xml and save it.  
5. Start WebSphere Application Server Liberty Base using the following command:

UNIXTM

Start the application server

```txt
./startAppServer.sh [-direct]
```

WindowsTM

Start the application server

```batch
startAppServer.bat [-direct]
```

as described in the section about starting and stopping WebSphere Application Server Liberty Base in Administration Guide.

Example:  
```xml
<?xml version"1.0"?>
<tdwc>
    ...
    <settings>
        <graphViews>
            <property name="planViewNewWindow" value="true"/>
        </graphViews>
    </settings>
    <settings role="TWSWEBUIOperator">
        <graphViews>
            <property name="planViewNewWindow" value="false"/>
        </graphViews>
    </settings>
    ...
</tdwc>
```

To view the complete syntax for the file, see TdwcGlobalSettings.xml sample on page 169.

# Customize video URLs

This section shows how you should customize your URLs that link video content in the Dynamic Workload Console so that you can link to a company intranet server to view help videos rather than a public video site.

The_baseURL prefix will be added to all your video URLs. If you do not specify a link for your video the default setting will automatically be used.

```xml
<?xml version"1.0"?>
<tdwc>
    ...
    <settings>
        --<videoGallery>
            <property name="_baseURL" value=""/>></property>
            <property name="depLoop" value=""/>></property>
            <property name="highlightRelDep" value=""/>></property>
            <property name="viewDepPrompt" value=""/>></property>
            <property name="usingImpactView" value=""/>></property>
            <property name="createUseTasks" value=""/>></property>
            <property name="weAddRemoveFile" value=""/>></property>
            <property name="weCreateDeps" value=""/>></property>
            <property name="weAddJob" value=""/>></property>
```

```xml
<property name="weHighlightDeps" value=""></property>  
<property name="weCreateJCL" value=""> </property>  
</videoGallery>
```

# Override graphical view limits

This section contains the configuration parameters that apply to the graphical views in the plan, such as the maximum number of objects shown in each view.

# planViewMaxJobstreams

The maximum number of job streams displayed in the Plan View. Default value is 1000. Values greater than 1000 are not supported.

# preProdPlanViewMaxJobstreams

The maximum number of job streams displayed in the preproduction plan view. Default value is 1000. Values greater than 1000 are not supported.

```xml
<?xml version"1.0"?>
<tdwc>
    ...
    <settings>
        <graphViews>
            <property name="planViewMaxJobstreams" value="1000"></property>
            <property name="preProdPlanViewMaxJobstreams" value="1000"></property>
        </graphViews>
    </settings>
</tdwc>
```

See TdwcGlobalSettings.xml sample on page 169 to view the complete syntax for the file.

For more information about how to customize global settings, see Customizing your global settings on page 155.

# Plan View in new window

This section is used to prevent Internet Explorer 7 from freezing while using the Plan View. To solve the problem, set value to true.

# planViewNewWindow

Set it to true if you want the plan view to be displayed in a new window each time it is launched. Default value is false.

```xml
<?xml version"1.0"?>
<tdwc>
    ...
    <settings>
        <graphViews>
            <property name="planViewNewWindow" value="true”/>
```

```txt
</graphViews>   
.   
./settings>   
</tdwc>
```

See TdwcGlobalSettings.xml sample on page 169 to view the complete syntax for the file.

For more information about how to customize global settings, see Customizing your global settings on page 155.

# Plan View auto refresh interval

Use this section to change the default setting of the auto refresh interval for the Show Plan View graphical view for all users. By default, the auto refresh interval is 300 seconds (five minutes).

# PlanViewAutorefresh

The graphical representation of the Plan View is automatically refresh every 300 seconds by default. To change this setting, edit the value assigned to the DefaultTime property. The minimum value you can set is 30 seconds. Any value specified below this value is reset to 30 seconds. You must restart the Dynamic Workload Console application server after modifying this value.

```xml
<?xml version"1.0"?>
<tdwc>
    ...
    <settings>
        <PlanViewAutorefresh>
            <property name="DefaultTime" value="300"/>
        </PlanViewAutorefresh>
    ...
    </settings>
</tdwc>
```

See TdwcGlobalSettings.xml sample on page 169 to view the complete syntax for the file.

For more information about how to customize global settings, see Customizing your global settings on page 155.

# Disable and customize NewsFeed function

This section contains the configuration details to be constantly up-to-date with product information.

# FeedURL

Contains the URL from which you receive news and updates. Default value is:https://community.ibm.com/community/user/legacy

# FeedType

A string that identifies the format of update information. Default value is JSONP.

# PollInterval

The interval in seconds between two checks for updates. Default value is 600.

# PollInitialDelay

An initial delay in seconds before the first attempt to read the news feeds. After the initial load, the poll interval is used. Default value is 120.

# NewsFeed

Property used to add further customized news feeds. Specify the format and address of the file that contains the customized communication. Supported formats are RSS 2.0 and ATOM 1.0. You must write the communication in ATOM 1.0 or RSS 2.0 format and store this file in the an HTTP server complying with the same origin policy. For browser security reasons, this policy permits to access information only on server using the same protocol, hostname and port number as the one to which you are connected. Optionally, if you want to store your customized feed on an external server, you must configure an HTTP reverse proxy server mapping the external server address.

```xml
<property name="NewsFeed" type="RSS" value="http://DWChostname:portnumber.com/news.css" />
```

![](images/36a421d0c084d0cdc47f5f83b7c9d311fb5787e0740332fca657bc22e1cb9bf4.jpg)

Note: To specify multiple feeds, you must specify multiple NewsFeed properties.

# NewsFeedCategory

The name of the customized information. It can be used to identify informational, warning or alert messages, for example. The path to an image can also be added to better identify the information with an icon.

To add more category images, specify a list of properties named NewsFeedCategory, for example:

```xml
<property name="NewsFeedCategory" value="my company info" icon="http://www.my.company.com/info.png" />
<property name="NewsFeedCategory" value="my company alert" icon="http://www.my.company.com/alert.png" />
```

If no customized feed is specified, the default feed is used, which retrieves the latest product information from official support sites. To disable any notification, comment the entire section. To disable only external notifications about product information updates, assign an empty string as value to the FeedURL property of JSONP feed like:

```txt
<property name="FeedURL" type="JSONP" value="" />
```

# Example:

```xml
<?xml version"1.0"?>
<tdwc>
    ...
    <settings>
        <NewsFeed>
            <property name="NewsFeed" type="RSS"
                value="http://www.DWChostname:portnumber.com/my_rss.xml" />
            <property name="NewsFeed" type="ATOM"
                value="http://www.DWChostname:portnumber.com/my_atom.xml" />
        <property name="PollInterval" value="600" />
        <property name="PollInitialDelay" value="1" />
        <property name="FeedURL" type="JSONP" value="'" />
    </property>
</xml>
```

```xml
<property name="NewsFeedCategory" value="my company info" icon="http://www.DWChostname:portnumber.com/info.png" /> <property name="NewsFeedCategory" value="my company alert" icon="http://www.DWChostname:portnumber.com/alert.png" /> </NewsFeed> </settings>
```

See TdwcGlobalSettings.xml sample on page 169 to view the complete syntax for the file.

For more information about how to customize global settings, see Customizing your global settings on page 155.

# Disable and customize the creation of predefined tasks

This section defines the environment for which predefined tasks are created.

# precannedTaskCreation

Some predefined tasks are created by default and are available when you log in to the console. There is a predefined Monitor task for every object, for both z/OS® and distributed engines. Default value is all. To change this setting, use one of the following values:

all

All predefined tasks are created. This is the default.

distributed

Only predefined tasks for distributed engines are created

ZOS

Only predefined tasks for z/OS engines are created

none

No predefined task is created.

```xml
<?xml version"1.0"?>
<tdwc>
    <settings>
        <application>
            <property name="precannedTaskCreation" value="all"/>
        </application>
    </settings>
</tdwc>
```

See TdwcGlobalSettings.xml sample on page 169 to view the complete syntax for the file.

For more information about how to customize global settings, see Customizing your global settings on page 155.

# Add customized URL to job and job streams

This section contains URLs where you can store customized documentation about your jobs or job streams. By default, this setting is not specified. If you want to associate customized documentation to a job or job stream, use this setting to specify the external address where this information is located.

If you want to specify a URL where customized documentation for a job and job stream is stored, uncomment the section lines, specify the required URL, and optionally assign a name to the UI label by specifying a value for the customActionLabel property. By default this name is Open Documentation. This label is then displayed in the More Actions menus in Monitor Jobs and Monitor Job Streams tasks, as well as in the graphical views of the plan (in the object's tooltips, context menus and properties). In this example, selecting Open Documentation accesses the relevant documentation making it possible to open the documentation while monitoring your job or job stream in the plan.

To implement this setting, assign values to the following keywords:

# customActionLabel

The name of the action displayed in menus, object properties, and tooltips to access customized documentation about your jobs or job streams. By default this name is "Open Documentation" unless you customize the name with this keyword.

# jobUrITemplate

The address of your job documentation. No default value available.

# jobstreamUrlTemplate

The address of your job stream documentation. No default value available.

Consider the following example:  
```xml
<?xml version"1.0"?>
<tdwc>
..
settings>
<twsobjectDoc>
    <property name="jobstreamUrlTemplate">
        value="http://www.yourhost.com/tws/docs/${js-encoded_folder_path}${js_name_w}"/>
    <property name="jobUrlTemplate">
        value="http://www.yourhost.com/docs/jobs/${job_name_w}"/>
    <property name="customActionLabel" value="Your Custom Label Name"/>
</twsobjectDoc>
</settings>
</tdwc>
```

See TdwcGlobalSettings.xml sample on page 169 to view the complete syntax for the file.

These properties must be valid URLs, containing one or more of the variables listed in the table below.

If you use any of the following special characters in the URL, you must write them as follows:

Table 22. Syntax for special characters  

<table><tr><td>Special characters</td><td>Write them as...</td></tr><tr><td>quote (&quot; )</td><td>\&quot;</td></tr><tr><td>apostrophe (&#x27; )</td><td>&amp;apos;</td></tr><tr><td>ampersand (&amp;)</td><td>&amp;amp;</td></tr><tr><td>less than (&lt;)</td><td>&amp;lt;</td></tr><tr><td>greater than (&gt; )</td><td>&amp;gt;</td></tr><tr><td>backslash (\\ )</td><td>\</td></tr></table>

Multiple variables can be included in a URL and must be specified using the following syntax: ${variable}:

Table 23. Variables used in the URL definition  

<table><tr><td>Name</td><td>Object</td><td>Description</td></tr><tr><td>job_number_w</td><td>Job z/OS®</td><td>The number of the job</td></tr><tr><td>job_wkst_w</td><td>Job</td><td>The name of the workstation on which the job runs and the folder where it is stored, if any.</td></tr><tr><td>job_jsname_w</td><td>Job</td><td>The name of the job stream that contains the job and the folder where it is stored, if any.</td></tr><tr><td>job_jswkst_w</td><td>Job</td><td>The name of the job stream that contains the job and the folder where it is stored, if any.</td></tr><tr><td>jobactualarriva_l_w</td><td>Job z/OS®</td><td>The actual start time of the job (date format: YYYY-MM-DDThh:mm:ss)</td></tr><tr><td>jobactualend_w</td><td>Job z/OS®</td><td>When the job actually completed (date format: YYYY-MM-DDThh:mm:ss)</td></tr><tr><td>job_starttime_w</td><td>Job</td><td>The start time of the job (date format: YYYY-MM-DDThh:mm:ss)</td></tr><tr><td>job_id_w</td><td>Job</td><td>The ID of the job</td></tr><tr><td>job_returncode_w</td><td>Job</td><td>The return code of the job</td></tr><tr><td>js_name_w</td><td>Job stream</td><td>The name of the job stream that contains the job</td></tr><tr><td>js_wkst_w</td><td>Job stream</td><td>The name of the job stream that contains the job and the folder where it is stored, if any.</td></tr><tr><td>js_id_w</td><td>Job stream</td><td>The job stream ID</td></tr><tr><td>jslatest_start_w</td><td>Job stream</td><td>The latest time at which a job stream can start (date format: YYYY-MM-DDThh:mm:ss)</td></tr></table>

Table 23. Variables used in the URL definition (continued)  

<table><tr><td>Name</td><td>Object</td><td>Description</td></tr><tr><td>engine_name_w</td><td>Engine</td><td>The name of the engine connection</td></tr><tr><td>engine_host_w</td><td>Engine</td><td>The hostname of the engine connection</td></tr><tr><td>engine_port_w</td><td>Engine</td><td>The port number of the engine connection</td></tr><tr><td>engine_plan_w</td><td>Engine</td><td>The ID of selected plan</td></tr><tr><td>engineServe_w</td><td>Engine</td><td>The remote server name of the engine connection</td></tr></table>

# User registry

Use this section to configure some properties related to the User Registry in use.

# groupIdMap

The property groupIdMap is related to the groups of User Registry, and can be modified to map and display the specified value of each group. By default the common name of the group is displayed.

# importSettingsMaxFileSize

The property importSettingsMaxFileSize is related to the "Manage settings" > "Import Settings" functionality and defines the max file size of the uploaded TDWCSettings.xml. KB is the unit of measure, and by default, it is set to 102400 KB (100 MB). If you need to upload a property file bigger than 100MB, you can increase this value, but for security purposes, it is strongly suggested to revert the file size back to the default value once the import has been performed.

# Examples:

```xml
<?xml version"1.0"?>
<tdwc>
    ...
    <settings>
        <security>
            <property name="groupIdMap" value="cn"></property>
        <property name="importSettingsMaxFileSize" value="102400"></property>
        </security>
        </settings>
    .
</tdwc>
```

Therefore, if you need to change the default value "cn" to "racfid", you can define this property as follows:

```xml
<property name="groupIdMap" value="racfid"></property>
```

See the section about the TdwcGlobalSettings.xml sample in Administration Guide to view the complete syntax for the file.

or see the section about user settings in IBM Workload Automation: Dynamic Workload Console User's Guide to manage Dynamic Workload Console settings.

For more information about how to customize global settings, see Customizing your global settings on page 155.

# z/OS http connections

Use this section to configure the timeout to read and write information on IBM® Z® Workload Scheduler engine. When you connect to the IBM® Z® Workload Scheduler engine to retrieve a list of defined objects, you receive an error message if the list is not returned within the timeout period. The value is expressed in milliseconds.

# Example:

```xml
<?xml version"1.0"?>
<tdwc>
..
<settings>
<http>
<property name="zosHttpTimeout" value="90000" />
</http>
..
</settings>
</tdwc>
```

See TdwcGlobalSettings.xml sample on page 169 to view the complete syntax for the file.

For more information about how to customize global settings, see Customizing your global settings on page 155.

# Limit the number of objects retrieved by queries

Use this section to configure: the number of results displayed for Monitor tasks, the maximum number of rows to display on each page, and the number of direct queries to maintain in history.

If you want to limit the number of results produced by your queries, you can specify the maximum number of items that must be retrieved using the monitorMaxObjectsPM property.

![](images/43646d3bedeec192d049fc1f19cab2f4af35fccf0b355d20a7e7a8e1048540bd.jpg)

Note: monitorMaxObjectsPM property only limits the number of results for archived plans queries. The property does not affect current plan queries.

For Multiple engine tasks, this limit is applied to each engine included in the query. Therefore, if you specify a limit of 500 results and, for example, you run a Monitor jobs on multiple engine task on three engines, the results produced by your query will be no more than 500 for each engine, for a maximum of 1500 rows.

![](images/6687bd4cb5bd4e026774ee2696b5f7c3bb831d272fba9bd702b6cdad564f0cdd.jpg)

Note: This setting does not apply to Monitor critical jobs tasks.

To set the maximum number of rows to display in a table view, configure the maxRowsToDisplay property.

To set the maximum number of direct queries to maintain in history, configure the maxHistoryCount property. These queries are available from the pull-down for the Query field on the Monitor Workload page.

```xml
<?xml version"1.0"?>
<tdwc>
    <settings>
        <monitor>
            <property name="monitorMaxObjectsPM" value="2000"></property>
        </monitor>
    <ph rev="v92"><monitor>
        <property name="maxRowsToDisplay" value="25"></property>
    </monitor>
    <monitor>
        <property name="maxHistoryCount" value="100"></property>
    </monitor>
</ph>
</settings>
<settings>
    <search>
        <property name="search_max_limit" value="1500"></property>
    </search>
</settings>
</tdwc>
```

See TdwcGlobalSettings.xml sample on page 169 to view the complete syntax for the file.

For more information about how to customize global settings, see Customizing your global settings on page 155.

# Limit task and engine sharing

Use this section to prevent users from sharing tasks and engines.

By default there is no limit to task and engine sharing and all users are authorized to share their tasks and engine connections. If you want to change this behavior, preventing users from sharing tasks and engines, set this property to true.

The property default value is false, set it to true to enable the limit:

# limitShareTask

Set to true to prevent users from sharing tasks.

# limitShareEngine

Set to true to prevent users from sharing engine connections.

```xml
<?xml version"1.0"?>
<tdwc>
.
.
<settings>
    <security>
        <property name="limitShareTask" value="false" />
    <property name="limitShareEngine" value="false" />
```

```xml
</security>  
</settings>  
.  
</tdwc>
```

See TdwcGlobalSettings.xml sample on page 169 to view the complete syntax for the file.

For more information about how to customize global settings, see Customizing your global settings on page 155.

# Show all dependencies

This section defines whether to show all dependencies displayed, regardless of their being satisfied or not.

# ShowDependencies

When you open the dependencies panel from Monitor jobs and Monitor job streams task results, by default only Not Satisfied dependencies are shown. Uncomment this section and leave the value set to "true" to have all dependencies displayed, regardless of their being satisfied or not. Possible values are:

true

All dependencies displayed, regardless of their being satisfied or not.

false

Only not satisfied dependencies are displayed.

```xml
<?xml version"1.0"?>
<tdwc>
<settings>
    <ShowDependencies>
        <property name="AlwaysShowAllDependencies"
            value="true"></property>
    </ShowDependencies>
</settings>
</tdwc>
```

See TdwcGlobalSettings.xml sample on page 169 to view the complete syntax for the file.

For more information about how to customize global settings, see Customizing your global settings on page 155.

# Auditing mobile app activity

This section defines whether to track activities performed in the Self-Service Dashboards application in an auditing log file.

For information about the name and location of the log file, see the logs and traces section in the Troubleshooting Guide.

# SSAuditing

This value is set to "true" by default so that operations performed in the Self-Service Dashboards application are written to a log file. The log file contains information such as creation, modification and deletion dates, the operations performed in the mobile apps, and the user performing the operations. Possible values are:

true

Operations performed in the Self-Service Dashboards application are tracked in an auditing log file.

false

Operations performed in the Self-Service Dashboards application are not tracked in an auditing log file.

# SSAuditingLogSize

The maximum size of a log file in KB. When a log file reaches the maximum size, the system rolls that log file over and creates a new file. By default, the maximum size of a log file is 100 KB.

# SSAuditingLogFiles

The default number of log files to create. When this number is met and the latest log file reaches its maximum size, the system deletes the oldest log file and rolls the latest file over and creates a new file.

```xml
<?xml version"1.0"?>
<tdwc>
.
.
<settings>
<SSCMAuditing>
    <property name = "SSAuditing" value="true"></property>
    <property name = "SSAuditingLogSize" value="100"></property>
    <property name = "SSAuditingLogFiles" value="2"></property>
</settings>
.
.
</tdwc>
```

See TdwcGlobalSettings.xml sample on page 169 to view the complete syntax for the file.

For more information about how to customize global settings, see Customizing your global settings on page 155.

# Modifying the number of archived plans displayed in the Dynamic Workload Console

You can modify the number of archived plans displayed in the Monitor Workload view of the Dynamic Workload Console. The default number is 30 plans.

To modify the default number, configure the following property in the TdwcGlobalSettings.xml file:

```txt
<monitor> <property name  $=$  "maxArchivedPlan"value  $=$  "30"></property> </monitor>
```

See TdwcGlobalSettings.xml sample on page 169 to view the complete syntax for the file.

For more information about how to customize global settings, see Customizing your global settings on page 155.

# Show or hide predecessors from What-if Analysis Gantt view

When you have hundreds of predecessors, you can optimize performance by excluding them from the What-if Analysis Gantt view. By default, all predecessors are loaded into the What-if Analysis Gantt view. To exclude them, uncomment this section and leave the default setting of the property whatIfAutoLoadPreds to "false". To revert back to the default behavior either set the property to "true" or comment the section again in the TdwcGlobalSettings.xml file.

To modify the default setting, configure the following property in the TdwcGlobalSettings.xml file:

```xml
<WhatifAnalysis> <property name  $=$  "whatIfAutoLoadPreds" value="false"></property> </WhatifAnalysis>
```

See TdwcGlobalSettings.xml sample on page 169 to view the complete syntax for the file.

For more information about how to customize global settings, see Customizing your global settings on page 155.

# TdwcGlobalSettings.xml sample

The following example is a sample of the file:

```xml
<?xml version="1.0"?>
<tdwc>
<!-- 
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # 
# # # # # # # # # # # # # 
# # # # # # # # # 
# # # # # # 
# # 
# #
-->
<settings>
<!-- 
# # # # # # # # # # # 
# # # # 
# # 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
# 
#
-->
This section shows how you should customize your URLs that link video content in the Dynamic Workload Console so that you can link to a company intranet server to view help videos rather than a public video site.
##### This prefix "_baseURL" will be added to all video URLs ###
##### Links to videos, missing entries or empty (blank) values are not considered ###
##### Graphical view: detect loop #
##### Graphical view: highlight and release dependencies #
##### Graphical view: reply to prompt dependency #
##### Graphical view: using the impact view #
##### Table: creating and using tasks #
##### Workload editor: add and remove a file dependency #
##### Workload editor: create a dependency #
##### Workload editor: add a job #
##### Workload editor: highlight dependencies #
##### Workload editor: creating a z/OS job #
-->
<!-- 
<!-- 
<videoGallery>
    <property name="_baseURL" value=""></property>
    <property name="depLoop" value=""></property>
    <property name="highlightRelDep" value=""></property>
    <property name="viewDepPrompt" value=""></property>
    <property name="USingImpactView" value=""></property>
    <property name="createUseTasks" value=""></property>
    <property name="weAddRemoveFile" value=""></property>
    <property name="weCreateDeps" value=""></property>
    <property name="weAddJob" value=""></property>
```

```txt
<property name="weighthightDeps" value \(= = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = 1000 for all properties.  
<!--  
    GRAPHICAL VIEW SETTINGS  
    <!--  
    <--  
    This section specifies the maximum number of objects shown in each graphical view.  
Default value is 1000 for all properties.  
--->  
    <!--  
    <graphViews>  
    <property name="planViewMaxJobstreams" value="1000"></property>  
    <property name="preProdPlanViewMaxJobstreams" value="1000"></property>  
    </graphViews>  
    --->  
    </!--  
    【AutoLayout configuration】【AutoLayout configuration】  
nodeSep: a number of pixels representing the separation between adjacent nodes in the same rank. Default is 30  
edgeSep: a number of pixels representing the separation between adjacent edges in the same rank. Default is 0  
rankSep: a number of pixels representing the separation between ranks. Default is 0  
rankDir: direction of the layout (Possible values are: "TB" (top-to-bottom), "BT" (bottom-to-top), "LR" (left-to-right), "RL" (right-to-left)). Default is TB  
marginX: a number of pixels representing the separation between adjacent nodes in the same rank. Default is 100  
marginY: number of pixels to use as a margin around the top and bottom of the graph. Default is 100  
setLinkVertices: If set to true the layout will adjust the links by setting their vertices. It defaults to false.  
If the option is defined as a function it will be used to set the vertices of links at the end of the layout.  
--->  
</AutoLayout>  
<property name="nodeSep" value="30"/>  
<property name="edgeSep" value="0"/>  
<property name="rankSep" value="0"/>  
<property name="rankDir" value="TB"/>  
<property name="marginX" value="100"/>  
<property name="marginY" value="1500"/>  
<property name="marginY" value="1500"/>  
<property name="setLinkVertices" value="false"/>  
</AutoLayout>  
--->  
<!--  
    【graphViews】  
    <property name="planViewNewWindow" value="true"/>  
    </graphViews>  
    --->  
    【disable /CUSTOMIZE CREATION OF PREDEFINED TASKS】【disable /CUSTOMIZE CREATION OF PREDEFINED TASKS】  
    【disable /CUSTOMIZE CREATION OF PREDEFINED TASKS】  
    --->  
    <!--  
        To avoid or customize the creation of predefined tasks at first logon. Possible values are:  
all both distributed and z/OS tasks are created. This is the default value  
none no task is created  
distributed only distributed tasks are created  
zos only z/OS tasks are created  
--->  
<application>  
<property name="precannedTaskCreation" value="all"/>  
<property name="updateWorkstationMaxNumber" value="20"/>  
</application>  
--->  
<!--  
    <PositionSorting>  
    <property name="enabled" value="true"></property>  
</positionsorting>  
--->
```

```txt
--  
<!--  
This section contains URLs where you can store customized documentation about your jobs or job streams. By default this setting is not specified. If you want to associate customized documentation to a job or job stream, use this setting to specify the external address where this information is located. If you want to specify a URL to be opened as related documentation for jobs and job streams, uncomment the section lines so that a new action, Open Documentation, is inserted in the More Actions menu for Monitor Jobs and Monitor Job Streams tasks. The new action links to the specified URL  
You can customize the URL template by using variables. The variables have the following syntax {{variable_name}}  
For the complete list of variables, please refer to the documentation.  
--->  
<!--  
<-->  
<twosobjectDoc>  
    <property name="jobstreamTemplate" value="http://www.yourhost.com/tws/docs/jobstream/\${js_name_w}" />  
    <property name="jobUrlTemplate" value="http://www.yourhost.com/docs/jobs/\${job_name_w}" />  
    <property name="customActionLabel" value="Custom Action" />  
</twosobjectDoc>  
--->  
<!--  
<!--  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
**********  
********** 
Z/OS HTTP CONNECTIONS  //   
//   
--->  
<!--  
<!--  
<-->  
<property name="groupIdMap" value="cn"></property>  
<property name="importSettingsMaxFileSize" value="102400"></property>  
</security>  
<--->  
<!--  
<--->  
<http>  
    <property name="zosHttpTimeout" value="90000" />  
</http>  
--->  
<!--  
<!--  
<--->  
<property name="monitorMaxObjectsPM" value="2000"></property>  
<monitor>
```

```xml
<property name="maxRowsToDisplay" value="25"></property> </monitor> --> <!-- You modify the number of archived plans displayed in the Monitor Workload view of the Dynamic Workload Console. The default number is 30 plans. --> <!-- <monitor> <property name="maxArchivedPlan"value="30"></property> </monitor> --> <!-- <monitor> <property name="maxHistoryCount" value="100"></property> </monitor> --> <!-- Custom SQL report HTML format maximum limit. The default limit is 10000. --> <!-- <monitor> <property name="SQL_REPORTedlyHTL_MODETResult_MAX_NUMBER" value="10000"></property> </monitor> --> <!-- <monitor> <property name="PROMPT_FILTER" value="true"></property> </monitor> --> <!-- <settings> <search> <property name="search_max_limit" value="500"></property> </search> </settings> --> <!-- <monitor> <property name="maxRowInfoNumber" value="100"></property> </monitor> --> <!-- Increase the share maximum limit to share engines, boards, queries, and data sources. --> <!-- <ShareLimit> <property name = "MaxShareCount" value="1000"></property> </ShareLimit> --> <!--
```

```txt
Use this section to prevent users from sharing tasks and engines. By default there is no limit to task and engine sharing and all users are authorized to share their tasks and engine connections. If you want to change this behavior, preventing users from sharing tasks and engines, set this property to true. The property default value is false, set it to true to enable the limit: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1-- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- --- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �--- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- �---- �----- {\}
```

```snap
Use this section to change the default behavior of the auditing of activities performed using the Self-Service Catalog and the Self-Service Dashboards applications. By default, auditing is enabled. You can also set the maximum size of the log file before it rolls over to a new log file, and the maximum number of log files maintained. Note: This section is valid only for the Self-Service Catalog V9.x, not for the latest one.  
--->  
<----  
<SSCMAuditing>  
<property name = "SSAuditing" value="true"></property>  
<property name = "SSAuditingLogSize" value="100"></property>  
<property name = "SSAuditingLogFiles" value="2"></property>  
</SSCMAuditing>  
--->  
<----  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#*********  
--->  
</settings>  
<----  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
--->  
<settings role="Administrator">  
<---> Put here setting to be applied only to users with Administrator role --->  
</settings>  
<--->  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
--->  
<settings role="Operator">  
</settings>  
<--->  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
--->  
<settings role="Configurator">  
</settings>  
<--->  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
#**********  
--->  
<settings role="Developer">  
</settings>  
<--->
```

For more information about how to customize global settings, see Customizing your global settings on page 155.

# Disable the What-if Analysis

You can disable the What-if Analysis in your environment by setting the optman enWhatIf | wi global option to no (default value is yes).

The enWhatIf | wi global option interacts with the enWorkloadServiceAssurance | wa global option, which enables or disables privileged processing of mission-critical jobs and their predecessors. For details about this interaction, see the following table.

Table 24. Interaction between enWorkloadServiceAssurance and enWhatIf global options  

<table><tr><td>Options</td><td>Interaction</td></tr><tr><td>enWorkloadServiceAssurance | wa is set to yes</td><td>Both the Workload service assurance and the What-if Analysis features are fully enabled in your environment.</td></tr><tr><td>enWhatIf | wi is set to yes</td><td></td></tr><tr><td>enWorkloadServiceAssurance | wa is set to yes</td><td>The Workload service assurance is enabled. The What-if Analysis feature is disabled and an exception is issued if you try to use it.</td></tr><tr><td>enWhatIf | wi is set to no</td><td></td></tr><tr><td>enWorkloadServiceAssurance | wa is set to no</td><td>The Workload service assurance is partially enabled, just to allow the What-if Analysis feature to work properly. This means that:</td></tr><tr><td>enWhatIf | wi is set to yes</td><td>• The Workload service assurance is disabled and an exception is issued if you try to use it. • No critical job is added to the plan.</td></tr><tr><td>enWorkloadServiceAssurance | wa is set to no</td><td>Both the Workload service assurance and the What-if Analysis features are disabled in your environment.</td></tr><tr><td>enWhatIf | wi is set to no</td><td></td></tr></table>

# Configuring High Availability

How to configure, change, and share your settings repository.

Performance can be highly improved by configuring multiple Dynamic Workload Console instances in a High Availability configuration, so as to have multiple console instances working at the same time and with the same repository settings.

The Dynamic Workload Console is set to be always in High Availability and a front-end Network Dispatcher must be set up to handle and distribute all incoming session requests.

If you use a Dynamic Workload Console in High Availability configuration, when you connect to a Dynamic Workload Console you are not actually connecting to a specific console but to a load balancer that dispatches and redirects the connections among the nodes in the configuration. Therefore, for example, if a node fails, new user sessions are directed to other active nodes in the configuration.

To implement this kind of configuration, the Administrator must ensure that the datasource.xml, located in the following path opt/wa/DWC/DWC_DATA/usr/servers/dwcServer/configDropins/overrides, has the same configuration on every Dynamic Workload Console in the cluster.

# Configuring Dynamic Workload Console to view reports

This topic describes the configuration steps that you perform to be able to see the reports from the Dynamic Workload Console, if are using an Oracle database.

To access the databases where reports are stored, you must have the following prerequisites:

- A user ID and password to access the database  
- A working connection between the Dynamic Workload Console and the database

Perform the following step on the system where the IBM Workload Scheduler engine is running:

- Configuring for an Oracle database on page 175  
- Configuring for a Db2 database in HADR on page 176

# Configuring for an Oracle database

# About this task

# Actions taken on IBM Workload Scheduler engine:

For Oracle, the IT administrator, or the IBM Workload Scheduler IT administrator, or both working together, do the following:

1. Use the TWS Oracle user specified during the master domain manager installation or perform the following steps to create a new user:

a. Create a database user authorized to access the database and specify a password.  
b. Launch the following script:

```txt
<TWA_home>/TWS/dbtools/Oracle/scripts/dbgrant.bat/.sh  
<ID_of_user_to_be Granted>  
<database_name>  
<database_admin_user> <password>
```

where the variables are as follows:

```txt
<TWA_home>
The IBM Workload Automation instance directory
<TID_of_user_to_be Granted>
The ID of the user created in step 1.a on page 175, who is going to be granted the access to the reports
<database_name>
The name of the database, as created when the master domain manager was installed
<database_schema_OWNER> <password>
The user ID and password of the database schema owner.
```

2. Define a valid connection string to the database:

a. Browse to the following path:

On Windows operating systems

<TWA_home>\usr\servers\engineServer\resources\properties

On UNIX operating systems

<TWA_DATA_DIR>/usr/server/engineServer/resources/properties

b. Ensure that the following property is set in the TwSConfig.properties file to point to the Oracle JDBC URL:

```txt
com.ibm.tws.webui.OracleJdbcURL
```

For example:

```javascript
com.ibm.tws.webui.OracleJdbcURL= jdbc:oracle:thin:@//9.132.235.7:1521/orcl
```

The Oracle JDBC URL is also to be specified in the PARAM_DataSourceUrl property in the .config

\`common.properties file. The common.properties file is required when setting up for command line reporting.

For more information about this file, see Setting up for command line audit reporting on page 374 and the section about setting up for command line batch reporting in IBM Workload Scheduler: User's Guide and Reference.

c. Restart WebSphere Application Server Liberty .

# Actions taken on the Dynamic Workload Console:

1. Log on to the Dynamic Workload Console.  
2. In the navigation bar, select Administration > Manage Engines. The Manage Engines panels open.  
3. Select the engine you defined or create another engine. The Engine Connection properties panel is displayed.  
4. In Database Configuration for Reporting, do the following:

a. Check Enable Reporting to enable the engine connection you selected to run reports.  
b. In Database User ID and Password, specify the database user and password that you authorized to access reports.

# Configuring for a Db2 database in HADR

Configure Db2 for generating Dynamic Workload Console reports when Db2 is configured for HADR

# About this task

You can optionally configure Db2 in HADR configuration so that you can connect to the secondary database if the primary database becomes unreachable.

To configure Db2 for generating reports when Db2 is configured for HADR, perform the following steps

1. Stop WebSphere Application Server Liberty, as described in Application server - starting and stopping on page 423.  
2. Browse to the following paths, depending on your operating system:

# On UNIX operating systems

TWA_home/usr/server/engineServer configDropins/template

# On Windows operating systems

TWA_home\usr\servers\engineServer\configDropins\templates

3. Copy the datasource.xml file to a working location and edit it by adding the following strings:

```xml
<variable name="db.clientRerouteAlternateServerName" value="secondary_database"/> <variable name="db.clientRerouteAlternatePortNumber" value="secondary_database_port_number"/>
```

4. You also need to add the call to the above variables. To perform this operation, modify the string:

```xml
<jndiEntry value="jdbc:db2://${db.serverName}:${db.portNumber}/${db(databaseName}" jndiName="db.url"/>
```

as follows:

```txt
:clientRerouteAlternateServerName  $=$  {{db.clientRerouteAlternateServerName};clientRerouteAlternatePortNumber er  $=$  {{db.clientRerouteAlternatePortNumber}；"
```

. The resulting string must be as follows:

```txt
<jndiEntry
value="jdbc:db2://\\({db.serverName}:\$\{db.portNumber\}/\$\{db(databaseName\}:\textclientRerouteAlternateServerName=\$\{db.clientReroute
AlternateServerName\};clientRerouteAlternatePortNumber=\$\{db.clientRerouteAlternatePortNumber\};"
jndiName="db.url"/>
```

5. Copy the edited file to the following paths:

# On UNIX operating systems

TWA_DATA_DIR/usr/servers/engineServer/configDropins/overrides

# On Windows operating systems

TWA_home\usr\servers\engineServer\configDropins\overridden

6. Start WebSphere Application Server Liberty, as described in Application server - starting and stopping on page 423.

# Results

You have now configured your Db2database in HADR.

For more information about HADR configuration, see An active-active high availability scenario on page 127. For more information about templates, see Configuring IBM Workload Scheduler using templates on page 418.

# Chapter 3. Configuring user authorization (Security file)

This chapter describes how to manage the authorizations to access scheduling objects assigned to IBM Workload Scheduler users.

# Getting started with security

The way IBM Workload Scheduler manages security is controlled by a configuration file named security file. This file controls activities such as:

- Linking workstations.  
- Accessing command-line interface programs and the Dynamic Workload Console.  
- Performing operations on scheduling objects in the database or in the plan.

The security file for a fresh installation is located in the following path:

For a fresh installation of version 9.5.x or later

TWA_DATA_DIR

TWA_home\TWS

Upgraded environment originating from a version earlier than 9.5:

TWA_home/TWS

TWA_home\TWS

The security file contains some predefined access definitions:

- A full access definition for the user who installed the product, <TWS_user>.  
- An access definition for the system administrator (root on UNIX™ or Administrator on Windows™).  
- The following access definitions for the Dynamic Workload Console:

Analyst  
$\text{。}$  Administrator  
Operator  
Developer

As you continue to work with the product, you might want to add more users with different roles and authorization to perform specific operations on a defined set of objects.

By default, the security model enabled when you perform a fresh installation is role-based. You can update your security file according to the role-based security model. The role-based security model allows you to update your security file with the security objects (domains, roles, and access control lists) that you define in the master domain manager database. You can define your security objects by using the Manage Workload Security interface from Dynamic Workload Console or the composer command-line program. The role-based security model is enabled through the setting of the optman enRoleBasedSecurityFileCreation global option. By default this option is set to yes. To use the classic security model instead, change the value to no. For details about updating the security file according to the role-based security model, see Role-based

security model on page 179. For more information about the enRoleBasedSecurityFileCreation global option, see Global options - detailed description on page 27.

If you are upgrading IBM Workload Scheduler version 9.3 or earlier, you might want to continue to use the classic security model that allows you to update the security file by using dumpsec and makesec commands from the command line. To continue to use the classic security model, the enRoleBasedSecurityFileCreation global option must be set to no. A new security file is then created and updated with the security objects (domains, roles, and access control lists) that you define in the master domain manager database by using the Manage Workload Security interface from Dynamic Workload Console or the composer command-line program. For details about updating the security file according to the classic security model, see Classic security model on page 205.

Changes to enRoleBasedSecurityFileCreation global option are effective immediately. For details about the enRoleBasedSecurityFileCreation global option, see Global options - detailed description on page 27.

![](images/a97d178903ca2fcb2500838401e69fcdb4fa0ba253e9ba013be72af1be616626.jpg)

Note: The role-based security model and the classic security model are mutually exclusive.

Starting from version 9.5, Fix Pack 3, the term  $\$ 5LAVES$ , which applies to all fault-tolerant agents in both the classic and role-based security models, was replaced with the term  $\$ A G E N T S$  with the same scope. No change is required to your existing scripts nor environments.

# Role-based security model

The security objects that you define by using the Manage Workload Security interface from Dynamic Workload Console, or the composer command-line program, are:

# Access control lists

Each access control list is defined assigning roles to users or groups, on a specific security domain or folder.

# Folders

Each folder has its own level of authorization that defines the set of actions that users or groups can perform on each folder.

# Security roles

Each role represents a certain level of authorization and includes the set of actions that users or groups can perform.

# Security domains

Each domain represents the set of scheduling objects that users or groups can manage.

You save the definitions of your security objects in the master domain manager database. If the role-based security model is enabled for your system (see Getting started with security on page 178), whenever you need to update the security objects, your security file is updated and converted into an encrypted format (for performance and security), replacing the previous file. The system uses this encrypted security file from that point onwards.

Each time a user runs IBM Workload Scheduler programs, commands, and user interfaces, the product compares the name of the user with the user definitions in the security file to determine if the user has permission to perform those activities, on the specified scheduling objects, in a certain security domain.

When the security file is updated on the master domain manager, the security settings on the master domain manager are automatically synchronized with the backup master domain manager.

![](images/c283c14db61ca0f12007c21172841f3f285b03bfcc4589350be61fe22eb7bc60.jpg)

Note: The role-based security model does not support centralized security management on fault-tolerant agents. On fault-tolerant agents, the security is managed locally on each workstation.

# Configuring role-based security from Dynamic Workload Console

# About this task

This section explains how to create and modify the security objects by using the Manage Workload Security interface from Dynamic Workload Console.

To create or modify security objects, you must have permission for the modify action on the object type file with attribute name=security.

When working with the role-based security from the Dynamic Workload Console, be aware that access to security objects is controlled by an "optimistic locking" policy. When a security object is accessed by user "A", it is not actually locked. The security object is locked only when the object update is saved by user "A", and then it is unlocked immediately afterward. If in the meantime, the object is accessed also by user "B", he receives a warning message saying that the object has just been updated by user "A", and asking him if he wants to override the changes made by user "A", or refresh the object and make his changes to the updated object.

# Managing access control list

# About this task

Create an access control list by assigning security roles to users or groups, in a certain security domain or in one or more folders.

You can:

- Give access to user or group.  
View access for user or group.  
- View access for Security Domain or folders.  
- Manage accesses.

# Give access to user or group

# About this task

To give access to users or groups complete the following procedure:

1. From the navigation toolbar, click Administration.  
2. In the Workload Environment Design, select Manage Workload Security.

# Result

The Manage Workload Security panel opens.

3. From the drop-down list, select the IBM Workload Scheduler engine on which you want to manage security settings.  
4. In the Access Control List section, click Give access to user or group.

# Result

The Create Access Control List panel opens.

5. Enter the user name or the group name, the assigned roles, and the security domain or enter the folders assigned. For each Access Control List you can associate one or more folders.  
6. Click Save to save the access definition in the database.  
7. Click Save and Create New to save the access definition in the database and proceed to create a new access definition.  
8. Click Save and Exit to save the access definition in the database and return to the Manage Workload Security panel.

# Results

The access definition has now been added to the database. If the optman enRoleBasedSecurityFileCreation global option is set to yes, the access definition is activated in your security file.

# View access for user or group

# About this task

From Manage Workload Security, you can also view the access for users or groups.

1. In the Access Control List section of the Manage Workload Security panel, click View access for user or group.

# Result

The input field for the user or group name is displayed.

2. Enter the user or group name and click View.

# Result

The user or group access, with the assigned roles, to the related security domains is displayed.

# View access for Security Domain

# About this task

From Manage Workload Security, you can also view the access to a certain security domain.

1. In the Access Control section of the Manage Workload Security panel, click View access for Security Domain.

# Result

The input field for the security domain name is displayed.

2. Enter the security domain name and click View.

# Result

The list of users or groups, with the assigned roles, that have access to the specified security domain is displayed.

# Manage accesses

# About this task

From Manage Workload Security, you can also remove and edit existing access control lists.

1. In the Access Control List section of the Manage Workload Security panel, click Manage Accesses.

# Result

The list of users or groups, with the assigned roles, that have access to the different security domains is displayed.

2. Select the access control list that you want to manage.  
3. Select the action that you want to run on the selected access control list.

If you select the edit action, you can change only the roles associated with the access control list. You cannot change the associated domain. If you want to change the domain, you must remove the access control list and redefine the access control list with a new domain.

# Managing folders

# About this task

Folders help you to organize jobs and job streams into different categories. You can create folders with different levels of authorization that define the set of actions that users or groups can perform on each folder. More than one folder can be associated to the same Access Control List, and the level of security is also applied to the subFolders.

You can also grant a user administrator privileges on a folder and its subFolders so that this user can then create access control lists, with a dedicated role to manage the objects contained in the folder. See Granting administrator permissions to a user on a folder on page 183.

# Creating, renaming, or deleting a folder

# About this task

To create, rename, or delete a folder:

1. From the navigation toolbar, click Administration.  
2. In the Security, select Manage Workload Security.  
3. From the drop-down list, select the IBM Workload Scheduler engine on which you want to manage security settings.

# Result

The Manage Workload Security panel opens.

4. In the folders section, click Manage Folder.

# Result

The Manage Folders panel opens. From this panel you can:

- Use the search box to search folders and job streams in the current view.  
- Create a folder or subfolder, rename or delete a folder.

# Granting administrator permissions to a user on a folder

# About this task

The IBM Workload Scheduler administrator can grant administrator permissions to a user on a folder so that the user can freely define access control lists for other users on the same folder or any subFolders. Users can then access the objects in the folder or subFolders in accordance with the access permissions they have on the objects.

![](images/86d032ec43134eb2cf1128f8c00124c43db41eea03936be52e7daa1264006c4e.jpg)

Tip: Users with the FULLCONTROL security role assigned automatically have administrator rights on folders.

The following scenario demonstrates how Tim, the IBM Workload Scheduler administrator, grants Linda, the application administrator (appl_admin user), permissions on the folder named /PRD/APP1/, and how Linda grants access to Alex, the application user, to work with the objects defined in /PRD/APP1/FINANCE:

1. Tim, the IBM Workload Scheduler administrator, grants Linda, the app1_admin user, administrator permissions on the folder, /PRD/APP1/, through the definition of an access control list and by modifying her currently assigned role, APPADMIN. Optionally, Tim can create a new role with the appropriate permissions to achieve the same result.

a. From the Manage Workload Security page, Tim selects Manage roles.  
b. He then selects her current role from the list, APPADMIN and clicks Edit.  
c. He gives this role administrator permissions on folders by selecting Delegate folder permission (folder - acl) in the Administrative Tasks section and clicks Save and Exit.  
d. Tim then creates an access control list for Linda, the app1_admin user. From the Manage Workload Security page, Tim selects Give access to users or groups.  
e. From the Create Access Control List page, Tim selects User name from the drop-down and enters Linda's user name, app1_admin in the text box.  
f. In the Role text box, Tim enters the APPADMIN role he modified earlier.  
g. In the text box next to the Folder selection, Tim enters the folder path of the folders on which he wants to grant Linda permissions, /PRD/APP1/.

# Result

Linda, the app1_admin user, with the APPADMIN role assigned, can now access the entire /PRD/APP1/ hierarchy, can create new folders in this path, and can assign access to these folders to other users.

2. Linda needs to give application users such as Alex, access to the objects in the /PRD/APP1/FINANCE folder. She creates a new access control list on the folder for the application user and assigns a role to this user.

a. From the Manage Workload Security page, Linda selects Give access to users or groups from the Access Control List section.  
b. On the Create Access Control List page, Linda selects User name from the drop-down and enters the user name for Alex, the application user, appl_user.  
c. Since Linda cannot create new roles, she specifies an existing role in the Role text box. Only Tim, the IBM Workload Scheduler administrator, can create new roles.  
d. In the text box next to the Folder selection, Linda enters the folder path to the new sub folder she created and to which Alex requires access: /PRD/APP1/FINANCE.

# Result

Alex now can access the /PRD/APP1/ FINANCE folder. He does not have access permissions on the /PRD/APP1 folder.

# Managing security domains

Managing security domains

# About this task

A security domain represents the set of objects that users or groups can manage. For example, you can define a domain that contains all objects named with a prefix 'AA'. If you want to specify different security attributes for some or all of your users, you can create additional security domains based on specific matching criteria.

You can filter objects by specifying one or more attributes for each security object type. You can include or exclude each attribute from the selection. For example, you can restrict access to a set of objects having the same name or being defined on the same workstation, or both.

For the attributes that you can specify for each security object type, seeAttributes for security object types on page 200.

For the values that you can specify for each object attribute, see Specifying object attribute values on page 201.

You can create new security domains or manage existing security domains.

# Create new security domain

# About this task

To create a new security domain from the Dynamic Workload Console, complete the following procedure:

1. From the navigation toolbar, click Administration.  
2. In the Security, select Manage Workload Security.

# Result

The Manage Workload Security panel opens.

3. From the drop-down list, select the IBM Workload Scheduler engine on which you want to manage security settings.  
4. In the Security Domains section, click Create new Security Domain.

# Result

The security domain creation panel opens.

5. Enter the name of the security domain that you are creating and, optionally, the domain description.  
6. Select the type of security domain that you want to define:

# Simple

To define a filtering rule that applies to all object types. Events and actions are excluded from this filtering rule.

# Complex

To define different filtering rules for different object types.

7. Use object filtering to select the set of security objects that users or groups can manage in the security domains that you are defining. You can use the wildcard character (*) when defining object attributes.

8. Click View to see the mapping between the set of security objects that you are assigning to the domain and the corresponding set of security objects in the classic security model.  
9. Click Save to save the security domain definition in the database.  
10. Click Save and Exit to save the security domain definition in the database and then exit.

# Results

The security domain has now been added to the database. If the optmanenRoleBasedSecurityFileCreation global option is set to yes, the security domain is activated in your security file.

# Edit security domain

# About this task

From Manage Workload Security, you can also remove, edit, and duplicate existing security domains.

1. In the Security Domains section of the Manage Workload Security panel, click Manage Security Domain.

# Result

The list of the available security domains is displayed.

2. Select the security domains that you want to manage.  
3. Select the action that you want to run on the selected security domains.

# Managing security roles

# About this task

A security role represents a certain level of authorization and includes the set of actions that users or groups can perform on a set of object types.

For the list of actions that users or groups can perform on the different objects, for each IBM Workload Scheduler task, see Actions on security objects on page 194.

A set of predefined security roles is available in the master domain manager database after the product has been installed:

- A full access definition for the user who installed the product, TWS_user with the default security role assigned named FULLCONTROL.  
- An access definition for the system administrator, root on UNIX or Administrator on Windows.

You can create new security roles or manage existing security roles.

# Create new role

# About this task

To create a new security role from the Dynamic Workload Console, complete the following procedure:

1. From the navigation toolbar, click Administration.  
2. In the Security select Manage Workload Security.

# Result

The Manage Workload Security panel opens.

3. From the drop-down list, select the IBM Workload Scheduler engine on which you want to manage security settings.  
4. In the Roles section, click Create new role.

# Result

The Create Role panel opens.

5. Enter the name of the security role that you are creating and, optionally, the role description.  
6. For each of the IBM Workload Scheduler tasks, assign the level of access for performing certain actions on specific object types to the security role. You can assign a predefined or a custom level of access.  
7. Click Show Details to see the permissions associated to a predefined level of access, or to define your custom level of access. Tooltips are available to explain what a certain permission means for a particular object type.  
8. Click View to see the mapping between the set of permissions that you are assigning and the corresponding set of permissions in the classic security model.  
9. Click Save to save the security role definition in the database.  
10. Click Save and Exit to save the security role definition in the database and return to the Manage Workload Security panel.

# Results

The security role has now been added to the database. If the optman enRoleBasedSecurityFileCreation global option is set to yes, the security role is activated in your security file.

# Manage roles

# About this task

From Manage Workload Security, you can also remove, edit, and duplicate existing roles.

1. In the Roles section of the Manage Workload Security panel, click Manage roles.

# Result

The list of the available security roles is displayed.

2. Select the security roles that you want to manage.  
3. Select the action that you want to run on the selected roles.

# Configuring role-based security with composer command-line

# About this task

This section explains how to create or modify the security objects in the database, by using the composer command line interface.

To define security objects in the database, see:

Access control list definition on page 187

Security domain definition on page 188

Security role definition on page 191

To manage security objects in the database, see the section about managing objects with composer command-line, in the User's Guide and Reference.

To define or modify security objects, you must have permission for the modify action on the object type file with attribute name=security.

# Security access control list definition

In the role-based security model, an access control list assigns security roles to users or groups, in a certain security domain or on a specific folder or folder hierarchy. You can include multiple security access control list definitions in the same text file, along with security domain definitions and security role definitions.

Each security access control list definition has the following format and arguments:

# Syntax

accesscontrollist for security_domain_name

user_or_group_name [security-role[, security-role]...]

[user_or_group_name [security-role, security-role...]]...

end

[securitydomain...]

[securityrole...]

accesscontrollist folder folder_name

user_or_group_name [security-role[, security-role]...]

[user_or_group_name [security-role, security-role...]]...

end

# Arguments

security_domain_name

Specifies the name of the security domain on which you are defining the access control list.

user_or_group_name[security-role], securityRole]

Assigns one or more security roles to a certain user or group, on the specified security domain.

folder_name

Specifies the name of the folder to which you can associate an access control list. If the access control list is associated to a folder, then the security roles are valid for all of the objects contained in the folder. When specifying folder names, ensure you include a forward slash (/) before the folder name. Include a forward slash

after the folder name to indicate that the access control list is defined only on the folder specified, excluding any subFolders. A folder name without a final forward slash indicates that the access control list is defined on the folder, as well as on any subFolders.

Associating an access control list to a folder is a quick and easy method to grant access to all of the objects defined in a folder. If, instead, you need to restrict access to a subset of objects in the folder (for example, objects with a certain name, or specific userlogon, cpu or jcl), then using an access control list associated to a security domain is more effective. With security domains you can filter objects by specifying one or more attributes for each security object type.

See the following composer commands documented in the User's Guide and Reference when working with folders: Chfolder, Listfolder, Mkfolder, Rmfolder, and Renamefolder.

# Example

# Examples

The following example defines:

- An access control list on the SECDOM1 domain  
An access control list on SECDOM2 domain  
An access control list on the folder /FOL1/FOL2/  
- An access control list on the folder /APPS/APP1 and any sub-folders, if present, for example, /APPS/APP1/APP1A.

```txt
ACCESSCONTROLLIST FOR SECDOM1
USER1 SECROLE1, SECROLE2, SECROLE3
USER2 SECROLE4
USER3 SECROLE2, SECROLE4
END
ACCESSCONTROLLIST FOR SECDOM2
USER1 SECROLE1, SECROLE2
USER2 SECROLE3
END
ACCESSCONTROLLIST FOLDER /FOL1/FOL2/
USER1 SECROLE1
END
ACCESSCONTROLLIST FOLDER /APPS/APP1
USER1 SECROLE1
END
```

# Security domain definition

In the role-based security model, a security domain represents the set of objects that users or groups can manage. For example, you can define a domain that contains all objects named with a prefix 'AA'. If you want to specify different security attributes for some or all of your users, you can create additional security domains based on specific matching criteria. You can filter objects by specifying one or more attributes for each security object type. You can include or exclude each attribute

from the selection. For example, you can restrict access to a set of objects having the same name or being defined on the same workstation, or both.

You can include multiple security domain definitions in the same text file, along with security role definitions and access control list definitions.

By default, a security domain named ALOBJECTS is available. It contains all scheduling objects and cannot be renamed nor modified. If you try to rename it, a copy of the domain is created with the new name.

Each security domain definition has the following format and arguments:

# Syntax

Each attribute can be included or excluded from the selection using the plus  $(+)$  and tilde  $(\sim)$  symbols.

securitydomain security_domain_name

[description "description"]

[common [+|~object_attribute [=value | @[, value | @]...]]]

object_type[[+|~]object_attribute [=value/@[value/@...]]

[object_type[[+|~]object_attribute [=value@[value@]...]]]...

end

[securityrole...]

[accesscontrollist...]

# Arguments

securitydomain security_domain_name

Specifies the name of the security domain. The name must start with a letter, and can contain alphanumeric characters, dashes, and underscores. It can contain up to 16 characters.

description "description"

Provides a description of the security domain. The description can contain up to 120 alphanumeric characters.

The text must be enclosed within double quotes.

common [[+|~]object_attribute [= value/@,value/@...]]

Provides object attributes that are common to all the security object types.

object_type[+|~]object_attribute [=value/@,value/@...]]

For each object type, specifies the attributes that apply to that object type and the related values. Each attribute can be included or excluded from the selection using the plus (+) and tilde (~) symbols. Wildcard (@) is supported for the attribute value: object_attribute = @ means that all the objects matching the object attribute must be included in the domain. For the use of wildcard (@), see the examples below.

For the attributes that you can specify for each security object type, see the section about managing security with the Dynamic Workload Console, in the Dynamic Workload Console User's Guide.

For the values that you can specify for each object attribute, see the section about managing security with the Dynamic Workload Console, in the Dynamic Workload Console User's Guide.

# Example

# Examples

The following example defines a security domain named SECDOM1 and a security domain named SECDOM2:

```txt
securitydomain SECDOM1
description "Sample Security Domain1"
job   cpu = $THISCPU, # The workstation where the user logs on
        $MASTER, # The master workstation
        $AGENTS, # Any fault tolerant agent
        $REMOTEs # Any standard agent
        cogs@ # Any workstation whose name starts with "cogs"
    + folder = / # Jobs defined in any folder
    + cpufolder = / # Workstations defined in any folder
    + name = A@ # Any job whose name starts with "A"
    ~ name = A2@ # but doesn't start with A2
    + jcltype = SCRIPTNAME # Allow only SCRIPTNAME type of job definition
    + jcltype = DOCOMMAND # Allow only DOCOMMAND type of job definition
    + logon = $USER, # Streamlogon is the conman/composer user
        $OWNER, # Streamlogon is the job creator
        $JCLOWNER, # Streamlogon is the OS owner of the file
        $JCLGROUP # Streamlogon is the OS group of the file
    ~ logon = root, twsuser # The job cannot logon as "root" or "twsuser"
    + jcl = "/usr/local/bin/@" # The jobs whose executable file that is
        present in /usr/local/bin
    ~ jcl = "@rm@" # but whose JSDL definition does not contain the
        string "rm"
end
securitydomain SECDOM2
description "Sample Security Domain2"
common   cpu@@name=@
userobj   cpu@@ + cpufolder = /
job   cpu@@+ folder = / + cpufolder = /
schedule   cpu@@name=AP@@+ folder = / + cpufolder = /
resource   cpu@@ + folder = / + + cpufolder = /
prompt   folder = /
file   name=@
cpu   cpu@@ + folder = /
parameter   cpu@@ + folder = / + cpufolder = /
calendar   folder = /
report   name=@
eventrule   name@@ + folder = /
action   provider=@
event   provider=@
variable   name@@ + folder = /
wkldapp   name@@ + folder = /
runcygrp   name@@ + folder = /
lob   name=@
folder   name=/
```

# Security role definition

In the role-based security model, a security role represents a certain level of authorization and includes the set of actions that users or groups can perform. You can include multiple security role definitions in the same text file, along with security domain definitions and access control list definitions.

Each security role definition has the following format and arguments:

# Syntax

```txt
securityrole security-role_name [description "description"] object_type access [=action[,action]...] [object_type access [=action[,action]...]... end   
[securitydomain ...]   
[accesscontrollist ...]
```

# Arguments

securityrolesecurityrolename

Specifies the name of the security role. The name must start with a letter, and can contain alphanumeric characters, dashes, and underscores. It can contain up to 16 characters.

description "description"

Provides a description of the security role. The description can contain up to 120 alphanumeric characters. The text must be enclosed within double quotes.

object_type access [=action[,action]...]

For each object type, specifies a list of actions that users or groups can perform on that specific object type.

Table 25: Security object types on page 191 shows the different object types and how they are referenced with composer and with the Dynamic Workload Console:

Table 25. Security object types  

<table><tr><td>Object type
- composer</td><td colspan="2">Object type
- Dynamic Workload Console</td><td>Description</td></tr><tr><td>action</td><td>Actions</td><td colspan="2">Actions defined in scheduling event rules</td></tr><tr><td>calendar</td><td>Calendars</td><td colspan="2">User calendars</td></tr><tr><td>cpu</td><td>Workstations</td><td colspan="2">Workstations, domains, and workstation classes</td></tr><tr><td>event</td><td>Events</td><td colspan="2">Event conditions in scheduling event rules</td></tr></table>

(continued)

Table 25. Security object types  

<table><tr><td>Object type
- composer</td><td>Object type
- Dynamic Workload Console</td><td>Description</td></tr><tr><td>eventrule</td><td>Event Rules</td><td>Scheduling event rule definitions</td></tr><tr><td>file</td><td>Files</td><td>IBM Workload Scheduler database files</td></tr><tr><td>folder</td><td>Folders</td><td>The folder within which jobs and job streams are defined.</td></tr><tr><td>job</td><td>Jobs</td><td>Scheduled jobs and job definitions</td></tr><tr><td>parameter</td><td>Parameters</td><td>Local parameters</td></tr><tr><td>prompt</td><td>Prompts</td><td>Global prompts</td></tr><tr><td>report</td><td>Reports</td><td>The following reports in Dynamic Workload Console:</td></tr><tr><td></td><td></td><td>RUNHIST</td></tr><tr><td></td><td></td><td>Job Run History</td></tr><tr><td></td><td></td><td>RUNSTATS</td></tr><tr><td></td><td></td><td>Job Run Statistics</td></tr><tr><td></td><td></td><td>WWS</td></tr><tr><td></td><td></td><td>Workstation Workload Summary</td></tr><tr><td></td><td></td><td>WWR</td></tr><tr><td></td><td></td><td>Workstation Workload Runtimes</td></tr><tr><td></td><td></td><td>SQL</td></tr><tr><td></td><td></td><td>Custom SQL</td></tr><tr><td></td><td></td><td>ACTPROD</td></tr><tr><td></td><td></td><td>Actual production details (for current and archived plans)</td></tr><tr><td></td><td></td><td>PLAPROD</td></tr><tr><td></td><td></td><td>Planned production details (for trial and forecast plans)</td></tr><tr><td>resource</td><td>Resources</td><td>Scheduling resources</td></tr><tr><td>runcygrp</td><td>Run Cycle Groups</td><td>Run cycle groups</td></tr><tr><td>schedule</td><td>Job Streams</td><td>Job streams</td></tr><tr><td>userobj</td><td>User Objects</td><td>User objects</td></tr><tr><td>variable</td><td>Variable Tables</td><td>Variable tables</td></tr></table>

Table 25. Security object types (continued)  

<table><tr><td>Object type</td><td>Object type</td><td></td><td>Description</td></tr><tr><td>- composer</td><td>- Dynamic</td><td></td><td></td></tr><tr><td></td><td>Workload Console</td><td></td><td></td></tr><tr><td>wkldappl</td><td>Workload</td><td>Workload application</td><td></td></tr><tr><td></td><td>Application</td><td></td><td></td></tr></table>

Table 26: Actions that users or groups can perform on the different objects on page 193 shows the actions that users or groups can perform on the different objects.  
Table 26. Actions that users or groups can perform on the different objects  

<table><tr><td colspan="4">Actions that users or groups can perform on the different objects</td></tr><tr><td>acl</td><td>deldep</td><td>modify</td><td>stop</td></tr><tr><td>add</td><td>delete</td><td>release</td><td>submit</td></tr><tr><td>adddep</td><td>display</td><td>reply</td><td>submitdb</td></tr><tr><td>altpass</td><td>fence</td><td>rerun</td><td>unlink</td></tr><tr><td>altpri</td><td>kill</td><td>resetfta</td><td>unlock</td></tr><tr><td>build</td><td>limit</td><td>resource</td><td>use</td></tr><tr><td>cancel</td><td>link</td><td>run</td><td></td></tr><tr><td>confirm</td><td>list</td><td>shutdown</td><td></td></tr><tr><td>console</td><td>manage</td><td>start</td><td></td></tr></table>

For the actions that users or groups can perform on a specific object type, for each of the IBM Workload Scheduler task, see the section about managing security roles with the Dynamic Workload Console, in the Dynamic Workload Console User's Guide.

# Example

# Examples

The following example defines security role SECROLE1 and security role SECROLE2:

```csv
SECURITYROLE SECROLE1
DESCRIPTION "Sample Security Role"
SCHEDULE ACCESS=ADD,ADDDEP,ALTPRI,CANCEL,DELDEP,DELETE,
DISPLAY,LIMIT,MODIFY,
RELEASE
RESOURCE ACCESS=ADD,DELETE,DISPLAY,MODIFY,RESOURCE,USE,List,UNLOCK
PROMPT ACCESS=ADD,DELETE,DISPLAY,MODIFY,REPLY,USE,List,UNLOCK
```

```txt
FILE ACCESS  $=$  BUILD,DELETE,DISPLAY,MODIFY,UNLOCK   
FOLDER ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,USE,LIST,UNLOCK,ACL   
CPU ACCESS  $=$  LIMIT,LINK,MODIFY,SHUTDOWN,START,STOP,UNLINK,LIST,UNLOCK,RUN   
PARAMETER ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,LIST,UNLOCK   
CALENDAR ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,USE,LIST,UNLOCK   
REPORT ACCESS  $=$  DISPLAY   
EVENTRULE ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,LIST,UNLOCK   
ACTION ACCESS  $=$  DISPLAY,SUBMIT,USE,LIST   
EVENT ACCESS  $=$  USE   
VARTABLE ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,USE,LIST,UNLOCK   
WKLDAPPL ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,LIST,UNLOCK   
RUNCYGRP ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,USE,LIST,UNLOCK   
LOB ACCESS  $=$  USE   
END   
SECURITYROLE SECROLE2   
DESCRIPTION "Sample Security Role"   
SCHEDULE ACCESS  $=$  ADD,ADDDEP,ALTPRI,CANCEL,DELDEP,DELETE, DISPLAYLIMIT,MODIFY,   
RELEASE   
RESOURCE ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,RESOURCE,USE,List,UNLOCK   
PROMPT ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,REPLY,USE,List,UNLOCK   
END
```

The following example defines a new security role APP_admin, for the user APP1_admin and assigns administrator permissions on the folder hierarchy /PRD/APP1/, so that the APP1_admin user can create access control lists to give other users access to the objects in this folder or its subFolders:

# Security role definition

```csv
SECURITYROLE APP.ADMIN  
DESCRIPTION "Security Role"  
JOB ADD,MODIFY,SUBMITDB,USE,ADDDEP,RUN,RELEASE,REPLY,DELETE,DISPLAY,CANCEL,SUBMIT,CONFIRM,RERUN,LIST,DELDEP,KILL,UNLOCK,ALTPRI  
SCHEDULE ADD,ADDDEP,ALTPRI,CANCEL,DELDEP,DELETE,DISPLAY,LIMIT,MODIFY,RELEASE  
FOLDER ADD,DELETE,DISPLAY,MODIFY,USE,LIST,UNLOCK,ACL
```

# Security file

```csv
USER APP_adminofAPP1  
CPU@+LOGON="APP.ADMIN"  
BEGIN  
JOB FOLDER="/PRD/APP1/","/PRD/APP1" + CPUFOLDER = / ACCESS=ADD,ADDDEP,ALTRPRI,CANCEL,SUBMIT,CONFIRM,RERUN,List,DELDEP,KILL,UNLOCK,ALTPRI  
SCHEDULE FOLDER="/PRD/APP1/","/PRD/APP1" + CPUFOLDER = / ACCESS=ADD,ADDDEP,ALTPRI,CANCEL,DELDEP,DELETE,DISPLAY,LIMIT,MODIFY,RELEASE  
FOLDER NAME="/PRD/APP1/","PRD/APP1" ACCESS=ADD,DELETE,DISPLAY,MODIFY,USE,LIST,UNLOCK,ACL
```

# Actions on security objects

The following tables show the actions that users or groups can perform on the different object types, for each IBM Workload Scheduler task. See in parenthesis the corresponding actions and objects values that you must use when defining role-based security with composer command line interface.

Table 27. Actions that users or groups can perform when designing and monitoring the workload  

<table><tr><td colspan="2">Design and Monitor Workload</td></tr><tr><td>Actions that users or groups can perform</td><td>Security object types</td></tr><tr><td>List (list)</td><td>Jobs (job)</td></tr><tr><td>Display (display)</td><td>Job Streams (schedule)</td></tr><tr><td>Create (add)</td><td>User Objects (userobj)</td></tr><tr><td>Delete (delete)</td><td>Prompts (prompt)</td></tr><tr><td>Modify (modify)</td><td>Resources (resource)</td></tr><tr><td>Use (use)</td><td>Calendars (calendar)</td></tr><tr><td>Unlock (unlock)</td><td>Run Cycle Groups (runcygrp)</td></tr><tr><td rowspan="2">Actions on remote workstations while modeling jobs (cpu-run)</td><td>Variable Tables (variable)</td></tr><tr><td>Workload Application (wkldappl)</td></tr><tr><td rowspan="2">Note: See in parenthesis the corresponding actions and objects values that you must use when defining role-based security with the composer command-line interface.</td><td>Workflow Folders (folder)</td></tr><tr><td>Parameters (parameter)</td></tr></table>

Table 28. Actions that users or groups can perform when modifying current plan  

<table><tr><td>Modify current plan
Actions that users or groups can perform on the current plan</td></tr><tr><td>Add job stream dependency (schedule - adddep)</td></tr><tr><td>Add job dependency (job - adddep)</td></tr><tr><td>Remove job dependency (job - deldep)</td></tr><tr><td>Remove job stream dependency (schedule - deldep)</td></tr><tr><td>Change job priority (job - altpri)</td></tr><tr><td>Change job stream priority (schedule - altpri)</td></tr><tr><td>Cancel job (job - cancel)</td></tr><tr><td>Cancel job stream (schedule - cancel)</td></tr><tr><td>Rerun job (job - rerun)</td></tr></table>

Table 28. Actions that users or groups can perform when modifying current plan

(continued)

Modify current plan

Actions that users or groups can perform on the current plan

Confirm job (job - confirm)

Release job (job - release)

Release job stream (schedule - release)

Kill jobs (job - kill)

Reply to prompts (prompt - reply)

Reply to job prompts (job - reply)

Reply to job stream prompts (schedule - reply)

Alter user password (userobj - altpass)

Change jobs limit (schedule - limit)

Actions on job remote system (job - run)

Change resource quantity (resource - resource)

![](images/0ebe8d7390cda71a86bb70bd2ac85cfbcc2fae0a256fd718d81322711a8f6cab.jpg)

Note: See in parenthesis the corresponding actions and objects values that you must use when defining role-based security with the composer command line interface.

Table 29. Actions that users or groups can perform when submitting workload

Submit Workload

Workload definitions that can be added to the current plan

Only existing job definitions (job - submitdb)

Existing jobs definitions and ad hoc jobs (job - submit)

Existing job stream definitions (schedule - submit)

# Table 29. Actions that users or groups can perform when submitting workload

(continued)

# Submit Workload

# Workload definitions that can be added to the current plan

![](images/5caff5049f64ee891a2124b5da3914d43278fffe80da5dfaae7bcd6b80711408.jpg)

Note: See in parenthesis the corresponding actions and objects values that you must use when defining role-based security with the composer command line interface.

# Table 30. Actions that users or groups can perform when managing the workload environment

# Manage Workload Environment

# Actions that users or groups can perform on workstations, domains, and workstation classes

List workstations (cpu - list)

Display workstation details (cpu - display)

Create workstations (cpu - add)

Delete workstations (cpu - delete)

Modify workstations (cpu - modify)

Use workstations (cpu - use)

Unlock workstations (cpu - unlock)

Start a workstation (cpu - start)

Stop a workstation (cpu - stop)

Change limit (cpu - limit)

Change fence (cpu - fence)

Shutdown (cpu - shutdown)

Reset FTA (cpu - resetfta)

Link (cpu - link)

Unlink (cpu - unlink)

Use 'console' command from conman (cpu - console)

Upgrade workstation (cpu - manage)

# Table 30. Actions that users or groups can perform when managing the workload environment

(continued)

# Manage Workload Environment

# Actions that users or groups can perform on workstations, domains, and workstation classes

![](images/7238b5a5b3bdaaa17d2a042a3c60ccda93935052718f1fb1f6c8338c140558a1.jpg)

Note: See in parenthesis the corresponding actions and objects values that you must use when defining role-based security with the composer command line interface.

# Table 31. Actions that users or groups can perform when managing event rules

# Manage Event Rules

# Actions that users or groups can perform on event rules

List event rules (eventrule - list)

Display event rules details (eventrule - display)

Create event rules (eventrule - add)

Delete event rules (eventrule - delete)

Modify event rules (eventrule - modify)

Use event rules (eventrule - use)

Unlock event rules (eventrule - unlock)

Display actions in the event rules (action - display)

Monitor triggered actions (action - list)

Use action types in the event rules (action - use)

Submit action (action - submit)

Use events in the event rules (event - use)

Use a File Monitor event on the workstation where the file resides. (event - display)

Table 31. Actions that users or groups can perform when managing event rules

(continued)

# Manage Event Rules

# Actions that users or groups can perform on event rules

![](images/32679963365addbe04406d98b20d6584a1de10fa5fa4e7a1de59eceddd955c96.jpg)

Note: See in parenthesis the corresponding actions and objects values that you must use when defining role-based security with the composer command line interface.

Table 32. Administrative tasks that users or groups can perform

# Administrative Tasks

# Administrative tasks that users or groups can perform

View configuration (dump security and global options) (file - display)

Change configuration (makesec, optman add) (file - modify)

Delete objects definitions (file - delete)

Unlock objects definitions (file - unlock)

Allow planman deploy, prosked and stageman (file - build)

Delegate security on folders (folder - acl)

![](images/c6cf9a398e6f13f204554861ece2e2faf73c09b87ff2ab19bd4c813226d83d90.jpg)

Note: See in parenthesis the corresponding action and object values that you must use when defining role-based security with the composer command-line interface.

Table 33. Actions that users or groups can perform on workload reports

# Workload Reports

# Actions that users or groups can perform on workload reports

Generate workload reports

(display report)

Reports in Dynamic Workload Console

RUNHIST

Job Run History

RUNSTATS

Job Run Statistics

WWS

Workstation Workload Summary

WWR

Workstation Workload Runtimes

Table 33. Actions that users or groups can perform on workload reports

(continued)

# Workload Reports

# Actions that users or groups can perform on workload reports

SQL

Custom SQL

ACTPROD

Actual production details (for current and archived plans)

PLAPROD

Planned production details (for trial and forecast plans)

![](images/6a560add1e7347af337a0ad1fb7339c80729f7920bb22af7b590a893dc7ec0fa.jpg)

Note: See in parenthesis the corresponding actions and objects values that you must use when defining role-based security with the composer command line interface.

Table 34. Actions that users or groups can perform on folders.

# Folders

# Actions that users or groups can perform on folders

Access folders

chfolder(display)

istfolder(list or list and display)

mkfolder (modify)

rmfolder (delete)

filename folder (add)

![](images/907b952d9379b16127fa5438daf29700f7076b7c85cbe9bcd3a9f246e027a9b7.jpg)

Note: See in parenthesis the corresponding actions and objects values that you must use when defining role-based security with the composer command line interface.

# Attributes for security object types

Table 35: Attributes for security object types on page 201 shows the attributes that you can specify for each security object type (see in parenthesis the corresponding object type and object attribute that you must use when defining security objects with the composer command line interface).

Table 35. Attributes for security object types  

<table><tr><td>Security object type</td><td>Attribute Name (name)</td><td>Workstation (cpu)</td><td>Custom (custom)</td><td>JCL (jcl)</td><td>JCLtype (jcltype)</td><td>Logon (logon)</td><td>Provider (provider)</td><td>Type (type)</td><td>Host (host)</td><td>Port (port)</td><td>Folder (folder)</td><td>CPU Fofder (cpu folder)</td></tr><tr><td>Actions (action)</td><td></td><td></td><td></td><td></td><td></td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td></td><td></td></tr><tr><td>Calendars (calendar)</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>✓</td><td></td></tr><tr><td>Workstations (cpu)</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td>✓</td><td></td><td></td><td>✓</td><td></td></tr><tr><td>Events (event)</td><td></td><td></td><td>✓</td><td></td><td></td><td></td><td>✓</td><td>✓</td><td></td><td></td><td></td><td></td></tr><tr><td>Event rules (eventrule)</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>✓</td><td></td></tr><tr><td>Files (file)</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Jobs (job)</td><td>✓</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td></td><td></td><td></td><td></td><td>✓</td><td>✓</td></tr><tr><td>Parameters (parameter)</td><td>✓</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>✓</td><td>✓</td></tr><tr><td>Prompts (prompt)</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>✓</td><td></td></tr><tr><td>Reports (report)</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>Resource (resource)</td><td>✓</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>✓</td><td></td></tr><tr><td>RunCycle groups (runcygrp)</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>✓</td><td></td></tr><tr><td>Job streams (schedule)</td><td>✓</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>✓</td><td>✓</td></tr><tr><td>User objects (userobj)</td><td></td><td>✓</td><td></td><td></td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td>✓</td></tr><tr><td>Variable tables (vartable)</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>✓</td><td></td></tr><tr><td>Workload applications (wkldappl)</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>✓</td><td></td></tr><tr><td>Folders (folder)</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>

For the values that are allowed for each object attribute, see Specifying object attribute values on page 201.

# Specifying object attribute values

The following values are allowed for each object attribute (see in parenthesis the corresponding object type and object attribute for the composer command line interface):

# Name (name)

Specifies one or more names for the object type.

- For the Files (file) object type, the following values apply:

# globalopts

Allows the user to set global options with the optman command. The following access types are allowed:

Display access for optman 1s and optman show  
- Modify access for optmanchg

# prodsked

Allows the user to create, extend, or reset the production plan.

# security

Allows the user to manage the security file.

# Symphony

Allows the user to run stageman and JnextPlan.

# trialsked

Allows the user to create trial and forecast plans or to extend trial plans.

![](images/89488c2c599cf75e84ec01b0c70b4a8a36fffc1fcc0a5cf5080185fc97215232.jpg)

Note: Users who have restricted access to files should be given at least the following privilege to be able to display other object types that is, Calendars (calendar) and Workstations (cpu):

```batch
file name=globalots action  $\equiv$  display
```

- For the Variable Tables (variable) object type, you can use the $DEFAULT value for the Name (name) attribute to indicate the default variable table. This selects the table that is defined with the isdefault attribute.

# Workstation (cpu)

Specifies one or more workstation, domain, or workstation class name. Workstations and workstation classes can optionally be defined in a folder. If this attribute is not specified, all defined workstations and domains can be accessed. Workstation variables can be used:

#  $MASTER

The IBM Workload Scheduler master domain manager.

# $AGENTS

Any fault-tolerant agent.

#  $REMOTES

Any standard agent.

#  $THISCPU

The workstation on which the user is running the IBM Workload Scheduler command or program.

If you use the composer command line to define security domains, the following syntax applies:

```txt
cpu=[folder/]workstation]...
```

# folder=foldername

Scheduling objects such as, jobs, job streams, and workstations, to name a few, can be defined in a folder. A folder can contain one or more scheduling objects, while each object can be associated to only one folder. The default folder is the root folder (/).

# cpufolder=foldername

The folder within which the workstation or workstation class is defined.

# Custom (custom)

Use this attribute to assign access rights to events defined in event plug-ins. The precise syntax of the value depends on the plug-in. For example:

- Specify different rights for different users based on SAP R/3 event names when defining event rules for SAP R/3 events.  
- Define your own security attribute for your custom-made event providers.  
- Specify the type of event that is to be monitored. Every event can refer to an event provider.

If you use composer command line to define security domains, the following syntax applies:

```txt
custom=value[,value]...
```

# JCL (jcl)

Specifies the command or the path name of a job object's executable file. If omitted, all defined job files and commands qualify.

You can also specify a string that is contained in the task string of a JSDL definition to be used for pattern matching.

If you use composer command line to define security domains, the following syntax applies:

```txt
jcl="path" | "command" | "jsdl"
```

# JCL Type (jcltype)

Specifies that the user is allowed to act on the definitions of jobs that run only scripts (if set to scriptname) or commands (if set to docommand). Use this optional attribute to restrict user authorization to actions on the definitions of jobs of one type only. Actions are granted for both scripts and commands when JCL Type (jcltype) is missing.

A user who is not granted authorization to work on job definitions that run either a command or a script is returned a security error message when attempting to run an action on them.

If you use composer command line to define security domains, the following syntax applies:

```txt
jcltype=[scriptname | docommand]
```

# Logon (logon)

Specifies the user IDs. If omitted, all user IDs qualify.

You can use the following values for the Logon (logon) attribute to indicate default logon:

# \$USER

Streamlogon is the conman/composer user.

# \$OWNER

Streamlogon is the job creator.

#  $JCLOWNER

Streamlogon is the OS owner of the file.

# SJCLGROUP

Streamlogon is the OS group of the file.

If you use composer command line to define security domains, the following syntax applies:

```txt
logon=username[,username]...
```

# Provider (provider)

For Actions (action) object types, specifies the name of the action provider.

For Events (event) object types, specifies the name of the event provider.

If Provider (provider) is not specified, no defined objects can be accessed.

If you use composer command line to define security domains, the following syntax applies:

```txt
provider=provider_name[,provider_name]...
```

# Type (type)

For Actions (action) object types, is the actionType.

For Events (event) object types, is the eventType.

For Workstations (cpu) object types, the permitted values are those used in composer or the Dynamic Workload Console when defining workstations, such as manager, broker, fta, agent, s-agent, x-agent, rem-eng, pool, d-pool, cpuclass, and domain.

![](images/5d49125ac8d4dca7cc59dc3aeb61cf9d6399eec182fcd63cdca11eb3137c87b2.jpg)

Note: The value master, used in conman is mapped against the manager security attributes.

If Type (type) is not specified, all defined objects are accessed for the specified providers (this is always the case after installation or upgrade, as the type attribute is not supplied by default).

If you use composer command line to define security domains, the following syntax applies:

```batch
type  $\equiv$  type[,type]...
```

# Host (host)

For Actions (action) object types, specifies the TEC or SNMP host name (used for some types of actions, such as sending TEC events, or sending SNMP). If it does not apply, this field must be empty.

If you use composer command line to define security domains, the following syntax applies:

```txt
host=host_name
```

# Port (port)

For Actions (action) object types, specifies the TEC or SNMP port number (used for some types of actions, such as sending TEC events, or sending SNMP). If it does not apply, this field must be empty.

If you use composer command line to define security domains, the following syntax applies:

```txt
port=port_number
```

# Classic security model

A template file named TWA_home/TWS/config/Security.conf is provided with the product. During installation, a copy of the template file is installed as TWA_home/TWS/Security.conf, and a compiled, operational copy is installed as TWA_home/TWS/Security.

This version of the file contains a full access definition for the user who installed the product, <TWS_user>, and the system administrator (root on UNIX™ or Administrator on Windows™), who are the only users defined and allowed to connect to the user interfaces and to perform all operations on all scheduling resources.

Within the IBM Workload Scheduler network, using the security file you can make a distinction between local root users and the root user on the master domain manager by allowing local root users to perform operations affecting only their login workstations and providing the master domain manager root user the authorizations to perform operations affecting any workstation across the network.

As you continue to work with the product you might want to add more users with different roles and authorization to perform specific operations on a defined set of objects.

Do not edit the original TWA_home/TWS/config/Security.conf template, but follow the steps described in Updating the security file on page 206 to make your modifications on the operational copy of the file.

# Security management overview

The way IBM Workload Scheduler manages security is controlled by a configuration file named security file. This file controls activities such as:

- Linking workstations.  
- Accessing command-line interface programs and the Dynamic Workload Console.  
- Performing operations on scheduling objects in the database or in the plan.

In the file you specify for each user what scheduling objects the user is allowed to access, and what actions the user is allowed to perform on those objects. You can determine access by object type (for example, workstations or resources) and, within an object type, by selected attributes, such as the object's name or the workstation in the object's definition. You can use wildcards to select related sets of objects. Access rights can be granted on an "included" or an "excluded" basis, or a combination of both.

Whenever you need to change access permissions you modify the configuration file and convert it into an encrypted format (for performance and security), replacing the previous file. The system uses this encrypted security file from that point onwards.

Each time a user runs IBM Workload Scheduler programs, commands, and user interfaces, the product compares the name of the user with the user definitions in the security file to determine if the user has permission to perform those activities on the specified scheduling objects.

By default, the security on scheduling objects is managed locally on each workstation. This means that the system administrator or the <TWS_user> who installed the product on that system can decide which IBM Workload Scheduler users defined on that system can access which scheduling resources in the IBM Workload Scheduler network and what actions they can perform.

Alternatively, you can centralize control of how objects are managed on each workstation. This can be configured by setting the enCentSec global option. In this scenario, you configure all user permissions in the security file on the master domain manager. The encrypted version of the file is distributed automatically every time you run JnextPlan, so that all workstations have the file locally to determine the permissions of the users on that workstation.

For more information about centralized security, see Centralized security management on page 210. For more information about global options, see Global options - detailed description on page 27.

# Updating the security file

# About this task

By default, every workstation in an IBM Workload Scheduler network (domain managers, fault-tolerant agents, and standard agents) has its own security file. You can maintain that file on each workstation, or, if you enable centralized security management, you can create a security file on the master domain manager and copy it to each domain manager and agent, ensuring that all IBM Workload Scheduler users are assigned the required authorization in the file (see Centralized security management on page 210). Whether working on an agent workstation for an individual security file, or on the master domain manager to modify a centralized file, the steps are just the same; all that changes are the number of users you are defining - just those on the local system or all in the IBM Workload Scheduler network.

If you are updating or upgrading your fault-tolerant agents to version 9.5 Fix Pack 2 or later, you must manually update the security file on the fault-tolerant agents in your environment to add access to folders for all of the scheduling objects that can be defined or moved into folders. These updates are especially important if you plan to use the command line on the fault-tolerant agents to perform operations on the objects in folders. More specifically, if centralized security is enabled (enCentSec / ts = YES), then you must first update or upgrade all of the fault-tolerant agents in your environment to version 9.5 Fix Pack 2 or later before you begin using the folder feature. If centralized security management is not enabled

(enCentSec / ts = NO), all stanzas that reference CPU are automatically updated to include folder access, for example, CPU  $\text{CPU} = \text{@+FOLDER} = {}^{\prime \prime} / {}^{\prime \prime}$ , unless you use wildcard characters (@) as matching criteria in your stanzas, for example, CPU  $\text{CPU} = \text{@HR}$ . In this case, if you want to be able to move these CPUs into folders, then you need to manually update those stanzas to include access to all folders, CPU  $\text{CPU} = \text{@HR + FOLDER} = {}^{\prime \prime} / {}^{\prime \prime}$ .

Neither the IBM Workload Scheduler processes nor the WebSphere Application Server Liberty infrastructure needs to be stopped or restarted to update the security file. You just need to close any open conman user interfaces before running makesec.

To modify the security file, perform the following steps:

1. Configure the environment, running one of the following scripts:

In UNIX®:

. . /TWA_home/TWS/tws_env.sh for Bourne and Korn shells  
. . /TWA_home/TWS/tws_env.csh for C shells

In Windows®:

TWA_home\TWS\tws_env.cmd

2. Navigate to the following directory from where you can submit the dumpsec and makesec commands:

TWA_home/TWS

TWA_home\TWS

3. Run the dumpsec command to decrypt the current security file into an editable configuration file. See dumpsec on page 208.  
4. Modify the contents of the editable security configuration file using the syntax described in Configuring the security file on page 211.  
5. Close any open conman user interfaces using the exit command.  
6. Stop any connectors on systems running Windows™ operating systems.  
7. Run the makesec command to encrypt the security file and apply the modifications. See makesec on page 209.  
8. If you are using local security, the file will be immediately available on the workstation where it has been updated.

If you are using centralized security (see Centralized security management on page 210), perform the following steps:

a. If you are using a backup master domain manager, copy the file to it.  
b. Distribute the centralized file manually to all fault-tolerant agents in the network (not standard, extended, or broker agents), and store it in the following directory:

# For a fresh installation of version 9.5.x or later

TWA_DATA_DIR

TWA_home\TWS

# Upgraded environment originating from a version earlier than 9.5:

TWA_home/TWS

TWA_home\TWS

c. Run JnextPlan to distribute the Symphony file that corresponds to the new Security file.

See dumpsec on page 208 and makesec on page 209 for a full description of the commands.

# dumpsec

Writes in an editable format the information contained in the compiled and encrypted security file. The output file can be edited and then used as input for the makesec command which compiles and activates the modified security settings.

# Authorization

You must have display access to the security file and write permission in the TWA_home/TWS directory from where the command must be run.

# Syntax

dumpsec -v | -u

dumpsec security_file[>output_file]

# Comments

If no arguments are specified, the operational security file is sent to stdout. To create an editable copy of the security file, redirect the output of the command to an output file, using the redirect symbol.

# Arguments

-v

Displays command version information only.

-u

Displays command usage information only.

security_file

Specifies the name of the security file to dump.

[>output_file]

Specifies the name of the output file, If omitted, the security file is output to the stdout.

# Example

# Examples

The following command dumps the operational security file (TWA_home/TWS/Security) to a file named mysec:

```txt
dumpsec > mysec
```

The following command dumps a security file named sectemp to stdout:

```txt
dumpsec sectemp
```

# makesec

Compiles security definitions and installs the security file. Changes to the security file are recognized as soon as makesec has completed, or, in the case of centralized security, after JnextPlan has distributed it.

![](images/e3b98e3059f1fa5d4544efb7b0032eb66749d7c15f80b2950b59493055aab371.jpg)

Note: Before running the makesec command, stop conman, and, on systems running Windows® operating systems, any connectors.

# Authorization

You must have modify access to the security file and read permission in the TWA_home/TWS directory from where the command must be run.

# Syntax

```txt
makesec -v | -u
```

```txt
makesec[-verify]in_file
```

# Comments

The makesec command compiles the specified file and installs it as the operational security file (.TWA_home/TWS/Security). If the -verify argument is specified, the file is checked for correct syntax, but it is not compiled and installed.

# Arguments

-v

Displays command version information only.

-u

Displays command usage information only.

-verify

Checks the syntax of the user definitions in in_file. The file is not compiled and installed as the security file.

in_file

Specifies the name of a file or set of files containing user definitions. Syntax checking is performed automatically when the security file is installed.

# Example

# Examples

# Example 1: Modifying the security file definitions - full scenario

The following example shows how to modify the security file definitions:

1. An editable copy of the operational security file is created in a file named tempsec with the dumpsec command:

```batch
dumpsec > tempsec
```

2. The user definitions are modified with a text editor:

```txt
edit tempsec
```

3. The file is then compiled and installed with the makesec command:

```txt
makesec tempsec
```

# Example 2: Compiling user definitions from multiple files

The following command compiles user definitions from the fileset userdef* and replaces the operational security file:

```txt
makesec userdef\*
```

# Centralized security management

An IBM Workload Scheduler environment where centralized security management is enabled is an environment where all workstations share the same security file information contained in the security file stored on the master domain manager and the IBM Workload Scheduler administrator on the master domain manager is the only one who can add, modify, and delete entries in the security file valid for the entire IBM Workload Scheduler environment.

This is configured with the enCentSec global option. By default the value assigned to the enCentSec option is no.

To set central security management, the IBM Workload Scheduler administrator must run the following steps on the master domain manager:

1. Use the optman command line program, to set the value assigned to the enCentSec global property to yes. For information on how to manage the global properties using optman, see Setting global options on page 13.  
2. Save the information in the security file into an editable configuration file using the dumpsec on page 208 command.  
3. Set the required authorizations for all IBM Workload Scheduler users, as described in Configuring the security file on page 211  
4. Close any open conman user interfaces using the exit command.  
5. Stop any connectors on systems running Windows® operating systems.  
6. Compile the security file using the makesec on page 209 command.  
7. If you are using a backup master domain manager, copy the compiled security file to it as soon as possible.  
8. Distribute the compiled security file to all the workstations in the environment and store it in their TWA_home/TWS directories.  
9. Run JnextPlan to update the security information distributed with the Symphony file.

The value of the checksum of the newly compiled security file is encrypted and loaded into the Symphony file and distributed to all the workstations in the IBM Workload Scheduler network.

On each workstation, when a link is established or when a user connects to a user interface or attempts to issue commands on the plan, either with conman or the Dynamic Workload Console, IBM Workload Scheduler compares the value of the checksum in the security file delivered with the Symphony file with the value of the checksum of the security file stored on the workstation. If the values are equal, the operation is allowed. If the values are different, the operation fails and a security violation message is issued.

# Centralized security usage notes

The following are some considerations to be aware of if centralized security management is enabled in your IBM Workload Scheduler environment.

When centralized security is enabled (enCentSec / ts = YES), and you plan to start using the folder feature to define or move scheduling objects into dedicated folders, then you must first update or upgrade all of the fault-tolerant agents in your environment to version 9.5 Fix Pack 2 or later. If centralized security management is not enabled (enCentSec / ts = NO), all stanzas that reference CPU are automatically updated to include folder access, for example, CPU CPU=@+FOLDER="/", unless you use wildcard characters (@) as matching criteria in your stanzas, for example, CPU CPU=@HR. In this case, if you want to be able to move these CPUs into folders, then you need to manually update those stanzas to include access to all folders, CPU CPU=@HR+FOLDER="/".

In a network with centralized security management, two workstations are unable to establish a connection if one of them has enCentSec turned off in its Symphony file or if their security file information does not match.

The only exception to the security file matching criteria introduced by the centralized security management mechanism is that a workstation must always accept incoming connections from its domain manager, regardless of the result of the security file matching process.

Centralized security does not apply to IBM Workload Scheduler operations for which the symphony file is not required. Commands that do not require the symphony file to run use the local security file. For example, the parms command, used to modify or display the local parameters database, continues to work according to the local security file, even if centralized security is active and the local security file differs from the centralized security rules.

If a workstation's security file is deleted and re-created, the checksum of the new security file will not match the value in the Symphony file. In addition, a run-number mechanism associated with the creation process of the Symphony file ensures prevention from tampering with the file.

# Configuring the security file

In the security file you can specify which scheduling objects a user can manage and how. You define these settings by writing user definitions. A user definition is an association between a name and a set of users, the objects they can access, and the actions they can perform on the specified objects.

When defining user authorization consider that:

- When commands are issued from the composer command line program, the user authorizations are checked in the security file of the master domain manager since the methods used to manage the entries in the database are invoked on the master domain manager. Therefore the user must be defined:

- As system user on the system where the master domain manager is installed.  
In the security file on the master domain manager with the authorizations needed to run the allowed commands on the specific objects.

- When commands are issued from the conman command line program, the user must be authorized to run the specific commands in the security file both on the connecting workstation and on the master domain manager where the command actually runs.

The security file is parsed one line at a time, thus any given line in the security file has been assigned a maximum length of 32768 characters. Since during the encryption process (makesec), one extra character is added to any string value in order to store its length, the number of "visible" characters could actually be more or less than 32768. As an example, consider the following line:

```txt
CPU  $\equiv$  @+LOGON  $\equiv$  test1，test2
```

The actual number of characters written into the encrypted Security file is determined according to this formula:

```txt
"CPU=" : 2 chars (token)  
"@": 2 chars (1 + 1 for the length)  
"LOGON=" : 2 chars (token)  
"test1," : 7 chars (6 + 1 for the length) (string)  
"test2" : 6 chars (5 + 1 for the length) (string)  
total : 19 chars
```

However, if counting the actual number of visible characters, there are 23 characters including the single space between test1 and test2 and the comma separating them.

![](images/678917ab7fffb586c8b6448cbfae3fa6dbc44741387afe386d7be94b5e64968c.jpg)

Note: The "CPU" and "LOGON" each have a real length of two characters even though they actually have three and five characters respectively. This is because certain keywords are "tokenized." This can actually help reduce the apparent character count in this case.

The configuration of the security file is described in these sections:

- Security file syntax on page 212  
- Specifying user attributes on page 214  
- Specifying object types on page 221  
- Specifying object attributes on page 223  
- Specifying access on page 228  
- The <TWS_user> - special security file considerations on page 251

# Security file syntax

The syntax of the security file is as follows:

# Syntax

[#comment]

user definition_name user_attributes

begin [* comment]

object_type [object_attributes].access [=keyword[,keyword]...]

[object_type [object_attributes].access [=keyword[,keyword]...]...]...

end | continue

# Arguments

[#|*]comment

All text following a pound sign or an asterisk and at least one space is treated as a comment. Comments are not copied into the operational security file installed by the makesec command.

user definition_name

Specifies the name of the user definition. The name can contain up to 36 alphanumeric characters and must start with an alphabetic character.

user_attributes

Contains one or more attributes that identify the user or users to whom the definition applies. For details of how to define user attributes, see Specifying user attributes on page 214.

begin

Begins the part containing object statements and accesses within the user definition.

object_type

Identifies the type of object (for example: workstation, resource, or prompt) to which access is to be given for the specified user or users. All object types that the specified user or users needs to access must be explicitly defined. If they are not, no access will be given. For details of how to define object types, see Specifying object types on page 221.

object_attributes

Contains one or more attributes that identify the specific objects of the defined object type to which the same access is to be given. If no object attributes are defined, access is given to all objects of the defined object type. For details of how to define object attributes, see Specifying object attributes on page 223.

access[=keyword[,keyword]...]

Describes the access to the specified objects given to the selected users. If none is specified (by specifying just the keyword "access") no access is given to the associated objects. If  $\text{access} = @$  then all access rights are assigned to the specified users. For details of how to define access, see Specifying access on page 228.

# continue

Allows a user to inherit authorization from multiple stanzas. Add the Continue keyword before the Begin keyword of each subsequent stanza to request that IBM Workload Scheduler must not stop at the first stanza, but must continue including also the following stanzas that match the user definition. The user gets the accesses for the first matching entry of each stanza. For an example of the use of the Continue keyword, see Users logged into multiple groups [continue keyword] on page 257.

# end

Terminates the user definition. The users defined in the user definition that terminates with an end statement do not match any subsequent user definition.

# Wildcards

The following wildcard characters are permitted in user definition syntax:

?

Replaces one alphanumeric character.

@

Replaces zero or more alphanumeric characters.

For information about variables supplied with the product that can be used in object attributes, refer to Using variables in object attribute definitions on page 228. Refer to Sample security file on page 252 for an example on how to use variables.

# Specifying user attributes

The user attributes define who has the access that is going to be subsequently defined. They can identify one user, a selection of users, a group of users, a selection of groups of users, or all users. You can also exclude one or more specific users or groups from a selection. As well as being identified by logon ID and group name, users can also be described by the workstation from which they log on. And finally, you can mix selection criteria, for example selecting all users in a named group that can access from a set of workstations identified by a wildcard, but excluding a specific set of users identified by their logon IDs.

A user must be uniquely identified. If different users have the same identifier, an error is issued when makesec command is run. You must edit the security file by using dumpsec command, assign a unique identifier to users, and rerun the makesec command.

# The general syntax

You make this selection by specifying one or more user attributes. Each user attribute is specified as follows:

user_attribute_type=value

# user_attribute_type

Can be cpu (workstation), group, or logon

# value

Identifies an individual cpu (workstation), group, or logon, or, by using wildcards, can identify a set of any of these.

# Including or excluding

Each attribute can be included or excluded from the selection.

Thus, for each attribute type, your options are one of the following:

# Include all

This is the default. Thus, for example, if you want to include all groups, you need add no user attribute with respect to any group.

# Include a selection

This can be defined in one of these ways:

- By specifically including users you want to select (individuals or one or more sets)  
- By specifically excluding (from the include all default) all users you do not want to select  
- By specifically including a set of users and then excluding some of those contained in the set

Which of these options you choose is determined by which is easier to specify.

# Using the include or exclude symbols

# Include

Precede the user attribute expression by a plus (+) sign. All users identified by the expression will be selected, unless they are also selected by an exclude expression. If the first attribute in your definition is an include, it does not need to have a (+) sign defined, because the sign is implicit.

The default (if you specify no user attributes) is to include all users, on all workstations, in all groups, so if you want to define, for example, all users except one named user, you would just supply the exclude definition for the one user.

# Exclude

Precede the user attribute expression by a tilde (\~) sign. All users identified by the expression will never be selected, regardless of if they are identified by any include expressions.

# Selection expressions

You can use the following different types of selection expression:

# Basis selection expressions

Include only one attribute

user_attribute_type=value

For example, to include one named user logon ID, and exclude all other users:

```txt
logon = jsmith1
```

# Exclude one attribute

~user_attribute_type=value

For example, to exclude one set of logon IDs identified by a wildcard (those that start with the letter "j"), but include all others:

```txt
$\sim$  logon=j@
```

# Include only several attributes of the same type

user_attribute_type=value[,value]...

For example, to include three specific users and exclude all others:

```txt
logon = jsmith1, jbrown1, jjones1
```

# Exclude several attributes of the same type

~user_attribute_type=value[,value]...

For example, to exclude three specific users and include all others:

```javascript
~logon=jsmith1,jbrown1,jjones1
```

# Complex selection expressions

# Include users identified by different selection expressions

basic_selection_expression[+basic_selection_expression]...

The selection expressions can be of the same or a different attribute type:

# Same attribute type

An example of the same attribute type is the following, which selects all the groups beginning with the letter "j", as well as those with the letter "z":

```gitattributes
group=j@+group=z@
```

If the first selection identifies 200 users, and the second 300, the total users selected is 500.

# Different attribute type

An example of selection expressions of a different attribute type is the following, which selects all the groups beginning with the letter "j", as well as all users with IDs beginning with a "6":

```txt
group=j@+logon=6@
```

If the first selection identifies 200 users, and the second 20, of whom 5 are also in the first group, the total users selected is 5.

Exclude users identified in one selection expressions from those identified in another

basic_selection_expression[~basic_selection_expression]...

# Same attribute type

The selection expressions can be of the same attribute type, provided that the second is a subset of the first. An example of the same attribute type is the following, which selects all the workstations beginning with the letter "j", but excludes those with a "z" as a second letter:

```txt
group=j~group=jz@
```

If the first selection identifies 200 users, and the second 20, the total users selected is 180. Note that if the second expression had not been a subset of the first, the second expression would have been ignored.

# Different attribute type

Selection expressions of a different attribute type do not have to have a subset relationship, an example being the following, which selects the group "mygroup", but excludes from the selection all users in the group with IDs beginning with a "6":

```txt
group=mygroup~logon=6@
```

If the first selection identifies 200 users, and the second 20, of whom 5 are also in the first group, the total users selected is 195.

# Multiple includes and excludes

You can link together as many include and exclude expressions as you need to identify the precise subset of users who require the same access. The overall syntax is thus:

[ \sim ]\text{user\_attribute\_type} = \text{value}, \text{value}] \dots [\{+|\sim \}\text{user\_attribute\_type} = \text{value}, \text{value}] \dots ]

![](images/876af49f7cdf9e234ad567a7f68c4fed688ee60ced8f6ccec0c6047a02f05274.jpg)

Note: Making your first user attribute an exclude means that all user attributes of that type are selected except the indicated value. Thus, ~user_attribute_type=value equates to the following:

user_attribute_type  $=$  @\~same_user_attribute_type=value

However, if you use this syntax, you cannot, and do not need to, specifically add "+"user_attribute_type=@", after the negated item, so you do not define:

![](images/6dac89814918dac760e03d8e68f252845598b858b7fcddfa03977b9e33285926.jpg)

~user_attribute_type=value+same_user_attribute_type=@

# Order of user definition

You must order user definitions from most specific to least specific. IBM Workload Scheduler scans the security file from top-down, with each user ID being tested against each definition in turn. If the user ID is satisfied by the definition, it is selected, and the matching stops.

For example:

# Incorrect:

```julia
#First User Definition in the Security File
USER TwsUser
CPU=@+LOGON=<TWS_user>
Begin
job name=@access=modify
End
#Second User Definition in the Security File
USER Twsdomain:TwsUser
CPU=@+LOGON=TWSDomain\<TWS_user>
Begin
job name=@access=display
End
```

The definitions are intended to determine the following:

1. Users on all workstations with a logon of "TWS_user" will be given "modify" access to all jobs  
2. Users on all workstations with a logon of "TWSDomain\TWS_user" will be given "display" access to all jobs

However, all users with a logon of "TWS_user" will satisfy the first rule, regardless of their domain, and will be given "modify" access to all jobs. This is because defining a user without its domain is a shorthand way of defining that user ID in any domain; it is the equivalent of "@\TWS_USER". So the second rule will never be satisfied, for any user, because the matching for the "TWS_user" stops after a successful match is made.

# Correct

```txt
First User Definition in the Security File   
USER Twsdomain:Tws 用户   
CPU  $\equiv$  @  $^+$  LOGON  $\equiv$  "TWSDomain\\<TWS_user>"   
Begin   
job name  $\equiv$  @access  $\equiv$  display   
End   
Second User Definition in the Security File   
USER Tws 用户   
CPU  $\equiv$  @  $^+$  LOGON  $\equiv$  <TWS_user>   
Begin   
job name  $\equiv$  @access  $\equiv$  modify   
End
```

By putting the more specific definition first, both object access definitions are applied correctly.

See Sample security file on page 252 for a practical example.

# User attribute types - detailed description

The user_attribute_types and their associated values can be any of the following:

cpu={{folder/] $\text{workstation} | / @ / [\text{folder}/]\text{workstation} | / @ / @ \})$

where:

workstation

Specifies the workstation on which the user is logged in. Wildcard characters are permitted. The following IBM Workload Scheduler variables can be used:

$master

Means that the user is logged in on the IBM Workload Scheduler master domain manager.

$manager

Means that the user is logged in on the IBM Workload Scheduler domain manager.

$thiscpu

Means that the user is logged in on the IBM Workload Scheduler workstation on which the security check is running.

@

Specifies that the user is accessing IBM Workload Scheduler with the Dynamic Workload Console, or is logged in on any IBM Workload Scheduler workstation.

group=firstname

Specifies the name of the group of which the user is a member. Available for UNIX™ users. Wildcard characters are permitted.

```bash
logon = {user name}@}

where:

user name

Specifies the user ID with which the user is logged in on a IBM Workload Scheduler workstation. Wildcard characters are permitted. The cpu= attribute must be set to a specific workstation name (no wildcards) or @.

The user name value can have one of the following formats:

user name

The Windows user. For example if you use the user1 value in the logon field, in the Security file you have the following line:

```txt
logon=user1
```

# domain\user name

The user belongs to a Windows domain. Insert the escape character '\' before the '\' character in the domain\user name value. For example if you use the MYDOMAIN\user1 value in the logon field, in the Security file you have the following line:

```txt
logon=MYDOMAIN\user1
```

# user name@internet_domain

The user belongs to an internet domain. The user name is in User Principal Name (UPN) format. UPN format is the name of a system user in an email address format. The user name is followed by the "at sign" followed by the name of the Internet domain with which the user is associated.

Insert the escape character '\' before the '@' character in the user name@internet_domain value. For example if you use the administrator@bvt.com value in the logon field, in the Security file you have the following line:

```txt
logon=administrator@bvt_env.com
```

For more information about the use of the wildcard with the domain\user name and user name@internet_domain format in the Security file, see Sample security file on page 252.

![](images/8174efdf18089b6698f6cbcdb6a67d18def0b7996abd7651f948753de0299cd8.jpg)

# Note:

1. If the WebSphere Application Server Liberty security configuration option useDomainQualifiedUserName is set to true, each user ID defined in the security file must have the format domain\username to use the product from one of the following:

$\circ$  composer  
Dynamic Workload Console  
- logman  
- optman  
planman

For more information on WebSphere Application Server Liberty security configuration, see Changing the security settings on page 415.

![](images/3ced086e30b59810a7ca83ea32f8839d92657d4835f3b164696c6020108e0bf0.jpg)

2. If the user is defined on a Windows™ 2003 system, or when upgrading the Windows™ operating system from an older version to one of those mentioned above, make sure you add the Impersonate a client after authentication right to the user settings.

@

Specifies any user logged in with any name or being a member of any IBM administrators group.

# Specifying object types

Specify one or more object types that the user or users in the associated user definition is authorized to access. If you specify the object type but no attributes, the authorized actions defined for the user with the access keyword apply to all the objects of that type defined in the IBM Workload Scheduler domain. If an object type from the following list is omitted for a user or users, no objects of that type can be accessed.

The object types are the following:

action

Actions defined in scheduling event rules

calendars

User calendars

cpu

Workstations, domains and workstation classes

event

Event conditions in scheduling event rules

eventrule

Scheduling event rule definitions

file

IBM Workload Scheduler database file

folder

The folder within which scheduling objects such as, jobs, job streams, and workstations, to name a few, are defined.

job

Scheduled jobs and job definitions

parameter

Local parameters.

# prompt

Global prompts

# report

The reports on the Dynamic Workload Console that have the following names:

# RUNHIST

Job Run History

# RUNSTATS

Job Run Statistics

# WWS

Workstation Workload Summary

# WWR

Workstation Workload Runtimes

# SQL

Custom SQL

# ACTPROD

Actual production details (for current and archived plans)

# PLAPROD

Planned production details (for trial and forecast plans)

Permission to use these reports is granted by default to the <TWS_user> on fresh installations.

# resource

Scheduling resources

# runcygrp

Run cycle groups

# schedule

Job streams

# userobj

User objects

# variable

Variable tables. This includes authorization to the variable definitions in the tables.

# wkldappl

Workload applications

# Specifying object attributes

Specify one or more attributes that identify a set of objects that the user of the user definition is authorized to access. If you specify the object type but no object sets, the authorized actions defined for the user with the access keyword apply to all the objects of that type defined in the IBM Workload Scheduler domain.

# The general syntax

Each object attribute is specified as follows:

object_attribute=value

# object_attribute

Object attributes differ according to the object. All objects can be selected by name, but some, jobs, for example, can be selected by the workstation on which they run. See Object attribute on page 223 for full details of which attributes are available for each object type.

value

Identifies an individual object, or, by using wildcards, a set of objects. See Specifying object attributes on page 223 for full details of which attributes are available for each object type.

# Object attribute

**Specifying object attributes on page 223** lists object attributes that are used to identify a specific set of objects from all objects of the same type. For example, access can be restricted to a set of resource objects having the same name or being defined on the same workstation, or both.

Table 36. Object attribute types for each object type  

<table><tr><td>Attribute Object</td><td>name</td><td>cpu</td><td>folder</td><td>cpufolder</td><td>cstom</td><td>jcl</td><td>jcltype</td><td>logon</td><td>provider</td><td>type</td><td>host</td><td>port</td></tr><tr><td>action</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>✓</td><td>✓</td><td>✓</td><td>✓</td></tr><tr><td>calendar</td><td>✓</td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>cpu (workstation)</td><td></td><td>✓</td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td>✓</td><td></td><td></td></tr><tr><td>event</td><td></td><td></td><td></td><td></td><td>✓</td><td></td><td></td><td></td><td>✓</td><td>✓</td><td></td><td></td></tr><tr><td>eventrule</td><td>✓</td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>file</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>folder</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>job</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td></td><td>✓</td><td>✓</td><td>✓</td><td></td><td></td><td></td><td></td></tr><tr><td>lob</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>parameter</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>

Table 36. Object attribute types for each object type (continued)  

<table><tr><td>Attribute Object</td><td>name</td><td>cpu</td><td>folder</td><td>cpufolder</td><td>cushom</td><td>jcl</td><td>jcltype</td><td>logon</td><td>provider</td><td>type</td><td>host</td><td>port</td></tr><tr><td>prompt</td><td>✓</td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>report</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>resource</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>runcygrp</td><td>✓</td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>schedule (job stream)</td><td>✓</td><td>✓</td><td>✓</td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>userobj</td><td></td><td>✓</td><td></td><td>✓</td><td></td><td></td><td></td><td>✓</td><td></td><td></td><td></td><td></td></tr><tr><td>variable</td><td>✓</td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>wkldappl</td><td>✓</td><td></td><td>✓</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></table>

![](images/9625f10b14ba8f0a29f93d3f4ab85e02d05c0994c64a11b78431e8d4d986b4bf.jpg)

# Note:

- Granting access to a workstation class or a domain means to give access just to the object itself, and grant no access to the workstations in the object.  
- When you specify access rights on a folder, the access rights apply also to all sub-folders.

# Including or excluding

Each attribute can be included or excluded from the selection using the plus (+) and tilde (~) symbols, in the same way as for the user attributes.

# Selection expressions

The detailed syntax and use of the selection expressions for objects is the same as that used to select users:

[ \sim ] ] object_attribute = value[,value]...[ \{+|~\} object_attribute = value[,value]...

# Order of object definition

You must order object definitions from most specific to least specific, in the same way as for user attributes. For example,

# Incorrect

```batch
job name  $\equiv$  @access  $\equiv$  display  
job name  $\equiv$  ar@access  $\equiv$  @
```

In this case, a job with the name beginning with "ar" would satisfy the first definition, and so would be given the display access, not all access.

# Correct

```txt
job name=ar@access=@  
job name=@access=display
```

Ensure that you order object definitions from most specific to least specific also when you use the Continue keyword.

The Continue keyword allows a user to inherit authorization from multiple stanzas. The user receives accesses as defined in the first matching entry of each stanza that matches the user definition. For an example of a security file with the Continue keyword, see Users logged into multiple groups [continue keyword] on page 257

# Specifying object attribute values

The following describes the values allowed for each object attribute type:

name=name[,name]...

Specifies one or more names for the object type. Wildcard characters are permitted. Multiple names must be separated by commas.

- The following values apply to the file object type:

# globalots

Allows the user to set global options with the optman command. Gives the following access types:

。 Display access for optman ls and optman show  
- Modify access for optmanchg

# prodsked

Allows the user to create, extend, or reset the production plan.

# security

Allows the user to manage the security file.

# Symphony

Allows the user to run stageman and JnextPlan.

# trialsked

Allows the user to create trial and forecast plans or to extend trial plans.

![](images/1244bcd229ca7d8270f95f92ab97bef164fbe8adf3e16924e327a43428472939.jpg)

Note: Users who have restricted access to files should be given at least the following privilege to be able to display other objects (ie. calendars and cpus):

```batch
file name=globalots access  $\equiv$  display
```

- For the event object type use one or more of the event type names listed in the TWSObjectsMonitor events table or the FileMonitor events table in the IBM Workload Scheduler: User's Guide and Reference.

- For the action object type use one or more of the action type names listed in the table Action types by action provider in the IBM Workload Scheduler: User's Guide and Reference.  
- For the variable object type, you can use the $DEFAULT value for the name attribute to indicate the default variable table. This selects the table defined with the isdefault attribute.

# cpu=workstation + folder=foldername

Specifies one or more workstation, domain, or workstation class names. Workstations and workstation classes can optionally be defined in a folder; if defined, the folder can be specified in the folder attribute. Wildcard characters are permitted. Multiple names must be separated by commas. If this attribute is not specified, all defined workstations and domains can be accessed. Workstation variables can be used - see Using variables in object attribute definitions on page 228.

# folder=foldername

Scheduling objects such as, jobs, job streams, and workstations, to name a few, can be defined in a folder. A folder can contain one or more scheduling objects, while each object can be associated to only one folder. The default folder is the root folder (/).

# cpufolder=foldername

The folder within which the workstation or workstation class is defined.

# ```python
custom=value[,value]...

Use this attribute to assign access rights to events defined in event plug-ins. The precise syntax of the value will depend on the plug-in. For example:

- Specify different rights for different users based on SAP R/3 event names when defining event rules for SAP R/3 events.  
- Define your own security attribute for your custom-made event providers.  
- Specify the type of event that is to be monitored. Every event can be referred to an event provider.

# jcl="path" | "command" | "jsdl"

Specifies the command or the path name of a job object's executable file. The command or path must be enclosed in double quotation marks (""). Wildcard characters are permitted. If omitted, all defined job files and commands qualify.

You can also specify a string contained in the task string of a JSDL definition to be used for pattern matching. Ensure that the string begins and ends with the @ wildcard character and that it is entirely enclosed in double quotation marks as follows: "@my_string@".

# jcltype=[scriptname | docommand]

Specifies that the user is allowed to act on the definitions of jobs that run only scripts (if set to scriptname) or commands (if set to docommand). Use this optional attribute to restrict user authorization to actions on the definitions of jobs of one type or the other only. Actions are granted for both scripts and commands when jcltype is missing.

A user who is not granted authorization to work on job definitions that run either a command or a script is returned a security error message when attempting to run an action on them.

# ```java
logon=username[,...]

Specifies the user IDs. Wildcard characters are permitted. Multiple names must be separated by commas. If omitted, all user IDs qualify.

The user ID can be a Windows domain user or an internet domain user and must be defined in one of the following formats:

# domain\user name

The user belongs to a Windows domain. Insert the escape character '\' before the '\' character in the domain\user name value. For example if you use the MYDOMAIN\user1 value in the logon field, in the Security file you have the following line:

```txt
logon=MYDOMAIN\user1
```

# user name@internet_domain

The user belongs to an internet domain. The user name is in User Principal Name (UPN) format. UPN format is the name of a system user in an email address format. The user name is followed by the "at sign" followed by the name of the Internet domain with which the user is associated.

Insert the escape character '\' before the '@' character in the user name@internet_domain value. For example if you use the administrator@bvt.com value in the logon field, in the Security file you have the following line:

```batch
logon  $\equiv$  administrator\@bvt_env.com
```

# provider  $\equiv$  provider_name[,...]

For action object types, specifies the name of the action provider.

For event object types, specifies the name of the event provider.

Wildcard characters are permitted. Multiple names must be separated by commas. If provider is not specified, no defined objects can be accessed.

# type  $=$  type[,...]

For action object types, is the actionType.

For event object types, is the eventType.

For cpu object types, the permitted values are those used in composer or the Dynamic Workload Console when defining workstations, such as manager, broker, fta, agent, s-agent, x-agent, rem-eng, pool, d-pool, cpuclass, and domain.

![](images/970b6a842204e917fab979b75bf1e37a0d722e97e8799f73c9ee17de42d6a656.jpg)

Note: The value master, used in conman is mapped against the manager security attributes.

Wildcard characters are permitted. Multiple names must be separated by commas. If type is not specified, all defined objects are accessed for the specified providers (this is always the case after installation or upgrade, as the type attribute is not supplied by default).

# host=host_name

For action object types, specifies the TEC or SNMP host name (used for some types of actions, such as sending TEC events, or sending SNMP). If it does not apply, this field must be empty.

# port=port_number

For action object types, specifies the TEC or SNMP port number (used for some types of actions, such as sending TEC events, or sending SNMP). If it does not apply, this field must be empty.

# Using variables in object attribute definitions

The following variables supplied with the product can be used in object attributes:

# Workstation identifiers

$master

The IBM Workload Scheduler master domain manager.

$manager

The IBM Workload Scheduler domain manager.

$thiscpu

The workstation on which the user is running the IBM Workload Scheduler command or program.

# Variable table identifiers

$default

The name of the current default variable table.

# Specifying access

# About this task

Specify the type of access the selected users are allowed to have to the specified objects as follows:

access[=keyword[,keyword]...]

- To specify that no actions are permitted, use access=  
- To specify that all actions are permitted, use access=@  
- To specify any other access, consult the access tables, by object type, below.

# How the access tables are organized

The access tables for object types are as follows:

Object types - calendar, cpu, eventrule, folder, job, prompt, resource, run cycle group, schedule, userobj, variable - using in composer on page 230

Most of the composer and GUI database maintenance actions are common to most objects, so they are listed in a table of common object access keywords.

Object type - action on page 233

This gives the access rights for action objects, which are not included in the common table.

Object type - calendar on page 234

This gives the access rights for calendars, which are different or additional to those in the common table.

Object type - cpu on page 235

This gives the access rights for workstations (cpus), which are different or additional to those in the common table.

Object type - event on page 237

This gives the access rights for events, which are different or additional to those in the common table.

Object type - file on page 237

This gives the access rights for files, which are different or additional to those in the common table.

Object type - folder on page 238

This gives the access rights for folders, which are different or in addition to those in the common table.

Object type - job on page 241

This gives the access rights for jobs, which are different or additional to those in the common table.

Object type - parameter on page 245

This gives the access rights for local parameters, which are not included in the common table.

Object type - prompt on page 245

This gives the access rights for prompts, which are different or additional to those in the common table.

Object type - report on page 246

This gives the access rights for reports, which are different or additional to those in the common table.

Object type - resource on page 246

This gives the access rights for resources, which are different or additional to those in the common table.

Object type - run cycle group on page 247

This gives the access rights for run cycle groups, which are different or additional to those in the common table.

# Object type - schedule on page 248

This gives the access rights for job streams (schedules), which are different or additional to those in the common table.

# Object type - userobj on page 249

This gives the access rights for userobj, which are different or additional to those in the common table.

# Object type - variable on page 250

This gives the access rights for variable tables, which are not included in the common table.

# Object type - workload application on page 251

This gives the access rights for workload applications, which are not included in the common table.

# Object types - calendar, cpu, eventrule, folder, job, prompt, resource, run cycle group, schedule, userobj, variable - using in composer

The following table gives the access keywords required to use composer to work with objects of the following types:

- calendar  
- cpu  
- eventrule  
- folder  
job  
- prompt  
resource  
run cycle group  
- schedule  
- userobj  
- variable

![](images/1405fcd0573f5718d8014bd3c22236b30684cccd00f4a3345fa75ed8493ae2a5.jpg)

# Note:

- The parameter keyword is reserved for parameters created and managed in a local parameter database with the `parms` utility command.

For more information about `pairs`, see the related section in the User's Guide and Reference.

![](images/f90444584de8a15b9b4975d405fb000d46f19a23e9eb7187c31b367404ab3f21.jpg)

- If you plan to upgrade your environment from a previous version of IBM® Workload Scheduler and use event-driven workload automation, you need to manually add the display access keyword to all workstations on which you plan to define File Monitor events.

For more information about event-driven workload automation, see the related section in the User's Guide and Reference.

Table 37. Access keywords for composer actions  

<table><tr><td></td><td></td><td>Activity</td><td>Access keywords required</td></tr><tr><td rowspan="8">Composer</td><td>add</td><td>Add new object definitions in the database from a file of object definitions. Unlock access is needed to use the unlock attribute. For variable tables, to add individual variable entries within a table, the table must have modify access.To add a CPU object as a member of a workstation class, you must add use access to the CPU object.</td><td>add, modify, unlock</td></tr><tr><td>add event rule</td><td>Add an event rule of type File Monitor.</td><td>display</td></tr><tr><td>create</td><td>Create a text file of object definitions in the database.Modify access is need to use the lock attribute. For variable tables, create individual variable entries within the table.</td><td>display, modify</td></tr><tr><td>delete</td><td>Delete object definitions from the database. For variable tables, to delete individual variable entries within a table, the table must have modify access.</td><td>delete</td></tr><tr><td>display</td><td>Display object definitions in the database.</td><td>display</td></tr><tr><td>extract</td><td>Extract a text file of object definitions from the database.</td><td>display</td></tr><tr><td>list</td><td>List object definitions in the database.</td><td>If the enListSecChk global option is set to yes on the master domain manager then, either list, or list and display are required.</td></tr><tr><td>lock</td><td>Lock object definitions in the database.</td><td>modify</td></tr></table>

Table 37. Access keywords for composer actions (continued)  

<table><tr><td></td><td></td><td>Activity</td><td>Access keywords required</td></tr><tr><td></td><td>modify</td><td>Modify object definitions in the database. Definitions are extracted into a file. After you have edited the file the definitions are used to replace the existing ones. For variable tables, to modify individual variable entries within a table, the table must have modify access.</td><td>add, modify</td></tr><tr><td></td><td>new</td><td>Create object definitions in the database from a template.</td><td>add, modify</td></tr><tr><td></td><td>print</td><td>Print object definitions in the database.</td><td>display</td></tr><tr><td></td><td>rewrite</td><td>Rename object definitions in the database. You need add access to the new object and delete and display access to the old object.</td><td>add, delete, display</td></tr><tr><td></td><td>replace</td><td>Replace object definitions in the database. Unlock access is needed to use the unlock attribute.</td><td>add, modify, unlock</td></tr><tr><td></td><td>unlock</td><td>Unlock object definitions in the database. For variable tables, unlocking a table unlocks all the variables contained therein. Unlocking a variable unlocks the entire table where it is defined.</td><td>unlock</td></tr><tr><td rowspan="8">Dynamic Workload Console</td><td>Add event rule</td><td>Add an event rule of type File Monitor.</td><td>display</td></tr><tr><td>Create object in database</td><td>Add new object definitions in the database.</td><td>add</td></tr><tr><td>Delete object in database</td><td>Delete object definitions from the database. Unlock access is needed to use the unlock option.</td><td>delete</td></tr><tr><td>Display object in database</td><td>Display object definitions in the database.</td><td>display</td></tr><tr><td>List object in database</td><td>List object definitions in the database.</td><td>display</td></tr><tr><td>Modify object in database</td><td>Modify object definitions in the database. Unlock access is needed to use the unlock option.</td><td>modify</td></tr><tr><td>Unlock object in database</td><td>Unlock object definitions in the database locked by another user.</td><td>unlock</td></tr><tr><td>Perform operations for job types with advanced options, both those supplied</td><td>Perform operations for job types with advanced options in the database.</td><td>run</td></tr></table>

Table 37. Access keywords for composer actions (continued)  

<table><tr><td></td><td>Activity</td><td>Access keywords required</td><td></td></tr><tr><td colspan="3">with the product and the additional types implemented through the custom plug-ins. You can define and perform operations on job types with advanced options with the Workload Designer.</td><td></td></tr><tr><td>Using the workload service assurance feature</td><td>All activities</td><td>For any user to perform any workload service assurance activities, the &lt;TWS_user&gt; must have the following access keywords for all cpu, job, and schedule objects:</td><td>display, modify, list</td></tr><tr><td colspan="3">Example</td><td></td></tr><tr><td colspan="3">To allow a user to use the composer list, display, and modify actions on event rules, specify:</td><td></td></tr><tr><td>eventrule</td><td>access=add, display, modify</td><td></td><td></td></tr></table>

# Object type - action

The following table gives the access keywords required for actions:

Table 38. Actions - access keywords  

<table><tr><td></td><td>Activity</td><td>Access keywords required</td></tr><tr><td rowspan="2">Dynamic Workload Console</td><td>Display action instances</td><td>display</td></tr><tr><td>List action instances.</td><td>list</td></tr><tr><td>Dynamic Workload Console</td><td>Use these specific action types in event rule definitions.</td><td>use</td></tr><tr><td>conman</td><td></td><td></td></tr></table>

Table 38. Actions - access keywords (continued)  

<table><tr><td>Activity</td><td>Access keywords required</td></tr><tr><td>For actions with provider TWSAction and types sbj, sbd, or sbs, you must set this keyword in combination with the submit access keyword for the specific jobs and job streams specified in the action.For actions with provider TWSAction and type reply, you must set this keyword in combination with the reply access keyword set for the specific prompts specified in the action.The &lt;TWS_user&gt; of the workstation running the event processing server must have these submit and reply authorizations, otherwise the event processing server will not be able to run this type of actions.</td><td></td></tr></table>

# Example

To allow a user to use the Dynamic Workload Console to list action instances, specify:

```gitattributes
action access=list
```

# Object type - calendar

The following table gives the additional access keywords required to work with calendars, other than those described in Table 37: Access keywords for composer actions on page 231:

Table 39. Calendar - additional access keywords  

<table><tr><td></td><td></td><td>Activity</td><td>Access 
keywords 
required</td></tr><tr><td>Composer</td><td>Use calendars in:</td><td></td><td>use</td></tr><tr><td rowspan="3">Dynamic Workload 
Console</td><td>• job streams</td><td></td><td></td></tr><tr><td>• run cycles</td><td></td><td></td></tr><tr><td>• run cycle groups</td><td></td><td></td></tr></table>

# Example 1

To allow a user to only use calendars when working with job streams in any of the interfaces, specify:

calendar access  $=$  use

# Example 2

To allow a user to display, list, and print calendars, and use them when working with job streams in any of the interfaces, specify:

calendar access  $\equiv$  display,use,list

# Object type - cpu

The following table gives the additional access keywords required to work with cpus (includes workstations, domains, and workstation classes), other than those described in Table 37: Access keywords for composer actions on page 231:

Table 40. Cpus - additional access keywords  

<table><tr><td></td><td></td><td>Activity</td><td>Access keywords required</td></tr><tr><td>Conman</td><td>console</td><td>View and send messages to the IBM Workload Scheduler conman console.</td><td>console</td></tr><tr><td>Dynamic Workload Console</td><td>deployconf</td><td>Force update the monitoring configuration file for the event monitoring engine.</td><td>start</td></tr><tr><td></td><td>fence</td><td>Alter workstation job fences in the production plan.</td><td>fence</td></tr><tr><td></td><td>limit cpu</td><td>Alter workstation job limits in the production plan.</td><td>limit</td></tr><tr><td></td><td>link</td><td>Open workstation links.</td><td>link</td></tr><tr><td></td><td>resetfta</td><td>Generates an updated Sinfonia file and sends it to a fault-tolerant agent on which the Symphony file has corrupted.</td><td>resetfta</td></tr><tr><td></td><td>showcpus</td><td>Display workstations, domains and links in the plan.</td><td>list</td></tr><tr><td></td><td>shutdown</td><td>Shut down IBM Workload Scheduler processing.</td><td>shutdown</td></tr><tr><td></td><td>start</td><td>Start IBM Workload Scheduler processing.</td><td>start</td></tr><tr><td></td><td>startappserver</td><td>Start the application server.</td><td>start</td></tr><tr><td></td><td>starteventprocessor</td><td>Start the event processor server.</td><td>start</td></tr><tr><td></td><td>startmon</td><td>Start the event monitoring engine.</td><td>start</td></tr><tr><td></td><td>stop</td><td>Stop IBM Workload Scheduler processing.</td><td>stop</td></tr><tr><td></td><td>stop;progressive</td><td>Stop IBM Workload Scheduler processing progressively.</td><td>stop</td></tr><tr><td></td><td>stopappserver</td><td>Stop the application server.</td><td>stop</td></tr><tr><td></td><td>stopeventprocessor</td><td>Stop the event processor server.</td><td>stop</td></tr></table>

Table 40. Cpus - additional access keywords (continued)  

<table><tr><td></td><td></td><td>Activity</td><td>Access 
keywords 
required</td></tr><tr><td></td><td>stopmon</td><td>Stop the event monitoring engine.</td><td>stop</td></tr><tr><td></td><td>switcheventprocessor</td><td>Switch the event processor server from the master domain 
manager to the backup master domain manager or vice 
versa.</td><td>start, stop</td></tr><tr><td></td><td>switchmgr</td><td>Switch the domain manager functionality to a workstation.</td><td>start, stop</td></tr><tr><td></td><td>unlink</td><td>Close workstation links.</td><td>unlink</td></tr><tr><td></td><td>upgrade</td><td>Install a fix pack or upgrade to a later version fault-tolerant 
agents and dynamic agents.</td><td>manage</td></tr><tr><td>Startup</td><td colspan="2">Start IBM Workload Scheduler processing.</td><td>start</td></tr><tr><td>Using the workload 
service assurance 
feature</td><td>All activities</td><td>For any user to perform any workload service assurance 
activities, the &lt;TWS_user&gt; must have the following access 
keywords:</td><td>display, 
modify, list</td></tr><tr><td>Submit a job</td><td colspan="2">When submitting a job defined in a folder, use access is required on the workstation 
(cpu) where the job is defined, in addition to access to the folder and the objects it 
contains.</td><td>use</td></tr><tr><td>Submit a job stream</td><td colspan="2">When submitting a job stream defined in a folder, use access is required on the 
workstation (cpu) where the job is defined, in addition to access to the folder and the 
objects it contains.</td><td></td></tr><tr><td>Composer</td><td colspan="2">Use a File Monitor event on the workstation where the file resides.</td><td>display</td></tr><tr><td>Dynamic Workload 
Console</td><td></td><td></td><td></td></tr></table>

![](images/d21e2119814c72fe866b29aee5464a4acf0e39e6af535ce0374b7f13388d9fda.jpg)

Note: If you plan to upgrade your environment from a previous version of IBM® Workload Scheduler and use event-driven workload automation, you need to manually add the display access keyword to all workstations on which you plan to define File Monitor events.

For more information about event-driven workload automation, see the related section in the User's Guide and Reference.

# Example

To allow a user to display, list, and print workstation, workstation class, and domain definitions, link and unlink workstations, and access all workstations defined in the root (/) folder, specify:

```batch
cpu name  $=$  @ + folder  $=$  / access  $\equiv$  display,link,unlink
```

# Object type - event

The following table gives the access keywords required to work with events:

Table 41. Events - access keywords  

<table><tr><td colspan="2">Activity</td><td>Access keywords required</td></tr><tr><td>Composer</td><td>Use an event in an event rule definition.</td><td>use</td></tr></table>

Dynamic Workload

Console

![](images/fb131a9331678acc0223a53596222b721866adbac97d1ad59bfa48c1b28fc8d2.jpg)

Note: If you plan to upgrade your environment from a previous version of IBM® Workload Scheduler and use event-driven workload automation, you need to manually add the display access keyword to all workstations on which you plan to define File Monitor events.

For more information about event-driven workload automation, see the related section in the User's Guide and Reference.

# Example

To allow a user to use an event in an event rule definition, specify:

```txt
event access  $=$  use
```

# Object type - file

The following table gives the access keywords required to work with files (valid only for the command line).

You must specify the file names on page 225 to which the type of access applies.

Table 42. Files - access keywords  

<table><tr><td colspan="2">Activity</td><td>Access keywords required</td></tr><tr><td>dumpsec</td><td>Create a text file of the settings contained in the compiled security file.</td><td>display</td></tr><tr><td>JnextPlan</td><td>Generate the production plan.</td><td>build</td></tr><tr><td>makesec</td><td>Compile the security file from a text file of the settings.</td><td>modify</td></tr><tr><td>optman</td><td>Is List all global options.</td><td>display</td></tr></table>

Table 42. Files - access keywords (continued)  

<table><tr><td></td><td colspan="2">Activity</td><td>Access 
keywords 
required</td></tr><tr><td></td><td>show</td><td>Show the details of a global option.</td><td>display</td></tr><tr><td></td><td>change</td><td>Change the details of a global option.</td><td>modify</td></tr><tr><td>planman</td><td>deploy</td><td>Manually deploy event rules.</td><td>build</td></tr><tr><td>prodsked</td><td colspan="2">Work with the production plan.</td><td>build</td></tr><tr><td>stageman</td><td colspan="2">Carry forward incomplete job streams, archive the old production plan, and install the new production plan.</td><td>build</td></tr><tr><td>agent_certificate</td><td colspan="2">Download certificates and JWT when installing dynamic agents</td><td>display</td></tr><tr><td>CREATEPERSONAL 
APIKEY</td><td colspan="2">Create personal API Key. This allows the CLI or API user access CLIs and APIs.</td><td>display</td></tr><tr><td>CREATESERVICEAP 
IKEY</td><td colspan="2">Create service API keys. Only administrators should have this permission.</td><td>display</td></tr><tr><td>LISTALLAPIKEYS</td><td colspan="2">Allows listing all API Keys in the database. This allows administrators list and then revoke existing API Keys. Without this permission, single users will be able to list ONLY 
API Keys with same UPN (User Personal Name) as their username (personally-owned 
API Keys) and service API Keys they have created (personally-owned Service API Keys).</td><td>display</td></tr><tr><td>DELETEALLAPIK 
EYS</td><td colspan="2">Allows deleting all API Keys in the database. This allows administrators revoke existing 
API Keys.</td><td>display</td></tr></table>

# Example 1

To allow a user to manage the globalopts file, specify:

```txt
file name=globalopts access  $\equiv$  display,modify
```

# Example 2

To allow a user to run JnextPlan, specify:

```txt
file access  $\equiv$  build
```

![](images/b4296c175ca32fc04e81460f62d11db9e0ff8ac14670f5c58670a5a8e3b13dd8.jpg)

Note: The user will also be able to run planman deploy, prodsked, and stageman.

# Object type - folder

The following table gives the additional access keywords required to work with folders, in addition to those common to most objects described in Table 37: Access keywords for composer actions on page 231:

Table 43. folders - access keywords  

<table><tr><td></td><td></td><td>Activity</td><td>Access keywords required</td></tr><tr><td rowspan="5">Composer</td><td>chfolder</td><td>Change the current folder or working directory.</td><td>display</td></tr><tr><td>listfolder</td><td>Lists folders defined in the database.</td><td>list, or list and display</td></tr><tr><td>mkfolder</td><td>Creates a new folder definition in the database.</td><td>add</td></tr><tr><td>rmfolder</td><td>Deletes folders defined in the database.</td><td>delete</td></tr><tr><td>renamefolder</td><td>Renames a folder definition in the database.</td><td>delete access to the folder with the old name, and add access to the folder with the new name</td></tr><tr><td rowspan="2">Conman</td><td>Chfolder</td><td>Changes the working directory or current directory.</td><td>display</td></tr><tr><td>Listfolder</td><td>Lists folders defined in the plan.</td><td>list, or list and display</td></tr></table>

See Example on page 239 for detailed examples about how to restrict access to folders.

For more information about designing workflow folders, see the related section in Dynamic Workload Console User's Guide.

# Example

The following examples demonstrate how to restrict access to specific folders. Even with access to a folder, a user still needs additional rights to work with the objects defined in it. When submitting a job or job stream defined in a folder, use access is required on the workstation (cpu) where the job is defined, in addition to access to the folder and the objects it contains.

IBM® Workload Scheduler administrator can grant administrator permissions to a user on a folder, ACL, so that the user can freely assign access control lists to other users on the same folder or any sub-folders. Users can then access the objects in the folder or sub-folders. For more information about delegating administrator access to users and groups on a folder, see the related topic in the Administration Guide.

# Examples

Tim the IBM® Workload Scheduler administrator, delegates Linda, the appl_admin user, permissions on the folder /PRD/APPL and any subFolders, by assigning her the ACL access on the folder. With this access, Linda can create access control lists to grant access to the folder or subFolders to other users with a predefined role. The following is the security file for Linda, the appl_admin user:

```python
# Sample Security File
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # 
USER APPADMINofPRDAPP1 cpu=JUPITER+LOGON=app1_admin
begin
# OBJECT ATTRIBUTES ACCESS CAPABILITIES
# ____________ _
job cpu=JUPITER + folder = "/PRD/APP1", "/PRD/APP1/"access=add,delete,display,modify,use, list, unlock
schedule cpu=JUPITER + folder = "/PRD/APP1", "/PRD/APP1/"access=add,delete,display,modify,use, list, unlock
folder name="/PRD/APP1", "/PRD/APP1/"access=add,delete,display,modify,use, list, unlock, acl
```

User jsmith is granted unrestricted access to jobs and job streams defined in the folder named APPS and on the workstation named JUPITER, specify:

```python
# Sample Security File
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
user jsmith cpu=JUPITER
begin
# OBJECT ATTRIBUTES ACCESS CAPABILITIES
# ____________ job cpu=JUPITER + folder = /APPS/ access=@
schedule cpu=JUPITER + folder = /APPS/ access=@
cpu cpu=JUPITER+LOGON=jsmith access=use
folder name=/APPS/ access=add,delete,display, modify,use, list, unlock, acl
```

To allow a user to have the specified rights on any folder, the root folder and any subFolders, specify:

```javascript
folder name  $=$  / access  $\equiv$  add,delete,display,modify,use,1ist,unlock
```

To grant a user access only to the root folder (/), you can omit specifying the folder object in the security file. This is the same behavior as in security files for releases prior to Version 9.5. After upgrading to Version 9.5, all of the objects are moved to the root folder, so if you continue to use your old security file which does not include the v95fp1 attribute or object (for example, for jobs, JOB CPU=@ ACCESS=ADD, ADDDEP,..., RERUN, SUBMIT, USE, LIST, UNLOCK, then users have access to only the root (/) folder by default.

To allow a user to have the specified rights only on the "APPS" folder, specify:

```txt
folder name  $=$  /APPS/ access  $=$  add,delete,display,modify,use,1ist,unlock
```

To allow a user to have the specified rights on the folder "APPS" and its subFolders, specify:

```txt
folder name  $=$  /APPS access  $\equiv$  add,delete,display,modify,use,1ist,unlock
```

To allow a user to have the specified rights only on folder "APP1" and its sub-folders, specify:

```txt
folder name  $=$  /APPS/APP1 access  $=$  add,delete,display,modify,use,1ist,unlock
```

To allow a user to have all rights on the folder "APPs" and on the folder "APP2" and its sub folder, but no rights on APP1, specify:

# Object type - job

The following table gives the additional access keywords required to work with jobs, other than those described in Table 37:

Access keywords for composer actions on page 231:

Table 44. Jobs - additional access keywords  

<table><tr><td></td><td colspan="2">Activity</td><td>Access 
keywords 
required</td></tr><tr><td>Composer</td><td colspan="2">Use jobs in job streams.</td><td>use</td></tr><tr><td>Dynamic Workload 
Console</td><td colspan="2">Also, if a job is used as a recovery job in a job definition, the user must have &quot;use&quot; access 
to the definition of the job identified as the recovery job.</td><td></td></tr><tr><td>Conman</td><td>adddep</td><td>Add dependencies to jobs in the production plan. Not valid for 
workstations in end-to-end environment.</td><td>adddep</td></tr><tr><td>Dynamic Workload 
Console</td><td>altpri</td><td>Alter the priority of jobs in the production plan. Not valid for 
workstations in end-to-end environment.</td><td>altpri</td></tr><tr><td></td><td>cancel job</td><td>Cancel jobs in the production plan. Not valid for 
workstations in 
end-to-end environment.</td><td>cancel</td></tr><tr><td></td><td>confirm</td><td>Confirm completion of jobs in the production plan. Not valid for 
workstations in end-to-end environment.</td><td>confirm</td></tr><tr><td></td><td>deldep job</td><td>Delete dependencies from jobs in the production plan. Not valid for 
workstations in end-to-end environment.</td><td>deldep</td></tr><tr><td></td><td>display</td><td>Display jobs in the plan.</td><td>display</td></tr><tr><td></td><td>Hold</td><td>Hold a job to prevent it from running</td><td>adddep</td></tr><tr><td></td><td>kill</td><td>Kill running jobs.</td><td>kill</td></tr><tr><td></td><td>release job</td><td>Release jobs from dependencies in the production plan. Not valid 
for workstations in end-to-end environment.</td><td>release</td></tr><tr><td></td><td>reply</td><td>Reply to job prompts in the production plan.</td><td>reply</td></tr><tr><td></td><td>rerun</td><td>Rerun jobs in the production plan. Not valid for 
workstations in 
end-to-end environment.</td><td>rerun; 
submitdb</td></tr><tr><td></td><td></td><td>To use the from argument, you must have submitdb access to the 
job.</td><td></td></tr><tr><td></td><td>showjobs</td><td>Display information about jobs in the production plan.</td><td>list</td></tr></table>

Table 44. Jobs - additional access keywords (continued)  

<table><tr><td></td><td></td><td>Activity</td><td>Access keywords required</td></tr><tr><td>Conman</td><td>submit docommand</td><td>Submit commands as jobs or recovery jobs into the production plan.</td><td>submit</td></tr><tr><td>Dynamic Workload Console</td><td></td><td>If the submit also identifies a second job with the &quot;ALIAS&quot; or &quot;RECOVERYJOB&quot; arguments, the user must have &quot;submit&quot; access to that other job, as well Not valid for workstations in end-to-end environment.</td><td></td></tr><tr><td></td><td>submit file</td><td>Submit files as jobs or recovery jobs into the production plan.</td><td>submit</td></tr><tr><td></td><td></td><td>If the submit also identifies a second job with the &quot;ALIAS&quot; or &quot;RECOVERYJOB&quot; arguments, the user must have &quot;submit&quot; access to that other job as well.</td><td></td></tr><tr><td></td><td></td><td>Not valid for workstations in an end-to-end environment.</td><td></td></tr><tr><td></td><td>submit job</td><td>Submit jobs or recovery jobs into the production plan.</td><td>submit</td></tr><tr><td></td><td></td><td>If the submit also identifies a second job with the &quot;ALIAS&quot; or &quot;RECOVERYJOB&quot; arguments, the user must have &quot;submit&quot; access to that other job as well.</td><td></td></tr><tr><td></td><td></td><td>If the job is defined in a folder, then use access is required on the workstation (cpu) where the job is defined, in addition to access to the folder itself and the objects it contains.</td><td></td></tr><tr><td></td><td></td><td>Not valid for workstations in an end-to-end environment.</td><td></td></tr><tr><td></td><td></td><td>Restricts the submission action to jobs defined in the database.</td><td>submitdb</td></tr><tr><td></td><td></td><td>With this authorization level a user cannot submit ad hoc jobs.</td><td></td></tr><tr><td></td><td></td><td>Use this keyword to allow a user to submit only jobs defined in the database. Use the submit keyword to allow a user to submit both defined and ad hoc jobs.</td><td></td></tr><tr><td></td><td></td><td>Users granted only submitdb rights:</td><td></td></tr></table>

Table 44. Jobs - additional access keywords (continued)  

<table><tr><td></td><td></td><td>Activity</td><td>Access keywords required</td></tr><tr><td></td><td></td><td>• Cannot run submit docommand and submit file successfully
• Are displayed tasks related to ad hoc job submission on the graphical user interfaces, but if they run them, are returned error messages for lacking the submit access right.</td><td></td></tr><tr><td></td><td>submit sched</td><td>Submit job streams into the production plan. Not valid for workstations in end-to-end environment.</td><td>submit</td></tr><tr><td></td><td>Hold</td><td>Hold a job to prevent it from running</td><td>adddep</td></tr><tr><td>Dynamic Workload Console</td><td>For critical jobs on which you run any of the following actions:</td><td>The predecessors are listed regardless of the fact that this authorization might not be extended to them. However, if you want to run any further action on any of the listed predecessors, this will require that you have the proper authorization.</td><td>list</td></tr><tr><td></td><td>• Display hot list</td><td></td><td></td></tr><tr><td></td><td>• Display critical path</td><td></td><td></td></tr><tr><td></td><td>• Display incomplete predecessors</td><td></td><td></td></tr><tr><td></td><td>• Display completed predecessors</td><td></td><td></td></tr><tr><td></td><td>Ors</td><td></td><td></td></tr><tr><td>Using the workload service assurance feature</td><td>All activities</td><td>For any user to perform any workload service assurance activities, the &lt;TWS_user&gt; must have the following access keywords:</td><td>display, modify, list</td></tr></table>

# Example 1

To allow a user to manage only job dependencies for jobs defined in the root (/) folder, specify:

job

access=adddep, deldep

# Example 2

To allow a user to only manage critical jobs defined in the root (/) folder, specify:

job

access=list,altpri

# Example 3

User administrator is granted add, modify, and display rights for all job definitions defined in the folder named "APPS" and any subFolders, on workstations defined in the root (/) folder, and is therefore permitted to create and modify job definitions that run scripts or commands as needed, with no restriction:

```txt
USER TWSADMIN   
CPU  $= @ +$  LOGON  $\equiv$  administrator   
BEGIN   
JOB CPU  $= @$  + FOLDER  $=$  /APPS  $^+$  CPUFOLDER  $=$  / ACCESS  $=$  ADD,MODIFY,DISPLAY,... [...]   
END
```

User sconnor is granted the same rights for jobs that match the condition jcltype=scriptname, which means that he can create or modify only job definitions that run scripts and cannot change any of them into a job that runs a command. He can also access all workstation defined in the root (/) folder:

```txt
USER RESTRICTED   
CPU  $\equiv$  @+LOGON=sconnor   
BEGIN   
JOB CPU  $\equiv$  @+JCLTYPE  $\equiv$  SCRIPTNAME + FOLDER  $=$  /APPS  $^+$  CPUFOLDER  $=$  / ACCESS=ADD,MODIFY,DISPLAY,...   
[...]   
END
```

# Example 4

User administrator is granted submit permission for all jobs defined in all folders (/"), and is therefore permitted to submit jobs defined in the database and ad hoc, with no restriction:

```txt
USER TWSADMIN   
CPU  $\equiv$  @+LOGON  $\equiv$  administrator   
BEGIN   
JOB CPU  $= 2$  + FOLDER  $= /$  + CPUFOLDER  $= /$  ACCESS  $\equiv$  ADD,ADDDEP,...,RERUN,SUBMIT,USE,LIST,UNLOCK [...]   
END
```

User jsmith is granted submitdb permission for all jobs defined in all folders, allowing her to submit all jobs defined in the database, but she is not permitted to run ad hoc job submissions. She also has access to workstations in the /MYCPUS folder:

```txt
USER RESTRICTED   
CPU  $\equiv$  @+LOGON=jsmith   
BEGIN   
JOB CPU  $= 1$  + FOLDER  $= /$  + CPUFOLDER  $= /$  MYCPUS ACCESS  $\equiv$  ADD,ADDDEP,...,RERUN,SUBMITDB,USE,LIST,UNLOCK [...]   
END
```

# Object type - parameter

The following table gives the access keywords required to work with parameters:

![](images/e4167991c6785cbf4d0506887fa057034f610c484e4cd18d503e0365aeb443c2.jpg)

Note: Starting from version 8.5, the parameter keyword is reserved for parameters created and managed in a local parameter database with the `parms` utility command. See the IBM Workload Scheduler: User's Guide and Reference for details on `parms`.

Table 45. Parameters - additional access keywords  

<table><tr><td colspan="2">Activity</td><td>Access keywords required</td></tr><tr><td>parms</td><td>Manage local parameter definitions.</td><td>display</td></tr></table>

# Example

To allow a user to perform all activities on parameters and with access to all workstations defined in the root (/) folder, specify:

```txt
parameter  $^+$  folder  $\equiv$  /  $^+$  cpufolder  $=$  /access  $\equiv$  @
```

# Object type - prompt

The following table gives the additional access keywords required to work with prompts, other than those described in Table 37: Access keywords for composer actions on page 231:

Table 46. Prompts - additional access keywords  

<table><tr><td></td><td colspan="2">Activity</td><td>Access keywords required</td></tr><tr><td>Composer</td><td colspan="2">Use prompts when defining or submitting jobs and job streams</td><td>use</td></tr><tr><td>Dynamic Workload Console</td><td colspan="2"></td><td></td></tr><tr><td>Conman</td><td>adddep</td><td>Use prompts when adding dependencies to jobs in the production plan. Not valid for workstations in end-to-end environment.</td><td>use</td></tr><tr><td>Dynamic Workload Console</td><td>recall</td><td>Display prompts waiting for a response.</td><td>display</td></tr><tr><td></td><td>reply</td><td>Reply to a job or Job Scheduler prompt.</td><td>reply</td></tr><tr><td></td><td>showprompts</td><td>Display information about prompts.</td><td>list</td></tr></table>

Table 46. Prompts - additional access keywords (continued)  

<table><tr><td></td><td>Activity</td><td>Access keywords required</td></tr><tr><td>submit</td><td rowspan="2">Use prompts when submitting commands as jobs into the production plan. Not valid for workstations in end-to-end environment.</td><td rowspan="2">use</td></tr><tr><td>docommand</td></tr><tr><td>submit file</td><td>Use prompts when submitting files as jobs into the production plan. Not valid for workstations in end-to-end environment.</td><td>use</td></tr><tr><td>submit job</td><td>Use prompts when submitting jobs into the production plan. Not valid for workstations in end-to-end environment.</td><td>use</td></tr><tr><td>submit sched</td><td>Use prompts when submitting job streams into the production plan. Not valid for workstations in end-to-end environment.</td><td>use</td></tr></table>

# Example

To allow a user to perform all activities on prompts except reply to them, specify:

prompt

access=use,display,list

# Object type - report

The following table gives the access keywords required to work with reports.

Table 47. Files- access keywords  

<table><tr><td colspan="2">Activity</td><td>Access keywords required</td></tr><tr><td>Dynamic Workload Console</td><td>Display reports on page 222 on Dynamic Workload Console.</td><td>display</td></tr></table>

# Example

To allow a user to display reports on the Dynamic Workload Console, specify:

report

access  $\equiv$  display

# Object type - resource

The following table gives the additional access keywords required to work with resources, other than those described in Table 37: Access keywords for composer actions on page 231:

Table 48. Resources - additional access keywords  

<table><tr><td></td><td></td><td>Activity</td><td>Access keywords required</td></tr><tr><td>Composer</td><td colspan="2">Use resources when defining or submitting jobs and job streams</td><td>use</td></tr><tr><td>Dynamic Workload Console</td><td></td><td></td><td></td></tr><tr><td>Conman</td><td>adddep</td><td>Use resources when adding dependencies to jobs in the production plan. Not valid for workstations in end-to-end environment.</td><td>use</td></tr><tr><td rowspan="7">Dynamic Workload Console</td><td>resource</td><td>Change the number of units of a resource on a workstation.</td><td>resource</td></tr><tr><td>showresources</td><td>Display information about resources.</td><td>list</td></tr><tr><td>submit</td><td rowspan="2">Use resources when submitting commands as jobs into the production plan. Not valid for workstations in end-to-end environment.</td><td rowspan="2">use</td></tr><tr><td>docommand</td></tr><tr><td>submit file</td><td>Use resources when submitting files as jobs into the production plan. Not valid for workstations in end-to-end environment.</td><td>use</td></tr><tr><td>submit job</td><td>Use resources when submitting jobs into the production plan. Not valid for workstations in end-to-end environment.</td><td>use</td></tr><tr><td>submit sched</td><td>Use resources when submitting job streams into the production plan. Not valid for workstations in end-to-end environment.</td><td>use</td></tr></table>

# Example

To allow a user to display information about resources defined in the root folder, and change the units of a resource on a workstation defined in the root folder (/), but not to use them in any other scheduling objects or actions, specify:

```javascript
resource + folder = / + cpufolder = / access=list,resource
```

# Object type - run cycle group

The following table gives the access keywords required to work with run cycle groups:

Table 49. Run cycle groups- access keywords  

<table><tr><td colspan="2">Activity</td><td>Access keywords required</td></tr><tr><td>Composer</td><td>Use run cycle groups in job streams.</td><td>use</td></tr></table>

Table 49. Run cycle groups- access keywords (continued)  

<table><tr><td>Activity</td><td>Access 
keywords 
required</td></tr><tr><td>Dynamic Workload 
Console</td><td></td></tr><tr><td>Example</td><td></td></tr><tr><td colspan="2">To allow a user to create and delete a run cycle group, specify:</td></tr><tr><td>runcygrp     access=add,delete</td><td></td></tr></table>

# Object type - schedule

The following table gives the additional access keywords required to work with job streams, other than those described in Table 37: Access keywords for composer actions on page 231:

Table 50. Job streams - additional access keywords  

<table><tr><td></td><td></td><td>Activity</td><td>Access keywords required</td></tr><tr><td>Conman</td><td>adddep</td><td>Add dependencies to job streams in the production plan. Not valid for workstations in end-to-end environment.</td><td>adddep</td></tr><tr><td>Dynamic Workload Console</td><td>altpri</td><td>Alter the priority of job streams in the production plan. Not valid for workstations in end-to-end environment.</td><td>altpri</td></tr><tr><td></td><td>cancel sched</td><td>Cancel job streams in the production plan. Not valid for workstations in end-to-end environment.</td><td>cancel</td></tr><tr><td></td><td>deldep sched</td><td>Delete dependencies from job streams in the production plan. Not valid for workstations in end-to-end environment.</td><td>deldep</td></tr><tr><td></td><td>display</td><td>Display job streams in the plan..</td><td>display</td></tr><tr><td></td><td>limit sched</td><td>Modify the limit for jobs concurrently running within a Job Scheduler.</td><td>limit</td></tr><tr><td></td><td>release sched</td><td>Release job streams from dependencies in the production plan. Not valid for workstations in an end-to-end environment.</td><td>release</td></tr><tr><td></td><td>reply</td><td>Reply to job stream prompts in the production plan.</td><td>reply</td></tr><tr><td></td><td>showschedules</td><td>Display information about job streams in the production plan.</td><td>list</td></tr><tr><td></td><td>submit sched</td><td>Submit job streams into the production plan.</td><td>submit</td></tr></table>

Table 50. Job streams - additional access keywords (continued)  

<table><tr><td colspan="2">Activity</td><td>Access keywords required</td><td></td></tr><tr><td></td><td></td><td>If the submit also identifies a second job stream with the &quot;ALIAS&quot; argument, the user must have &quot;submit&quot; access to that other job stream as well.</td><td></td></tr><tr><td></td><td></td><td>If the job stream is defined in a folder, then use access is required on the workstation (cpu) where the job stream is defined, in addition to access to the folder itself and the objects it contains.</td><td></td></tr><tr><td></td><td></td><td>Not valid for workstations in an end-to-end environment.</td><td></td></tr><tr><td>Using the workload service assurance feature</td><td>All activities</td><td>For any user to perform any workload service assurance activities, the &lt;TWS_user&gt; must have the following access keywords:</td><td>display, modify, list</td></tr></table>

# Example

To allow a user to perform all actions on job streams defined in the "test" folder and its sub-folders, except submit and release, and access to all workstations defined in the root (/) folder, specify:

```javascript
schedule folder = /test + CPUFOLDER = /access=adddep,altpri,cancel,deldep,display,limit-reply, list
```

# Object type - userobj

The following table gives the additional access keywords required to work with users, other than those described in Table 37: Access keywords for composer actions on page 231:

Table 51. Users - additional access keywords  

<table><tr><td></td><td></td><td>Activity</td><td>Access keywords required</td></tr><tr><td>Composer</td><td>Modeling of job types with advanced options</td><td>When defining job types with advanced options allows the modeler to specify in the credentials section of the job that the user name and password values required to submit the job are resolved at run time with values extracted from the database and defined with the User definition composer commands (username and password) or Dynamic Workload Console panel.</td><td>use</td></tr><tr><td>Dynamic Workload Console</td><td></td><td></td><td></td></tr></table>

Table 51. Users - additional access keywords (continued)  

<table><tr><td colspan="2">Activity</td><td>Access 
keywords 
required</td><td></td></tr><tr><td colspan="3">Note that on dynamic agents User definitions can be used 
regardless of the operating system.</td><td></td></tr><tr><td>Conman</td><td>altpass</td><td>Alter user passwords in the plan.</td><td>altpass</td></tr><tr><td>Dynamic Workload 
Console</td><td></td><td></td><td></td></tr><tr><td>Example</td><td></td><td></td><td></td></tr><tr><td colspan="3">The following access definition allows a user to:</td><td></td></tr><tr><td colspan="3">·List and modify user information, including passwords in the database (display, modify, and altpass).</td><td></td></tr><tr><td colspan="3">·When defining job types with advanced options on dynamic agents, to specify in the credentials section of the job 
that the user name and password values required to submit the job are resolved at run time with values extracted from 
the database and defined with the User definition (use).</td><td></td></tr><tr><td>userobj</td><td>access=display,modify,altpass,use,list</td><td></td><td></td></tr></table>

# Object type - variable

The following table gives the access keywords for using variable tables and the variables they contain (this includes the global variables)

Table 52. Variable tables - access keywords  

<table><tr><td colspan="2">Activity</td><td>Access 
keywords 
required</td></tr><tr><td>Composer</td><td>Use variable tables in run cycles, run cycle groups, job streams, and workstations</td><td>use</td></tr><tr><td>Dynamic Workload 
Console</td><td></td><td></td></tr><tr><td>Example</td><td></td><td></td></tr><tr><td colspan="3">To allow a user only to use variable tables when defining other scheduling objects, specify:</td></tr><tr><td>variable</td><td>access=use</td><td></td></tr></table>

# Object type - workload application

The following table gives the access keywords required to work with workload applications:

Table 53. Workload applications - access keywords  

<table><tr><td></td><td></td><td>Activity</td><td>Access keywords required</td></tr><tr><td rowspan="11">Dynamic Workload Console</td><td>add</td><td>Add new workload applications templates to the database. Unlock access is needed to use the ;unlock attribute.</td><td>add, unlock</td></tr><tr><td>create</td><td>Create a workload application template in the database. Modify access is needed to use the ;lock attribute.</td><td>display, modify</td></tr><tr><td>delete</td><td>Delete a workload application template from the database.</td><td>delete</td></tr><tr><td>display</td><td>Display a workload application template.</td><td>display</td></tr><tr><td>list</td><td>List workload application templates in the database.</td><td>list</td></tr><tr><td>lock</td><td>Lock workload application templates in the database.</td><td>modify</td></tr><tr><td>modify</td><td>Modify a workload application template in the database.</td><td>add, modify</td></tr><tr><td>new</td><td>Create a workload application template in the database.</td><td>add, modify</td></tr><tr><td>rewrite</td><td>Rename workload application templates in the database. The user needs add access to the new object and delete and display access to the old object.</td><td>add, delete, display</td></tr><tr><td>replace</td><td>Replace workload application templates in the database. Unlock access is needed to use the ;unlock attribute.</td><td>add, modify, unlock</td></tr><tr><td>unlock</td><td>Unlock workload application templates in the database.</td><td>unlock</td></tr></table>

# Example

To allow a user to create and delete a workload application, specify:

wkldappl

access  $=$  add,delete

The <TWS_user> - special security file considerations

The <TWS_user> is a special user, and requires special consideration for the security file.

Required access for the<TWS_user> for workload service assurance

For any user to perform Workload service Assurance activities, the <TWS_user> must have display, modify and list access keywords assigned for all job, schedule and cpu objects.

# New<TWS_user> in migrated Security file

If you change the <TWS_user> of your environment, for example, as you might do when performing a parallel upgrade, and then you migrate the Security file (to preserve your settings) you must set up the new <TWS_user> in the Security file in advance, with all its required access rights, before attempting to start IBM Workload Scheduler.

# Update definitions for Windows domain <TWS_user> in the Security file after upgrade to version 10.2.5

Due to new support of the UPN Windows user, if you have Windows domain users that are defined in the logon fields as domain\username, after performing an upgrade to version 10.2.5, update the Security file before starting the IBM Workload Scheduler instance. Insert the escape character \' before the \' character in the domain\username value.

For example, if you use the MYDOMAIN\user1 value in the logon field, after the upgrade, in the Security file you must update the line in following way:

```batch
logon  $\equiv$  MYDOMAIN\user1
```

# Sample security file

This section contains a sample security file divided into sections for each different class of user.

Note that the order of definitions is from most to least-specific. Because of the order, TWS_users and root users are matched first, followed by users in the sys group, and then users in the mis group. All other users are matched with the last definition, which is the least specific.

# TWS_users and root users logged in on the master domain manager

user mastersm cpu \(=\) \\(master + logon \)\equiv\( <TWS_user>,root  
```shell
#!/bin/bash
# Sample Security File
#!/bin/bash
# APPLIES TO TWS_users AND ROOT USERS LOGGED IN ON THE
# MASTER DOMAIN MANAGER.
user mastersmp cpu=\\(master + logon=<TWS_user>,root
begin
# OBJECT ATTRIBUTES ACCESS CAPABILITIES
# _____________
job cpu=@ + folder = / + cpufolder = / access=@
schedule cpu=@ + folder = / + cpufolder = / access=@
resource + folder = / + cpufolder = / access=@
prompt + folder = / access=@
file access=@
calendar + folder = / access=@
cpu cpu=@ + folder = / access=@
parameter name=@ ~ name=r@ + folder = / + cpufolder = / access=@
userobj cpu=@ + logon=@ + cpufolder = / access=@
eventrule name=@ + folder = / access=add,delete,display,modify, list, unlock
action provider=@ access=display, submit, use, list
```

```julia
event provider \(= \text{包}\) access \(=\) use   
report name \(\coloneqq\) @ access \(=\) display   
runcygrp name \(\coloneqq\) @ + folder \(= /\) access \(=\) add,delete,display,modify,use,1ist,unlock   
variable name \(= a\text{已},\) \\(default + folder \(= /\) access \(=\) add,delete,display,modify,use,1ist,unlock   
wkldappl name \(\coloneqq\) @ + folder \(= /\) access \(=\) add,delete,display,modify,1ist,unlock   
lob name \(\coloneqq\) @ access \(=\) use   
folder name \(\coloneqq /\) access \(=\) @   
end
```

This user definition applies to GUI and CLI access for TWS_users and root users logged into a master domain manager. They are given unrestricted access to all objects, except parameters that have names beginning with r. Access to the r parameters is given only to users in the mis group. They are the only ones who can generate all kinds of plans and who can create, update, and delete event rule definitions.

All users have access to all variable tables beginning with "a" and to the default table, irrespective of the default variable table name.

TWS_users and root users logged in on any domain manager (other than the master)

user testerlondon cpu  $\equiv$  \$manager  $^+$  logon  $\equiv <  TWS\_ user>$  ,root  
```prolog
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # 
# Sample Security File
# #
# APPLIES TO TWS_users AND ROOT USERS LOGGED IN ON ANY
# DOMAIN MANAGER.
user testerlondon cpu= $manager + logon=<TWS_user>,root
begin
# OBJECT ATTRIBUTES ACCESS CAPABILITIES
# _
job cpu=@ + folder = / + cpufolder = / access=add,delete,display
schedule cpu=@ + folder = / + cpufolder = / access=add,delete,display
resource + folder = / + cpufolder = / access=@
prompt + folder = /
file name=prosked access/build, display
file name=trialsked access/build, display
calendar + folder = /
cpu cpu=@ + folder = / access=@
parameter name=@ ~ name=v@ + folder = / + cpufolder = / access=@
userobj cpu=@ + logon=@ + cpufolder = / access=@
eventrule name=@ + folder = / access=add,delete,display,modify, list, unlock
action provider=@ access=display, submit, use, list
event provider=@ access=use
report name=@ access=display
runcygrp name=@ + folder = / access=add, delete, display, modify, use, list, unlock
variable name=a@,$default + folder = / access=add, delete, display, modify, use, list, unlock
wkdappl name=@ + folder = / access=add, delete, display, modify, list, unlock
lob name=@ access=use
folder name=/ access=@
end
```

This user definition applies to GUI and CLI access for TWS_users and root users logged into any domain manager other than the master. They are given unrestricted access to all objects, except parameters that have names beginning with v, and jobs

and jobs streams to which they have limited access. They can access all workstations defined in the root folder (/). They can generate all types of plans and can create, update, and delete event rule definitions defined in the root folder.

All users have access to all variable tables beginning with "a" and to the default table, irrespective of the default variable table name.

TWS_users and root users logged in on any workstation other than any domain manager

user sm ~CPU \(=\) \\(MANAGER logon \)\equiv\( <TWS_user>,root  
```txt
# APPLIES TO TWS_users AND ROOT USERS LOGGED IN ON ANY
# WORKSTATION OTHER THAN THE MASTER DOMAIN MANAGER.
user sm logon=<TWS_user>,root
begin
# OBJECT ATTRIBUTES ACCESS CAPABILITIES
# ____________ _
job cpu=$thiscpu + folder = / + cpufolder = / access@
schedule cpu=$thiscpu + folder = / + cpufolder = / access@
resource cpu=$thiscpu + folder = / + cpufolder = / access@
prompt + folder = / access@
calendar + folder = / access@
cpu cpu=$thiscpu + folder = / access@
parameter cpu=$thiscpu ~ name=r@ + folder = / + cpufolder = / access@
action provider=@ access=display,submit,use,list
event provider=@ access=use
report name=RUNHIST,RUNSTATS access=display
runcygrp name=@ + folder = / access=add,delete,display,modify,use,lock
file name=globalots access=display
lob name=@ access=use
folder name=/myfolder access=@
end
```

This user definition applies to TWS_users and root users to whom definition (1) does not apply, which are those who are logged in on any workstation other than the master domain manager or any other domain manager. They are given unrestricted access to all objects on their login workstation. Note that prompts, files, and calendars are global in nature and are not associated with a workstation.

They can use event rules, but are not allowed to create, update, or delete event rule definitions.

Users logged into the sys group on the master domain manager

user masterop cpu  $=$  \$master + group  $\equiv$  sys  
```shell
#!/binomial
# APPLIES TO USERS LOGGED INTO THE SYS GROUP ON THE
# MASTER DOMAIN MANAGER.
user masterop cpu=$master + group=sys
begin
# OBJECT ATTRIBUTES ACCESS CAPABILITIES
# _____________
job cpu=@ + logon="TWS_domain\<TWS_user>" +
    + folder = / access=@
job cpu=@ + logon=root + folder = /
```

```txt
+cpulolder \(=\) /   
access \(\equiv\) adddep,altpri,cancel,confirm,   
deldep,release-reply,rerun,submit,use   
job cpu \(\coloneqq\) @ + logon \(\coloneqq\) @ ~ logon \(\coloneqq\) root + folder \(=\) /   
+cpulfolder \(=\) /   
access \(\coloneqq\) add,addep,altpri,cancel,confirm,deldep, release,reply, rerun,submit,use   
schedule cpu \(\coloneqq\) \\(thiscpu + folder \(=\) / + cpulfolder \(=\) / access \(\coloneqq\) adddep,altpri,cancel, deldep,limit, release, submit   
schedule cpu \(\coloneqq\) @ + folder \(=\) / + cpulfolder \(=\) / access \(\coloneqq\) adddep,altpri,cancel, deldep, limit, release, submit   
resource + folder \(=\) / access \(\coloneqq\) add,display, resource, use   
file name=globalopts access \(\coloneqq\) display   
file name=prosked access \(\coloneqq\) display   
file name=symphony access \(\coloneqq\) display   
file name=trialsked access \(\coloneqq\) build, display   
calendar + folder \(=\) / access \(\coloneqq\) display, use   
cpu cpu \(\coloneqq\) @ + folder \(=\) / access \(\coloneqq\)   
parameter name \(\coloneqq\) @ ~ name=r@ + folder \(=\) / access \(\coloneqq\)   
report name=RUNHIST,RUNSTATS access \(\coloneqq\) display   
wkldappl name \(\coloneqq\) @ + folder \(=\) / access \(\coloneqq\) add,delete,display,modify,No lock   
lob name \(\coloneqq\) @ access \(\coloneqq\) use   
folder name=/ access \(\coloneqq\)   
end
```

This user definition applies to users logged into the sys group on the master domain manager. They are given a unique set of access capabilities. Multiple object statements are used to give these users specific types of access to different sets of objects. For example, there are three job statements:

- The first job statement permits unrestricted access to jobs that run on any workstation (@) under the user's name (TWS_domain\<TWS_user>).  
- The second job statement permits specific types of access to jobs that run on any workstation and that run as root.  
- The third job statement permits specific types of access to jobs that run on any workstation. Jobs that run as root are excluded.

They are the only users defined on the master domain manager, different from maestro or root, who can generate trial and forecast plans.

# Users logged into the sys group on any workstation other than the master domain manager

user op ~cpu=\\(master group=sys  
```txt
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # 
# APPLIES TO USERS LOGGED INTO THE SYS GROUP ON ANY 
# WORKSTATION OTHER THAN THE MASTER DOMAIN MANAGER 
user op group=sys 
begin
# OBJECT ATTRIBUTES ACCESS CAPABILITIES
# ____________ 
job cpu=\(thiscpu + logon@ + folder = / + cpufolder = / access@ 
job cpu=\)thiscpu + logon=root + folder = /
```

```prolog
+cpufolder \(=\) /access \(\equiv\) adddep,altpri,cancel,confirm,deldep, release-reply,erun,submit,use   
job cpu \(\equiv\) \\(thiscpu \~ logon \)=\( root + folder \) = \(1\( +cpufolder \(=\) /access \(\equiv\) adddep,altpri,cancel,confirm,deldep, release-reply,erun,submit,use   
schedule cpu \(\equiv\) \\)thiscpu \(^+\) folder \(= /\) \(^+\) cpufolder \(= /\) access@ resource +folder \(= /\) access \(\equiv\) adddisplay,resource,use   
runcygrp name \(\equiv\) @ + folder \(= /\) access \(\equiv\) add,delete,display,modify,use, list, unlock prompt + folder \(= /\) access \(\equiv\) add,display,reply,use   
calendar + folder \(= /\) access \(\equiv\) use   
cpu cpu \(\equiv\) \\(thiscpu \(^+\) folder \(= /\) access \(\equiv\) console,fence,limit, link,start,stop,unlink   
parameter name \(\equiv\) @ ~name=r@ + folder \(= /\) access@   
wkldappl name \(\equiv\) @ + folder \(= /\) access \(\equiv\) add,delete,display,modify, list, unlock   
lob name \(\equiv\) @ access \(\equiv\) use   
folder name=/access \(\equiv\)   
end
```

This user definition applies to sys group users to whom definition (3) does not apply, which are those who are logged in on any workstation other than the master domain manager. They are given a set of access capabilities similar to those in definition (3). The exception is that access is restricted to objects on the user's login workstation (\$thiscpu).

# Users logged into the mis group on any workstation

# user misusers group=mis

```prolog
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # 
# APPLIES TO USERS LOGGED INTO THE MIS GROUP ON
# ANY WORKSTATION.
user misusers cpu= @ group=mis
begin
# OBJECT ATTRIBUTES ACCESS CAPABILITIES
# ____________ _
job cpu=$thiscpu + folder = /
+ logon=@ + cpufolder = / access=@
job cpu=$thiscpu + folder = /
+ logon=@
~ logon=root + cpufolder = / access=submit,use
schedule cpu=$thiscpu + folder = /
+ cpufolder = / access=add,submit,modify,display
cpu cpu=@ + type=agent,s-agent,fta + folder = /
access=console,fence,limit,link,start,stop,unlink
parameter name=r@ + folder = / + cpufolder = / access=@
parameter name=@ + folder = / + cpufolder = / access=display
runcygrp name=@ + folder = / access=add,delete,display,modify,use,start,unlock
folder name=/ access=@
end
```

This user definition applies to users logged into the mis group on workstations defined in the root folder. They are given a limited set of access capabilities to fault-tolerant, standard, and dynamic agents. Resources, prompts, files, calendars, and

workstations are omitted, which prevents access to these objects. These users are given unrestricted access to parameters with names that begin with  $\mathbf{r}$ , and that are defined in the root folder, but can only display other parameters.

# Users logged into multiple groups [continue keyword]

This is an example of a security file where the continue keyword is used. This kind of security file allows a user to inherit authorization from multiple stanzas. The user gets the accesses for the first matching entry of each stanza that matches the user definition.

user misusers cpu@ group=mis  
```txt
#User misusers USER DEFINITION APPLIES TO USERS LOGGED IN TO #THE MIS GROUP ON ANY WORKSTATION.# #User dbusers USER DEFINITION APPLIES TO USERS LOGGED IN TO #THE DB GROUP ON ANY WORKSTATION.# #User default USER DEFINITION APPLIES TO ALL USERS.#   
user misusers cpu  $\equiv$  @ group  $\equiv$  misbegin #OBJECT ATTRIBUTES ACCESS CAPABILITIES # job cpu  $\equiv$  @ +name=mis@ + folder  $=$  /  $^+$  cpufolder  $=$  /access  $\equiv$  schedule name=mis@ + folder  $=$  / +cpufolder  $=$  /access  $\equiv$  @parameter name=mis@ + folder  $=$  / +cpufolder  $=$  /access  $\equiv$  @continue folder name=/ access  $\equiv$  @user dbusers cpu  $\equiv$  @ group  $\equiv$  dbbegin #OBJECT ATTRIBUTES ACCESS CAPABILITIES #job cpu  $\equiv$  @ +name=db_ $@$  +folder  $=$  / $^+$  cpufolder  $=$  /access  $\equiv$  @schedule name=db_ $@$  + folder  $=$  / $^+$  cpufolder  $=$  /access  $\equiv$  @parameter name=db_ $@$  + folder  $=$  / +cpufolder  $=$  /access  $\equiv$  @continue folder name=/access  $\equiv$  @user default cpu  $\equiv$  @ +logon  $\equiv$  @begin #OBJECT ATTRIBUTES ACCESS CAPABILITIES # parameter name  $\equiv$  @ + folder  $=$  / +cpufolder  $=$  /access  $\equiv$  /end
```

Users that belong only to the mis group get access to all objects that have a name starting with the mis prefix, as specified in the user misusers user definition. In addition, the user default user definition gives them display access to all parameters.

Users that belong only to the db group get access to all objects that have a name starting with the db prefix, as specified in the user dbusers user definition. In addition, the user default user definition gives them display access to all parameters.

Users that belong to both the mis and the db groups get access to the objects that have a name starting with the mis prefix and to the objects that have a name starting with the db prefix, as specified in the user misusers and in the user dbusers user definitions. In addition, the user default user definition gives them display access to all parameters. Access to jobs, job streams, workstations, and parameters is limited to only those defined in the root (/) folder.

You must order definitions from most specific to least specific. The user default user definition gives generic accesses, and must be therefore specified at the end of the file.

# All other users logged in on any workstation

user default cpu  $=$  @ + logon  $\equiv$  @  
```prolog
# APPLIES TO ALL OTHER USERS LOGGED IN ON ANY
# WORKSTATION.
user default cpu= @ + logon= @
begin
# OBJECT ATTRIBUTES ACCESS CAPABILITIES
# _____________
job cpu= @ + folder = / + cpufolder = / access= @
schedule cpu= @ + folder = / + cpufolder = / access= @
resource + folder = / + cpufolder = / access= @
prompt + folder = / access= @
file access= @
calendar + folder = / access= @
cpu cpu= @ + folder = / access= @
parameter name= @ ~ name=r@ + folder = / + cpufolder = / access= @
userobj cpu= @ + logon= @ + cpufolder = / access= @
eventrule name= @ + folder = / access=add,delete,display,modify, list, unlock
action provider= @ access=display, submit, use, list
event provider= @ access=use
report name= @ access=display
runcygrp name= @ access=add, delete, display, modify, use, list, unlock
variable name=a@, $default + folder = / access=add, delete, display, modify, use, list, unlock
wkldappl name= @ + folder = / access=add, delete, display, modify, list, unlock
lob name= @ access=use
folder name= / access= @
end
```

They are given unrestricted access to all objects, except parameters that have names beginning with r. They are the only ones who can generate all kinds of plans and who can create, update, and delete event rule definitions. All users have access to all variable tables beginning with "a" and to the default table, irrespective of the default variable table name. Access to most scheduling objects is limited to those defined in the root (/) folder.

# All domain1.com windows users logged in on any workstation

user cpu  $= @$  +logon  $= @\backslash$  @domain1.com  
```prolog
#APPLIES TO ALL OTHER USERS IN THE 'domain1.com' INTERNET DOMAIN LOGGED IN ON ANY   
#WORKSTATION.   
user default cpu \(@ +\) logon \(\equiv\) @@domain1.com   
begin   
#OBJECT ATTRIBUTES ACCESS CAPABILITIES   
#-   
job cpu \(\equiv\) @ + logon \(=\) a@@domain1.com + folder = / +cpufolder \(=\) /access=display   
job cpu \(\equiv\) @ + folder \(=\) / +cpufolder \(=\) /access \(\equiv\)   
schedule + folder \(=\) / + cpufolder \(=\) /access \(\equiv\)   
resource + folder \(=\) / + cpufolder \(=\) /access \(\equiv\)   
prompt + folder \(=\) /access \(\equiv\)   
file access \(\equiv\)   
calendar + folder \(=\) /access \(\equiv\)   
cpu cpu \(\equiv\) @ + folder \(=\) /access \(\equiv\)   
parameter name \(\equiv\) @ ~name=r@ + folder \(=\) / + cpufolder \(=\) /access \(\equiv\)   
userobj cpu \(\equiv\) @ + logon \(\equiv\) @ + cpufolder \(=\) /access \(\equiv\)   
eventrule name \(\equiv\) @ + folder \(=\) /access=add,delete,display,modify,No lock   
action provider \(\equiv\) @access=display,submit,use,No   
event provider \(\equiv\) @access=use   
report name \(\equiv\) @access=display   
runcygrp name \(\equiv\) @ + folder \(=\) /access=add,delete,display,modify,No use,No unlock   
variable name=g@,\\(default + folder \(=\) /access=add,delete,display,modify,No use,No unlock   
wkldappln name \(\equiv\) @ + folder \(=\) /access=add,delete,display,modify,No use,No unlock   
lob name \(\equiv\) @access=use   
folder name=/access \(\equiv\)   
end
```

Windows Users in domain1.com whose name begins with 'a' can display only jobs and can manage parameters which name does not begin with r. All other domain1.com Windows users that are logged in on any workstation are given access to all objects defined in the root (/) folder, and to parameters that have names beginning with r. They are the only ones who can generate all kinds of plans and who can create, update, and delete event rule definitions. All users have access to all variable tables beginning with "g" and to the default table, irrespective of the default variable table name.

# All MYWINDOW windows users logged in on any workstation

user default cpu  $= @ +$  logon  $\equiv$  MYWINDOM\@  
```txt
# APPLIES TO ALL "MYWINDOW" WINDOWS USERS LOGGED IN ON ANY # WORKSTATION.
user default cpu=@ + logon=MYWINDOW\@ 
begin
# OBJECT ATTRIBUTES ACCESS CAPABILITIES
# _____________
job cpu=@ + folder = /
+ cpufolder = /
access=@
schedule cpu=@ + folder = /
+ cpufolder = /
access=@
```

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #  
```prolog
resource + folder = / + cpufolder = / access@  
prompt + folder = / access@  
file access@  
calendar + folder = / access@  
cpu cpu@ + folder = / access@  
parameter name@ + folder = / + cpufolder = / access@  
userobj cpu@ + logon =MYWINDOM\r@ + cpufolder = / access=display  
userobj cpu@ + logon@ + cpufolder = / access@  
eventrule name@ + folder = / access=add,delete,display,modify, list, unlock  
action provider@ access=display, submit, use, list  
event provider@ access=use  
report name@ access=display  
runcygrp name@ + folder = / access=add, delete, display, modify, use, list, unlock  
variable name@g&, $default + folder = / access=add, delete, display, modify, use, list, unlock  
wkldappl name@ + folder = / access=add, delete, display, modify, list, unlock  
lob name@ access=use  
folder name=/ access@  
end
```

Windows Users in MYWINDOM whose name begins with 'r' can display only userjobs. All others MYWINDOM Windows user that are logged in on any workstation are given unrestricted access to all objects. Access to workstations is limited to workstations defined in the root (/) folder. Access to scheduling objects that can be defined in folders is limited to the root (/) folder, as specified. For example, access to prompts is limited to prompts defined in the root folder prompt + folder = / access@. They are the only ones who can generate all kinds of plans and who can create, update, and delete event rule definitions. All users have access to all variable tables beginning with "g" and to the default table, irrespective of the default variable table name.

![](images/7dea11f29b89611905398c7a10b2e8bc1f41a0b3cb45d3aba0f318f1d378c2d3.jpg)

Note: Starting with version 9.2, due to support of the Windows users in User Principal Name (UPN) format, you have to specify the windows domain users in a different way in the Security file. In the same example for the previous version you have the following syntax:

```perl
user default cpu  $@ +$  logon  $\equiv$  MYWINDOM\@   
userjob cpu  $\equiv$  @  $^+$  logon  $\equiv$  MYWINDOM\r@ access  $\equiv$  display
```

# Security file on the master domain manager to install fix packs or upgrade fault-tolerant agents and dynamic agents

user MAESTRO CPU  $=$  @+LOGON  $\equiv$  tws94user,Administrator  
```python
# APPLIES TO tws94user and Administrator LOGGED IN ON ANY WORKSTATIONS.
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
CPU=@+LOGON=tws94user,Administrator
BEGIN
USEROBJ CPU=@ + cpufolder = / ACCESS=ADD, DELETE, DISPLAY, MODIFY, USE, ALTPASS, LIST, UNLOCK
JOB CPU=@ + folder = / + cpufolder = /
ACCESS=ADD, ADDDEP, ALTPRI, CANCEL, CONFIRM, DELDEP, DELETE, DISPLAY,
KILL, MODIFY, RELEEASE, REPLY, RERUN, SUBMIT, USE, LIST, UNLOCK, SUBMITDB, RUN
SCHEDULE CPU=@ + folder = / + cpufolder = /
ACCESS=ADD, ADDDEP, ALTPRI, CANCEL, DELDEP, DELETE, DISPLAY, LIMIT,
```

```prolog
MODIFY,RELEASE,REPLY,SUBMIT,LIST,UNLOCK   
RESOURCE CPU  $\equiv$  @  $^+$  folder  $= /$  +cpufolder  $= /$  ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY, RESOURCE,USE,LIST,UNLOCK   
PROMPT ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,REPLY,USE,LIST,UNLOCK   
FILE NAME  $\equiv$  @ ACCESS  $=$  BUILD,DELETE,DISPLAY,MODIFY,UNLOCK   
CPU CPU  $\equiv$  @  $^+$  folder  $= /$  ACCESS  $=$  ADD,CONSOLE,DELETE,DISPLAY,FENCE,LIMIT,LINK, MODIFY,SHUTDOWN,START,STOP,UNLINK,LIST,UNLOCK,RUN,RESETFTA,MANAGE   
PARAMETER CPU  $\equiv$  @  $^+$  cpufolder  $= /$  ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,LIST,UNLOCK   
CALENDAR ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,USE,LIST,UNLOCK   
REPORT NAME  $\equiv$  @ ACCESS  $=$  DISPLAY   
EVENTRULE NAME  $\equiv$  @ ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,LIST,UNLOCK   
ACTION PROVIDER  $\equiv$  @ ACCESS  $=$  DISPLAY,SUBMIT,USE,LIST   
EVENT PROVIDER  $\equiv$  @ ACCESS  $=$  USE   
VARIABLE NAME  $\equiv$  @ ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,USE,LIST,UNLOCK   
WKLDAPPL NAME  $\equiv$  @ ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,LIST,UNLOCK   
RUNCYGRP NAME  $\equiv$  @ ACCESS  $=$  ADD,DELETE,DISPLAY,MODIFY,USE,LIST,UNLOCK   
LOB NAME  $\equiv$  @ ACCESS  $=$  USE   
folder NAME  $\equiv$  / ACCESS  $\equiv$  @   
END
```

The default MAESTRO definition applies to Dynamic Workload Console and CLI access for tws94user and Administrator users logged into any workstation in the network. They can install a fix pack or upgrade to a later version fault-tolerant agents and dynamic agents in the network simultaneously.

For more information about this feature, see the section about centralized agent update in Planning and Installation Guide.

# Chapter 4. Configuring authentication

This section describes how to configure authentication using, amongst other methods, the popular LDAP (Lightweight Directory Access Protocol). It is divided into these main topics:

- Where to configure authentication on page 262  
Available configurations on page 262  
- Rules for using a Federated User Registry with IBM Workload Scheduler on page 263  
- Completing the LDAP configuration on page 263  
- Configuring an IBM Tivoli Directory Server on page 265  
- Configuring Microsoft Active Directory on page 268  
- Configuring an OpenID Connect Client on page 272

# Where to configure authentication

Authentication must be configured for each WebSphere Application Server Liberty profile, following these rules:

# To authenticate command-line users

For users of the command-line, the command-line client, and the command-line as clients connected to the master domain manager using HTTP or HTTPS, the same authentication method must be configured for the following components:

- Master domain manager  
- Backup master domain manager

# To authenticate Z connector users

The Z connector is always installed on the same instance as the Dynamic Workload Console. You do not need to separately configure authentication for it.

# To authenticate dynamic domain manager users

The same authentication method must be configured for each dynamic domain manager and its corresponding backup dynamic domain manager. This authentication method does not need to be the same as that used for the master domain manager.

# Available configurations

On installation, all IBM Workload Scheduler components that use WebSphere Application Server Liberty are configured by default to use a local file-based user repository. For information about supported authentication mechanisms in WebSphere Application Server Liberty see the section about authenticating users in WebSphere Application Server Liberty.

You can implement an LDAP-based user repository by configuring the sample authentication templates provided in XML format.

If you choose to enable an LDAP-based user repository, for your convenience, a set of sample configuration templates are provided in XML format. See Configuring IBM Workload Scheduler using templates on page 418 for a list of the templates. You can further customize the templates by adding additional elements to the XML files. For a full list of the elements that you can configure to complement or modify the configuration, see the section about LDAP user registry in WebSphere Application Server Liberty documentation.

# Rules for using a Federated User Registry with IBM Workload Scheduler

This section describes the simple rules you must follow when configuring IBM Workload Scheduler to use a Federated User Registry:

# No duplicate User IDs

You can define any number of user registries in a Federated User Registry. However, no user ID must be present in more than one registry and no user ID must be present twice in the same registry. Thus, if you configure multiple user registries it is because you have users in different non-inclusive groups that use different user registries and which need to access IBM Workload Scheduler.

# Completing the LDAP configuration

# About this task

After you have configured the WebSphere Application Server Liberty to use a new authentication configuration, whichever configuration method you used, you must also update the security file, and propagate the changes in your environment.

# Updating the security file

# About this task

If you use the classic security model, you need to update the IBM Workload Scheduler security file to allow users to access IBM Workload Scheduler objects. For more information, see the section about updating the security file in Administration Guide. The following example shows an updated security file, where the user TEST_LDAP has been added to the USER MAESTRO section:

```csv
USER MAESTRO  
CPU=+LOGON=tws83,Administrator,administrator,TEST_LCD  
BEGIN  
USEROBJ CPU=@ ACCESS=ADD,DELETE,DISPLAY,MODIFY,ALTPASS,UNLOCK,LIST  
JOB CPU=@ + FOLDER = / ACCESS=ADD,ADDDEP,ALTPRI,CANCEL,CONFIRM,DELDEP,DELETE,DISPLAY,KILL,MODIFY,RELEASE,REPLY,RERUN,SUBMIT,USE,LIST,UNLOCK  
SCHEDULE CPU=@ + FOLDER = / ACCESS=ADD,ADDDEP,ALTPRI,CANCEL,DELDEP,DELETE,DISPLAY,LIMIT,MODIFY,RELEASE,REPLY,SUBMIT,LIST,UNLOCK  
RESOURCE CPU=@ + FOLDER = / + CPUFOLDER = / ACCESS=ADD,DELETE,DISPLAY,MODIFY,RESOURCE,USE,LIST,UNLOCK  
PROMPT + FOLDER = / ACCESS=ADD,DELETE,DISPLAY,MODIFY,REPLY,USE,LIST,UNLOCK  
FILE NAME=@ ACCESS=CLEAN,DELETE,DISPLAY,MODIFY,UNLOCK  
CPU CPU=@ + FOLDER = / ACCESS=ADD,CONSOLE,DELETE,DISPLAY,FENCE,LIMIT,LINK,MODIFY,SHUTDOWN,START,STOP,UNLINK,LIST,UNLOCK  
PARAMETER CPU=@ + FOLDER = / + CPUFOLDER = / ACCESS=ADD,DELETE,DISPLAY,MODIFY,UNLOCK,LIST  
CALENDAR + FOLDER = / ACCESS=ADD,DELETE,DISPLAY,MODIFY,USE,UNLOCK,LIST
```

FOLDER NAME  $=$  ACCESS  $\equiv$  ADD,DELETE,DISPLAY,MODIFY,USE,LIST,UNLOCK，ACL

END

In this example, the useDomainQualifiedUserName security property is set to false therefore the user name has been specified without the domain.

# Propagating the changes

# About this task

Propagate the changes you have made as follows:

1. If your changes involved changing the primary WebSphere Application Server Liberty administrator, then update the wa_user.xml file with the credentials. The wauser_variables.xml file can be found in the path:

# Dynamic Workload Console

DWC_DATA_dir/usr/servers/dwcServer/configDropins/overrides

# masterdomainmanager

TWA_DATA_DIR/usr/services/engineServer/configDropins/overrides

# Dynamic Workload Console

DWC_home\usr\servers\dwcServer\configDropins\overdrafts

# masterdomainmanager

TWA_home\usr\servers\engineServer\configDropins\overdrafts

a. Copy the wauser_variables.xml file for both the Dynamic Workload Console and the master domain manager to a temporary directory.  
b. Create a copy of the original wauser_variables.xml file for both the Dynamic Workload Console and the master domain manager in another directory for backup purposes.  
c. Edit the files in the temporary directory with the updated information about the primary WebSphere Application Server Liberty administrator.  
d. Copy the updated wauser_variables.xml files to the overrides directory on both the Dynamic Workload Console and the master domain manager.

2. Update the USERNAME and PASSWORD fields in the useropts file on every command-line client that points to your workstation.  
3. Update the USERNAME and PASSWORD fields in the useroptions file on every fault-tolerant agent in your environment that has an HTTP/HTTPS connection defined in localopts that points to your workstation. The HTTP/HTTPS connection is used to submit a predefined job or job stream.  
4. Update the USERNAME and PASSWORD fields in the engine connection parameters on every connected Dynamic Workload Console.

# Example

![](images/d0e792380cc5f998ea706ab3cbc4b4881221925c539bd23a51b7b9f899a6d226.jpg)

Note: To change the useropts file, change the USERNAME and type the new PASSWORD in plain text between double quotation marks. The password will be encrypted the first time you log in.

# Configuring an IBM Tivoli Directory Server

Enable web single sign-on and use IBM Tivoli Directory Server as an identity provider.

# About this task

Client applications, for example, the Dynamic Workload Console, can verify the identity of a user by relying on authentication from IBM Tivoli Directory Server. You can configure the WebSphere Application Server Liberty server to function as IBM Tivoli Directory Server to take advantage of web single sign-on and to use IBM Tivoli Directory Server as an identity provider.

To simply the configuration of the WebSphere Application Server Liberty server, a sample configuration file in XML format is provided named auth_IDS_config.xml.

Update the configuration file with the details about your identity provider.

a. Copy the template file to a working directory. The template is located in the following path:

# UNIX

```txt
DWC_DATA_dir/usr/servers/dwcServer/configDropins/templatess/authentication
```

# Windows

```txt
DWC_home\usr\servers\dwcServer\configDropins\templates\authentication
```

b. Edit the template file in the working directory with the desired configuration.  
c. Optionally, create a backup copy of the configuration file authentication_config.xml present in the overrides directory in a different directory.

Ensure you do not copy the backup file in the path where the template files are located.

d. The overrides directory is located in the following path:

# UNIX

```txt
DWC_DATA_dir/usr/servers/dwcServer/configDropins/overrides
```

# Windows

```txt
DWC_home\usr\servers\dwcServer\configDropins\overridden
```

e. Copy the updated template file to the overrides directory, renaming it to authentication_config.xml to override the original authentication_config.xml file.

Alternatively, if you prefer maintaining the original name of the template, ensure you delete authentication_config.xml after you have copied the updated template file to the overrides directory to avoid conflicts.

f. Stop and restart WebSphere Application Server Liberty using the stopappserver and startappserver commands located in TWA_home/appserververtetools.

# What to do next

For more detailed information about the IBM Tivoli Directory Server parameters and values to configure in the auth_IDS_config.xml file, see the related WebSphere Application Server Liberty documentation at Configuring LDAP user registries in Liberty.

# Example configurations of LDAP servers for IDS

Refer to this template if you are using an IBM Tivoli Directory Server (IDS). This file describes a default configuration. For more advanced and specific configurations, refer to the relevant WebSphere Application Server Liberty documentation, for example at Configuring LDAP user registries in Liberty or to your LDAP administrator.

# IBM Directory Server

```xml
<server description="federated基礎LDAP">
    <variable name="admin.group.name" value="Admins"/>
    <variable name="ldap.base.DN" value="">  
    <variable name="ldap.port" value="">  
    <variable name="ldap.host" value="">  
    <variable name="ldap_adminDN" value="">  
    <variable name="ldap.password" value="">  
    <jndiEntry value="/${admin.group.name}" jndiName="admin.group.name" />  
    <administrator-role>
        <group>${admin.group.name}</group>
    </administrator-role>
    < federatedRepository searchTimeout="20m">
        <primaryRealm name="TWSRealm" allowOpIfRepoDown="true">
            <participatingBaseEntry name="o=BasicRealm"/>
        </participatingBaseEntry name="o=BasicRealm"/>
    </participatingBaseEntry name="o=BasicRealm"/>
</server description="federated基礎LDAP">
    <variable name="ldap.base.DN" value="" />
    <variable name="ldap.port" value="" />
    <variable name="ldap.host" value="" />
    <variable name="ldap.AdminDN" value="" />
    <variable name="ldap.AdminGroup.name" jndiName="admin.group.name" />  
    <administrator-role>
        <group>${admin.group.name}</group>
    </administrator-role>
    < federatedRepository searchTimeout="20m">
        <primaryRealm name="TWSRealm" allowOpIfRepoDown="true">
            <participatingBaseEntry name="o=BasicRealm"/>
        </participatingBaseEntry name="o=BasicRealm"/>
    </participatingBaseEntry name="a=BasicRealm"/>
```

```xml
<participatingBaseEntry name  $\equiv$  "${\ldap.base.DN}" /> <uniqueGroupIdMapping inputProperty  $\equiv$  "uniqueName" outputProperty  $\equiv$  "uniqueName"/> <groupSecurityNameMapping inputProperty  $\equiv$  "cn" outputProperty  $\equiv$  "cn"/> <groupDisplayNameMapping inputProperty  $\equiv$  "cn" outputProperty  $\equiv$  "cn"/> <userDisplayNameMapping inputProperty  $\equiv$  "principalName" outputProperty  $\equiv$  "principalName"/> <userSecurityNameMapping inputProperty  $\equiv$  "principalName" outputProperty  $\equiv$  "principalName"/> <uniqueUserIdMapping inputProperty  $\equiv$  "uniqueName" outputProperty  $\equiv$  "uniqueName"/> </primaryRealm> </federatedRepository>
```

```xml
<ldapRegistry
baseDN="${ldap.base.DN}"\n\nldapType="IBM Tivoli Directory Server"
port="${ldap.port} "
host="${ldap.host} "
id="ldap"
bindDN="${ldap adminDN} "
bindPassword="${ldap.password} "
searchTimeout="20"
sslEnabled="false"
sslRef="twaSSLSettings"
userFilter="/"(&p; (uid=%v)(objectclass=ePerson))"
groupFilter="/"(&p; (cn=%v) ( | (objectclass=groupOfNames)
(objectclass=groupOfUniqueNames)(objectclass=groupOfURLs)))"
userIdMap=*:uid"
groupIdMap=*:cn"
groupMemberIdMap="mycompany-allGroups:member;
mycompany-allGroups:uniqueMember;
groupOfNames:member;
groupOfUniqueNames:uniqueMember";
<ldapEntityType name="Group">
    <objectClass>groupOfNames</objectClass>
</ldapEntityType>
<ldapEntityType name="PersonAccount">
    <objectClass>inetOrgPerson</objectClass>
</ldapEntityType>
<ldapEntityType name="OrgContainer">
    <objectClass>organization</objectClass>
    <objectClass>organizationalUnit</objectClass>
    <objectClass>domain</objectClass>
    <objectClass>container</objectClass>
</ldapEntityType>
```

```txt
</ldapRegistry>   
basicRegistry id="basic" realm="BasicRealm"> user name \(=\) "\\({user.twsuser.id}" password \(=\) "\\({user.twsuser.password}]"/> group name \(=\) "\\({admin.group.name}"> member name \(=\) "\\({user.twsuser.id}"/> </group>
```

```txt
</basicRegistry> </server>
```

# Configuring Microsoft Active Directory

Enable web single sign-on and use Microsoft Active Directory as an identity provider.

# About this task

Client applications, for example, the Dynamic Workload Console, can verify the identity of a user by relying on authentication from Microsoft Active Directory. You can configure the WebSphere Application Server Liberty server to function as Microsoft Active Directory to take advantage of web single sign-on and to use Microsoft Active Directory as an identity provider.

To simply the configuration of the WebSphere Application Server Liberty server, a sample configuration file in XML format is provided named auth_AD_config.xml.

Update the configuration file with the details about your identity provider.

a. Copy the template file to a working directory. The template is located in the following path:

# UNIX

```javascript
DWC_DATA_dir/usr/servers/dwcServer/configDropins/templates/authentication
```

# Windows

```txt
DWC_home\usr\servers\dwcServer\configDropins\templates\authentication
```

b. Edit the template file in the working directory with the desired configuration.  
c. Optionally, create a backup copy of the configuration file authentication_config.xml present in the overrides directory in a different directory.

Ensure you do not copy the backup file in the path where the template files are located.

d. The overrides directory is located in the following path:

# UNIX

```txt
DWC_DATA_dir/usr/servers/dwcServer/configDropins/overrides
```

# Windows

```txt
DWC_home\usr\servers\dwcServer\configDropins\overridden
```

e. Copy the updated template file to the overrides directory, renaming it to authentication_config.xml to override the original authentication_config.xml file.

Alternatively, if you prefer maintaining the original name of the template, ensure you delete authentication_config.xml after you have copied the updated template file to the overrides directory to avoid conflicts.

f. Stop and restart WebSphere Application Server Liberty using the stopappserver and startappserver commands located in TWA_home/appserververtetools.

# What to do next

For more detailed information about Microsoft Active Directory parameters and values to configure in the auth_AD_config.xml file, see the related WebSphere Application Server Liberty documentation, for example Configuring LDAP user registries in Liberty.

# Example configurations of LDAP servers for Microsoft Active Directory

Refer to this template if you are using Microsoft Active Directory. This file describes a default configuration. For more advanced and specific configurations, refer to the relevant WebSphere Application Server Liberty documentation at Configuring LDAP user registries in Liberty or to your LDAP administrator.

```txt
<server description="federated基礎LDAP">
    <!--
        This variable specifies the group name containing the primary DWC's Administrator users.
        It can be a group defined in file based userRegistry (into <basicRegistry> section) or in your LDAP-based directory services authentication.
    */
    <variable name="admin.group.name" value="Admins"/>
    <!--
        The value of your Base distinguished name (DN) of the directory service, which indicates the starting point for LDAP searches in the directory service.
        Sample: <variable name="ldap.base.DN" value="o=domain,c=us"/>
    <!--
        <variable name="ldap.base.DN" value="DC=TWS,DC=com"/>
    <!--
        The Port number of the LDAP server.
        Sample: <variable name="ldap.port" value="389"/>
    <!--
        <variable name="ldap.port" value="389"/>
    <!--
        The Address of the LDAP server in the form of an IP address or a domain name service (DNS) name.
        Sample: <variable name="ldap.host" value="host.domain.com"/>
    <!--
        <variable name="ldap.host" value="<your_host_name"/>
    <!--
        The Distinguished name (DN) for the application server, which is used to bind to the directory service.
        Specify a user defined in Microsoft Active Directory Server with look-up rights.
        Sample: <variable name="ldap adminDN" value="cn=testuser,o=domain,c=us"/>
    <!--
        <variable name="ldap_adminDN" value="CN=Operators,DC=TWS,DC=com"/>
    </server description="federated基礎LDAP">
</server description="federated基礎LDAP">
<!-- 
This variable specifies the group name containing the primary DWC's Administrator users.
It can be a group defined in file based userRegisty (into <basicRegisty> section) or in your LDAP-based directory services authentication. 
-->
    <variable name="admin.group.name" value="Admins"/>
    <!--
        The value of your Base distinguished name (DN) of the directory service, which indicates the starting point for LDAP searches in the directory service.
Sample: <variable name="ldap.base.DN" value="o=domain,c=us"/>
    <!--
        <variable name="ldap.base.DN" value="DC=TWS,DC=com"/>
    <!--
        The Port number of the LDAP server.
Sample: <variable name="ldap.port" value="389"/>
    <!--
        <variable name="ldap.port" value="389"/>
    <!--
        The Address of the LDAP server.
Sample: <variable name="ldap.host" value="host.domain.com"/>
    <!--
        <variable name="ldap.port" value="389"/>
    <!--
        The Distinguished name (DN) for the application server, which is used to bind to the directory service.
        Specify a user defined in Microsoft Active Directory Server with look-up rights.
        Sample: <variable name="ldap adminDN" value="cn=testuser,o=domain,c=us"/>
    <!--
        <variable name="ldap adminDN" value="CN=Operators,DC=TWS,DC=com"/>
    </server description="federated基礎LDAP">
</server description="federated基礎LDAP">
<!-- 
This variable specifies the group name containing the primary DWC's Administrator users.
It can be a group defined in file based userRegisty (into <basicRegisty> section) or in your LDAP-based directory services authentication. 
-->
    <variable name="admin.group.name" value="Admins"/>
</server description="federated基礎LDAP">
<!-- 
This variable specifies the group name containing the primary DWC's Administrator users.
It can be a group defined in file based userRegisty (into <basicRegisty> section) or in your LDAP-based directory services authentication. 
-->
    <variable name="admin.group.name" value="DC=TWS,DC=com"/>
```

```txt
<!--   
The Distinguished name (DN) for the application server, which is used to bind to the directory service.   
You can use the liberty provided tool <wlp_dir>/bin/securityUtility to know the encrypted value of your password.   
1. run: <wlp_dir>/bin/securityUtility encode mypassword   
2. output: {xor}MiYvPiwsKDAtOw==   
3. fill the value field with the printed output value   
Sample: <variable name="ldap-password" value="{{xor}MiYvPiwsKDAtOw=}"/>   
-->   
<variable name="ldap-password" value=""/>   
<jndiEntry value="\${admin.group.name}" jndiName="admin.group.name" />   
<!-- Assign 'admin' to Administrator -->   
<administrator-role> <group>\$\{admin.group.name\}</group> </administrator-role>   
<!-- Details about how to configure LDAP registry and federate it with basic registry, can be found following this link:   
https://www.ibm.com/support/knowledgecenter/en/SSAW57_liberty/com.ibm.websphere.wlp.md-multiplatform.doc/ae/tw lp_sec_ldap.html   
https://www.ibm.com/support/knowledgecenter/en/SSEQTP_liberty/com.ibm.websphere.wlp.doc/ae/cwlp_repository_fed eration.html   
To troubleshoot any LDAP authentication issues, copy trace.xml in overrides with the following traceSpecification: traceSpecification="com.ibm.ws.security.wim.*=all:com.ibm.websphere.security.wim.*=all"   
-->   
<FederatedRepository searchTimeout="20m"> <primaryRealm name="TWSRealm" allowOpIfRepoDown="true"> <participatingBaseEntry name="o=BasicRealm"/> <participatingBaseEntry name="${ldap.base.DN}" /> <uniqueGroupIdMapping inputProperty="uniqueName" outputProperty="uniqueName"/> <groupSecurityNameMapping inputProperty="cn" outputProperty="cn"/> <groupDisplayNameMapping inputProperty="cn" outputProperty="cn"/> <userDisplayNameMapping inputProperty="principalName" outputProperty="principalName"/> <userSecurityNameMapping inputProperty="principalName" outputProperty="principalName"/> <uniqueUserIdMapping inputProperty="uniqueName" outputProperty="uniqueName"/> </primaryRealm> </federatedRepository>   
<!-- Note for LDAP directory service configured in SSL: 1. the settings sslEnabled to "true" 2. Import the LDAP certificate in trustStore used by the server, (it is defined in configDropins/defaults/ssl_config.xml file, the default one is resources/security/TWSServerTrustFile). For importing the exported LDAP certificate yourldap.cert run \\(JAVA_HOME/bin-keytool -import -file ./yourldap.cert -alias ldapCA -keystore resources/security/TWSServerTrustFile   
- >   
<ldapRegistry id="AD" host \(=\) "\\({ldap.host}" port \(=\) "\\({ldap.port}" ignoreCase \(=\) "true"
```

```html
baseDN="${ldap.base.DN}"  
bindDN="${ldap_adminDN}"  
bindPassword="${ldap.password}"  
ldapType="Microsoft Active Directory"  
sslEnabled="false"  
sslRef="twaSSLSettings">  
<activatedFilters  
userFilter="/&amp;(sAMAccountName=%v)(objectcategory=user)"  
groupFilter="/&amp;(cn=%v)(objectcategory=group)"  
userIdMap "*:sAMAccountName"  
groupIdMap"*:cn"  
groupMemberIdMap="memberOf:member" >  
</activatedFilters>  
</ldapRegistry>  
<basicRegistry id="basic" realm="BasicRealm">  
<!-- DO NOT DELETE -->  
<user name="/${user.twsuser.id}" password="/${user.twsuser-password}]"/>  
<!-- END DO NOT DELETE -->  
<group name="/${admin.group.name}"  
<member name="/${user.twsuser.id}]"/>  
</group>  
<!-- Sample for adding other users or group in file based user registry. -->  
<!--  
<user name="nonadmin" password="nonadmin"/>  
<user name="analyst" password="analyst"/>  
<user name="developer" password="developer"/>  
<user name="configurator" password="configurator"/>  
<user name="operator" password="operator"/>  
<group name="Admins">  
<member name="/${user.twsuser.id}]"/>  
</group>  
-->  
</basicRegistry>
```

If you have nested groups in your Microsoft Active Directory, ensure you set the recursiveSearch property in the IdapRegistry id="AD" section to true, as follows:

```shell
......
<ldapRegistry id="AD"
host="${ldap.host}" port="${ldap.port}" ignoreCase="true"
baseDN="${ldap.base.DN} "
bindDN="${ldap_adminDN} "
bindPassword="${ldap.password} "
ldapType="Microsoft Active Directory"
recursiveSearch="true"
sslEnabled="false"
sslRef="twaSSLSettings">
......
</ldapRegistry>
```

# Configuring an OpenID Connect Client

Enable web single sign-on and use the OpenID Connect Provider as an identity provider.

# About this task

Client applications, for example, the Dynamic Workload Console, can verify the identity of a user by relying on authentication from an OpenID Connect Provider. You can configure the WebSphere Application Server Liberty server to function as an OpenID Connect Client to take advantage of web single sign-on and to use the OpenID Connect Provider as an identity provider.

To simply the configuration of the WebSphere Application Server Liberty server, a sample configuration file in XML format is provided named openid_connect.xml.

Update the configuration file with the details about your identity provider.

a. Copy the template file to a working directory. The template is located in the following path:

# UNIX

```txt
DWC_DATA_dir/usr/servers/dwcServer/configDropins/template/authentication
```

# Windows

```txt
DWC_home\usr\servers\dwcServer\configDropins\templates\authentication
```

b. Edit the template file in the working directory with the desired configuration.  
c. Optionally, create a backup copy of the configuration file authentication_config.xml present in the overrides directory in a different directory.

Ensure you do not copy the backup file in the path where the template files are located.

d. The overrides directory is located in the following path:

# UNIX

```txt
DWC_DATA_dir/usr/servers/dwcServer/configDropins/overrides
```

# Windows

```txt
DWC_home\usr\servers\dwcServer\configDropins\overridden
```

e. Copy the updated template file to the overrides directory, renaming it to authentication_config.xml to override the original authentication_config.xml file.

Alternatively, if you prefer maintaining the original name of the template, ensure you delete authentication_config.xml after you have copied the updated template file to the overrides directory to avoid conflicts.

f. Stop and restart WebSphere Application Server Liberty using the stopappserver and startappserver commands located in TWA_home/appserververtetools.

# What to do next

For more detailed information about the OpenID parameters and values to configure in the openid_connect.xml file, see the related WebSphere Application Server Liberty documentation at Configuring an OpenID Connect Client in Liberty.

# Chapter 5. Network administration

This chapter describes how to administer the IBM Workload Scheduler network. It has the following topics:

Network overview on page 274  
Network definition on page 275  
Network communications on page 276  
Network operation on page 284  
- Support for Internet Protocol version 6 on page 307  
- Optimizing the network on page 289  
- Netman configuration file on page 301  
- Defining access methods for agents on page 303  
- IP address validation on page 307  
- Impact of network changes on page 309

# Network overview

A IBM Workload Scheduler network consists of one or more domains arranged hierarchically. A IBM Workload Scheduler domain is a logical grouping of workstations, consisting of a domain manager and a number of agents.

![](images/8863963b3f7a9a599b34388bc1993ea7d5b196bcafe644d378d96dc3686ca081.jpg)  
Figure 6. IBM Workload Scheduler network domain structure

![](images/46a43c2c317c1aade67743ad44432ab8b5b7908ab803d6ecb8194479009c4dbc.jpg)

# Network definition

# Domain

A named group of IBM Workload Scheduler workstations consisting of one or more agents and a domain manager. All domains have a parent, except the master domain.

# Master domain

The topmost domain in an IBM Workload Scheduler network.

# Master domain manager

The domain manager in the topmost domain of an IBM Workload Scheduler network. It contains the centralized master files used to document scheduling objects. It creates the Production Control file (Symphony) at the start of each production period and performs all logging and reporting for the network. See also Domain Manager.

# Backup master domain manager

A fault-tolerant agent capable of assuming the responsibilities of the master domain manager.

# Parent domain

The domain directly above the current domain. All domains, except the master domain, have a parent domain. All communications to/from a domain is rooted through the parent domain manager.

# Domain Manager

The management hub in a domain. All communications in and from the agents in a domain is routed through the domain manager. See also Master Domain Manager.

# Backup domain manager

A fault-tolerant agent capable of assuming the responsibilities of its domain manager.

# Fault-tolerant agent

An agent workstation capable of resolving local dependencies and launching its jobs in the absence of a domain manager.

# Standard agent

An agent workstation that launches jobs only under the direction of its domain manager.

# Extended agent

An agent workstation that launches jobs only under the direction of its host. Extended agents can be used to interface IBM Workload Scheduler with non-IBM Workload Scheduler systems and applications

# Dynamic agent

A workstation that manages a wide variety of job types, for example, specific database or FTP jobs, in addition to existing job types. This workstation is automatically created and registered when you install the dynamic agent. Because the installation and registration processes are performed automatically, when you view the agent in the Dynamic Workload Console, it results as updated by the Resource Advisor Agent. You can group agents in pools and dynamic pools.

In a simple configuration, dynamic agents connect directly to a master domain manager or to a dynamic domain manager. However, in more complex network topologies, if the network configuration prevents the master domain manager or the dynamic domain manager from directly communicating with the dynamic agent, then you can configure your dynamic agents to use a local or remote gateway.

# Host

The scheduling function required by extended agents. It can be performed by any IBM Workload Scheduler workstation, except another extended agent.

# Network communications

In a IBM Workload Scheduler network, agents communicate with their domain managers, and domain managers communicate with their parent domain managers. There are basically two types of communications that take place:

- Start-of-production period initialization (distribution of new Symphony file)  
- Scheduling events in the form of change-of-state messages during the production period

Before the start of each new production period, the master domain manager creates a production control file called Symphony. Then, IBM Workload Scheduler is restarted in the network, and the master domain manager sends a copy of the new Symphony file to each of its automatically-linked agents and subordinate domain managers. The domain managers, in turn, send copies to their automatically-linked agents and subordinate domain managers. Agents and domain managers that are not set up to link automatically are initialized with a copy of Symphony as soon as a link operation is run in IBM Workload Scheduler.

Once the network is started, scheduling messages, like job starts and completions, are passed from the agents to their domain managers, through parent domain managers to the master domain manager. The master domain manager then broadcasts the messages throughout the hierarchical tree to update the Symphony files of all domain managers and the domain managers forward the messages to all fault-tolerant agents in their domain running in FullStatus mode.

# Network links

Links provide communications between IBM Workload Scheduler workstations in a network. Links are controlled by the AUTO Link flag, and the Console Manager link and unlink commands. When a link is open, messages are passed between two workstations. When a link is closed, the sending workstation stores messages in a local pobox file and sends them to the destination workstation when the link is reopened.

This means that when links are closed, the message queues fill up with messages for the inaccessible workstations. To maximize the performance of IBM Workload Scheduler, monitor workstations for closed links and attempt to reopen them as soon as possible.

![](images/6ee839753de39142197a106230efe3dbf0fd7d75d761f9a14363be3488e06c17.jpg)

Note: Extended agents do not have links. They communicate with their domain managers through their hosts.

To have a workstation link opened automatically, turn on the AUTO Link flag in the workstation's definition. The link is first opened when IBM Workload Scheduler is started on the Master Domain workstation. If the subdomain manager

and workstations are not initialized and their AUTO Link flag is on, the master domain manager attempts to link to its subordinates and begin the initialization processes. If the AUTO Link flag is turned off, the workstation is only initialized by running a link command from the master domain manager. After the workstation is initialized, it automatically starts and issues a link back to its domain manager.

If you stop a workstation, the links from it to other workstations are closed. However, the links from the other workstations to it remain open until either one of the following situations occurs:

- The stopped workstation is restarted and a link command is issued  
- The other workstations' mailman processes time out, and perform an unlink for the workstation

When the link command is issued and the connection has been established, if the domain manager does not receive any reply within the timeout period, the chkhlst service is automatically invoked by mailman.

This service verifies that the workstation mailbox can be successfully read, and checks if there are errors in the mailbox header. Resulting information is logged in the TWSMERGE.log file of the domain manager as follows:

- If a file system error occurs while opening the mailbox, the following message is reported: AWSBDY126E An error occurred opening the Mailbox.msg file in CPU_NAME.  
- If an error occurs while opening the mailbox because mailman is reading the mailbox, the following message is reported: AWSBDY123I The Mailbox.msg file in CPU_NAME is correctly read by Mailman.  
- If the mailbox is correctly opened, but an error occurs while reading the header, the following message is reported: AWSBDY125E An error occurred reading the header of the Mailbox.msg file in CPU_NAME.  
- If the mailbox is correctly opened and no error occurs while reading the header, the following message is reported: AWSBDY124W The Mailbox.msg file in CPU_NAME is not read by Mailman.

This service can also be launched manually by using the conman command. See the IBM Workload Scheduler User's Guide and Reference for more details.

To be certain that inter-workstation communication is correctly restored, you can issue a link command after restarting a workstation.

# Working across firewalls

In the design phase of a IBM Workload Scheduler network, the administrator must know where the firewalls are positioned in the network, which fault-tolerant agents and which domain managers belong to a particular firewall, and which are the entry points into the firewalls. When this has been clearly understood, the administrator should define the behindfirewall attribute for some of the workstation definitions in the IBM Workload Scheduler database. In particular, if a workstation definition is set with the behindfirewall attribute to ON, this means that there is a firewall between that workstation and the IBM Workload Scheduler master domain manager. In this case, the workstation-domain manager link is the only link allowed between the workstation and its domain manager.

All IBM Workload Scheduler workstations should be defined with the behindfirewall attribute if the link with the corresponding domain manager, or with any domain manager in the IBM Workload Scheduler hierarchy right up to the master domain manager, is across a firewall.

When mapping an IBM Workload Scheduler network over an existing firewall structure, it does not matter which fault-tolerant agents and which domain managers are on the secure side of the firewall and which ones are on the non secure side. Firewall boundaries should be the only concern. For example, if the master domain manager is in a non secure zone and some of the domain managers are in secured zones, or vice versa, does not make any difference. The firewall structure must always be considered starting from the master domain manager and following the IBM Workload Scheduler hierarchy, marking all the workstations that have a firewall between them and their corresponding domain manager.

For all workstations with behindfirewall set to ON, the conman start and stop commands on the workstation, and the showjobs commands are sent following the domain hierarchy, instead of making the master domain manager or the domain manager open a direct connection to the workstation. This makes a significant improvement in security.

This attribute works for multiple nested firewalls as well. For extended agents, you can specify that an extended agent workstation is behind a firewall by setting the behindfirewall attribute to ON, on the host workstation. The attribute is readily in the plan; to change it in the plan, the administrator must update it in the database and then re-create the plan.

See the IBM Workload Scheduler: User's Guide and Reference for details on how to set this attribute.

# Configuring dynamic agent communications through a gateway

In some complex network topologies, the master domain manager or the dynamic domain manager are prevented from directly communicating with the dynamic agent.

# Before you begin

In a simple configuration, dynamic agents connect directly to the master domain manager or to the dynamic domain manager. However, in more complex network topologies, if the network configuration prevents the master domain manager or the dynamic domain manager from directly communicating with the dynamic agent, for example, if the agents are behind a firewall and need to communicate through the internet, or if they need to communicate with a Network Address Translation (NAT) process, then you can configure your dynamic agents to use a local or remote gateway.

# About this task

You can set up your dynamic agents to use a gateway for communication with the master domain manager or to the dynamic domain manager when you install a dynamic agent, or you can configure a gateway subsequent to the installation.

For information about the gateway parameters available with the installation of a dynamic agent, see the section about agent installation parameters in Planning and Installation Guide.

To configure an existing IBM Workload Scheduler version 9.2 or later dynamic agent to communicate to its master domain manager or dynamic domain manager through a local gateway, perform the following configuration steps:

1. Edit the JobManager.ini file on the dynamic agent workstation that you want to configure to communicate through a gateway. Edit the [ResourceAdvisorAgent] section so that the value of the ResourceAdvisorURL parameter is https://\\(tdbb_server):\\)tdwb_port)/ita/JobManagerGW/JobManagerRESTWeb/JobScheduler/resource, where, \\)tdwb_server) and \(t\text{d} w\text{b\_port}\) correspond to the host name and port of the gateway that you want to use for communication with the master domain manager or the dynamic domain manager.  
2. Stop and start the dynamic agent to implement the changes.

# Results

The master domain manager or dynamic domain manager can now communicate with the dynamic agent workstation through the gateway.

![](images/16eef7114dcd2b7b8f671bee65c989086d2cd065aca0cf52a69033382f0b3ef4.jpg)

Note: If you have more than 100 dynamic agents that communicate through one single gateway to the master domain manager or dynamic domain manager, in the JobManagerGW. ini file on the dynamic agent workstation where the gateway resides, set the ActionPollers parameter as described in Configuring general properties [ITA] on page 74.

# Example

The following diagram depicts a network topology where the master domain manager communicates to the dynamic agents, located behind a firewall, through a gateway configured on one of the dynamic agents.

![](images/64d49bdce7b665a9b0f34e3d67bf02ff9f8b75cf071ec1c4d1277890e945e929.jpg)

The following are the configuration settings used in the network topology depicted in the figure:

Table 54. Configuration settings  

<table><tr><td>Dynamic Agent</td><td>Configur-ation File</td><td>Parameter</td><td>Value</td></tr><tr><td rowspan="3">Dynamic Agent 1 - Local gateway</td><td rowspan="3">JobManage-r.ini</td><td>Section</td><td rowspan="3">https://\\( (tdwb_server) : \)\$ (tdwb_port)/ita/ JobManagerGW/</td></tr><tr><td>[ResourceAdvisorAgent]</td></tr><tr><td>ResourceAdvisorUrl</td></tr></table>

Table 54. Configuration settings (continued)  

<table><tr><td>Dynamic Agent</td><td>Configur-ation File</td><td>Parameter</td><td>Value</td></tr><tr><td></td><td></td><td></td><td>JobManagerRESTWeb/JobScheduler/resource</td></tr><tr><td></td><td></td><td></td><td>where, $(tdwb_server)The host name of the Dynamic Agent 1 workstation. $(tdwb_port)The port number of the Dynamic Agent 1 workstation.</td></tr><tr><td>Dynamic Agent 2 - Remote gateway</td><td>JobManage r.ini</td><td>Section [ResourceAdvisorAgent] ResourceAdvisorUrl</td><td>https:// $(tdwb_server): $(tdwb_port)/ita/JobManagerGW/JobManagerRESTWeb/JobScheduler/resource</td></tr><tr><td></td><td></td><td></td><td>where, $(tdwb_server)The host name of the Dynamic Agent 1 workstation. $(tdwb_port)The port number of the Dynamic Agent 1 workstation.</td></tr><tr><td>Dynamic Agent 3 - Local gateway</td><td>JobManage r.ini</td><td>Section [ResourceAdvisorAgent] ResourceAdvisorUrl</td><td>https:// $(tdwb_server): $(tdwb_port)/ita/JobManagerGW/JobManagerRESTWeb/JobScheduler/resource</td></tr><tr><td></td><td></td><td></td><td>where, $(tdwb_server)The host name of the Dynamic Agent 3 workstation. $(tdwb_port)The port number of the Dynamic Agent 3 workstation.</td></tr></table>

# What to do next

For more information about the parameters in the JobManager.ini and JobManagerGW.ini files, see Configuring the agent on page 71.

To see an example of the installation parameters that must be specified to configure a gateway when installing a dynamic agent, see the section containing example dynamic agent gateway installations in the Planning and Installation Guide.

# Enabling Ports

When you install the master domain manager in a IBM Workload Scheduler network all the incoming and outgoing ports are shown in the figure below:

![](images/3b88654fdd7ef4e296c7985f39156380b238a1a24a3bd8f580bf291956047ee5.jpg)

If you enable the event driven workload automation (EDWA) behind the firewall feature the figure below shows all the incoming and outgoing ports.

![](images/aba65040f011eb860b22f9094ddc547fe3c6670e53db400e9dd0d0ba9d593aa8.jpg)

The following is the complete list of all ports:

# Communication agent - master domain manager

- 31111 - incoming/outcoming Netman port (localhosts)  
- 31115 - HTTP_PORT  
- 31116 - HTTPS Protocol port (localhosts)  
- 31113 - port used to listen for incoming SSL connections. This value must match the one defined in the nm SSL port local option of the workstation  
- 31131 - eventProcessorEIFPort specifies the Job Manager Event Integration Facility (EIF) port number. (optman Is)  
- 31132 - -gweifport gateway_eif_port. Specifies the Job Manager Event Integration Facility (EIF) port number. The default value is 31132. The valid range is 1 to 65535  
- 5529 - EIF Probe server port. Used in event rule management

# dynamic domain manager

- 31114 - dynamic domain manager JobManager port (ssl_port in the ita.ini file)  
- 31117 - dynamic domain manager ResourceAdvisor port (used for JobStatus Update and ResourcesStatus Update)  
- 41114 - BROKER_NETMAN_PORT - The TCP/IP port number used by the netman process to listen to communication from the dynamic domain manager  
- 35116 - CLI connections (localopts)

# Dynamic Workload Console

- 9444 - HTTP_PORT  
- 9443 - HTTPS_PORT  
- 12809 - bootstrap port  
- 19402 - bootstrap security port, to be used for connecting to the Z connector

# event-driven workload automation

- 31131 - HTTP/HTTPS Config Deploy port

# Network operation

The batchman process on each domain manager and fault-tolerant agent workstation operates autonomously, scanning its Symphony file to resolve dependencies and launch jobs. Batchman launches jobs via the jobman process. On a standard agent, the jobman process responds to launch requests from the domain manager's batchman.

The master domain manager is continuously informed of job launches and completions and is responsible for broadcasting the information to domain managers and fault-tolerant agents so they can resolve any inter-workstation dependencies.

The degree of synchronization among the Symphony files depends on the setting of the FullStatus mode in a workstation's definition. Assuming that these modes are turned on, a fault-tolerant agent's Symphony file contains the same information as the master domain manager's (see the section that explains how to manage workstations in the database in the IBM Workload Scheduler: User's Guide and Reference).

![](images/6730e979818daaf0d3c9223b5c690da6428e4dc58f74fb3578b0a438e33ff8de.jpg)  
Figure 7. Symphony file synchronization

# Network processes

Netman is started by the StartUp script (command). The order of process creation is netman, mailman, batchman, and jobman. On standard agent workstations, batchman does not run. All processes, except jobman, run as the TWS user. Jobman runs as root.

When network activity begins, netman receives requests from remote mailman processes. Upon receiving a request, netman creates a writer process and passes the connection off to it. Writer receives the message and passes it to the local mailman. The writer processes (there might be more than one on a domain manager) are started by link requests and are stopped by unlink requests (or when the communicating mailman terminates).

Domain managers, including the master domain manager, can communicate with a large number of agents and subordinate domain managers. For improved efficiency, you can define mailman servers on a domain manager to distribute the communications load (see the section that explains how to manage workstations in the database in the IBM Workload Scheduler: User's Guide and Reference).

Figure 8. Process creation on domain manager and fault-tolerant agent  
![](images/7a47a024369541d5a20deadd2d41601212e07f420284d223a5ae2995be0af88e.jpg)  
The StartUp command is normally run automatically, but can also be run manually, as follows:

# StartUp

Starts netman, the IBM Workload Scheduler network management process.

In Windows™, the netman service is started automatically when a computer is restarted. StartUp can be used to restart the service if it is stopped for any reason.

In UNIX™, the StartUp command can be run automatically by invoking it from the /etc/inittab file, so that WebSphere Application Server Liberty infrastructure and netman is started each time a computer is rebooted. StartUp can be used to restart netman if it is stopped for any reason.

The remainder of the process tree can be restarted with the

```txt
conman start conman startmon
```

commands. See the documentation about conman in the User's Guide and Reference for more information.

![](images/a3b35e1e3fda68d295631326916e13d365f5fcaafe3b7c8e4175aa3c8a2b5d6b.jpg)

Note: If you start the StartUp command using a remote shell, the netman process maintains the shell open without returning the prompt. To avoid this problem, modify the StartUp command so that the netman process is called in the background, as follows:

```batch
Start netman /usr/local/TWS95/mae95/TWS/bin/netman&
```

# Authorization

You must have start access to the workstation.

# Syntax

StartUp [-v | -u]

# Arguments

```txt
-v Displays the command version and exits.   
-u Displays command usage information and exits.
```

# Example

# Examples

To display the command name and version, run the following command:

```txt
StartUp -v
```

To start the netman process, run the following command:

```txt
StartUp
```

# Monitoring the IBM Workload Scheduler processes

You can use event-driven workload automation (EDWA) to monitor the status of network processes and to start a predefined set of actions when one or more specific events take place. For more information about event-driven workload automation, refer to User's Guide and Reference.

You can monitor the following processes:

agent  
- appservman  
- batchman  
jobman  
mailman  
monman  
- netman

The .XML file contains the definition of a sample event rule to monitor the status of the specified processes on the specified workstation. This event rule calls the MessageLogger action provider to write a message in a log file in an internal auditing database. If the condition described in the rule is already existing when you deploy the rule, the related event is not generated. For more information about the MessageLogger action provider, refer to IBM Workload Scheduler User's Guide and Reference:

```xml
<eventRule name  $=$  "PROCESSES" ruleType  $=$  "filter" isDraft  $=$  "no"> <eventCondition name  $\equiv$  "twsProcMonEvt1" eventProvider  $\equiv$  "TWSApplicationMonitor" eventType  $\equiv$  "TWSProcessMonitor"> <scope> AGENT, BATCHMAN DOWN </scope> <filteringPredicate> <attributeFilter name  $\equiv$  "ProcessName" operator  $\equiv$  "eq"> <value>process_name1</value> </attributeFilter> <attributeFilter name  $\equiv$  "TWSPath" operator  $\equiv$  "eq"> <value>TWS_path</value> </attributeFilter> <attributeFilter name  $\equiv$  "Workstation" operator  $\equiv$  "eq"> <value>workstation_name</value> </attributeFilter> <attributeFilter name  $\equiv$  "SampleInterval" operator  $\equiv$  "eq"> <value>sample_interval</value> </attributeFilter> </filteringPredicate> </eventCondition> <action actionProvider  $\equiv$  "MessageLogger" actionType  $\equiv$  "MSGLOG" responseType  $\equiv$  "onDetection"> <scope> OBJECT=AAAAAAAMESSAGE  $\equiv$  TWS PROCESS DOWN: %{TWSPROCONEVT1.PROCESSNAME}   
ON \%{TWSPROCONEVT1.TWSPATH} </scope> <parameter name  $\equiv$  "ObjectKey"> <value>object_key</value> </parameter> <parameter name  $\equiv$  "Severity"> <value>message_severity</value> </parameter> <parameter name  $\equiv$  "Message"> <value>log_message</value> </parameter> </action> </eventRule> </eventRuleSet>
```

where:

Is the name of the process to be monitored. You can insert more that one process name, as follows:

process_name  
TWS_path  
workstation_name  
sample_interval  
object_key  
message_severity  
log_message  
```txt
<attributeFilter name="ProcessName" operator="eq"> <value>agent</value> <value>batchman</value> </attributeFilter>
```

Is the directory containing the Symphony file and the bin directory.

Is the workstation on which the event is generated.

Is the interval, expressed in seconds, for monitoring the process status.

Is a key identifying the object to which the message pertains.

Is the severity of the message.

Is the message to be logged.

# Optimizing the network

The structure of a IBM Workload Scheduler network goes hand in hand with the structure of your enterprise's network. The structure of the domains must reflect the topology of the network in order to best use the available communication channels.

But when planning the IBM Workload Scheduler network, the following must be taken into consideration:

Data volumes  
Connectivity

# Data volumes

Network capacity must be planned to adapt to the amount of data that is circulating. Particularly high transmission volumes might be caused by the following:

- Transfer of large Symphony files.  
- Message traffic between the master domain manager and a FullStatus agent.  
- Message traffic from a domain manager when the domain has many agents.  
- Heavy use of internetwork dependencies, which extends traffic to the entire network.

# Connectivity

For the more critical agents in your network, you need to consider their position in the network. The reliability of workload execution on a particular agent depends on its capacity to receive a fresh Symphony file at the start of the production period. If the workload contains many dependencies, a reliable connection to the rest of the network is also required. These factors suggest that the best place for critical agents is in the master domain, or to be set up as domain managers immediately under the master domain manager, possibly receiving their Symphony files through a set of dedicated mailman servers. Further, it is important for critical agents that any domain manager above them in the tree structure must be hosted on powerful systems and must have an adequate backup system to ensure continuity of operation in the event of problems.

IBM Workload Scheduler provides two mechanisms to accommodate a particular network situation: the domain structure and mailman servers. Whereas domain structure establishes a hierarchy among IBM Workload Scheduler agents, mailman servers are used to tune the resources dedicated to the connection between two agents.

# Domain

Use the IBM Workload Scheduler domain structure mechanism to create a tree-shaped structure for the network, where all communications between two points use the unique path defined by the tree (climb to the common ancestor and go down to the target, as opposed to direct TCP communication). As a consequence, the domain structure separates the network into more-manageable pieces. This is for easier filtering, overview, action, and monitoring. However, it does also introduce some delay in the workload processing. For instance when distributing the Symphony file, a fault-tolerant agent inside a domain needs to wait for two steps of Symphony distribution to be completed (from master domain manager to domain manager and from domain manager to fault-tolerant agent). The same is valid for every other type of communication that comes from the master domain manager.

This has the following implications:

Critical business activities must be as close as possible to the master domain manager  
- The domain manager must be installed on as powerful a workstation as possible  
- A similarly powerful backup domain manager must be included in the network  
- The network link between the domain manager and its backup must be as fast as possible to pass all the updates received from the subtree  
- If intervention is needed directly on the domain, either give shell access to the operators to use the IBM Workload Scheduler command line, or install a connector so that the Dynamic Workload Console can be used.

# Mailman servers

Mailman servers allocate separate processes dedicated to the communication with other workstations. The main mailman is dedicated to the transfer and network hub activities. The use of mailman servers on the domain manager must be carefully planned. The main parameter is the number of downstream connections at each level of the tree. This number describes the number of mailman servers that a main mailman is connected to, or the number of agents a mailman server is connected to. The maximum number of downstream connections is about 50 for Windows™ and about 100 for other UNIX™ workstations, depending on their power.

Typical downstream connections is about 15 for Windows™ and about 20 for other UNIX™ workstations.

However, you must also take into consideration the link speed and the queue sizes, discussed below.

# Planning space for queues

In order to plan space for event queues, and possible alert levels and reactions, it is necessary to model the flows passing through the agents, and the domain managers in particular.

![](images/707c0228fe17b58a9f32047d56a294dce79caf775782941ee495cf7a3b6c9ff1.jpg)  
Figure 9. Typical IBM Workload Scheduler network flows.

For a typical domain manager, the main flow comes from update activity reported by the sub tree, and from ad hoc submissions arriving from the master domain manager and propagating to the entire network. Under these conditions, the most critical errors are listed by order of importance in Table 55: Critical flow errors on page 291:

Table 55. Critical flow errors  

<table><tr><td>Flow no.</td><td>Location</td><td>Queue</td><td>Risk</td><td>Impact</td></tr><tr><td>1</td><td>Upper domain manager</td><td>dm.msg</td><td>The queue fills up because of too many unlinked workstations in the domain or a downstream domain manager has failed.</td><td>The upper domain manager fails and propagates the error.</td></tr><tr><td>2</td><td>Domain manager</td><td>FullStatus fta.msg</td><td>The queue fills because of too many unlinked workstations in the domain or because the FullStatus fault-tolerant agent is not coping with the flow.</td><td>The domain manager fails and favors the occurrence of #1.</td></tr><tr><td>3</td><td>Domain manager and FullStatus fault-tolerant agent</td><td>Mailbox.msg or Intercom.msg</td><td>The queue fills because the FullStatus fault-tolerant agent cannot cope with flow.</td><td>The FullStatus fault-tolerant agent fails and favors the occurrence of #2.</td></tr></table>

Table 55. Critical flow errors (continued)  

<table><tr><td>Flow no.</td><td>Location</td><td>Queue</td><td>Risk</td><td>Impact</td></tr><tr><td>4</td><td>Domain manager</td><td>tomaster.msg</td><td>The queue fills because of too many unlinked workstations in the domain.</td><td>The domain manager starts to unlink the subtree and accumulates messages in the structure.</td></tr><tr><td>5</td><td>Fault-tolerant agents - only when enSwfaultTol global option is set to yes</td><td>deadletter.msg</td><td>The queue fills because of too many unlinked workstations in the domain.</td><td>The agent stops.</td></tr><tr><td>6</td><td>Fault-tolerant agents - only when enSwfaultTol global option is set to yes</td><td>ftbox.msg</td><td>This queue is circular. The rate of messages entering the queue exceeds the rate of messages being processed, because of too many unlinked workstations in the domain.</td><td>Events are lost.</td></tr></table>

![](images/134529aa4f2127674880d32269d319017996b3cc8fdef9d8b5eff72d6ec0c13e.jpg)

# Note:

1. Flows are greater at the master domain manager and at any FullStatus fault-tolerant agents in the master domain than at subordinate domain managers or FullStatus fault-tolerant agents.  
2. Use evtsize -show to monitor queue sizes.  
3. The amount of update flow is related to the amount of workload running in a particular subtree and is unavoidable.  
4. The amount of ad hoc flow is related to the amount of additional workload on any point of the network. It can be reduced by planning more workload even if it is inactive. Note that simple reruns (not rerun from) do not create an ad hoc flow.

The planning, alert, and recovery strategy must take into account the following points:

- Queue files are created with a fixed size and messages are added and removed in a cyclical fashion. A queue reaches capacity when the flow of incoming messages exceeds the outgoing flow for a sufficient length of time to use up the available space. For example, if messages are being added to a queue at a rate of 1MB per time unit and are being processed and removed at a rate of 0.5 MB per time unit, a queue sized at 10 MB (the default) is at capacity after 20 time units. But if the inward flow rate descends to be the same as the outward flow rate after 19 time units, the queue does not reach capacity.  
- The risk of the domain manager failing can be mitigated by switching to the backup domain manager. In this case, the contents of the queues on the domain manager are unavailable until the domain manager backup is started. In

all cases, the size of the queue on the upper domain manager towards any other domain manager must respect the condition A, as indicated in the table Table 56: Queue sizing conditions. on page 293.

- The risk that fault-switching fault-tolerant agents might not be able to cope with the flow must be planned beforehand. The specifications for fault-switching fault-tolerant agents must be similar to those of the domain manager, to avoid that an agent receives a load that is not appropriate to its capacity. Check if a queue is forming at the FullStatus fault-tolerant agents, both in ordinary and peak operation situations.  
- Once risk #2 has been dealt with, the possibility of a network link failure can be mitigated by sizing the queue from a domain manager to the FullStatus fault-tolerant agents appropriately as a function of the average network outage duration, and by increasing the size of the mailbox in case of unexpected long outage (see condition B of Table 56: Queue sizing conditions. on page 293).  
- The same condition applies for avoiding an overflow of the domain manager's tomaster.msg queue with respect to network outages (see condition C) of Table 56: Queue sizing conditions. on page 293.

Table 56. Queue sizing conditions.  

<table><tr><td>A</td><td>MaxAlertTime &lt;= size(UpperDM#queueToDM) / averageAdhocFlow</td></tr><tr><td>B</td><td>MaxNetOutage &lt;= size(DM#queueToFSFTA) / (averageAdhocFlow + averageUpdateFlow)</td></tr><tr><td>C</td><td>MaxNetOutage &lt;= size(DM#queueToUpperDM) / (averageUpdateFlow)</td></tr></table>

# Monitoring the IBM Workload Scheduler message queues

You can use event-driven workload automation (EDWA) to monitor the size of message queues and to start a predefined set of actions when one or more specific events take place. For more information about event-driven workload automation, refer to IBM Workload Scheduler: User's Guide and Reference.

You can monitor the following message queues:

- appserverbox  
- mailbox  
- clbox  
intercom  
courier  
- monbox  
moncmd  
- server  
- tomaster  
pobox  
planbox

The following .XML file contains the definition of a sample event rule to monitor the mailbox queue on the specified workstation and send an email when the filling percentage is greater than the specified value. If the condition described in the rule is already existing when you deploy the rule, the related event is not generated. This event rule calls the MailSender

action provider to send an email to the receivers you specify. For more information about the MailSender action provider, refer to IBM Workload Scheduler: User's Guide and Reference:

```xml
<?xml version="1.0"?>
<eventRuleSet xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
		\xmns="http://www.ibm.com/xmnlns/prod/tws/1.0/event-management/rules"
		xsi:schemaLocation="http://www.ibm.com/xmnlns/prod/tws/1.0/event-management/rules"
		http://www.ibm.com/xmnlns/prod/tws/1.0/event-management/rules/EventRules.xsd">
    <eventRule name="MONITORQUEUE" ruleType="filter" isDraft="no">
        <eventCondition name="twsMesQueEvt1" eventProvider="TWSApplicationMonitor" eventType="TWSMessageQueues">
            <scope>
                MAILBOX FILLED UP 80% ON FTA
            </scope>
            <filteringPredicate>
                <attributeFilter name="MailboxName" operator="eq">
                    <value>mailbox_name</value>
                    </attributeFilter>
                    <attributeFilter name="FillingPercentage" operator="ge">
                        <value>filling_percentage</value>
                        </attributeFilter>
                        <attributeFilter name="Workstation" operator="eq">
                            <value>workstation_name</value>
                            </attributeFilter>
                            <attributeFilter name="SampleInterval" operator="eq">
                            <value>sample_interval</value>
                            </attributeFilter>
                            </filteringPredicate>
        </eventCondition>
        <action actionProvider="MailSender" actionType="SendMail" responseType="onDetection">
            <scope>
                TWSUSER@TWS : THE MAILBOX ON workstation_name...
            </scope>
            <parameter name="To">
                <value>main_receiver_list</value>
            </parameter>
            <parameter name="Subject">
                <value>mailsubject</value>
            </parameter>
            </action>
        </eventRule>
        </eventRuleSet>
```

where:

newsletter_name

Is the name of the mailbox to monitor.

filling percentage

Is the filling percentage. Supported operators are as follows:

ge

causes the event generation when the mailbox filling percentage increases over the threshold value. The event is generated only the first time the specified mailbox filling percentage is reached. If you restart the SSM agent and the filling percentage is higher than the threshold value,

the event is generated again. Table 57: Example for the ge operator on page 295 provides an example in which the ge operator is set to  $70\%$ .

Table 57. Example for the ge operator  

<table><tr><td>Ma</td><td></td><td></td></tr><tr><td>il</td><td></td><td></td></tr><tr><td>box</td><td></td><td>A</td></tr><tr><td>n</td><td></td><td>ct</td></tr><tr><td>ame</td><td>Filling percentage</td><td>ion</td></tr><tr><td>Sa &gt;= 70%</td><td></td><td>ev</td></tr><tr><td>m</td><td></td><td>ent</td></tr><tr><td>ple</td><td></td><td>not</td></tr><tr><td>(0)</td><td></td><td>ge</td></tr><tr><td></td><td></td><td>ne</td></tr><tr><td></td><td></td><td>ra</td></tr><tr><td></td><td></td><td>ted</td></tr><tr><td>Sa &lt; 70%</td><td></td><td>ev</td></tr><tr><td>m</td><td></td><td>ent</td></tr><tr><td>ple</td><td></td><td>not</td></tr><tr><td>(0)</td><td></td><td>ge</td></tr><tr><td></td><td></td><td>ne</td></tr><tr><td></td><td></td><td>ra</td></tr><tr><td></td><td></td><td>ted</td></tr><tr><td>Sa &lt; 70%</td><td></td><td>ev</td></tr><tr><td>m</td><td></td><td>ent</td></tr><tr><td>ple</td><td></td><td>not</td></tr><tr><td>(n</td><td></td><td>ge</td></tr><tr><td>-1)</td><td></td><td>ne</td></tr><tr><td></td><td></td><td>ra</td></tr><tr><td></td><td></td><td>ted</td></tr><tr><td>Sa &gt;= 70%</td><td></td><td>ev</td></tr><tr><td>m</td><td></td><td>ent</td></tr><tr><td>ple</td><td></td><td></td></tr><tr><td>(n)</td><td></td><td>ge</td></tr><tr><td></td><td></td><td>ne</td></tr><tr><td></td><td></td><td>ra</td></tr><tr><td></td><td></td><td>ted</td></tr><tr><td>Sa &gt;= 70%</td><td></td><td>ev</td></tr><tr><td>m</td><td></td><td>ent</td></tr><tr><td>ple</td><td></td><td></td></tr></table>

Table 57. Example for the ge operator (continued)  

<table><tr><td>Ma
il</td><td></td></tr><tr><td>box</td><td>A</td></tr><tr><td>n</td><td>ct</td></tr><tr><td>ame</td><td>Filling percentage</td></tr><tr><td>(n</td><td>ge</td></tr><tr><td>+1)</td><td>ne</td></tr><tr><td></td><td>ra</td></tr><tr><td></td><td>ted</td></tr></table>

# le

causes the event generation when the mailbox filling percentage decreases under the threshold value. The event is generated only the first time the specified mailbox filling percentage is reached. If you restart the SSM agent and the filling percentage is lower than the threshold value, the event is not generated until the filling percentage increases over the threshold value and then decreases under it again. Table 58: Example for the le operator on page 296 provides an example in which the le operator is set to  $50\%$ :

Table 58. Example for the le operator  

<table><tr><td>Ma</td><td></td></tr><tr><td>il</td><td></td></tr><tr><td>box</td><td></td></tr><tr><td>n</td><td></td></tr><tr><td>ame</td><td>Filling percentage</td></tr><tr><td>Sa &lt;= 50%</td><td>ev</td></tr><tr><td>m</td><td>ent</td></tr><tr><td>ple</td><td>not</td></tr><tr><td>(0)</td><td>ge</td></tr><tr><td></td><td>ne</td></tr><tr><td></td><td>ra</td></tr><tr><td></td><td>ted</td></tr><tr><td>Sa &gt; 50%</td><td>ev</td></tr><tr><td>m</td><td>ent</td></tr><tr><td>ple</td><td>not</td></tr><tr><td>(0)</td><td>ge</td></tr><tr><td></td><td>ne</td></tr><tr><td></td><td>ra</td></tr><tr><td></td><td>ted</td></tr></table>

Table 58. Example for the le operator (continued)  

<table><tr><td>Ma
il</td><td></td></tr><tr><td>box</td><td>A</td></tr><tr><td>n</td><td>ct</td></tr><tr><td>ame</td><td>Filling percentage</td></tr><tr><td>Sa &gt;50%</td><td>ev</td></tr><tr><td>m</td><td>ent</td></tr><tr><td>ple</td><td>not</td></tr><tr><td>(n</td><td>ge</td></tr><tr><td>-1)</td><td>ne</td></tr><tr><td></td><td>ra</td></tr><tr><td></td><td>ted</td></tr><tr><td>Sa &lt;= 50%</td><td>ev</td></tr><tr><td>m</td><td>ent</td></tr><tr><td>ple</td><td></td></tr><tr><td>(n)</td><td>ge</td></tr><tr><td></td><td>ne</td></tr><tr><td></td><td>ra</td></tr><tr><td></td><td>ted</td></tr><tr><td>Sa &lt;= 50%</td><td>ev</td></tr><tr><td>m</td><td>ent</td></tr><tr><td>ple</td><td>not</td></tr><tr><td>(n</td><td>ge</td></tr><tr><td>+1)</td><td>ne</td></tr><tr><td></td><td>ra</td></tr><tr><td></td><td>ted</td></tr></table>

# workstation_name

Is the workstation on which the event is generated.

# sample_interval

Is the interval, expressed in seconds, for monitoring the mailbox filling percentage.

# main Receiver_list

Is the main receiver list.

# mailsubject

Is the subject of the mail.

# Changing a queue size

Use the evtsize command to resize a queue.

When you have used evtsize to resize a queue, the queue remain at that size until the next time you use evtsize. It only reverts to the default size of 60 MB if you delete it, at which point IBM Workload Scheduler re-creates it with the default size.

# evtsize

Defines the size of the IBM Workload Scheduler message files. This command is used by the IBM Workload Scheduler administrator either to increase the size of a message file after receiving the message, "End of file on events file.", or to monitor the size of the queue of messages contained in the message file.

# Authorization

You must be maestro or root in UNIX™, or Administrator in Windows™ to run evtsize. Stop the IBM Workload Scheduler engine before running this command.

# Syntax

evtsize -V | -U

evtsize file_name size

evtsize -compact file_name [size]

evtsize -show file_name

# Arguments

-V

Displays the command version and exits.

-U

Displays command usage information and exits.

-compact file_name [size]

Reduces the size of the specified message file to the size occupied by the messages present at the time you run the command. You can optionally use this keyword to also specify a new file size.

-show file_name

Displays the size of the queue of messages contained in the message file

file_name

The name of the event file. Specify one of the following:

Courier.msg

Intercom.msg

Mailbox.msg

PlanBox.msg

Server.msg

pobox/workstation.msg

# size

The maximum size of the event file in bytes. When first built by IBM Workload Scheduler, the maximum size is set to 10 MB.

![](images/5ea416efc1ae51c90377145e613d93f51a782b326d530655ab458305aff05905.jpg)

Note: The size of the message file is equal to or bigger than the real size of the queue of messages it contains and it progressively increases until the queue of messages becomes empty; as this occurs the message file is emptied.

# Example

# Examples

To set the maximum size of the Intercom.msg file to 20 MB, run the following command:

```batch
evtsize Intercom.msg 200000000
```

To set the maximum size of the pobox file for workstation chigco to 15 MB, run the following command:

```batch
evtsize pobox\chicago.msg 15000000
```

The following command:

```txt
evsize -show Intercom.msg
```

returns the following output:

```txt
IBM Workload Scheduler (UNIX)/EVTSIZE 9.4 (1.2.2.4) Licensed Materials - Licensed Materials - Property of IBM* and HCL** 5698-WSH  
(C) Copyright IBM Corp. 1998, 2016 All rights reserved.  
(C) Copyright HCL Technologies Ltd. 2016, 2024 All rights reserved  
*Trademark of International Business Machines  
**Trademark of HCL Technologies Limited  
AWSDEK703I Queue size current 240, maximum 10000000 bytes (read 48, write 288)
```

where:

# 880

Is the size of the current queue of the Intercom.msg file

# 1000000

Is the maximum size of the Intercom.msg file

# read 48

Is the pointer position to read records

# write 928

Is the pointer position to write records

# Tuning mailman servers

Once the distribution of agents to mailman servers has been established, all the groups of agents attached to the same server must respect the link condition.

The link condition relates the number of agents connected to a mailman process and the tuning parameters for unlink on the mailman and writer side.

# No_agenti)

The number of agents connected to a given mailman server  $i$

# Mm_unlink

A parameter set in the localopts of both domain manager and agent. Specifies the maximum number of seconds mailman waits before unlinking from a workstation that is not responding.

# Wr_unlink

A parameter set in the localopts of both domain manager and agent. Specifies the number of seconds the writer process waits before exiting if no incoming messages are received.

# Max_down Agents

The maximum probable number of agents that are unavailable without having the ignore flag set in the database and having the autolink flag on.

# tcp timeout

A parameter set in the localopts of both domain manager and agent. Specify the maximum number of seconds that can be waited for the completion of a TCP/IP request on a connected workstation that is not responding.

The condition is:

```txt
Wr_unlink = Mm_unlink > 1.2 * Max_down Agents * tcp timeout
```

This condition expresses that if the time before unlink is smaller than the probable time of idle waiting of the mailman process (waiting connect timeout for each agent that is currently down) in its loop to reactivate the connections, the agents unlink constantly when some agents are down.

# Netman configuration file

The netman configuration file exists on all IBM Workload Scheduler workstations to define the services provided by netman. It is called <TWA_home>/TWS/network/Netconf. The NetConf file includes comments describing each service. The services are:

2001

Start a writer process to handle incoming messages from a remote mailman.

2002

Start the mailman process. Mailman, in turn, starts the rest of the process tree (batchman, jobman).

2003

Stop the IBM Workload Scheduler process to handle incoming messages from a remote mailman.

2004

Find and return a stdlist file to the requesting Conman process.

2005

Switch the domain manager in a domain.

2006

Locally download scripts scheduled by an IBM Z Workload Scheduler master domain manager.

2007

Required to bypass a firewall.

2008

Stop IBM Workload Scheduler workstations in a hierarchical fashion

2009

Runs the switchmgr script to stop and restart a manager in such a way that it does not open any links to other workstations until it receives the switchmgr event. Can only be used when the enSwfaultTol global option is set to yes.

2010

Starts mailman with the parameter demgr. It is used by the service 2009. Can only be used when the enSwfaultTol global option is set to yes.

2011

Runs monman as a child process (son bin/monman.exe)

2012

Runs conman to stop the event monitoring engine (command bin/conman.exe stopmon).

2013

Runs conman to switch event processors (command bin/conman.exe switchevtproc -this)

2014

Runs conman to start event processing (command bin/conman.exe startevtproc -this)

2015

Runs conman to stop event processing (command bin/conman.exe stopevtproc -this)

2016

Runs conman to force the update of the monitoring configuration file for the event monitoring engine (command bin/conman.exe deployconf)

2017

Runs conman to stop event processing on a client (client bin/conman.exe synchronizedcmd -stopevtproc)

2018

Runs conman to check event processing on a client (client bin/conman.exe synchronizedcmd -checkevtproc)

2021

Runs conman to start appservman

2022

Runs conman to run the subcommand stopappserver that stops the application server

2023

Runs conman to run the subcommand startappserver that starts the application server

2501

Check the status of a remote job.

2502

Start the Console Manager - a service requested by the client side of the Remote Console. See the IBM®

Tivoli® Remote Control: User's Guide for more information.

2503

Used by the connector to interact with r3batch extended agent.

# Determining internal Symphony table size

The mailman service (2002) can optionally take a parameter that determines the initial size of the internal Symphony table. If you do not supply this parameter, mailman calculates the initial table size based on the number of records in the file.

![](images/54967a5735b0d7514d654d158227edf632ea9473ce293dc511119795d4c750cf.jpg)

Note: Mailman expands the table if it needs to, even if this parameter is not supplied.

In normal circumstances, leave mailman to take the default value in the NetConf file as supplied (32000). However, if you are experiencing problems with memory, you can allocate a table that is initially smaller. To do this you change the parameter to the service 2002 in the NetConf file. The syntax for the entry is:

```txt
2002 son bin/emailman [-perm number]
```

where, number is used to calculate the initial Symphony table size based on the number of records in the Symphony file.

If  $r$  is the number of records in the Symphony file when batchman starts, Table 59: Calculation of internal Symphony table on page 303 shows how the size of the internal Symphony table is calculated, depending on the value of number.

Table 59. Calculation of internal Symphony table  

<table><tr><td>Value of number</td><td>Table size</td></tr><tr><td>0</td><td>(4/3r) + 512</td></tr><tr><td rowspan="2">n</td><td>if n &gt; r, n</td></tr><tr><td>if n &lt;= r, (4/3r) + 512</td></tr><tr><td>-1</td><td>65535</td></tr><tr><td rowspan="2">-n</td><td>if +n =&gt; r, n</td></tr><tr><td>if +n &lt; r, r + 512</td></tr></table>

If during the production period you add more jobs, the maximum internal Symphony table size is increased dynamically, up to the maximum number of records allowed in the Symphony file, which is 2,000,000,000.

# Defining access methods for agents

Access methods are used to extend the job scheduling functions of IBM Workload Scheduler to other systems and applications. They run on:

# Extended agents (applies only to IBM Workload Scheduler)

They are logical workstations related to an access method hosted by a physical IBM Workload Scheduler workstation (not another extended agent). More than one extended agent workstation can be hosted by the same IBM Workload Scheduler workstation and use the same access method. The extended agent runs on fault-tolerant agents defined using a standard IBM Workload Scheduler workstation definition, which gives the extended agent a name and identifies the access method. The access method is a program that is run by the hosting workstation whenever IBM Workload Scheduler submits a job to an external system.

Jobs are defined for an extended agent in the same manner as for other IBM Workload Scheduler workstations, except that job attributes are dictated by the external system or application.

Information about job running execution is sent to IBM Workload Scheduler from an extended agent using the job stdlist file. A method options file can specify alternate logins to launch jobs and check opens file dependencies. For more information, see the User's Guide and Reference.

A physical workstation can host a maximum of 255 extended agents.

# dynamic agents and IBM Z Workload Scheduler agents (z-centric)

They communicate with external systems to start the job and return the status of the job. To run access methods on external applications using dynamic agents, you define a job of type access method.

Access methods are available on the following systems and applications.

SAP  
- z/OS  
- Custom methods  
- UNIXssh  
- UNIXRsh

The UNIX™ access methods included with IBM Workload Scheduler, are described in the related section in Administration Guide.

If you are working with dynamic agents, for information about defining IBM Workload Scheduler workstations, see the section that explains how to define workstations in the database in User's Guide and Reference. For information about writing access methods, see the section about the access method interface in User's Guide and Reference.

More information about access methods is found in Scheduling Job Integrations with IBM Workload Automation.

# UNIX™ access methods

IBM Workload Scheduler includes two types of UNIX™ access methods, local UNIX access methods and remote UNIX access methods.

The Local UNIX™ access method runs on extended agents. Use the Local UNIX™ access method to enable a single UNIX™ workstation to operate as two IBM Workload Scheduler workstations, both of which you can run IBM Workload Scheduler scheduled jobs.

The Remote UNIX™ access method runs on extended agents and dynamic agents.

# On extended agents

Use the Remote UNIX™ access method to designate a remote UNIX™ workstation to run IBM Workload Scheduler scheduled jobs without having IBM Workload Scheduler installed on it.

# On dynamic agents

Define a job of type xajob that runs on dynamic agents. The dynamic agent communicates with the external system to start the job and return the status of the job.

# Local UNIX™ access method running on fault-tolerant agents only

The Local UNIX™ method can be used to define multiple IBM Workload Scheduler workstations on one workstation: the host workstation and one or more extended agents. When IBM Workload Scheduler sends a job to a local UNIX™ extended agent, the access method, unixlocl, is invoked by the host to run the job. The method starts by running the standard configuration script on the host workstation (<TWA_home>/TWS/jobmanrc). If the logon user of the job is permitted to use a local configuration script and the script exists as $HOME/TWS/.jobmanrc, the local configuration script is also run. The job itself is then run either by the standard or the local configuration script. If neither configuration script exists, the method starts the job.

The launching of the configuration scripts, jobmanrc and .jobmanrc is configurable in the method script. The method runs the configuration scripts by default, if they exist. To disable this feature, you must comment out a set of lines in the method script. For more information, examine the script file <TWA_home>/TWS/methods/unixloc1 on the extended agent's host.

# Remote UNIX™ access method

The Remote UNIX™ access method can be used to designate a non-IBM Workload Scheduler workstation to run jobs scheduled by IBM Workload Scheduler. You can use `unixrsh` or `unixssh':

# The unixrsh access method

When IBM Workload Scheduler sends a job to a remote UNIX™ extended agent, the access method, unixrsh, creates a /tmp/maestro directory on the non-IBM Workload Scheduler workstation. It then transfers a wrapper script to the directory and runs it. The wrapper then runs the scheduled job. The wrapper is created only once, unless it is deleted, moved, or is outdated.

To run jobs using the `unixrsh` access method, the job logon users must be given appropriate access on the non-IBM Workload Scheduler UNIX™ workstation. To give appropriate access, a `rhost`, /etc/host.equiv, or equivalent file must be set up on the workstation. On extended agents, if `opens` file dependencies are to be checked, `root` access must also be permitted. Contact your system administrator for help. For more information about the access method, examine the script file TWA_home/TWS/methods/unixrsh on an extended agent's host.

# The UNIXsh access method

The unixssh access method works like unixrsh but uses a secure remote shell to connect to the remote host.

The files used by this method are:

methods/unixssh

methods/unixssh.wrp

The `unixssh` method uses the `ssh` key. You can generate this keyword with any tools that are compatible with the secure remote shell.

![](images/9f80d20056b3a4a02e0b49daaf6a2c8d5a1c56664e9ab5718c748bf360681235.jpg)

Note: The passphrase must be blank.

The following scenario gives an example of how to set up the method:

You installed a IBM Workload Scheduler, fault-tolerant agent or dynamic agent with the TWS_user.twsuser. You want to run a remote shell in the remote host "REMOTE_HOST" with the user "guest". The procedure is as follows:

1. Create the public and private key for the usertwsuser, The following is an example using rsa:

a. Log on as twsuser  
b. Run

```txt
ssh-keygen -t rsa
```

c. When the tool asks for the passphrase, press Enter (leaving the passphrase blank.) The keys are saved as follows:

# Key

# Location

# Comment

Public TWA_home/TWS/.ssh/id_rsa.pub

Private TWA_home/TWS/.ssh/id_rsa Do not send this file!

![](images/6b083e86113cd1f5a2ae3fd91575a1c5d3a671892a41bd17057d478681fd0d91.jpg)

Note: Different tools store the key in different places.

2. At the remote host, perform the following actions:

a. Telnet to the remote host.  
b. Log on as "guest".  
c. Change to the .ssh directory in the user home directory, or create it if it does not exist (the directory permissions must be adequate: for example, 700 for the directory and 600 for its contents).  
d. Append the public key you created in step 1 to the authorized_keys file (create the file if it does not exist), using the command:

```txt
cat id_rsa.pub >> authorized_keys
```

3. At the fault-tolerant agent or dynamic agent, make the remote host "known" before attempting to let IBM Workload Scheduler processes use the connection. This action can be achieved in one of two ways:

- Log on as twsuser and connect to the host using the command:

```txt
ssh -l guest remote_host_name ls
```

A prompt is displayed saying that the host is not known, and asking permission to access it. Give permission, and the host is added to the list of known hosts.

- Alternatively, use the ssh documentation to add the remote host to the file of known hosts.

# Managing production for extended agents

In general, jobs that run on extended agents behave like other IBM Workload Scheduler jobs. IBM Workload Scheduler tracks a job's status and records output in the job's stdlist files. These files are stored on the extended agent's host workstation. For more information on managing jobs, see the section that describes IBM Workload Scheduler plan tasks in the IBM Workload Scheduler: User's Guide and Reference.

# Failure launching jobs on extended agents and dynamic agents

If the access method is not in the proper directory on the extended agent's host, on the dynamic agent, or the method cannot be accessed by IBM Workload Scheduler, jobs fail to launch or a file dependency is not checked. For a job, the IBM Workload Scheduler jobs logon or the logon specified in the method options file must have read and execute permissions for the access method. When checking a file to satisfy an opens dependency, root is used as the login unless another login is specified in the method options file. For more information about method options, see the IBM Workload Scheduler: User's Guide and Reference.

# IP address validation

When a TCP/IP connection is established, netman reads the requester's node name and IP address from the socket. The IP address and node name are used to search the Symphony file for a known IBM Workload Scheduler workstation with one of the following possible results:

- If an IP address match is found the validation is considered successful.  
- If a node name match is found, the validation is considered successful.  
- If no match is found in the Symphony file or the IP address returned does not match the one read from the socket, the validation is considered unsuccessful.

The local option, nm ipvalidate, determines the action to be taken if IP validation is unsuccessful. If the option is set to full, unsuccessful validation causes IBM Workload Scheduler to close the connection and generate an error message. If the option is set to none (default), IBM Workload Scheduler permits all connections, but generates a warning message for unsuccessful validation checks.

# Support for Internet Protocol version 6

IBM Workload Scheduler supports Internet Protocol version 6 (IPv6) in addition to the legacy IPv4. To assist customers in staging the transition from an IPv4 environment to a complete IPv6 environment, IBM Workload Scheduler provides IP dualstack support. In other terms, the product is designed to communicate using both IPv4 and IPv6 protocols simultaneously with other applications using IPv4 or IPv6.

To this end, the IPv4-specific gethostbyname and gethostbyaddr functions have been replaced by the new getaddrinfo API that makes the client-server mechanism entirely protocol independent.

The getaddrinfo function handles both name-to-address and service-to-port translation, and returns sockaddr structures instead of a list of addresses These sockaddr structures can then be used by the socket functions directly. In this way,

getaddrinfo hides all the protocol dependencies in the library function, which is where they belong. The application deals only with the socket address structures that are filled in by getaddrinfo.

# Operating system configuration (UNIX™ only)

IP validation depends on the system call getaddrinfo() to look up all the valid addresses for a host. The behavior of this routine varies, depending on the system configuration. When getaddrinfo() uses the file /etc/hosts, it returns the first matching entry. If the connection is initiated on an address which appears after the first matching entry, IP validation fails. To resolve the problem, place the entry used to initiate the connection before any other matching entries in the /etc/hosts file. If getaddrinfo() uses the "named" name server or the Network Information Service server and getaddrinfo() fails, contact your system administrator for assistance.

# IP address validation messages

Following is a list of the messages for IP validation. If the Local Option nm ipvalidate is set to none (default), the errors appear as warnings.

See the end of the list of conditions for the key to the variables:

- IBM Workload Scheduler workstation name is not found in the Symphony file

```txt
Ip address validation failed for request:
Service <num> for <program> on <workstation>(<operating_system_type>). Connection received from IP address:
<c_ipaddr>. MAESTRO CPU <workstation> not found in Symphony file.
```

- Call to getaddrinfo() fails:

```txt
IP address validation failed for request: Service num for <program> on cpu(<operating_system_type>). Connection received from IP address: <c_ipaddr>. getaddrinfo() failed, unable to retrieve IP address of connecting node: <node>.
```

- IP Addresses returned by getaddrinfo() do not match the IP address of connection workstation:

```txt
IP address validation failed for request: Service <num> for <program> on <workstation>(<operating_system_type>). Connection received from IP address: <c_ipaddr>. System known IP addresses for node name node: <k_ipaddr>.
```

- The IP address specified in the workstation definition for the IBM Workload Scheduler workstation indicated in the service request packet does not match the IP address of connecting workstation:

```txt
IP address validation failed for request: Service <num> for <program> on <workstation>(<operating_system_type>). Connection received from IP address: <c_ipaddr>. TWS known IP addresses for cpu <k_ipaddr>.
```

- Regardless of the state of nm ipvalidate, the following information message is displayed when IP validation cannot be performed because the Symphony file does not exist or an error occurs when reading it:

```txt
IP address validation not performed for request: Service <num> for <program> on <workstation>(<operating_system_type>). Connection received from IP address: <c_ipaddr>. Cannot open or read Symphony file. Service request accepted.
```

Where:

```txt
<num> Service number (2001-writer, 2002-mailman...)   
<program> Program requesting service   
<workstation> IBM Workload Scheduler workstation name of connecting workstation   
<operating_system_type> Operating system of connecting workstation   
<node> Node name or IP address of connecting workstation   
<c_ipaddr> IP address of connecting workstation   
<k_ipaddr> Known IP address for connecting workstation
```

IP validation is always successful in the absence of a Symphony file. In communications from a domain manager to an agent it is normally successful because a Symphony file does not yet exist. However, if the agent has a Symphony file from a previous run, the initial link request might fail if the Symphony file does not include the name of the domain manager.

# Impact of network changes

Any changes that you make to your network might have an impact on IBM Workload Scheduler. Workstations can be identified within IBM Workload Scheduler by host name or IP address. Any changes to host names or IP addresses of

specific workstations must obviously be also implemented in the IBM Workload Scheduler database. However, remember that if those workstations are involved in jobs that are currently scheduled in the Symphony file, those jobs are looking for the old workstation identity.

Changes to host names or IP addresses of specific workstations can be activated immediately by running JnextPlan -for 0000. A new production plan is created (containing the updated IP addresses and host names), but the plan time span is not extended.

Thus, plan any network changes with the job schedules in mind, and for major changes you are advised to suspend IBM Workload Scheduler activities until the changes complete in the network and also implemented in the IBM Workload Scheduler database.

Network changes also have a specific impact on the connection parameters used by the application server and the command-line client:

# Application server

If you change the network you will need to change the communication parameters specified in the application server configuration files. For more information, see Configuring IBM Workload Scheduler using templates on page 418.

# Command-line client

When you connect from the command-line client you supply a set of connection parameters. This is done in one of these ways:

# From the localopts file

The default method is that the connection parameters in the localoptions file are customized when the command line client is installed.

# From the useropts file

A useropts file might have been created for the user in question, containing a version of the connection parameters personalized for the user.

# In the command line, individually

When you invoke one of the command-line programs, you can optionally include the parameters as arguments to the command. These override the values in the localargs or userargs files.

# In the command line, in a file

When you invoke one of the command-line programs, you can optionally include the parameters in a file, the name of which is identified as the -file argument to the command. These override the values in the localopts or useropts files.

Modify whichever method you are using to incorporate the new network connection details.

# Chapter 6. Configuring secure communications

IBM® Workload Scheduler ensures your business operations are always secure with robust, authenticated, and encrypted connections powered by the Secure Sockets Layer (SSL) protocol.

By leveraging certificates, only trusted devices, users, and systems can access the environment resources, providing the ultimate protection for your critical workloads.

In the following chapters, you can find all the information you need to easily manage certificates and maintain secure communication across your entire infrastructure:

- Managing certificates using Certman on page 311  
- Certificate rotation on page 321  
- Scenario: SSL Communication across the fault-tolerant agent network on page 323

# Managing certificates using Certman

Using Certman tool, you can easily manage the custom certificates in both fresh installation or upgrade procedures.

Certman supports the following actions:

- Generate new certificates and a Certificate Authority (CA) on page 311  
- Generate new certificates from an existing Certificate Authority (CA) on page 313  
- Extract certificates from an existing keystore on a master domain manager on page 314  
- Verify the validity of certificates on page 317  
- Import certificates from a master domain manager into the Dynamic Workload Console on page 318  
- Remove an alias from the keystore or truststore on page 320

You can find Certman at the following path: TWS_INST_DIR/TWS/bin, where TWS_INST_DIR is the IBM® Workload Scheduler installation directory.

To verify the version of Certman you are using, you can run the following command: certman version.

Running any command of Certman, you can also see where the logs file is located.

# Generate new certificates and a Certificate Authority (CA)

# About this task

If you want to secure the communication based on the Secure Sockets Layer (SSL) protocol, but you do not have a corporate Certificate Authority (CA), you can use Certman to create one and generate the required certificates.

1. Browse to the following path: <image_location>/TWS/<interp_name>/<tivoli_LWA_<interp_name>\TWS\bin  
2. Generate the CA and certificates by running the following command:

```txt
certman generate -keypasswd <pwd> -outpath <output path> [-capath <ca path>] [-wauser <user>] [-wagroup <group>]
```

Where:

# keypasswd

Specify the password to encrypt the private key.

# outpath

Specify the folder where generate the certificates.

# capath

Leave empty to generate a ca.crt and ca.key.

# wauser

Optionally, specify the<TWS_user> that must be set as owner of the output files.

# wagroup

Optionally, specify the<TWS_user> that must be set as group of the output files..

![](images/2e56cb053fd89b1c9e27c6e53b58bc6ded2150a23a5995e2fd40fc668e865e85.jpg)

Note: To specify an owner and group in wauser and wagroup parameters, the user who

launches Certman must have the permissions to change the owner and group on output files.

# Results

The following output files are the CA and certificates you can find in the specified output folder:

ca.crt

The file that contains the Root ca.

ca.key

The private key of the CA.

- tls.crt

The certificate signed and validated by the CA.

- tls.key

The private key of the tls certificate.

- tls.sth

The stash file of the tls certificate that contains the password encoded in Base64 format.

![](images/fca2178617fc6197541368bbf64979d1d73957098f321713170bbef994c72506.jpg)

Note: It is strongly suggested that you save the ca .key so that in future, if needed, you can generate or replace the certificates only.

After having generated the CA, add it to the OS and browser so that they can trust the new CA.

# Generate new certificates from an existing Certificate Authority (CA)

# About this task

If you need to generate new certificates from an existing Certificate Authority (CA), you can use Certman to generate the required certificates. In this case, the capath parameter is required and you need to provide the path of the existing ca.crt and ca.key files.

1. Browse to the following path: <image_location>/TWS/<interp_name>/<tivoli_LWA_<interp_name>\TWS\bin  
2. Generate the new certificates by running the following command:

```txt
certman generate -keypasswd <pwd> -outpath <output path> [-capath <ca path>] [-wauser <user>] [-wagroup <group>]
```

Where:

keypasswd

Specify the password to encrypt the private key.

outpath

Specify the folder where generate the certificates.

capath

Specify the path where ca.crt and ca.key files are stored.

wauser

Optionally, specify the<TWS_user> that must be set as owner of the output files.

wagroup

Optionally, specify the<TWS_user> that must be set as group of the output files..

![](images/0044bc591d7a9db97562da8631d8e189f21f6c43d68acf70f446fc0b57ec7bf0.jpg)

Note: To specify an owner and group in wauser and wagroup parameters, the user who

launches Certman must have the permissions to change the owner and group on output files.

# Results

The following output files are the certificates you can find in the specified output folder:

- tls.crt

The certificate signed and validated by the CA.

- tls.key

The private key of the tls certificate.

- tls.sth

The stash file of the tls certificate that contains the password encoded in Base64 format.

# Extract certificates from the keystore and trustore

# About this task

You can use Certman to extract certificates from the keystore and trustore on a master domain manager, an agent, or the Dynamic Workload Console to provide them to the backup master domain manager or Dynamic Workload Console.

# Extract certificates from version 10.2.3 or later

# About this task

You can extract certificates from the keystore and trustore on a master domain manager, an agent, or the Dynamic Workload Console V10.2.3 or later by completing the following steps:

1. Browse to one of the following installation bin paths, according to the component from which you want to extract the certificate:

# Master domain manager

<MDM_INST_PATH>/TWS/bin/certman, where <MDM_INST_PATH> is the master domain manager installation directory.

# Dynamic Workload Console

<DWC_INST_PATH>/bin/certman, where <DWC_INST_PATH> is the Dynamic Workload Console installation directory.

# Agent

<AGENT_INST_PATH>/TWS/bin/curteman, where <AGENT_INST_PATH> is the agent installation directory.

2. Extract the certificates by running the following command:

```txt
certman extract -outpath <output path> [-storepasswd <pw>] [-agentscope] [-wauser <user>] [-wagroup <group>] [-workdir <working directory>] [-cachain-splitted]
```

Where:

# outpath

Specify the folder where to store the certificates.

# storepasswd

Optionally, specify the password of the keystore on the master domain manager.

![](images/7b443a78efe90d6e1669c9c1c8fd96a9c9d35742cbfdf5c5d979800cd9803c21.jpg)

Note: For version 9.4.x, this parameter is required.

# agentscope

Optionally, specify that the action performed by the command applies to the keystore of an agent.

![](images/9d172bce2d286b80b3f56946fbfa7764662d6404b63d11076455efd60aa6d70e.jpg)

Note: To target the keystore of a master domain manager, omit the agentscope option and run the command separately.

# wauser

Optionally, specify the<TWS_user> that must be set as owner of the output files.

# wagroup

Optionally, specify the<TWS_user> that must be set as group of the output files..

![](images/1166bf0b61100191644648e0b11d6731b50bc49db08e0146197ec771573690a5.jpg)

Note: To specify an owner and group in wauser and wagroup parameters, the user who launches Certman must have the permissions to change the owner and group on output files.

# workdir

Optionally, specify the working directory used by the command for storing data while running. When the command stops running, the working directory is deleted. Ensure you have write access to the specified directory and enough space is available.

# cachain-splitted

Optionally, specify the CA chain to be split into multiple files. By default, it is false.

# Results

The following output files are the certificates you can find in the specified output folder:

ca.crt

The file that contains the intermediate CA certificate and ends up with the Root ca.

![](images/4f58f5ba00679e1530ab96e5d1207fff5ce8d3a5b0ccf15c84aa762679329390.jpg)

Note: If you enabled the cachain-splittled parameter, the ca.crt contains only the Root ca. The intermediate CA certificates are stored in the additionalCAs subfolder.

- t1s.crt

The certificate signed and validated by the CA.

- tls.key

The private key of the tls certificate.

- tls.sth

The stash file of the tls certificate that contains the password encoded in Base64 format.

additionalCAs

The subfolder where any intermediate CA certificate extracted by the truststore is stored.

# Extract certificates from a previous product version level

# About this task

You can extract certificates from a previous product version level by completing the following steps:

1. From IBM Fix Central, download the 10.2.5 installation package: 10.2.4-IWS--<component>--<operating_system>.zip  
2. Extract the content, browse to the path <IMAGE_DIR>/TWS/<OPERATING_SYSTEM>_<ARCHITECTURE>/ Tivoli_LWA_<operating_system>/TWS/bin/, and copy the following files:

certman  
certman.extract.json  
certman_generate.json  
certman import.json  
certmanverify.json  
certman(version.json

3. Paste the Certman files into the following path: TWS_INST_DIR/TWS/bin, where TWS_INST_DIR is the IBM® Workload Scheduler installation directory.

![](images/ac9af927f441fa5c9fd48c5d83555f5b656e3c3380ce9ba600832b5623e0e9c5.jpg)

Note: For UNIX systems, ensure that all the files have the ownership of the user who installed the master domain manager and the correct permissions (775 for certman and 644 for the json files).

4. Extract the certificates by running the following command:

```txt
certman extract -outpath <output path> [-storepasswd <pw>] [-agentscope] [-wauser <user>] [-wagroup <group>] [-workdir <working directory>] [-cachain-splittled]
```

Where:

outpath

Specify the folder where to store the certificates.

storepasswd

Optionally, specify the password of the keystore on the master domain manager.

![](images/a9e48bc38621f1ed29822b7a1e753f365f6d248eb4fa4ef96bf72ae29f94d204.jpg)

Note: For version 9.4.x, this parameter is required.

# agentscope

Optionally, specify that the action performed by the command applies to the keystore of an agent.

![](images/7afacb8395f2fc47e7b09b9b44d3a922286a448f7a680718a8afdd39a8ff310f.jpg)

Note: To target the keystore of a master domain manager, omit the agentscope option and run the command separately.

# wauser

Optionally, specify the<TWS_user> that must be set as owner of the output files.

# wagroup

Optionally, specify the<TWS_user> that must be set as group of the output files..

![](images/b305bc114538de5756039dd476be02024cdfcf58523658eeb7a3115df4c6b3fb.jpg)

Note: To specify an owner and group in wauser and wagroup parameters, the user who launches Certman must have the permissions to change the owner and group on output files.

# workdir

Optionally, specify the working directory used by the command for storing data while running. When the command stops running, the working directory is deleted. Ensure you have write access to the specified directory and enough space is available.

# cachain-splitted

Optionally, specify the CA chain to be splitted into multiple files. By default, it is false.

# Results

The following output files are the certificates you can find in the specified output folder:

ca.crt

The file that contains the intermediate CA certificate and ends up with the Root ca.

![](images/a49d5faffd6d45b064f63e2e1da9bed149f7188327fb7104dfb13276bff45024.jpg)

Note: If you enabled the cachain-splittled parameter, the ca.crt contains only the Root ca. The intermediate CA certificates are stored in the additionalCAs subfolder.

- tls.crt

The certificate signed and validated by the CA.

- tls.key

The private key of the tls certificate.

- tls.sth

The stash file of the tls certificate that contains the password encoded in Base64 format.

additionalCAs

The subfolder where any intermediate CA certificate extracted by the truststore is stored.

# Verify the validity of certificates

# About this task

If you want to verify whether certificates are in a valid .pem format, are not expired, or have a stash that matches the private key password, you can use Certman to verify the validity.

1. Browse to the following path: <image_location>/TWS/<interp_name>/<tivoli_LWA_<interp_name>\TWS\bin  
2. Check the validity by running the following command:

```txt
certman verify -inpath <input path> -keypasswd <key pwd> [-minkeysize <minimum key size>] [-workdir <working directory>]
```

Where:

# inpath

Specify the folder that contains the following certificates:

。tls.crt  
·tls.key  
·tls.sth  
ca.crt

# keypasswd

Specify the password used to encrypt the private key.

# minkeysize

Optionally, specify the minimum size of the key. The default value is 1024.

# workdir

Optionally, specify the working directory used by the command for storing data while running. When the command stops running, the working directory is deleted. Ensure you have write access to the specified directory and enough space is available.

# Results

Using the verify command, the following checks are performed:

- The key password.  
- The stash password (if the t1s.sth file is available).  
- The certificate expiration date.  
- The key length.  
- The certificate and key in .pem format.  
- The private key and public key match.  
- The public key in tls.key and public key in tls.crt match.  
- The correctness of the tls.crt in the CA chain.  
- The purposes of the tls.crt file, which must be suitable for both client and server connections.

# Import certificates into the trustore

# About this task

You can use Certman to import a CA chain into the truststore of the Dynamic Workload Console, of a master domain manager or of an agent.

If certificates being imported are part of a chain consisting of 3 or more certificates (one Root CA, followed by one or more Intermediate CAs, followed by the end user certificate), then the ca.crt must contain the Root ca certificate only. Any Intermediate CA certificates must be stored in the additional CAs subfolder, which therefore becomes a mandatory subfolder. Each Intermediate CA must be stored in the additional CAs subfolder in its own file.

![](images/fd9b550834712a86d5a776ce08ca8ef7433d44b0c3e3d782da493c6d00130c7e.jpg)

Note: From V10.2.3, if certificates being imported are part of a chain, the ca.crt can contain also the intermediate CAs. In this case, it must begin with one or more intermediate CA certificates and end with the Root ca.

1. Browse to one of the following installation bin paths, according to the component on which you want to import the CA chain:

# Master domain manager

<MDM_INST_PATH>/TWS/bin/certman, where <MDM_INST_PATH> is the master domain manager installation directory.

# Dynamic Workload Console

<DWC_INST_PATH>/bin/certman, where <DWC_INST_PATH> is the Dynamic Workload Console installation directory.

# Agent

<AGENT_INST_PATH>/TWS/bin/certman, where <AGENT_INST_PATH> is the agent installation directory.

2. Import the CA chain by running the following command:

```txt
certman import (-inpath <input path> [-storepasswd <store pwd>] [-all -keypasswd <key pwd>] | -url <host:port> -storepasswd <store pwd>) -alias <alias> [-forcealias] [-agentscope] [-updatedepot] [-workdir <working directory>]
```

Where:

inpath

Specify the folder that contains the CA chain.

storepasswd

Optionally, specify the password of the trustore on the master domain manager.

all

Optionally, import the certificate, the key and the CA chain.

keypasswd

Specify the password used to encrypt the private key. If all is specified, this value is mandatory.

url

The URL of a server that contains the CA chain to be imported (for example, the master domain manager server).

Where

host

The fully qualified host name or IP address of the server.

port

The HTTPS port.

alias

Specify an alias to be used in the truststore file during the import.

forcealias

Optionally, specify an alias to be used in the trustore file that overwrites the existing alias. Use this parameter if the master domain manager already communicates with the Dynamic Workload Console.

agentscope

Optionally, specify that the action performed by the command applies to the truststore of an agent.

![](images/0e8197c607a15e100de1d0a46cd70fd69db6540a339e28ebb0dd6c034b2d3465.jpg)

Note: To target the trustore of a master domain manager, omit the agentscope option and run the command separately.

updatedepot

Optionally, update the master domain manager depot folder located at: <TWSDATA>/ssl/depot

workdir

Optionally, specify the working directory used by the command for storing data while running. When the command stops running, the working directory is deleted. Ensure you have write access to the specified directory and enough space is available.

# Results

The CA chain has been imported in the Dynamic Workload Console, master domain manager or agent.

# Remove an alias from the keystore or truststore

# About this task

You can remove an alias from the keystore or truststore on a master domain manager, an agent, or the Dynamic Workload Console by completing the following steps:

1. Browse to one of the following installation bin paths, according to the component from which you want to delete the alias:

# Master domain manager

<MDM_INST_PATH>/TWS/bin/certman, where <MDM_INST_PATH> is the master domain manager installation directory.

# Dynamic Workload Console

<DWC_INST_PATH>/bin/certman, where <DWC_INST_PATH> is the Dynamic Workload Console installation directory.

# Agent

<AGENT_INST_PATH>/TWS/bin/certman, where <AGENT_INST_PATH> is the agent installation directory.

2. Remove the alias by running the following command:

```txt
certman delete -alias <alias> -storetype <KEY|TRUST|ALL> [-storepasswd <store pwd>] [-agentscope] [-workdir <work dir>]
```

Where:

# alias

Specify the alias to remove.

# storetype

Specify KEY to remove the alias from the keystore, TRUST to remove the alias from the truststore, or ALL to remove the alias from both the keystore and trustore.

![](images/0efb2e7a740a8f57662ff931344b26f9443919c02370f5bed5726a6e64b6e1e6.jpg)

Note: Specifying ALL without the alias being actually present on both the keystore and the trustore, leads to the failure of the certman delete command.

# storepasswd

Optionally, specify the password of the keystore or trustore on the master domain manager.

# agentscope

Optionally, specify that the action performed by the command applies to the keystore or truststore of an agent.

![](images/999eac4bd6f338350b4c643eee00034618d5d97d009a580ea92febf984b5273d.jpg)

Note: To target the keystore or trustore of a master domain manager, omit the agentscope option and run the command separately.

# workdir

Optionally, specify the working directory used by the command for storing data while running. When the command stops running, the working directory is deleted. Ensure you have write access to the specified directory and enough space is available.

# Results

Using the delete command, the specified alias is removed.

# Certificate rotation

Procedure to rotate certificates in your environment

# About this task

The procedure explained below is one of several procedures you can perform to achieve the same results and is intended only as an example. In this procedure, it is assumed your certificates have been signed by a Certificate Authority (CA) you created for this purpose. For more information about using an external CA or manually modifying all the keystores and key databases, see Replacing Default SSL Certificates with CA Signed Custom Certificates.

You can extend the certificate customization also to backup master domain manager, dynamic domain manager, and Dynamic Workload Console.

To customize the certificates for communication between master domain manager and dynamic agent, perform the following steps:

1. On the master domain manager, generate a self-signed certificate or issue a certificate sign request to a CA and import the certificate into TWSServerKeyFile.p12. For example, you can generate the private key to be used for signing the custom certificate by issuing the following command:

```batch
openssl genrsa -des3 -out TLS.key <key_size>
```

where  $\langle \text{key\_size} \rangle$  must be equal to or major than 2048.

2. Create the certificate sign request:

```batch
openssl req -new -key TLS.key -out TLS.csr -config <TWS_DATA_DIR>/ssl/openSSL.cnf
```

3. Send the .csr to the CA:

```batch
openssl x509 -req -in TLS.csr -days 3650
-CA ca.crt -CAkey ca.key -CAcreateserial -out TLS.crt
```

4. After receiving back the signed certificate, you can import the custom certificate along with its private key into TWSServerKeyFile.p12, as follows:

a. Create a single file containing both:

```txt
cat tls.key tls.crt > tls.tot
```

b. Export the t1s.tot file to a PKCS12 keystore for the master domain manager:

```batch
openssl pkcs12 -export -out TWSSServerKeyFile.p12 -in TLS.tot -name server
```

c. Replace the existing TWSServerKeyFile.p12 file located in TWA_DATA_DIR/usr/servers/engineServer/resources/security with the file you created in step 4b.  
d. Export the t1s.tot file created in step 1 to a PKCS12 keystore for the dynamic agent:

```batch
openssl pkcs12 -export -out TWSSClientKeyStore.p12 -in TLS.tot -name client
```

e. Replace the existing TwSClientKeyStore.p12 file located in TWA_DATA_DIR/ssl/certs with the file you created in step 4d.

5. On the master domain manager, import the CA certificate in the TWSServerTrustFile.p12:

```batch
keytool -importcert -file ca.crt -keystore TWSServerTrustFile.p12  
-alias ca -trustcacerts
```

6. Export the certificates, as described below. Steps 6 on page 322 to 8 on page 323 ensure the handshake for APIKey authentication with JWT between master domain manager and agent completes correctly.

```shell
keytool -exportcert -keystore
$WA_DATADIR/usr/servers/engineServer/resources/security/TWSServerKeyFile.p12
-storepass password -storetype pkcs12 -file /tmp/tls.crt -alias server -noprompt
```

7. Import the certificates, as follows:

```shell
keytool -importcert -keystore
\$WA_DATADIR/usr/servers/engineServer/resources/security/TWSServerTrustFile.p12
-storepass password -storetype pkcs12 -file /tmp/tls.crt -alias mpjwtkey -noprompt
```

8. Edit the value of the mp.jwt.trust.key variable from the twstrustkey to mpjwtkey in the jwt_variables.xml file located inside the WebSphere Application Server Liberty Base overrides folder. For more information about templates, see the topic about configuring IBM Workload Scheduler using templates in Administration Guide.

If you do not remember what the public certificate alias is called, run the following command to retrieve the list of certificates within the keystore:

```shell
keytool -list -keystore $WA_DATADIR/usr/servers/engineServer/resources/security/TWSServerKeyFile.p12
-storepass password -storetype pkcs12
```

9. Replace the existing TWSServerTrustFile.p12 located in TWA_DATA_DIR/usr/services/engineServer/resources/security with the file you created in step 5.  
10. On the master domain manager, edit the TWA_DATA_DIR/broker/config/BrokerWorkstation.properties file and update the list of authorized Common Names for the dynamic domain manager (broker). Append the Common Name used for the custom certificate to the BrokerAuthorizedCNS property:

```txt
Broker.AuthorizedCNs=Server;ServerNew;new_CN
```

11. Run the AgentCertificateLoader script on the dynamic agent. The script connects to the master domain manager, downloads the certificates in .PEM format (tls.key, TLS.crt, ca.crt files), and deploys them to the agent. The certificates must be available on the master domain manager in a specific path. For more information, see the section about the AgentCertificateLoader script in IBM Workload Scheduler: Planning and Installation.

# Scenario: SSL Communication across the fault-tolerant agent network

SSL communication is enabled by default for fresh installations, however, you might need to set it up at upgrade time, as described in the following topics.

You can enable the SSL connection using OpenSSL Toolkit for the following components:

- Master domain manager and its domain managers  
- Master domain manager and fault-tolerant agents in the master domain  
- Master domain manager and backup master domain manager  
- Domain manager and fault-tolerant agents that belong to that domain

The default certificates and the custom certificates are located in the <TWSDATA>\ssl\certs directory.

# Using SSL for netman and conman

IBM Workload Scheduler provides a secure, authenticated, and encrypted connection mechanism for communication across the network topology. This mechanism is based on the Secure Sockets Layer (SSL) protocol and uses the OpenSSL Toolkit, which is automatically installed with IBM Workload Scheduler.

The SSL protocol is based on a private and public key methodology. SSL provides the following authentication methods:

# CA trusting only

Two workstations trust each other if each receives from the other a certificate that is signed or is trusted. That is, if the CA certificate is in the list of trusted CAs on each workstation. With this authentication level, a workstation does not perform any additional checks on certificate content, such as the distinguished name. Any signed or trusted certificate can be used to establish an SSL session. See Setting local options on page 48 for a definition of the caonly option used by the ssl auth mode keyword.

# Check if the distinguished name matches a defined string

Two workstations trust each other if, after receiving a trusted or signed certificate, each performs a further check by extracting the distinguished name from the certificate and comparing it with a string that was defined in its local options file. See Setting local options on page 48 for a definition of the string option.

# Check if the distinguished name matches the workstation name

Two workstations trust each other if, after receiving a signed or trusted certificate, each performs a further check by extracting the distinguished name from the certificate and comparing it with the unique ID of the workstation that sent the certificate. You can obtain the unique ID by using the ;showid composer filter. Only if the unique ID is empty, you can use the name of the workstation instead of the unique ID.

See Setting local options on page 48 for a definition of the cpu option.

To provide SSL security for a domain manager attached to z/OS® in an end-to-end connection, configure the OS/390® Cryptographic Services System SSL in the IBM Workload Scheduler code that runs in the OS/390® USS UNIX® shell in the IBM Z Workload Scheduler server address space. See the IBM Z Workload Scheduler documentation.

When configuring SSL you can:

# Use the same certificate for the entire network

If the workstations are configured with CA trusting only, they accept connections with any other workstation that sends a signed or trusted certificate. To enforce the authentication you define a name or a list of names that must match the contents of the certificate distinguished name (DN) field in the localopts file of each workstation.

# Use a certificate for each domain

Install private keys and signed certificates for each domain in the network. Then, configure each workstation to accept a connection only with partners that have a particular string of the certificate DN field in the localopts file of each workstation.

# Use a certificate for each workstation

Install a different key and a signed certificate on each workstation and add a Trusted CA list containing the CA that signed the certificate. Then, configure each workstation to accept a connection only with partners that have their workstation name specified in the Symphony file recorded in the DN field of the certificate.

# Configuring SSL attributes

Use the composer command line or the Dynamic Workload Console to update the workstation definition in the database. See the section about workstation definition in User's Guide and Reference for further information.

Configure the following attributes:

# secureaddr

Defines the port used to listen for incoming SSL connections. This value is read when the security level attribute is set.

# For workload broker workstations

Ignore this attribute.

# For remote engine workstations using HTTPS protocol to communicate with the remote engine

Specify the HTTPS port number of the remote engine.

# For other types of workstations

Specify the value assigned in the localopts file for variable nm ssl port. The value must be different value from the value assigned to nm port variable in the localopts file.

If securitylevel is specified, but this attribute is missing, the default value for this field is 31113. Specify a value in the range from 1 to 65535.

See the Administration Guide for information about SSL authentication and local options set in the TWS_home/localopts configuration file.

# securitylevel

Specifies the type of SSL authentication for the workstation. Do not specify this attribute for a workstation with type broker. It can have one of the following values:

# enabled

The workstation uses SSL authentication only if its domain manager workstation or another fault-tolerant agent below it in the domain hierarchy requires it.

# on

The workstation uses SSL authentication when it connects with its domain manager. The domain manager uses SSL authentication when it connects to its parent domain manager. The fault-tolerant agent refuses any incoming connection from its domain manager if it is not an SSL connection.

# force

The workstation uses SSL authentication for all of its connections and accepts connections from both parent and subordinate domain managers.

# force_enabled

The workstation uses SSL authentication for all of its connections to all target workstations which are set to this value. The workstation tries to establish a connection in FULLSSL mode and, if the attempt fails, it tries to establish an unsecure connection. If you plan to set different security levels between master domain manager and fault-tolerant agents, ensure all these components are at version 95 Fix Pack 4 or later. For versions earlier than 95 Fix Pack 4, the same security level is required for master domain manager and fault-tolerant agents.

If this attribute is omitted, the workstation is not configured for SSL connections and any value for secureaddr is ignored. Make sure, in this case, that the nm ssl port local option is set to 0 to ensure that netman process does not try to open the port specified in secureaddr. See the Administration Guide for information about SSL authentication and local options set in the TWS_home/localopts configuration file.

The following table describes the type of communication used for each type of security level setting.

Table 60. Type of communication depending on the security level value  

<table><tr><td>Value set on the Fault-tolerant Agent (or the Domain Manager)</td><td>Value set on its Domain Manager (or on its Parent Domain Manager)</td><td>Type of connection established</td></tr><tr><td>Not specified</td><td>Not specified</td><td>TCP/IP</td></tr><tr><td>Enabled</td><td>Not specified</td><td>TCP/IP</td></tr><tr><td>On</td><td>Not specified</td><td>No connection</td></tr><tr><td>Force</td><td>Not specified</td><td>No connection</td></tr><tr><td>Not specified</td><td>On</td><td>TCP/IP</td></tr><tr><td>Enabled</td><td>On</td><td>TCP/IP</td></tr><tr><td>On</td><td>On</td><td>SSL</td></tr><tr><td>Force</td><td>On</td><td>SSL</td></tr><tr><td>Not specified</td><td>Enabled</td><td>TCP/IP</td></tr><tr><td>Enabled</td><td>Enabled</td><td>TCP/IP</td></tr><tr><td>On</td><td>Enabled</td><td>SSL</td></tr><tr><td>Force</td><td>Enabled</td><td>SSL</td></tr><tr><td>Not specified</td><td>Force</td><td>No connection</td></tr><tr><td>Enabled</td><td>Force</td><td>SSL</td></tr></table>

Table 60. Type of communication depending on the security level value (continued)  

<table><tr><td>Value set on the Fault-tolerant Agent (or the Domain Manager)</td><td>Value set on its Domain Manager (or on its Parent Domain Manager)</td><td>Type of connection established</td></tr><tr><td>On</td><td>Force</td><td>SSL</td></tr><tr><td>Force</td><td>Force</td><td>SSL</td></tr><tr><td>force_enable</td><td>force_enable</td><td>SSL</td></tr></table>

The value for securitylevel is not specified for dynamic workload broker workstations.

The following example shows a workstation definition that includes the security attributes:

```txt
cpuname MYWIN  
os WNT  
node apache  
tcpaddr 30112  
secureaddr 32222  
for maestro  
autolink off  
fullstatus on  
securitylevel on  
end
```

# Configuring full SSL security

This section describes how to implement full SSL security when using an SSL connection for communication across the network by netman and conman. It contains the following topics:

- Overview on page 327  
- Setting up full SSL security on page 328  
- Configuring full SSL support for internetwork dependencies on page 328

![](images/b200cb9c0c2f2b98c5eb5dd39416de61058252f80e901a26946b70bd5bb1f9c6.jpg)

Note: The full SSL security feature is not applicable to the communication between dynamic agents and the broker workstation that is defined for the master domain manager or the dynamic domain manager to which the dynamic agents are connected.

# Overview

This feature provides the option to set a higher degree of SSL-based connection security on IBM Workload Scheduler networks in addition to the already available level of SSL security.

If you require a more complete degree of SSL protection, this feature supplies new configuration options to setup advanced connection security, otherwise you can use the standard settings documented above in this chapter.

# The Full SSL security enhancements

Full SSL security support provides the following enhancements:

- TCP ports that can become security breaches are no longer left open.  
- Traveling data, including communication headers and trailers, is now totally encrypted.

# Compatibility between SSL support levels

The non-full and the full SSL support levels are mutually exclusive. That is, they cannot be configured simultaneously and cannot be enabled at the same time. If you enable full SSL support for an IBM Workload Scheduler network, any connection attempts by agents that are not configured for full SSL will be rejected by agents with full SSL support enabled. Vice versa, agents configured for full SSL support cannot communicate with the rest of a network set up for non-full SSL support.

# Setting up full SSL security

# About this task

To set full SSL connection security for your network, you must configure the following options:

# enSSLFullConnection (or sf)

Use optman on the master domain manager to set this global option to Yes to enable full SSL support for the network. For more information, see Setting global options on page 13.

# nm SSL full port

If you defined the SSL port at installation time using the netmanssslport parameter, no further action is required. For more information about the netmanssslport parameter, see the section about agent and master installation parameters in IBM Workload Scheduler: Planning and Installation.

If you have not defined the SSL port at installation time, edit the `localhosts` file on every agent of the network (including the master domain manager) to set this local option to the port number used to listen for incoming SSL connections. For more information, see Setting local options on page 48. Take note of the following:

- This port number is to be defined also for the SECUREADDR parameter in the workstation definition of the agent. For more information, see the topic about workstation definition in User's Guide and Reference.  
- Check that the security level parameter in the workstation definition of each workstation using SSL is set at least to enabled. For more information, see the topic about workstation definition in User's Guide and Reference.  
- In a full SSL security setup, the nm SSL port local option is to be set to zero. For more information, see Setting local options on page 48.  
- You must stop netman (conman shut;wait) and restart it (StartUp) after making the changes in localargs.

# Configuring full SSL support for internetwork dependencies

# About this task

The network agent that resolves internetwork dependencies requires a particular setup for full SSL support.

To enable a network agent for full SSL support:

1. Configure both the hosting and the remote fault-tolerant agents for full SSL support.  
2. On the hosting fault-tolerant agent copy or move the netmth_opts file from the DATA_DIR/config to the

DATA_DIR/methods directories and add (and configure) the following options:

# SSL remote CPU

The workstation name of the remote master or fault-tolerant agent.

# SSL remote full port

The port number defined for full SSL support on the remote master or fault-tolerant agent.

# The local options that specify the private key and certificate on the hosting fault-tolerant agent

These are documented in the Setting local options on page 48).

Note that if the hosting fault-tolerant agent hosts more than one network agent, the DATA_DIR/methods directory contains one netmth_opts file for every defined network agent. In this case the complete name of each netmth_opts file must become:

```txt
network-agent-name_netmth.opts
```

If the DATA_DIR/methods directory contains both network-agent-name_netmth.opts and netmth.opts files, only network-agent-name_netmth.opts is used. If multiple agents are defined and the directory contains only netmth.opts, this file is used for all the network agents.

The following example adds full SSL support to the example described in A sample network agent definition in User's Guide and Reference:

- This is the workstation definition for the NETAGT network agent:

```txt
CPUNAME NETAGT  
DESCRIPTION "NETWORK AGENT"  
OS OTHER  
NODE MASTERA.ROME.ITALY.COM  
TCPADDR 31117  
FOR maestro  
HOST MASTERB  
ACCESS NETMTH  
END
```

- These are the full SSL security options in the netmeth_opts file of NETAGT:

```txt
#!/binomial
# Remote cpu parameters
#!/binomial
# Remote full port = 31119
SSL remote CPU = MASTERA
# Configuration Certificate
#!/binomial
SSL key = "C:\TWS\installations\SSL\xA.key"
SSL certificate = "C:\TWS\installations\SSL\xA.crt"
```

```batch
SSL CA certificate = "C:\TWS\installations\SSL\VeriSte.crt"  
SSL key pwd = "C:\TWS\installations\SSL\XA.sth"  
SSL certificate chain = "C:\TWS\installations\SSL\TWSCertificateChain.crt"  
SSL random seed = "C:\TWS\installations\SSL\random_file.rnd"  
SSL auth mode = cpu  
SSL auth string = tws
```

![](images/dbb0e3523d51a47175b1e5ce7e211418783b864baddbd189676e03dfef245bdf.jpg)

Note: The SSL configuration certificate options must refer to the private key and certificate defined on the hosting fault-tolerant agent.

- This is the workstation definition for MASTER (the remote workstation):

```proteindb
CPUNAME MASTERA  
OS WNT  
NODE 9.168.68.55 TCPADDR 31117  
SECUREADDR 31119  
DOMAIN NTWKA  
FOR MAESTRO  
TYPE MANAGER  
AUTOLINK ON  
BEHINDFIREWALL OFF  
SECURITY FORCE_ENABLED  
FULLSTATUS ON  
SERVER H  
END
```

# Chapter 7. Data maintenance

This chapter describes how to maintain your IBM Workload Scheduler database and other data files. The database is hosted on either the DB2® or Oracle RDBMS infrastructure, as you determined when you installed it. You should use the documentation of DB2® or Oracle for general instructions on database maintenance. This chapter describes the maintenance activities that are specific to IBM Workload Scheduler.

It comprises the following sections:

- Backing up and restoring the database on page 331  
Reorganizing the DB2 database on page 333  
- Maintaining the file system on page 334  
- Administrative tasks - DB2 on page 346  
- Administrative tasks - Oracle on page 352  
- Customizing your RDBMS server on page 353  
- Keeping track of database changes using audit reports on page 373  
Collecting job metrics on page 378

# Backing up and restoring the database

To minimize downtime during disaster recovery, back up your master data files frequently to either offline storage or a backup master domain manager.

# Using a backup master domain manager with a backup database

Set up a backup master domain manager that accesses a different database than the master domain manager, and get your database administrator to set up a mirror of the master domain manager's database onto the backup master domain manager's database. In this way your backup master domain manager not only receives copies of all the processing messages, as is provided for by the setting of the FullStatus attribute on the backup master domain manager, but is also able to access the mirrored database. The mirror frequency must be set high enough to match the frequency with which you change the database.

For more information about how to use a backup master domain manager, see Switching the master to a backup on page 387.

# Backing up the configuration files

The configuration files used by IBM Workload Scheduler are found in the following places:

useropts

<TWS>

For the localopts, sfinal, Security and *.msg files

On Windows operating systems

<TWA_home>

On UNIX operating systems

```txt
<TWA_DATA_DIR>
```

IBM Workload Scheduler configuration files

On Windows operating systems

```batch
<TWA_home>\TWS\mozart\*.*
```

On UNIX operating systems

```txt
<TWA_DATA_DIR>/TWS/mozart/*.*
```

This directory might contain the following files:

runmsgno

This is used for the allocation of unique prompt numbers. On the master domain manager, this file should not be edited manually. On other workstations it can be edited only in the circumstances described in the Troubleshooting Guide. This file does not need to be backed up.

globalots

This is used to store a copy of three of the global properties stored in the database. It must be edited only in the circumstances described in Switching the master to a backup on page 387. This file should be backed up if it is edited.

Application server configuration files, such as TWSConfig.properties

On Windows operating systems

```txt
<TWA_home>\usr\server\engineServer\resources\properties
```

On UNIX operating systems

```txt
<TWA_DATA_DIR>/usr/servers/engineServer/resources/properties
```

# Forecast plan files

On Windows operating systems

```txt
<TWA_home>\TWS\schedForecast
```

On UNIX operating systems

```txt
<TWA_DATA_DIR>/TWS/schedForecast
```

# Archived plan files.

On Windows operating systems

```txt
<TWA_home>\TWS\schedlog
```

On UNIX operating systems

```txt
<TWA_DATA_DIR>/TWS/schedlog
```

# Trial plan files

On Windows operating systems

TWA_home\TWS\schedTrial

On UNIX operating systems

<TWA_DATA_DIR>/TWS/schedTrial

A detailed list of all files is not supplied, as there are too many files. Back up all the files in these directories.

![](images/3c5d95d11cf99bfe2d820f5588d51bffb97b24b0f48d3f0fa30559239342080c.jpg)

Note: The wapull_info tool is provided for sending information to support, but can also be used to perform a backup of a DB2® database and some of the configuration files. For more information, see the section on data capture utility in the Troubleshooting Guide.

# Backing up log files

If you use wapull_info for backup, you do not need to separately backup these files. For more information, see the section on data capture utility in the Troubleshooting Guide.

# Reorganizing the DB2 database

The database requires routine maintenance, as follows:

# DB2®

The DB2® database has been set up to maintain itself, so there is little user maintenance to do. Periodically, DB2® checks the database by running an internal routine. DB2® determines when this routine must be run using a default policy. This policy can be modified, if need be, or can be switched off so that DB2® does not perform internal automatic maintenance. Using the statistical information that DB2® discovers by running this routine, it adjusts its internal processing parameters to maximize its performance.

This routine has also been made available for you to run manually in the case either where you feel that the performance of DB2® has degraded, or because you have just added a large amount of data, and anticipate performance problems. The routine is imbedded in a tool called dbrunstats, which can be run to improve performance while DB2® is processing data without causing any interruption.

It is also possible to physically and logically reorganize the database using the dbreorg script. This effectively re-creates the tablespace using its internal algorithms to determine the best way to physically and logically organize the tables and indexes on disk. This process is time-consuming, and requires that IBM® Workload Scheduler is down while it is run, but it does provide you with a freshly reorganized database after major changes.

The use of these tools is described in Administrative tasks - DB2 on page 346.

These tools are implementations of standard DB2 facilities. If you are an expert user of DB2 you can use the standard facilities of DB2® to achieve the same results. For details go to DB2® documentation.

# Maintaining the file system

Some of the file systems and directories need periodic maintenance. The details are given under the following topics:

- Avoiding full file systems on page 334  
- Log files and archived files on page 340  
- Temporary files on page 345  
- Managing event message queue file sizes on page 346

# Avoiding full file systems

Perhaps the most important maintenance task to perform is that of regularly controlling the file system or systems where IBM Workload Scheduler is installed, particularly on the master domain manager.

IBM Workload Scheduler has a number of files that can grow in size, either with more extensive use, such as the Symphony file, or in the event of network problems, such as the message files. If the Symphony file, in particular, cannot be expanded to contain all the required records, it might become corrupted. If this happens on a fault-tolerant agent or on a domain manager other than the master domain manager, there is a recovery procedure (see the IBM Workload Scheduler: Troubleshooting Guide). If the Symphony file on the master domain manager is corrupted, you have no alternative but to restart IBM Workload Scheduler, losing the current plan's workload.

It is thus most important that you monitor the available space on the file system of the master domain manager where the Symphony file is generated, to ensure that there is always sufficient space for it to expand to cover any workload peaks, and also that there is sufficient space for message files to expand in the event of network problems. Your experience with your workload and your network will guide you to determine what are the acceptable limits of available disk space.

The approximate size of the Symphony file can be estimated in advance. It contains items related both to the plan (see Table 61: Algorithm for calculating the approximate size of the plan data in the Symphony file on page 334) and to the database (see Table 62: Algorithm for calculating the approximate size of the database data in the Symphony file on page 335).

Estimate how many items you have in each category, multiply them by the indicated size in bytes, and sum them to find the approximate Symphony file size:

Table 61. Algorithm for calculating the approximate size of the plan data in the Symphony file  

<table><tr><td>Data in Symphony file from the current plan</td><td>Bytes per instance</td></tr><tr><td>Per Job Scheduler instance:</td><td>512</td></tr><tr><td>Per job instance:</td><td>512</td></tr><tr><td>Per job &quot;docommand&quot; string &gt; 40 bytes:</td><td>The length of the &quot;docommand&quot; string</td></tr><tr><td>Per ad hoc prompt:</td><td>512</td></tr><tr><td>Per file dependency:</td><td>512</td></tr><tr><td>Per recovery prompt:</td><td>512</td></tr><tr><td>Per recovery job:</td><td>512</td></tr></table>

Table 62. Algorithm for calculating the approximate size of the database data in the Symphony file  

<table><tr><td>Data in Symphony file from the database (on the master domain manager)</td><td>Bytes per instance</td></tr><tr><td>Per workstation:</td><td>512</td></tr><tr><td>Per resource:</td><td>512</td></tr><tr><td>Per user:</td><td>256</td></tr><tr><td>Per prompt:</td><td>512</td></tr><tr><td>If the global option ignoreCalendars is set to off, per calendar:</td><td>512</td></tr></table>

If you find that disk space is becoming too limited, and you cannot dynamically extend it, you must create a backup master domain manager with much more space on its file system and then use the switchmgr command so that the backup becomes your new domain manager. Instructions on how to do this for any domain manager are given in Switching a domain manager on page 381, and in particular for a master domain manager, in Switching the master to a backup on page 387.

# Monitoring the disk space used by IBM Workload Scheduler

You can use event-driven workload automation (EDWA) to monitor the disk space used by IBM Workload Scheduler and to start a predefined set of actions when one or more specific events take place. This type of event is managed by the TWSApplicationMonitor event provider. These types of events are supported on fault-tolerant agents only and not supported on dynamic agents. You can use EDWA to set up an event rule that monitors the used disk space, to verify that there is enough space to generate the Symphony and log files, and to allow the product to work correctly. For more information about event-driven workload automation, see the section about event-driven workload automation in the User's Guide and Reference.

When calculating disk space usage, the SSM agent divides the used space by the total space and then rounds up the result to the next highest integer. This is important to note especially when the usage is close to the specified threshold. See Table 63: Example for the ge operator on page 337 and Table 64: Example for the le operator on page 338 for examples on how this impacts the disk space usage calculation.

The following .XML file contains the definition of a sample event rule to monitor the disk usage percentage. This event rule triggers the MessageLogger action provider to write a message in a log file in an internal auditing database when the event occurs. For more information about the MessageLogger action provider, see IBM Workload Scheduler User's Guide and Reference :

```xml
<?xml version="1.0"?>   
<eventRuleSet xmlns:xi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.ibm.com/xmlns/prod/tws/1.0/event-management/rules" xmlns:schemaLocation="http://www.ibm.com/xmlns/prod/tws/1.0/event-management/rules" http://www.ibm.com/xmlns/prod/tws/1.0/event-management/rules/EventRules.xsd"> <eventRule name  $=$  "FILESYSTEMFULL" ruleType  $=$  "filter" isDraft  $=$  "yes"> <eventCondition name  $\coloneqq$  "twsDiskMonEvt1" eventProvider  $\coloneqq$  "TWSApplicationMonitor" eventType  $\coloneqq$  "TWSDiskMonitor"> <scope> \* Disk is filling up </scope> <filteringPredicate> <attributeFilter name  $\coloneqq$  "FillingPercentage" operator  $\coloneqq$  "ge">
```

```xml
<value>usage_percent</value> </attributeFilter> <attributeFilter name="Workstation" operator="eq"> <value>workstation_name</value> </attributeFilter> <attributeFilter name="SampleInterval" operator="eq"> <value>sample_interval</value> </attributeFilter> <attributeFilter name="MountPoint" operator="eq"> <value>mount_point</value> </attributeFilter> </filteringPredicate> </eventCondition> <action actionProvider="MessageLogger" actionType="MSGLOG" responseType="onDetection"> <scope> OBJECT=ADWDADMESSAGE=Disk is filling up </scope> <parameter name="ObjectKey"> <value>object_key</value> </parameter> <parameter name="Severity"> <value>message_severity</value> </parameter> <parameter name="Message"> <value>log_message</value> </parameter> </action> </eventRule> </eventRuleSet>
```

where:

# usage_percentage

Is the disk usage percentage.

![](images/8faaf7ab1549d74220699ab1c62667430cd9491b7cd2b980f2920ba0edc9a7d9.jpg)

Important: When creating the event rule, always use a whole integer in the range 1-99 (inclusive) to express the threshold value. Fractions, decimals and negative numbers are not supported and the event rule is ignored.

Supported operators are as follows:

ge

causes the event generation when the disk usage exceeds the percentage specified by the threshold value. If the condition described in the rule already exists when you deploy the rule, the related event is generated. If the condition does not exist at the time the rule is deployed, then the event is generated when the disk usage percentage reaches or exceeds the threshold. The event is generated again only if the disk usage percentage subsequently falls below the threshold value and then rises again and either reaches or exceeds the threshold. If you restart the SSM agent and the disk usage percentage is higher than the threshold value, the event is generated again.

Table 63: Example for the ge operator on page 337 provides an example in which the ge operator is set to  $70\%$ .  
Table 63. Example for the ge operator  

<table><tr><td>Ma
il
box
n
ame</td><td>Disk usage percentage</td><td>A
ct
ion</td></tr><tr><td>Sa &gt;= 70%</td><td></td><td>ev</td></tr><tr><td>m</td><td></td><td>ent</td></tr><tr><td>ple</td><td></td><td></td></tr><tr><td>(0)</td><td></td><td>ge</td></tr><tr><td></td><td></td><td>ne</td></tr><tr><td></td><td></td><td>ra</td></tr><tr><td></td><td></td><td>ted</td></tr><tr><td>Sa &lt; 70%</td><td></td><td>ev</td></tr><tr><td>m</td><td></td><td>ent</td></tr><tr><td>ple</td><td></td><td>not</td></tr><tr><td>(0)</td><td></td><td>ge</td></tr><tr><td></td><td></td><td>ne</td></tr><tr><td></td><td></td><td>ra</td></tr><tr><td></td><td></td><td>ted</td></tr><tr><td>Sa &lt; 70%</td><td></td><td>ev</td></tr><tr><td>m</td><td></td><td>ent</td></tr><tr><td>ple</td><td></td><td>not</td></tr><tr><td>(n</td><td></td><td>ge</td></tr><tr><td>-1)</td><td></td><td>ne</td></tr><tr><td></td><td></td><td>ra</td></tr><tr><td></td><td></td><td>ted</td></tr><tr><td>Sa &gt;= 70%</td><td></td><td>ev</td></tr><tr><td>m</td><td></td><td>ent</td></tr><tr><td>ple</td><td></td><td></td></tr><tr><td>(n)</td><td></td><td>ge</td></tr><tr><td></td><td></td><td>ne</td></tr><tr><td></td><td></td><td>ra</td></tr><tr><td></td><td></td><td>ted</td></tr><tr><td>Sa &gt;= 70%</td><td></td><td>ev</td></tr><tr><td>m</td><td></td><td>ent</td></tr><tr><td>ple</td><td></td><td></td></tr><tr><td>(n)</td><td></td><td>ge</td></tr><tr><td></td><td></td><td>ne</td></tr><tr><td></td><td></td><td>ra</td></tr><tr><td></td><td></td><td>ted</td></tr></table>

Table 63. Example for the ge operator (continued)  

<table><tr><td>Ma</td><td></td><td></td></tr><tr><td>il</td><td></td><td></td></tr><tr><td>box</td><td></td><td>A</td></tr><tr><td>n</td><td></td><td>ct</td></tr><tr><td>ame</td><td>Disk usage percentage</td><td>ion</td></tr><tr><td>(n</td><td></td><td>ge</td></tr><tr><td>+1)</td><td></td><td>ne</td></tr><tr><td></td><td></td><td>ra</td></tr><tr><td></td><td></td><td>ted</td></tr></table>

# le

causes the event generation when the disk usage percentage decreases under the threshold value. If the condition described in the rule already exists when you deploy the rule, the related event is not generated. The event is generated only the first time the specified disk usage percentage is reached. The event is generated again only if the disk usage percentage subsequently rises and exceeds the threshold value and then falls below the threshold. If you restart the SSM agent and the disk usage percentage is lower than the threshold value, the event is not generated until the disk usage percentage exceeds the threshold value and then falls below it again. Table 64: Example for the le operator on page 338 provides an example in which the le operator is set to  $50\%$ :

Table 64. Example for the le operator  

<table><tr><td>Ma</td><td></td></tr><tr><td>il</td><td></td></tr><tr><td>box</td><td></td></tr><tr><td>n</td><td></td></tr><tr><td>ame</td><td>Disk usage percentage</td></tr><tr><td>Sa &lt;= 50%</td><td>ev</td></tr><tr><td>m</td><td>ent</td></tr><tr><td>ple</td><td>not</td></tr><tr><td>(0)</td><td>ge</td></tr><tr><td></td><td>ne</td></tr><tr><td></td><td>ra</td></tr><tr><td></td><td>ted</td></tr><tr><td>Sa &gt; 50%</td><td>ev</td></tr><tr><td>m</td><td>ent</td></tr><tr><td>ple</td><td>not</td></tr><tr><td>(0)</td><td>ge</td></tr><tr><td></td><td>ne</td></tr></table>

Table 64. Example for the le operator (continued)  

<table><tr><td>Ma
il
box
n
ame</td><td>Disk usage percentage</td><td>A
ct
ion</td></tr><tr><td></td><td></td><td>ra
ted</td></tr><tr><td>Sa &gt; 50%</td><td></td><td>ev</td></tr><tr><td>m</td><td></td><td>ent</td></tr><tr><td>ple</td><td></td><td>not</td></tr><tr><td>(n</td><td></td><td>ge</td></tr><tr><td>-1)</td><td></td><td>ne</td></tr><tr><td></td><td></td><td>ra
ted</td></tr><tr><td>Sa &lt;= 50%</td><td></td><td>ev</td></tr><tr><td>m</td><td></td><td>ent</td></tr><tr><td>ple</td><td></td><td></td></tr><tr><td>(n)</td><td></td><td>ge</td></tr><tr><td></td><td></td><td>ne</td></tr><tr><td></td><td></td><td>ra
ted</td></tr><tr><td>Sa &lt;= 50%</td><td></td><td>ev</td></tr><tr><td>m</td><td></td><td>ent</td></tr><tr><td>ple</td><td></td><td>not</td></tr><tr><td>(n</td><td></td><td>ge</td></tr><tr><td>+1)</td><td></td><td>ne</td></tr><tr><td></td><td></td><td>ra
ted</td></tr></table>

# workstation_name

Is the workstation on which the event is generated.

# sample_interval

Is the interval, expressed in seconds, for monitoring the disk usage percentage.

# mount_point

Is the mount point of the file system where IBM Workload Scheduler is installed, for example: "C:" on Windows™ systems or "/" on UNIX™ systems.

# object_key

Is a key identifying the object to which the message pertains.

# message_severity

Is the severity of the message.

# log_message

Is the message to be logged.

# Log files and archived files

Log files are produced from a variety of IBM Workload Scheduler activities. Other activities produce files which are archived after they have been used. The details are given in Table 65: Log and trace file maintenance on page 340.

Starting from version 10.1 Fix Pack 1, when generating a job log in the monitoring section of the Dynamic Workload Console, by default the log is stored in memory. This ensures compliance with the PCI standard.

To change this behavior and have the job log stored in a file, as it was in versions earlier than version 10.1 Fix Pack 1, perform the following steps:

1. Add the com.ibm.twsconn.plan.output.logtype property in the TWSConfig.properties file.  
2. Set the property to file.  
3. Stop and start all the IBM® Workload Scheduler processes.

Table 65. Log and trace file maintenance  

<table><tr><td>Activity</td><td>Description</td><td>Location</td><td>Maintenance method</td></tr><tr><td rowspan="2">Fault-tolerant agent</td><td>Each IBM Workload Scheduler process logs its activities, writing them in log and trace message files:</td><td></td><td></td></tr><tr><td>Log messagesThese are messages intended for use directly by you, and provide information, errors and warnings about the processes.</td><td>netman</td><td>rmstdlist</td></tr></table>

Table 65. Log and trace file maintenance (continued)  

<table><tr><td>Activity</td><td>Description</td><td>Location</td><td>Maintenance method</td></tr><tr><td></td><td></td><td>yyyymmdd_NETMAN.log</td><td></td></tr><tr><td></td><td></td><td>Other processesOn Windows systemsTWA_home\TWS\st dlist\logs\yyyy mmdd_TWSMERGE.log</td><td></td></tr><tr><td></td><td></td><td>On UNIX operating systems&lt; TWA_DATA_DIR&gt; /stdlist/logs/y yyymmdd_TWSMERG E.log</td><td></td></tr><tr><td></td><td></td><td>This is the default situation. You can set an option in the localopts file to create separate log files for the major processes.</td><td></td></tr><tr><td></td><td>Trace messagesThese are messages written when a problem occurs that you can probably not solve without the assistance of IBM Software Support.</td><td>netman</td><td></td></tr></table>

Table 65. Log and trace file maintenance (continued)  

<table><tr><td>Activity</td><td>Description</td><td>Location</td><td>Maintenance method</td></tr><tr><td></td><td></td><td>yymmdd_TWSMERGE.log</td><td></td></tr><tr><td></td><td></td><td>On UNIX operating systems&lt; TWA_DATA_DIR&gt; /stdlist/logs/y yymmdd_TWSMERG E.log</td><td></td></tr><tr><td></td><td></td><td>This is the default situation. You can set an option in the localopts file to create separate trace files for the major processes.</td><td></td></tr><tr><td>Master domain manager job management</td><td>The job manager process on the master domain manager archives the previous period&#x27;s Symphony file.</td><td>On Windows systems TWA_home&gt;\TWS\schedlog\d ate On UNIX systems &lt; TWA_DATA_DIR&gt;/sched1 og/date</td><td>Manual</td></tr><tr><td>Job</td><td>Each job that runs under IBM Workload Scheduler control creates an output file. These files are archived.</td><td>On Windows systems TWA_home\TWS\stdlist\d ate On UNIX systems &lt; TWA_DATA_DIR&gt;/stdlist/d ate where date is in the format yyyy.mm.dd</td><td>rmstdlist</td></tr><tr><td>Dynamic agent</td><td>Log messages</td><td>Windows TWA_home&gt;\TWS\stdlist\JM \JobManager_message.log UNIX &lt; TWA_DATA_DIR&gt;/stdlist/J M/JobManager_message.log</td><td>Regular housekeeping is performed through the configuration of several parameters. See Regular</td></tr></table>

Table 65. Log and trace file maintenance (continued)  

<table><tr><td>Activity</td><td>Description</td><td>Location</td><td>Maintenance method</td></tr><tr><td></td><td>Trace messages</td><td>Windows
·TWA_home&gt;
\TWS\tdlist\JM
\ITA_trace.log
·TWA_home&gt;
\TWS\tdlist\JM
\JobManager_trace.
log
·TWA_home&gt;
\TWS\JavaExt\logs\j
javaExecutor0.log</td><td>maintenance on page 101.</td></tr><tr><td></td><td></td><td>UNIX
·&lt;TWA_DATA_DIR&gt;/tdl
ist/JM/ITA_trace.
log
·&lt;TWA_DATA_DIR&gt;/tdl
ist/JM/JobManager_t
race.log
·&lt;TWA_DATA_DIR&gt;/Java
Ext/logs/javaExecut
or0.log</td><td></td></tr><tr><td></td><td>Jobs with advanced options</td><td>Windows
TWA_home&gt;\TWS\tdlist\JM
\date&gt;</td><td></td></tr><tr><td></td><td></td><td>UNIX
&lt;TWA_DATA_DIR&gt;/tdli
st/JM/date&gt;</td><td></td></tr><tr><td></td><td></td><td>where date is in the format yyyy.mm.dd</td><td></td></tr><tr><td>Forecast and trial plan creation</td><td>The creation of forecast and trial plans require manual maintenance.</td><td>Forecast plan
These files are to be maintained manually</td><td>Manual</td></tr></table>

Table 65. Log and trace file maintenance (continued)  

<table><tr><td>Activity</td><td>Description</td><td>Location</td><td>Maintenance method</td></tr><tr><td></td><td></td><td>Trail plan
These files are to be maintained manually</td><td></td></tr><tr><td>Audit</td><td>The audit facility writes log files.</td><td>On Windows operating systems
TWA_home\TWS\audit
On UNIX operating systems
&lt;TWA_DATA_DIR&gt;/audit</td><td>Manual</td></tr><tr><td>DB2® UDB</td><td>DB2® logs its activities.</td><td>Information about the location and viewing method for DB2® log files is supplied in the DB2® documentation, in IBM Documentation for DB2®.
The main file to control is the db2diag.log file, which is the most important DB2® diagnostic file, which, without intervention, grows endlessly with no reuse of wasted space. This does not apply, however, to the database log files used by IBM Workload Automation, which are set up for circular reuse of disk space, so they don&#x27;t grow in size over a maximum value.</td><td>See the DB2® documentation.</td></tr><tr><td>Oracle database</td><td>Oracle logs its activities.</td><td>See the Oracle documentation.</td><td>See the Oracle documentation.</td></tr><tr><td>WebSphere Application Server Liberty</td><td>The application server writes log files.</td><td>On the server components:
On Windows operating systems
&lt;TWA_home&gt;\TWS\tdlist\appserver\engineServer\logs
On UNIX operating systems
&lt;TWA_DATA_DIR&gt;/tdlist\appserver/engineServer/1ogs</td><td>Manual</td></tr></table>

Table 65. Log and trace file maintenance (continued)  

<table><tr><td>Activity</td><td>Description</td><td>Location</td><td>Maintenance method</td></tr><tr><td></td><td></td><td>On the Dynamic Workload Console: 
On Windows operating systems 
TWA_home\stdlist\appserver\dwcServer\logs 
On UNIX operating systems 
&lt;TWA_DATA_DIR&gt;/stdlist\appserver\dwcServer\logs</td><td></td></tr><tr><td>Netcool® SSM monitoring agent (not supported on IBM i systems)</td><td>The agent writes log files. (ssmagent.log, traps.log)</td><td>On Windows operating systems 
TWA_home\TWS\Ssm\Log 
On UNIX operating systems 
&lt;TWA_DATA_DIR&gt;/EDWA\Ssm/Log/</td><td>Manual</td></tr><tr><td>Other</td><td>Other activities also write trace and log files.</td><td>On Windows operating systems 
TWA_home\TWS\methods 
On UNIX operating systems 
TWA_home&gt;/methods</td><td>Manual</td></tr></table>

The easiest method of controlling the growth of these directories is to decide how long the log files are needed, then schedule a IBM Workload Scheduler job to remove any files older than the given number of days. Use the rmstdlist command for the process and job log files, and use a manual date check and deletion routine for the others. Make sure that no processes are using these files when you perform these activities.

See the User's Guide and Reference for full details of the rmstdlst command.

![](images/b13a9ba4825bdf855f4b9b5bec722e5431b0450520fe598edc6c01895b208a0a.jpg)

Note: The rmstdlist command might give different results on different platforms for the same scenario. This is because on UNIX® platforms the command uses the -mtime option of the find command, which is interpreted differently on different UNIX® platforms.

# Temporary files

The IBM Workload Scheduler master domain manager uses temporary files, located in <TWA_home>/TWS/tmp or /tmp and named TWS<XXXX>, when compiling new production control databases. These files are deleted when compiling is complete.

This directory also contains the IBM Workload Scheduler installation files and log files, it is primarily used to handle temporary files that composer CLI creates as a work repository when it is invoked to perform CRUD actions against the IBM Workload Scheduler modeling objects. Directory rights are set to 777 to allow all users running the composer to have access. For security reasons the composer CLI is defined by using the sticky bit, so the files it creates can be owned by users different from the IBM Workload Scheduler installation user. IBM Workload Scheduler conman can be used by any user therefore the folder is 777. If the users eligible to use conman/composer are inserted into the IBM Workload Scheduler group then the permission can be set to 774. In that way, only these users will be able to run conman/composer commands

# Managing event message queue file sizes

This publication contains the following information with respect to managing event message queue file sizes:

- See Planning space for queues on page 291 to learn about planning space for message event queues (and also how to use evtsize to resize the queues  
- See Managing the event processor on page 416 to learn about managing the EIF event queue  
- See Disk Space on page 454 to learn about the impacts that increased fault tolerance can have on message queues  
- See Workload spreading on page 451 to learn about how to avoid bottlenecks in the Mailbox.msg queue.

# Administrative tasks - DB2®

A set of scripts and SQL files is provided to perform actions such as granting rights or reorganizing the database. These files are located in inst_dir/dbtools/db2-script. To use these files, copy the relevant folder to the database server. The DB2® tools must be run by a user who has the following permissions:

- DB2 administrator permissions - the user must be defined to DB2 as a DB2 Administrator  
- Full access (777) to the IBM® Workload Scheduler installation directory

The available files are as follows:

# dbrunstats

This script runs the DB2 statistics program, to maximize the performance of DB2.

# dbreorg

This script reorganizes the database. See Reorganizing the DB2 database on page 349 for a full description of how to use the tool.

# dbgrant

This script adds grants to new users on IBM® Workload Scheduler DB schema for the views that can be used to generate reports

To find out how to perform specific administrative tasks on DB2®, see:

- Changing DB2 passwords on page 347  
- Locating the DB2 tools on page 347

- User permissions for running the DB2 tools on page 347  
- Running DB2 maintenance manually on page 348  
- Reorganizing the DB2 database on page 349  
Monitoring the lock list memory on page 350

# Changing DB2® passwords

# About this task

You can change passwords used by DB2®, such as the <<TWS_user>> password or the passwords of the user IDs used by IBM Workload Scheduler to access the database, as described in Changing key IBM Workload Scheduler passwords on page 402. If you need to change other DB2-related passwords, follow the instructions in the DB2® documentation.

After you have changed the password, modify the db.password parameter in the datasource_db2.xml configuration file, as described in Changing the properties for the database on page 408. You can optionally encrypt the password, as described in the topic about the secure script in IBM Workload Scheduler: Planning and Installation.

# Locating the DB2® tools

# About this task

IBM Workload Scheduler is supplied with a small set of tools that you use to perform the following administrative tasks for DB2®:

- Run the DB2® statistics program, to maximize the performance of DB2® (dbrunstats). See Running DB2 maintenance manually on page 348 for a full description of how to use the tool.  
- Reorganize the database (dbreorg). See Reorganizing the DB2 database on page 349 for a full description of how to use the tool.

The tools are available in the following directory:

```txt
inst_dir/TWS/dbtools/db2
```

Copy the tools to the DB2 server workstation where the IBM Workload Scheduler database is located.

![](images/01f1f7172a96f65bc8ae6f63e0673959224ef0012f257c56352fe843c6e7d8bd.jpg)

Note: The tools in this directory might include some that are for the use of IBM Software Support:

dbmove

Do not run this script. To do so might damage or overwrite the data in your database.

# User permissions for running the DB2® tools

The DB2® tools must be run by a user who has the following permissions:

- DB2® administrator permissions - the user must be defined to DB2® as a DB2® Administrator  
- Full access (777) to the IBM Workload Scheduler installation directory

# Running DB2® maintenance manually

At installation, DB2® automatic maintenance is switched on, which means that DB2® periodically checks to see if it needs to collect new database statistics, so that it can perform the maintenance, adjusting the performance parameters to maximize performance.

This section describes how to perform the DB2® maintenance process on demand, instead of waiting for DB2® to do it according to its automatic maintenance policy. The process is run by the dbrunstats tool which you can run whenever you need to, without stopping DB2® or interrupting its processing.

To run this tool, follow this procedure:

1. Locate the DB2® tools: see Locating the DB2 tools on page 347.  
2. Check that the user who is going to run the procedure has the appropriate rights (see User permissions for running the DB2 tools on page 347)  
3. On the DB2 server, open a DB2® shell, as follows:

# UNIXTM

Follow these steps:

a. Issue the command su - db2inst1, or change to the subdirectory sqllib of the home directory of the owner of the DB2® instance (by default db2inst1)  
b. Launch the command ./db2profile

# WindowsTM

Select from the Start menu, Programs  $\rightarrow$  ; IBM DB2  $\rightarrow$  ; Command Line Tools  $\rightarrow$  ; Command Window

4. Check that the command shell is correctly initialized by issuing the command db2, and checking that the command is recognized.  
5. Issue the command quit to leave the DB2® Processor mode.  
6. From within the shell, browse to the directory where you copied the script.  
7. Run the script:

# UNIXTM

dbrunstats.sh database [user [password]]

# WindowsTM

dbrunstats database [user [password]]

# where:

# database

The name of the database. The default name is Tws. Supply this value unless you have changed it.

# user

The DB2® administration user. If this is omitted, the ID of the user running the command will be used.

# password

The password of the DB2® administration user. If this is omitted, it will be requested interactively.

The script runs, giving you various messages denoting its progress and successful conclusion. At the end (it is not particularly time-consuming) the database performance parameters have been reset to maximize performance.

# Reorganizing the DB2® database

# About this task

Using this tool, the database physically reorganizes the data tables and indexes, optimizing disk space usage and ease of data access. The process is time-consuming, requires that the database is backed up, and that IBM Workload Scheduler is stopped. However, at the end you have a database that is completely reorganized.

To reorganize the database follow this procedure:

1. Stop WebSphere Application Server Liberty and appservman by running the following command:

```txt
conman "stopappserver;wait"
```

See Starting and stopping the application server and appservman on page 426 for full details.

2. Back up the IBM Workload Scheduler database. Follow the instructions in the database vendor documentation, as appropriate.  
3. Check that the user who is going to run the procedure has the appropriate rights (see User permissions for running the DB2 tools on page 347)  
4. On the DB2 server where you copied the script, open a DB2® shell, as follows:

UNIXTM

Follow these steps:

a. Issue the command su - db2inst1, or change to the subdirectory sqllib of the home directory of the owner of the DB2® instance (by default db2inst1)  
b. Launch the command ./.db2profile

WindowsTM

Select from the Start menu, Programs  $\rightarrow$  ; IBM DB2  $\rightarrow$  ; Command Line Tools  $\rightarrow$  ; Command Window

5. Check that the command shell is correctly initialized by issuing the command db2, and checking that the command is recognized.  
6. Issue the command quit to leave the DB2® Processor mode.  
7. From within the shell, browse to the directory where you copied the script.  
8. Run the script:

UNIXTM

dbreorg.sh database [user [password]]

WindowsTM

dbreorg database [user [password]]

where:

# database

The name of the database. The default name is Tws. Supply this value unless you have changed it.

user

The DB2® administration user. If this is omitted, the ID of the user running the command will be used.

# password

The password of the DB2® administration user. If this is omitted, it will be requested interactively.

The script runs, giving you various messages denoting its progress and successful conclusion.

9. Restart WebSphere Application Server Liberty and appservman by running the following command:

```txt
conman "startappserver;wait"
```

See Starting and stopping the application server and appservman on page 426 for full details.

# Monitoring the lock list memory

# About this task

If the memory that DB2® allocates for its lock list begins to be fully used, DB2® can be forced into a "lock escalation", where it starts to lock whole tables instead of just individual table rows, and increasing the risk of getting into a deadlock.

This happens especially when there are long transactions, such as the creation or extension of a plan (production, trial, or forecast).

To avoid this problem occurring, set the automatic notification in the DB2® Health Center, so that you can be advised of any lock list problems building up.

However, if you think that deadlock situations have been occurring, follow this procedure to verify:

1. With the WebSphere Application Server Liberty active, log on as DB2® administrator to the DB2® server, for example, su - db2inst1  
2. Run the following command to determine where the IBM Workload Scheduler database is located:

db2 list active databases

The output might be as follows:

```hcl
Database name = TWS  
Applications connected currently = 2  
Database path = /home/db2inst1/db2inst1/NODE0000/SQL00002/
```

3. Run:

cd <Database_path>/db2event/db2detaildeadlock

4. Connect to the IBM Workload Scheduler database, for example:

db2 connect to TWS

5. Flush the event monitor that watches over deadlocks (active by default) with the following:

db2 flush event monitor db2detaildeadlock

6. Disconnect from the database with:

db2 terminate

7. Obtain the event monitor output with:

db2evmon -path . > deadlock.out

The file deadlock.out now contains the complete deadlock history since the previous flush operation.

8. To find out if there have been deadlocks and when they occurred, run:

grep "Deadlock detection time" deadlock.out

The output might be as follows:

Deadlock detection time: 11/07/2008 13:02:10.494600

Deadlock detection time: 11/07/2008 14:55:52.369623

9. But the fact that a deadlock occurred does not necessarily mean that the lock list memory is inadequate. For that you need to establish a relationship with lock escalation. To find out if there have been lock escalation incidents prior to deadlocks, run:

grep "Requesting lock as part of escalation: TRUE" deadlock.out

The output might be as follows:

Requesting lock as part of escalation: TRUE

Requesting lock as part of escalation: TRUE

If there has been lock escalation related to deadlocks, it is a good idea to modify the values of the following parameters.

# LOCKLIST

This configures, in 4KB pages, the amount of memory allocated to locking management

# MAXLOCKS

This configures the percentage of the memory that a single transaction can use, above which DB2® escalates, even though the memory might not be full

10. To determine the values currently being applied to the IBM Workload Scheduler database, do the following:

db2 get dbcfg for TWS | grep LOCK

The output might be as follows:

```txt
Max storage for lock list (4KB) (LOCKLIST) = 8192  
Percent. of lock lists per application (MAXLOCKS) = 60  
Lock timeout (sec) (LOCKTIMEOUT) = 180
```

The example shows the typical output for the IBM Workload Scheduler database if no modification has taken place to these values:

$^\circ 8192^{\prime \prime} = 4KB\times 8192$  pages  $= 32$  MB of memory  
$^\circ 60^{\prime \prime} = 60\%$  - the percentage of memory that a single transaction can occupy before triggering an escalation  
$^\circ 180^{\prime \prime} = 3$  minutes of timeout for the period a transaction can wait to obtain a lock

11. The most straightforward action to take is to double the amount of memory to 64MB, which you do with the command:

db2 update dbcfg for TWS using LOCKLIST 16384 immediate

12. Alternatively, you can set DB2® to automatically modify the LOCKLIST and MAXLOCKS parameters according to the amount of escalation being experienced and the available system memory. This self-tuning is a slow process, but adapts the database to the needs of the data and the available system configuration. It is done by setting the values of these parameters to AUTOMATIC, as follows:

db2 update dbcfg for TWS using LOCKLIST AUTOMATIC immediate

DB2® responds with messages telling you that MAXLOCKS has also been set to AUTOMATIC:

```txt
SQL5146W "MAXLOCKS" must be set to "AUTOMATIC" when "LOCKLIST" is "AUTOMATIC".
```

```txt
"MAXLOCKS" has been set to "AUTOMATIC"
```

![](images/d78aacdb527c81acc330d423128d77cb9d81aaf105e3499668e88ebd09c26972.jpg)

Note: The self-tuning facility is only available from V9.1 of DB2®.

# Administrative tasks - Oracle

A script is provided to perform actions such as granting rights or reorganizing the database. The file is located in inst_dir/dbtools/oracle/script

Oracle

dbgrant

This script grants the user permissions for the Dynamic Workload Console views. See the Dynamic Workload Console online help for full details.

A second script named dbmove is available, but it is to be run only if requested by Software Support.

![](images/392c179e62c65b7006f98968e7f927ad77c59b91daf2fde84ac6fb323b175d1d.jpg)

Note: Do not run the dbmove script unless instructed to do so by Software Support. Running the script autonomously might damage or overwrite the data in your database.

Ensure you have the following permissions before running the scripts:

- Oracle administrator permissions - the user must be defined to Oracle as an administrator  
- Full access (777) to the IBM® Workload Scheduler installation directory

You can perform a number of other tasks on Oracle databases as follows:

# Changing the Oracle access password

For more information, see Changing the properties for the database on page 408.

# Maintaining the Oracle database

Like DB2, Oracle has a routine that regularly maintains the database. Similarly, this too can be run manually. The tool is invoked as follows:

```txt
dbms.stats.gather_schema_statsschema-owner
```

See the Oracle documentation for full details of how and when to run it.

# Obtaining information about the IBM® Workload Scheduler databases installed on an Oracle instance

To determine which IBM Workload Scheduler databases are installed on an Oracle instance, do the following:

```sql
su - oracle (UNIX only)  
sqlplus system/system_password@service_name  
SQL> select * from all_tws_schemas;
```

The output should look like the following:

```txt
SCHEMA_NAME  
MDL  
mdm10.2.5 <<TWS_user>>
```

![](images/e0909f358d6f426609d81b67ed9473b6310bf927959aa96f1fcdf03bf7a3a989.jpg)

# Note:

1. More than one instance of IBM Workload Scheduler can be shared in one instance of Oracle, using different schemas.  
2. In Oracle, the concept of "schema" and "user" are the same, so dropping an Oracle schema means dropping an Oracle user, which you do as follows:

SQL> drop user MDL cascade;

# Customizing your RDBMS server

# About this task

You can perform several operations to customize your database, such as:

- Upgrading the JDBC drivers. For more information, see the FAQ about customizing the JDBC drivers in Planning and Installation Guide.  
- Changing the instance owner, by editing the db.user property in the datasource_<dbvendor>.xml file. For more information, see Changing the properties for the database on page 408.

- Relocating the DB to the another host by editing the db.serverName property in the datasource_<dbvendor>.xml file. For more information, see Changing the properties for the database on page 408.  
- Changing the database port, database name, or database access credentials by editing the db.portNumber, db(databaseName, db.user, and db.password properties in the datasource_<dbvendor>.xml file. For more information, see Changing the properties for the database on page 408.

If you want to upgrade your database version, change the instance owner, or relocate it to a different host, complete the following steps:

1. If you are changing DB2®, check the node directory and database directory and make a note of the current configuration. To do this, issue the following commands at the DB2® command-line:

```txt
db2 list database directory
```

where the show detail attribute is specified to give the full information in the directory.

Make a note of the displayed details.

2. Stop the application server, using the command

```txt
conman stopappserver ;wait
```

3. Make the upgrade, instance owner change, or relocation, of the database following the instructions from your database supplier.  
4. If you have changed the database access credentials, you will need to update the application server's security properties, as described in Changing the security settings on page 415.  
5. Reconfigure the database for IBM Workload Scheduler, as follows:

# DB2®

a. Check the node directory and database directory, as you did in step 1 on page 354  
b. If necessary, modify the data displayed by these commands to match the data you noted in step 1 on page 354. If you are not certain of how to do this, contact IBM Software Support for assistance.

# Oracle

Check the Oracle Listener and make sure that the service name is correctly specified.

6. Restart the database.  
7. Restart the application server, using the command:

```txt
conman startappserver ;wait
```

# Connecting the master domain manager to a new database

Connecting the master domain manager to a new database involves reconfiguring the system to recognize and interact with the new database. This process typically includes updating connection strings, ensuring database drivers are compatible,

migrating relevant data, and validating connectivity. This ensures the master domain manager can continue to perform its tasks without interruption, leveraging the new database resources and capabilities.

# About this task

This section applies to IBM Workload Scheduler master domain managers and their backups. It documents how to connect the master domain manager and backup master domain manager to a new database. If your environment contains pools, see Connecting the master domain manager to a new database when using pools on page 358.

![](images/fe90e7df236c8b618f946cb4da5682b39def614d86c730e495a31af09fabb9c7.jpg)

Note: This cloning procedure does not clone the following information from the source environment:

The preproduction plan  
- The history of job runs and job statistics  
The audit records  
- The state of running event rule instances. This means that any complex event rules, where part of the rule has been satisfied prior to cloning of the environment, are generated as new rules after the cloning procedure. Even if the subsequent conditions of the event rule are satisfied, the record that the first part of the rule was satisfied is no longer available, so the rule will never be completely satisfied.

Follow this procedure to export data from your previous database, import it to a new one, and connect the master domain manager and backup master domain manager to the new database.

1. Install the new database.  
2. Run the configDb command to create the new database on the new target RDBMS. For more information, see the section about the configDB script in IBM Workload Scheduler: Planning and Installation.  
3. On the master domain manager, extract all scheduling object definitions and global options from the previous RDBMS running the dataexport command.

```txt
dataexport source_dir export_dir
```

where:

source_dir

Is the TWS_HOME directory of IBM Workload Scheduler.

export_dir

Is the directory where the export files are created.

For example:

```batch
dataexport.cmd F:\IWS1025\twsDBuser F:\IWS1025\export
```

For more information, see the section about the dataexport command in User's Guide and Reference.

4. Verify that the following files were created in export_dir:

ac1s.def  
- calendars.def

erules.def  
- folders.def  
globalOptions.def  
- jobs.def

![](images/556dc2d4d8e37f26507566c5354721b88719b94d62b602aa5099b7044670f663.jpg)

Note: The record length supported by DB2® is 4095 bytes, but it decreases to 4000 bytes with Oracle. When you migrate your job definitions to Oracle, any job with task string (scripts or commands) exceeding 4000 bytes in length are not migrated. In this case, the data import utility replaces the job definition with a dummy job definition and sets the job priority to 0, guaranteeing that successors are not run.

$\circ$  parms.def  
o prompts.def  
rcgroups.def  
resources.def  
schedules.def  
sdoms.def  
srols.def  
topology.def  
- users.def (includes encrypted user passwords)  
o variable.s.def

5. Run exportserverdata to export dynamic domain manager data from the database. This command is not documented because it is an internal command. The command is located in /opt/IBM/TWA/TDWB/bin/. For the purpose of this procedure, use the following syntax:

```txt
./exportserverdata.sh -dbUsr username -dbPwd password [-exportFile exportFile]
```

where:

dbUsr

Is the database user. This parameter is required.

dbPwd

Is the database user password. This parameter is required.

-exportFile

Is the file name to which the server data is to be exported from the database. This parameter is required if you use a file different from the default server.properties file, located in the same path as the exportserverdata command. If you use a file other than server.properties, specify the name and path of the file.

6. Stop WebSphere Application Server Liberty on the master domain manager and backup master domain manager.  
7. Reconfigure the master domain manager and backup master domain manager by performing the following changes:

a. Edit the WebSphere Application Server Liberty datasource.xml file, so that it points to the new RDBMS. For more information, see Changing the properties for the database on page 408.  
b. In the TWA_DATA_DIR/usr/servers/engineServer/resources.properties/ TWSConfig.properties file, uncomment the com.ibm.tws.dao.rdbms.rdbmsName line and specify the name of your RDBMS. For more information, see Changing the properties for the database on page 408.  
c. In the TWA_DATA_DIR/broker/config/DAOCommon.properties file, change the com.ibm.tdwb.dao.rdbms.rdbmsName line to specify the name of your RDBMS.  
d. In the TWA_DATA_DIR/broker config/CLIConfig.properties file, change the following strings:

com.ibm.tdwb.dao.rdbms.rdbmsName

to specify the name of your RDBMS.

com.ibm.tdwb.dao.rdbms.jdbcPath

to specify the path to your JDBC connection string.

com.ibm.tdwb.dao.rdbms.jdbcDriver

to specify the name of the class implementing your JDBC driver.

e. In the TWA_DATA_DIR/usr/servers/engineServer/jvmoptions file, specify the path to the database drivers.  
f. In the TWA_home/TDWB/bin/tdwb_env.sh file, specify the path to the database drivers.

8. Run addserverdata to add dynamic domain manager data in the database. The command is located in / opt/IBM/TWA/TDWB/bin/. This command is not documented because it is an internal command. For the purpose of this procedure, use the following syntax:

```txt
./addserverdata.sh -dbUsr username -dbPwd password  
-importFile importFile {{-MDM true]}
```

where:

dbUsr

Is the database user. This parameter is required.

dbPwd

Is the database user password. This parameter is required.

-importFile

Is the file name from which the server data is to be imported into the database. This parameter is required if you use a file different from the default server.properties file, located in the same path as the addserverdata command. If you use a file other than server.properties, specify the name and path of the file.

MDM

Specifies whether the workstation where you run the command is the master domain manager. This parameter is required on the master domain manager and is optional on the dynamic domain manager.

9. Restart WebSphere Application Server Liberty on the master domain manager.

10. Reload the shell session for the changes to take effect and check that the environment is working correctly by running the following commands:

```txt
optman ls composer display cpu=MDM_name
```

11. Wait for the dynamic workload broker definition to be created, and subsequently for all dynamic agents to register with the master domain manager.  
12. Run the dataimport command to import data from your previous RBDMS.

```batch
dataimport.cmd F:\IWS1025\twsDBuser F:\IWS1025\export
```

where:

source_dir

is the TWS_HOME directory of the source environment instance of IBM® Workload Scheduler, which corresponds to installation_dir/TWS.

export_dir

is the directory where you copied the object definitions and the global options retrieved from the source environment.

For more information, see the section about the dataimport command in User's Guide and Reference.

13. Run the following command to align the plan with the information inserted in the database:

```txt
Jnextplan -for 0000 -noremove
```

14. Run the following command to extend the plan by 24 hours:

```txt
JnextPlan -to startOfDay tz your_timezone -noremove
```

For more information about Jnextplan, see the section about the JnextPlan command in User's Guide and Reference.

Result

The master domain manager and backup master domain manager are now configured to connect to the new database and your environment is up and running.

If you need to connect the Dynamic Workload Console to a new database, see the topic about connecting the Dynamic Workload Console to a new database in IBM® Workload Scheduler: Planning and Installation.

# Connecting the master domain manager to a new database when using pools

Connecting the master domain manager to a new database involves reconfiguring the system to recognize and interact with the new database. This process typically includes updating connection strings, ensuring database drivers are compatible, migrating relevant data, and validating connectivity. This ensures the master domain manager can continue to perform its tasks without interruption, leveraging the new database resources and capabilities.

# About this task

This section applies to IBM Workload Scheduler master domain managers and their backups. It documents how to connect the master domain manager and backup master domain manager to a new database.

![](images/119da3a13d68e06dc8854d55d1797059cddc15d65ff210a66fc568f392b8bc39.jpg)

Note: This cloning procedure does not clone the following information from the source environment:

The preproduction plan  
- The history of job runs and job statistics  
The audit records  
- The state of running event rule instances. This means that any complex event rules, where part of the rule has been satisfied prior to cloning of the environment, are generated as new rules after the cloning procedure. Even if the subsequent conditions of the event rule are satisfied, the record that the first part of the rule was satisfied is no longer available, so the rule will never be completely satisfied.

Follow this procedure to export data from your previous database, import it to a new one, and connect the master domain manager and backup master domain manager to the new database. This procedure involves your existing master domain manager, MASTER_1, and a new one, MASTER_TEMP, which is installed solely to perform the initial configuration of the new database, ensuring it is properly set up before data import.

![](images/3d9e8ff148c2031adbf6ea6b7328a8c885ce7e9005f67ca2fbe0a00802b746f8.jpg)

1. Install the new database.  
2. Install a new master domain manager, named MASTER_TMP. This master domain manager is installed only to perform the initial configuration of the new database, ensuring it is properly set up before importing data.  
3. Run the configureDb command to create the new database on the new target RDBMS. For more information, see the section about the configureDB script in IBM Workload Scheduler: Planning and Installation.

4. On MASTER_1, extract all scheduling object definitions and global options from the previous RDBMS running the dataexport command.

```txt
dataexport source_dir export_dir
```

where:

source_dir

Is the TWS_HOME directory of IBM Workload Scheduler.

export_dir

Is the directory where the export files are created.

For example:

```batch
dataexport.cmd F:\IWS1025\twsDBuser F:\IWS1025\export
```

For more information, see the section about the dataexport command in User's Guide and Reference.

5. Verify that the following files were created in export_dir:

acls.def  
- calendars.def  
erules.def  
- folders.def  
globalOptions.def  
- jobs.def

![](images/19d81e6eea887c54a822bf576aeb666f08e86b233c199079e57cc48e61ac1285.jpg)

Note: The record length supported by DB2® is 4095 bytes, but it decreases to 4000 bytes with Oracle. When you migrate your job definitions to Oracle, any job with task string (scripts or commands) exceeding 4000 bytes in length are not migrated. In this case, the data import utility replaces the job definition with a dummy job definition and sets the job priority to 0, guaranteeing that successors are not run.

- parms.def  
o prompts.def  
rcgroups.def  
resources.def  
schems.def  
sdoms.def  
srols.def  
topology.def  
- users.def (includes encrypted user passwords)  
o variable.s.def

6. On MASTER_1, run exportserverdata to export dynamic domain manager data from the database. This command is not documented because it is an internal command. The command is located in /opt/IBM/TWA/TDWB/bin/. For the purpose of this procedure, use the following syntax:

```txt
./exportserverdata.sh -dbUsr username -dbPwd password [-exportFile exportFile]
```

where:

dbUsr

Is the database user. This parameter is required.

dbPwd

Is the database user password. This parameter is required.

-exportFile

Is the file name to which the server data is to be exported from the database. This parameter is required if you use a file different from the default server.properties file, located in the same path as the exportserverdata command. If you use a file other than server.properties, specify the name and path of the file.

7. On MASTER_1, relocate the definitions of the specified components from file topology.def to a newly created file named topology_env.def, placing it in a different folder.

- MASTER_1 (modify type from MANAGER to FTA)  
- MASTER_1_1  
$\text{。}$  MASTER_2  
MASTER_2_1  
$\text{。}$  SERVER_XA

Agent definitions remain in the original topology.def file.

8. On MASTER_TMP, run the addserverdata command. The command is located in /opt/IBM/TWA/TDWB/bin/. This command is not documented because it is an internal command. For the purpose of this procedure, use the following syntax:

```txt
./addserverdata.sh -dbUsr <ORACLE_user> -dbPwd <ORACLE_password>  
-importFile <file_created_by_exportserverdata>
```

9. On MASTER_TMP, import the master domain manager definition, using the following command:

```batch
composer replace topology_env.def
```

10. Modify the definitions of MASTER_1 to MANAGER and MASTER_TEMP to FTA.  
11. On MASTER_1, set the fence to HIGH, by running the following command:

```txt
conman fence @ HI noask
```

12. Stop WebSphere Application Server Liberty on both MASTER_1 and MASTER_2 (MASTER_2 is the backup master domain manager).  
13. Reconfigure the master domain manager and backup master domain manager by performing the following changes:

a. Edit the WebSphere Application Server Liberty datasource.xml file, so that it points to the new RDBMS. For more information, see Changing the properties for the database on page 408.  
b. In the TWA_DATA_DIR/usr/server/engineServer/resources.properties/ TWSConfig.properties file, uncomment the com.ibm.tws.dao.rdbms.rdbmsName line and specify the name of your RDBMS. For more information, see Changing the properties for the database on page 408.  
c. In the TWA_DATA_DIR/broker/config/DAOCommon.properties file, change the com.ibm.tdwb.dao.rdbms.rdbmsName line to specify the name of your RDBMS.  
d. In the TWA_DATA_DIR/broker config/CLIConfig.properties file, change the following strings:

com.ibm.tdwb.dao.rdbms.rdbmsName

to specify the name of your RDBMS.

com.ibm.tdwb.dao.rdbms.jdbcPath

to specify the path to your JDBC connection string.

com.ibm.tdwb.dao.rdbms.jdbcDriver

to specify the name of the class implementing your JDBC driver.

e. In the TWA_DATA_DIR/usr/servers/engineServer/jvmoptions file, specify the path to the database drivers.  
f. In the TWA_home/TDWB/bin/tdwb_env.sh file, specify the path to the database drivers.

14. On On MASTER_2, run addserverdata to add dynamic domain manager data in the database. The command is located in /opt/IBM/TWA/TDWB/bin/. This command is not documented because it is an internal command. For the purpose of this procedure, use the following syntax:

```txt
./addserverdata.sh -dbUsr username -dbPwd password  
-importFile importFile [[-MDM true]]
```

where:

dbUsr

Is the database user. This parameter is required.

dbPwd

Is the database user password. This parameter is required.

-importFile

Is the file name from which the server data is to be imported into the database. This parameter is required if you use a file different from the default server.properties file, located in the same path as the addserverdata command. If you use a file other than server.properties, specify the name and path of the file.

MDM

Specifies whether the workstation where you run the command is the master domain manager. This parameter is required on the master domain manager and is optional on the dynamic domain manager.

15. On MASTER_1 restart WebSphere Application Server Liberty on the master domain manager.

16. On MASTER_1, reload the shell session for the changes to take effect and check that the environment is working correctly by running the following commands:

```txt
optman ls composer display cpu=MDM_name
```

17. Remove the workstation definitions for SERVER_TEMP and SERVER_TEMP_1.  
18. On MASTER_1, run the dataimport command to import data from your previous RBDMS.

```batch
dataimport.cmd F:\IWS1025\twsDBuser F:\IWS1025\export
```

where:

source_dir

is the TWS_HOME directory of the source environment instance of IBM® Workload Scheduler, which corresponds to installation_dir/TWS.

export_dir

is the directory where you copied the object definitions and the global options retrieved from the source environment.

For more information, see the section about the dataimport command in User's Guide and Reference.

19. Restart MASTER_2.  
20. On MASTER_1, set the fence to 0, as follows:

```txt
conman fence @ 0 noask
```

21. Run the following command to align the plan with the information inserted in the database:

```txt
Jnextplan -for 0000 -noremove
```

22. Run the following command to extend the plan by 24 hours:

```txt
JnextPlan -to startOfDay tz your_timezone -noremove
```

For more information about Jnextplan, see the section about the JnextPlan command in User's Guide and Reference.

# Result

The master domain manager and backup master domain manager are now configured to connect to the new database and your environment is up and running. Your pools are migrated to the new database.

If you need to connect the Dynamic Workload Console to a new database, see the topic about connecting the Dynamic Workload Console to a new database in IBM® Workload Scheduler: Planning and Installation.

# Auditing facilities

Describes the audit facilities to track changes in the database and the plan, as well as those that track changes to objects involved in dynamic workload scheduling.

In the Dynamic Workload Console, operators and schedulers can review all changes to scheduling objects, both in the database and in the plan, discover which user performed a specific change, and when the change was performed.

Administrators can request that each user provide a justification when making changes to an object and log this information

in audit trails. Application developers and schedulers can compare and restore previous versions of each changed object, and promote the job workflow from development to test or production environments.

For more information, see the section about keeping track of changes in Dynamic Workload Console User's Guide.

Audit trails are useful to check enforcement and effectiveness of IT controls, for accountability, and vulnerability and risk analysis. IT organizations can also use auditing of security-related critical activities to aid in investigations of security incidents. When a security incident occurs, audit trails enable analysis of the history of activities (who did what, when, where, and how) that occurred prior to the security incident, so appropriate corrective actions can be taken. For these reasons, audit trails might need to be archived and accessible for years.

For more information about maintaining audit trails, see Database and plan audit on page 364.

# Database and plan audit

An auditing option is available to track changes to the database and the plan. It is disabled by default. It is described in these sections:

- Enabling and storing audit trails on page 364  
Audit log header format on page 366  
Audit log body format on page 367  
- Sample audit log entries on page 371

# Enabling and storing audit trails

You can maintain audit trails for information stored in the database and in the plan. By default, auditing is enabled. To disable auditing, use the following global options:

# enDbAudit

Enables auditing of the information available in the database.

# enPlanAudit

Enables auditing of the information available in the plan.

For more information about global options, see Global options - detailed description on page 27.

You can store auditing information in a file, in the IBM® Workload Scheduler database, or in both. To define in which type of store to log the audit records, use the auditStore global option. For more information about global options, see Global options - detailed description on page 27. When auditing database information, all the user modifications are logged, including the current definition of each modified database object. If an object is opened and saved, the action is logged even if no modification was made. When auditing plan information, all the user modifications to the plan are logged. Actions are logged whether or not they are successful.

Choose the storage location of audit records according to the type of information you are auditing, whether it is database or plan:

# auditing of the information available in the database (enDbAudit global option)

You can track changes to the database in a file, in the database itself, or in both. To define which type of store to log the audit records, use the auditStore global option. For more information about global options, see Global options - detailed description on page 27. All the user modifications are logged, including the current definition of each modified database object. If an object is opened and saved, the action is logged even if no modification was made.

# auditing of the information available in the plan (enPlanAudit global option)

You can track changes to the plan in a file. When you enable auditing of the information available in the plan, the information is saved to a file. All the user modifications to the plan are logged. Actions are logged whether or not they are successful.

# Storing auditing information in a file (auditStore=file)

This storage location is available when you audit information in the database (enDbAudit global option) and in the plan (enPlanAudit global option). Choose to store auditing information in a file by setting the auditStore global option to file. For more information about the auditStore global option, see Global options - detailed description on page 27.

Each audit log provides audit information for one day, from 00:00:00 UTC to 23:59:59 UTC regardless of the time zone of the local workstation, but the log file is created only when an action is performed or the WebSphere Application Server Liberty is started.

The files are called _yyyymmdd, and are created in the following directories:

```txt
<TWA_home>/TWS/audit/plan <TWA_home>/TWS/audit/database
```

Audit entries are logged to a flat text file in . json format on the master domain manager and backup master domain manager.

The log formats are the same for both plan and database. The logs consist of a header portion which is the same for all records, an action ID, and a section of data that varies according to the action type. All data is kept in clear text and formatted to be readable and editable from a text editor such as vi or notepad.

For more information about the details available in the logs, see Audit log header format on page 366 and Audit log body format on page 367.

![](images/3376cd6618168c2bad435839c4ab5b0ce292902c2d7badcd30466cdd8c48b66d.jpg)

Note: For modify commands, two entries are made in the log for resources, calendars, parameters, and prompts. The modify command is displayed in the log as a combination of the delete and add commands.

See the following example of a . json file:

```jsonl
{"timestamp": "20210917062859", "auditType": "CONMAN", "objectType": "PLWKSTN", "actionType": "MODIFY", "workstationName": "WA_DWB", "userName": "wauser", "frameworkUser": "", "objectName": "WA_DWB", "actionDependentContents": "link @;noask"}
```

# Storing auditing information in the database (auditStore  $\equiv$  db)

This storage location is available when you audit information in the database (enDbAudit global option). Choose to store auditing information in the database by setting the auditStore global option to db. For more information about the auditStore global option, see Global options - detailed description on page 27.

The AUDIT_STORE_RECORDS_V table is created in the IBM Workload Scheduler database.

For more information, see the section about the AUDIT_STORE_RECORDS_V table in IBM Workload Scheduler: Database Views.

# Storing auditing information both in the database and in a file (auditStore=both)

This storage location is available when you audit information in the database (enDbAudit global option). Choose to store auditing information both in the database and in a file by setting the auditStore global option to both. For more information about the auditStore global option, see Global options - detailed description on page 27.

For details about how the information is stored, see Storing auditing information in the database (auditStore=db) on page 366 and Storing auditing information in a file (auditStore=file) on page 365.

# Audit log header format

Each log file starts with a header record that contains information about when the log was created and whether it is a plan or database log.

The header record fields are separated by a colon ( : ), as follows:

```textproto
HEADER: <GMT_date>: <GMT_time>: <local_date>: <local_time>: <object_type>: > <workspace>: <user_ID>: <version>: <level>
```

Log Type

HEADER

GMT Date

The GMT date when the log file was created.

GMT Time

The GMT time when the log file was created.

Local Date

The local date when the log file was created. The local date is defined by the time zone option of the workstation.

Local Time

The local time when the log file was created. The local time is defined by the time zone option of the workstation.

# Object Type

DATABASE for a database log file and PLAN for a plan log file.

# Workstation Name

The IBM Workload Scheduler workstation name for which this file was created. Each workstation in the IBM Workload Scheduler network creates its own log.

# User ID

The IBM Workload Scheduler user ID that created the log file.

# Version

The version of the file.

# Level

The logging level.

# Audit log body format

The audit log formats are basically the same for the plan and the database. The log consists of a timestamp, a series of tags which identify the audit, object, and action type, and data sections that vary with the action type. The data is in clear text format and each data item is separated by a comma (,).

The log file entries are in the following format:

```javascript
"timestamp":"timestamp", "auditType":"audit_type", "objectType":"object_type", "actionType":"action_type", "frameworkUser":"framework_user", "objectName":"object_name", "actionDependentContents":"action-dependent_fields"
```

The log files contain the following information:

# timestamp

Displays the date and time the action was performed in GMT time. The format is yyyy-mm-dd:hh-mm-ss.

# auditType

Displays an eight-character value indicating the source of the log record. The following log types are supported:

# CONMAN

conman command text

# DATABASE

Database action

# HEADER

The log file header

# MAKESEC

makesec run

# PARMS

Parameter command text

# PLAN

Plan action

# RELEASE

release command text

# STAGEMAN

stagemar run

# objectType

Displays the type of the object that was affected by an action, from the following:

# DATABASE

Database definition (for header only)

# DBCAL

Database calendar definition

# DBDOMAIN

Database domain definition

# DBJBSTRM

Database Job Scheduler definition

# DBJOB

Database job definition

# DBPARM

Database parameter definition

# DBPROMPT

Database prompt definition

# DBRES

Database resource definition

# DBSEC

Database security

# DBUSER

Database user definition

# DBVARTAB

Database variable table definition

# DBWKCLS

Database workstation class definition

# DBWKSTN

Database workstation definition

# PLAN

Plan (for header only)

# PLDOMAIN

Plan domain

# PLFILE

Plan file

# PLJBSTRM

Plan Job Scheduler

# PLJOB

Plan job

# PLPROMPT

Plan prompt

# PLRES

Plan resource

# PLWKSTN

Plan workstation

# actionType

Displays what action was performed on the object. The appropriate values for this field are dependent on which action is being performed.

For the plan, the "action_type" can be ADD, DELETE, MODIFY, or INSTALL.

For the database, the ADD, GET, DELETE and MODIFY actions are recorded for workstation, workstation classes, domains, users, jobs, job streams, calendars, prompts, resources and parameters in the database.

The "actionType" field also records the installation of a new Security file. When makesec is run, IBM Workload Scheduler records it as an INSTALL action for a Security definition object.

LIST and DISPLAY actions for objects are not logged.

For parameters, the command line with its arguments is logged.

# workspaceName

Displays the IBM Workload Scheduler workstation from which the user is performing the action.

# userName

Displays the logon user who performed the particular action. On Windows® operating systems, if the user who installed WebSphere Application Server Liberty was a domain user, for Log Types stageman and conman this field contains the fully qualified user ID domain\user.

# frameworkUser

Displays the framework user.

# objectName

Displays the fully qualified name of the object. The format of this field depends on the object type as shown here:

# DATABASE

N/A

# DBCAL

"calendar"

# DBDOMAIN

"domain"

# DBJBSTRM

"workstation"# "job_STREAM"

# DBJOB

"workstation"# "job"

# DBPARM

"workstation"#"parameter"

# DBPROMPT

"prompt"

# DBRES

"workstation"#"resource"

# DBSEC

N/A

# DBUSER

["workspace"#] "user"

# DBVARTAB

"variable_table"

# DBWKCLS

"workstation_class"

# DBWKSTN

"workstation"

# PLAN

N/A

# PLDOMAIN

"domain"

# PLFILE

"workspace"#path("qualifier")

# PLJBSTRM

"workstation"#"job_STREAM_instance"

# PLJOB

"workflow"#"job_STREAM_instance"."job"

# PLPROMPT

["workstation"#]"prompt"

# PLRES

"workstation"#"resource"

# PLWKSTN

"workstation"

# actionDependentContents

Displays the action-dependent data fields. The format of this data is dependent on the "actionType" field.

# Sample audit log entries

This is a sample database audit log:

```txt
HEADER |20080207|084124|20080207|094124|DATABASE| |WK1| | |Version=A1.0| Level=1  
DATABASE|20080207|084124|20080207|094124|DBRES |ADD |WK1|operator1| res=WK1#RESOURCE  
DATABASE|20080207|100524|20080207|110524|DBWKSTN |MODIFY|WK1|operator1| ws=TIVOLI10  
DATABASE|20080207|100525|20080207|110525|DBWKSTN |MODIFY|WK1|operator1| ws=ASLUTRI1  
DATABASE|20080207|100525|20080207|110525|DBWKSTN |MODIFY|WK1|operator1| ws=WK1
```

```txt
DATABASE|20080207|100526|20080207|110526|DBDOMAIN|MODIFY|WK1|operator1| |dom=MASTERDM  
DATABASE|20080207|100610|20080207|110610|DBWKSTN |MODIFY|WK1|operator1| |ws=TIVOLI10  
DATABASE|20080207|100610|20080207|110610|DBWKSTN |MODIFY|WK1|operator1| |ws=ASLUTRI1  
DATABASE|20080207|100611|20080207|110611|DBWKSTN |MODIFY|WK1|operator1| |ws=WK1  
DATABASE|20080207|100611|20080207|110611|DBWKSTN |ADD |WK1|operator1| |ws=WK2  
DATABASE|20080207|100612|20080207|110612|DBDOMAIN|MODIFY|WK1|operator1| |dom=MASTERDM
```

This is a sample plan audit log:

```txt
HEADER |20080207|100758|20080207|110758|PLAN | |WK1|admin | |Version=A1.0|Level=1  
STAGEMAN |20080207|100758|20080207|110758|PLAN |INSTALL|WK1|admin | C:\IBM\TWS\oper1\Symphony|AWSBHV030I The new Symphony file is installed.  
STAGEMAN |20080207|100758|20080207|110758|PLAN |INSTALL|WK1|admin | C:\IBM\TWS\oper1\Sinfonia|AWSBHV036I Multi-workstation Symphony file copied to C:\IBM\TWS\oper1\Sinfonia  
STAGEMAN |20080207|100758|20080207|110758|ADITLEVL|MODIFY |WK1|admin | AWSBHV077I Audit level changing from 0 to 1.  
CONMAN |20080207|100800|20080207|110800|PLWKSTN |MODIFY | |admin | WK1 continue & start  
CONMAN |20080207|100941|20080207|110941|PLWKSTN |MODIFY | |admin | SLUTRI1 limit cpu=slutri1;10  
PLAN |20080207|101018|20080207|111018|PLWKSTN |MODIFY |WK1|oper1 | WK1 limit cpu=SLUTRI1;20  
PLAN |20080207|101028|20080207|111028|PLDOMAIN|MODIFY |WK1|oper1 | ECCOLO reply ECCOLO;yes
```

A ResetPlan command run against the current production plan is stored in the plan audit log file as follows:

```txt
STAGEMAN|20080207|100758|20080207|110758|PLAN|DELETE|WK1|admin|  
//home/WK1/schedlog/M200803140127|  
AWSBHV025I The old Symphony file renamed /home/WK1/schedlog/M200803140127
```

# Enabling audit for authentication events

This topic explains how to enable audit for authentication events.

To enable audit for authentication events, proceed as follows:

1. Goto <DWC_DATA_dir>/usr/server/dwcServer/configDropins/overrides

![](images/473487a6b3bb57e92808707af9f1391cc7b24b68f7b80aa09d6de3d550a97005.jpg)

Note: On Windows systems, the path is: <DWC_home>\usr\servers\dwcServer\configDropins

\oversides

2. Create a file named auditing.xml and paste the following content:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<server>
<!-- Enable features -->
<featureManager>
<feature>audit-1.0</feature>
</featureManager>
<!-- Enabling Audit Filehandler--">
<auditFileHandler maxFiles="100" maxFileSize="10" compact="true">
<events name="AuditEvent_1" eventName="SECURITY_AUTHN" outcome="SUCCEED"/> 
<events name="AuditEvent_2" eventName="SECURITY_AUTHN" outcome="REDIRECT"/> 
<events name="AuditEvent_3" eventName="SECURITY_AUTHN" outcome="DENIED"/> 
</auditFileHandler>
</server>
```

3. Stop and start WebSphere Application Server Liberty. For further information about the stop and start commands, see Application server - starting and stopping on page 423.  
4. Access the Dynamic Workload Console.

You successfully enabled the audit for authentication events. To see the authentication logs, open the audit.log file located at the following path:

On Windows operating systems

TWA_home> \stdlib\appserver\dwcServer\logs

On UNIX operating systems

<TWA_DATA_DIR>/stdlib/appserver/dwcServer/logs

For further information about audit logs, see WebSphere Application Server Liberty documentation.

# Keeping track of database changes using audit reports

To keep always track of the changes that impact objects stored in the database, you can use the following audit reports, which can be run in batch mode using the command line interface:

General audit report

The report provides information about objects that have been modified in the database. More specifically, it details who made the change, on which objects, and when.

# Details report

The report provides further details about the changes implemented. It specifies who made the change, on which objects, when, and what has been changed. More specifically it shows the object definition before and after the change.

You can run these reports on DB2 and Oracle databases.

# A sample business scenario

The administrator of an insurance company needs to keep track of all the changes impacting the insurance policies, conditions and terms of all the customers registered in the company database. To do it, the administrator periodically runs the audit general and details reports.

To satisfy this request, he creates an audit general report that provides details about which TWS objects have been modified in the database, who modified them and on which date. Then, to find out more details about the changes, he also creates an audit details report.

To accomplish his task, he runs the following steps:

1. He customizes the property files related to the audit reports, specifying the format and content of the report output.  
2. He schedules jobs to obtain the reports:

a. The first job generates an audit to be saved locally.  
b. The second job runs a detail report overnight to retrieve more details about the specific changes implemented. The report output is sent using an mail to the analyst. The information collected is used to keep all the insurance branch offices updated with any change and news.

3. The administrator adds the two jobs to a job stream scheduled to run weekly and generates the plan.

# Setting up for command line audit reporting

# About this task

Before running these reports you must perform a few setup steps:

1. The software needed to run these reports is contained in a package named TWSBatchReportCLI included in the IBM Workload Scheduler installation image, in the TWSBatchReportCLI directory. If you plan to run them from within a scheduled job, extract the package file on one of the operating systems listed at Dynamic Workload Console Detailed System Requirements.

After extracting the package, you obtain the following file structure:

config  
Jars  
jre  
License  
L notification  
properties  
ReportEngine  
reports  
ssl  
common Logging.properties  
copyright  
license_en.txt  
 notices.txt  
readme.txt  
reportcli.cmd  
reportcli.sh

Because the native UNIX™ tar utility does not support long file names, if you are extracting the files on AIX® systems, ensure that the latest GNU version of tar (gtar) is installed to extract the files successfully.

![](images/032d5473985a70fc869e522842c7579297e676ad93e5212c56c7ea750715c32d.jpg)

# Note:

a. Make sure you run the following commands in the directory where you extracted the files:

# On UNIXTM

```batch
chmod -R  $^+$  x\* chown -R username \*
```

# On WindowsTM

Ensure IBM Workload Scheduler is installed.

```txt
setown -u username \*
```

Where username is the IBM Workload Scheduler user that will run the reports.

b. If you plan to schedule jobs that run these reports, the system where you extract the package must be accessible as network file system from a fault-tolerant agent defined in the local scheduling environment.

2. If you use an Oracle database, download the JDBC drivers required by your Oracle server version.

3. Copy the JDBC drivers in the reportCLI_installation_dir\jars directory and in

report_client_installation_dir\ReportEngine\plugins

\org.eclipse.birt.report.data.oda.jdbc_4.2.1.v20120820\drivers directory. The report cli automatically discovers the two jar files.

4. Configure the template file .config\common.properties by specifying the following information.

a. If you use an Oracle database, connect to the database where the historical data are stored as follows:

i. Retrieve the location of the Oracle JDBC drivers. This information is stored in the

com.ibm.tws.webui.OracleJdbcURL property in the TWSConfig.properties file, located in

On Windows operating systems

<TWA_home>\usr\server\engineServer\resources\properties

On UNIX operating systems

<TWA_DATA_DIR>/usr/server/engineServer/resources/properties

For more information about this file, see Configuring for an Oracle database on page 175.

ii. Specify the location of the Oracle JDBC drivers in the PARAM_DataSourceUrl property in the common.properties file.

No customization is required if you use DB2.

b. Set the date and time format, including the time zone. The file .config\timezone.txt contains a list of time zones supported by IBM Workload Scheduler and the information on how to set them. The time zone names are case sensitive.  
c. Make the report output available on the URL specified in ContextRootUrl field. This is an example of the configuration settings:

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #

HTTP Server information

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #

Specify the context root where the report will be available

To leverage this possibility it needs to specify in the report output dir

#the directory that is referred by your HTTP Server with this contact root

ContextRootUrl  $\equiv$  http://myserver/reportoutput

In this case, en sure that the output_report_dir specified when running the reports command points to the same directory specified in the ContextRootUrl.

d. Send the report output using a mail. This is an example of the configuration settings:

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #

Email Server configuration

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #

PARAM_SendReportByEmail=true

SMTP server

mailsmtp.host  $\equiv$  myhost.mydomain.com

#IMAP provider

mail.imap(socketFactory+fallback=false

mail.imap.port=993

mailimap(socketFactory.port=993

POP3 provider

```txt
mail.pop3(socketFactory+falsback=false   
mail.pop3.port  $= 995$    
mail.pop3(socketFactory.port  $= 995$    
#Emailproperties   
############   
PARAM_EmailFrom  $\equiv$  user1@your_company.com   
PARAM_EmailTo  $\equiv$  user2@your_company.com, user3@your_company.com   
PARAM_EmailCC  $\equiv$  user4@your_company.com   
PARAM_EmailBCC  $\equiv$  user5@your_company.com   
PARAM_EmailSubject  $\equiv$  Test send report by email   
PARAM_EmailBody  $\equiv$  This is the report attached
```

An explanation of all the customizable fields is contained in the template file.

# Running audit reports from the command line

To run audit report on the database, you must first enable the audit feature and configure the audit options described in Global options - detailed description on page 27.

The \reports\templates directory contains a sample template file for each type of report.

Before running any of these reports, ensure that you customize the corresponding template file, either ad.properties or ag.properties.

In that file, named report_name.properties, you can specify:

- The information to display in the report header.  
- How to filter the information to display the expected result.  
- The format and content of the report output.

For more information about the specific settings see the explanation provided in the template file beside each field.

After you set up the environment as it is described in Setting up for command line audit reporting on page 374, and you configured report template file, use the following syntax to run the report:

```shell
reportcli -p report_name.property  
[-o output_report_dir]  
[-r report_output_name]  
[-k key=value]  
[-k key=value]
```

where:

-p report_name.property

Specifies the path name to the report template file.

- o output_report_dir

Specifies the output directory for the report output.

-r report_output_name

Specifies the name of the report output.

-k key=value

Specifies the value of a settings. This value override the corresponding value, if defined, in the common.properties file or in the report_name.properties file.

# Examples

1. In this example the reportcli.cmd is run with the default parameter:

```batch
reportcli.cmd -p D:\ReportCLI\TWSReportCLI\reports\templates\ag.properties -r audit1
```

2. In this example the reportcli.cmd is run using the -k parameter to override the values set for PARAM_DateFormat in the .\config\common.properties file:

```batch
reportcli.cmd -p D:\ReportCLI\TWSReportCLI\reports\templates\ag.properties  
-r audit2 -k PARAM_DateFormat=short
```

3. In this example the reportcli.cmd is run using the -k parameter to override the format specified for the report output in the .properties file:

```shell
./reportcli.sh -p /TWSReportCLI/REPORTLI/reports/templates/wwr.properties  
-r audit3 -k REPORT_OUTPUT.format=htm1 -k OutputView=charts
```

![](images/aaac8132a8be57f139fe94673dfe6fe2915a27d1ac98f4e4c247ba262bd391c1.jpg)

Note: If the report is run through a IBM Workload Scheduler job, the output of the command is displayed in the job output.

# Collecting job metrics

You can run the following SQL queries on the Workload Scheduler data base to retrieve the number of jobs run by IBM Workload Scheduler over a period of time. One query determines the number of jobs run by specific workstations, while the other query determines the number of jobs run on the entire IBM Workload Scheduler domain. You can run the queries from the command line interface of your database or you can add them in the Dynamic Workload Console to create your custom SQL reports, as described in section creating a task to create custom SQL reports in Dynamic Workload Console User's Guide.

# Job metrics queries for DB2

Use the following SQL query to find the number of jobs run on specific workstations:

```sql
SELECT year(job_run_date_time) AS Year, month(job_run_date_time) AS Month, cast (count(job_run_date_time) AS INT) AS JobNbr FROM mdl.job_history_v WHERE workstation_name IN ('WKS_1', 'WKS_2', 'WKS_N')  
GROUP BY year(job_run_date_time), month(job_run_date_time)
```

where 'WKS_1', 'WKS_2', 'WKS_N' are the names of the workstations that ran the jobs you want counted.

Use the following SQL query to find the number of jobs run on the entire IBM Workload Scheduler domain:

```sql
SELECT year(job_run_date_time) AS Year, month(job_run_date_time) AS Month, cast (count(job_run_date_time) AS INT) AS JobNbr FROM mdl.job_history_v GROUP BY year(job_run_date_time), month(job_run_date_time)
```

# Job metrics queries for DB2 for zOS

Use the following SQL query to find the number of jobs run on specific workstations:

```sql
SELECT year(job_run_date_time) AS Year, month(job_run_date_time) AS Month, cast (count(job_run_date_time) AS INT) AS JobNbr FROM mdl.job_history_v WHERE workstation_name IN ('WKS_1', 'WKS_2', 'WKS_N') GROUP BY year(job_run_date_time), month(job_run_date_time)
```

where 'WKS_1', 'WKS_2', 'WKS_N' are the names of the workstations that ran the jobs you want counted.

Use the following SQL query to find the number of jobs run on the entire IBM Workload Scheduler domain:

```sql
SELECT year(job_run_date_time) AS Year, month(job_run_date_time) AS Month, cast (count(job_run_date_time) AS INT) AS JobNbr FROM mdl.job_history_v GROUP BY year(job_run_date_time), month(job_run_date_time)
```

# Job metrics queries for Oracle database

Use the following SQL query to find the number of jobs run on specific workstations:

```sql
SELECT EXTRACT(year FROM job_run_date_time) AS Year,  
EXTRACT(month FROM job_run_date_time) AS Month,  
cast (count(job_run_date_time) AS INT) AS JobNbr FROM job_history_v  
WHERE workstation_name IN ('WKS_1', 'WKS_2', 'WKS_N')  
or (workstation_name = '-' and JOB_STREAM_WKS_NAME_IN RunsIn('WKS_1', 'WKS_2', 'WKS_N'))  
GROUP BY EXTRACT(year FROM job_run_date_time), EXTRACT(month FROM job_run_date_time);
```

where 'WKS_1', 'WKS_2', 'WKS_N' are the names of the workstations that ran the jobs you want counted.

Use the following SQL query to find the number of jobs run on the entire IBM Workload Scheduler domain:

```sql
SELECT EXTRACT(year FROM job_run_date_time) AS Year,  
EXTRACT(month FROM job_run_date_time) AS Month,  
cast (count(job_run_date_time) AS INT) AS JobNbr FROM job_history_v  
GROUP BY EXTRACT(year FROM job_run_date_time), EXTRACT(month FROM job_run_date_time);
```

# Chapter 8. Administrative tasks

This chapter describes how to perform some specific administrative tasks on IBM Workload Scheduler, as follows:

# The tasks

# Switching a domain manager on page 381

Change a domain manager or dynamic domain manager, either in the event of the failure of the computer where it is installed, or as part of a planned replacement activity.

# Switching the master to a backup on page 387

Change a master domain manager, either in the event of the failure of the computer where it is installed, or as part of a planned replacement activity.

# Changing key IBM Workload Scheduler passwords on page 402

Change the password of the <TWS_user>, or any other of the users that have an infrastructure role in IBM Workload Scheduler.

# Unlinking and stopping IBM Workload Scheduler on page 407

The correct procedure to unlink the master domain manager from its agents and stop the master processing.

# Changing the properties for the database on page 408

If you need to change the host, port or name of the database, effect the change in the application server, where the data source configuration is maintained.

# Changing the workstation host name or IP address on page 411

Change the host name or IP address of a workstation.

# Changing the security settings on page 415

If you need to update the properties that define your SSL connection or authentication mechanism, you need to make the changes in the WebSphere Application Server Liberty.

# Managing the event processor on page 416

If you are using event-driven workload automation, you will need to perform periodic maintenance on the event processor.

# Application server tasks

The following tasks might need to be performed on the application server:

# Application server - starting and stopping on page 423

How to stop and start the application server when you need to.

# Application server - automatic restart after failure on page 424

The application server is managed by a utility that restarts it if it stops for any reason (subject to a configurable policy). This section describes how to modify the policy and deal with any situations that the policy cannot handle.

# Application server - encrypting the profile properties files on page 427

Several of the application server configuration files contain passwords. To avoid that these remain in the files in plain text, run a utility to encrypt them.

# Application server - configuration files backup and restore on page 428

The application server configuration manages the data source and security aspects of your IBM Workload Scheduler environment. The files should be regularly backed up and when necessary can be restored.

# Application server - changing the host name or TCP/IP ports on page 428

If you need to change the host or ports used by the application server, follow the correct procedure.

# Application server - changing the trace properties on page 428

The application server has a trace facility. This section describes how to increase the trace level to obtain more information for troubleshooting, and how to reduce the level to improve performance.

# Changing the application server properties

Several of the above tasks require you to run a common procedure based on templates whereby you:

1. Copy the template file from the templates folder to a working folder.  
2. Edit the template file in the working folder with the desired configuration.  
3. Optionally, create a backup copy of the relevant configuration file present in the overrides directory in a different directory. Ensure you do not copy the backup file in the path where the template files are located.  
4. Copy the updated template file to the overrides folder. Maintaining the original folder structure is not required.  
5. Changes are effective immediately.

This procedure is fully described in Configuring IBM Workload Scheduler using templates on page 418.

# Switching a domain manager

# About this task

Being prepared for network problems makes recovery easier. Set up a backup domain manager for each domain manager in your network to more easily ensure that IBM Workload Scheduler peak job scheduling loads are met. Choose any fault-tolerant agent in the domain to be a backup domain manager.

A domain manager might need to be changed because you want it to run on a different workstation, or it might be forced on you as the result of network linking problems or the failure of the domain manager workstation itself. This section, and its subsections, describes how to prepare for and use a backup domain manager. However, if the domain manager to be

changed is a master domain manager or dynamic domain manager, there are some specific additional steps to perform; see Switching the master to a backup on page 387.

Running without a domain manager has the following effects:

- Agents and subordinate domain managers cannot resolve inter-workstation dependencies, because activity records broadcast by the master domain manager are not being received.  
- The upward flow of events is interrupted. This impacts events that report the status of jobs, job streams and dependencies defined on workstations in the IBM Workload Scheduler network hierarchy under the failed domain manager.  
- Standard agents that are hosted by the failed domain manager cannot perform any processing, since they depend on the domain manager for all scheduling and job launching.

If the problem is expected to be of short duration, you can wait for the problem to be resolved and IBM Workload Scheduler will recover on its own, as described in the Troubleshooting Guide in the section about network linking problems. If you are uncertain about the duration, or if you want to restore normal agent operation, you must switch to a backup, as described in the following sections.

Ensure that the FullStatus mode is selected in the backup workstation definition. For more information about workstation properties, see the section about workstation definition in User's Guide and Reference.

Also ensure that the backup domain manager is synchronized with respect to time with the domain manager. The most secure way is to use a Network Time Protocol Server to control the time on both systems, with the same repeat interval.

Network security is enforced using IP address validation. As a consequence, workstation linking (autolink option or link command) might fail if an agent has an old Symphony file that does not contain the new domain manager. If a connection fails, remove the old Symphony file on the agent and retry the connection.

For more information about the autolink option, see the section about workstation definition in User's Guide and Reference.

For more information about the link command, see the section about the link command in User's Guide and Reference.

# Simplified procedure for switching a domain manager

Use one of these procedures when you have a short-term loss of a domain manager.

# Using the command line

See the procedure described under the switchmgr command in User's Guide and Reference.

# Using the Dynamic Workload Console

1. In the navigation bar at the top, click Monitoring and Reporting > Orchestration Monitor.  
2. Select an engine.  
3. From the drop-down menu, select Workstation.  
4. From the Query drop-down list, select a query to monitor workstations.

5. Click Run to run the monitoring task.  
6. From the table containing the list of workstations, select a workstation and click More Actions >

# Become Master Domain Manager.

Domain managers remain switched until you perform another switch manager operation, or run JnextPlan. To return to the original domain manager without running JnextPlan, repeat this procedure.

Here is the procedure to follow every time you switch the master domain manager or dynamic domain manager if you run dynamic scheduling in your network:

1. Set the job fence to go priority level. For further details, see the fence command in User's Guide and Reference.  
2. Switch the master domain manager or dynamic domain manager to a backup workstation. Use either the conman switchmgr command or the Dynamic Workload Console. For more information about both methods, see the procedure described under the switchmgr command in User's Guide and Reference.  
3. Once the switch has been performed, restore the job fence to zero. For further details, see the fence command in User's Guide and Reference.

# Complete procedure for switching a domain manager

This section summarizes the steps required to replace a running domain manager with its backup and to complete the procedure by restoring the original domain manager to its function. Follow these steps to make sure that no overlapping problems arise with obsolete versions of the Symphony file. You can also follow these steps to switch a master domain manager or a dynamic domain manager. The steps are documented for four scenarios:

# Planned outage

The domain manager is replaced with its backup for planned maintenance work (for example, an upgrade of the operating system).

# Unplanned outage

The domain manager is replaced with its backup because of an unexpected failure or malfunction.

# Short-term

The domain manager is expected to return to service before the next new production period turnover (run of the JnextPlan job).

# Long-term

The domain manager is not expected to return to service before the next new production period turnover (run of the JnextPlan job).

Table 66. Complete procedure for switching a domain manager in case of a planned outage.  

<table><tr><td colspan="2">Planned outage</td></tr><tr><td>Short-term</td><td>Long-term</td></tr><tr><td>1. Switch the domain manager to a backup workstation.Use either the conman switchmgr command or the</td><td>1. Switch the domain manager to a backup workstation. Useeither the conman switchmgr command or the Dynamic Workload</td></tr></table>

Table 66. Complete procedure for switching a domain manager in case of a planned outage. (continued)  

<table><tr><td colspan="2">Planned outage</td></tr><tr><td>Dynamic Workload Console. For more information about both methods, see the Switching a master domain manager or dynamic domain manager chapter in the Administration Guide.
2. Check that the message boxes for the domain manager undergoing maintenance are large enough not to fill up before it is restored. Increase their size if necessary.</td><td>Console. For more information about both methods, see the Switching a master domain manager or dynamic domain manager chapter in the Administration Guide.
2. Check that the message boxes for the domain manager undergoing maintenance are large enough not to fill up before it is restored. Increase their size if necessary.</td></tr><tr><td>3. Shut down IBM Workload Scheduler processing on the domain manager undergoing maintenance.</td><td>3. Shut down IBM Workload Scheduler processing on the original domain manager undergoing maintenance.</td></tr><tr><td rowspan="3"></td><td>4. In the IBM Workload Scheduler database assign the role of domain manager to the backup workstation. This is done by changing the workstation type in the database from MANAGER to FTA on the original domain manager and from FTA to MANAGER on the backup.</td></tr><tr><td>5. Set the workstation running the original domain manager to ignore, using either the composer mod cpu &lt;workstation_name&gt; command or the Dynamic Workload Console.</td></tr><tr><td>6. Run JnextPlan to generate the new production plan so that the backup master domain manager is removed from the plan.</td></tr><tr><td rowspan="3">When ready to restore the ownership of the domain to the original domain manager:</td><td>When ready to restore the ownership of the domain to the original domain manager:</td></tr><tr><td>7. Remove the ignore flag from the workstation running the original domain manager.</td></tr><tr><td>8. Run JnextPlan to generate the new production plan so that the backup master domain manager is reinserted in the plan.</td></tr><tr><td>4. Switch from the backup workstation to the domain manager using one of the methods indicated in step 1.</td><td>9. Reassign ownership of the domain to the original domain manager in the IBM Workload Scheduler database. This is done by changing the workstation type in the database from MANAGER to FTA on the original backup and from FTA to MANAGER on the original domain manager</td></tr><tr><td>5. Link the domain manager from the master to download a fresh version of the Symphony file.</td><td>10. Optional: In the original domain manager, remove the comman start command from the init procedure and delete any existing copies of the Symphony, Sinfonia, and message box files.</td></tr></table>

Table 66. Complete procedure for switching a domain manager in case of a planned outage. (continued)  

<table><tr><td colspan="2">Planned outage</td></tr><tr><td rowspan="3"></td><td>Note: This step is recommended to avoid that any outdated symphony present in the computer is automatically triggered at the first startup. You can add conman start again later.</td></tr><tr><td>11. Switch from the backup workstation to the domain manager using one of the methods indicated in step 1.</td></tr><tr><td>12. Link the domain manager from the master to download a fresh version of the Symphony file.</td></tr></table>

Table 67. Complete procedure for switching a domain manager after an unplanned outage.  

<table><tr><td colspan="2">Unplanned outage</td></tr><tr><td>Short-term</td><td>Long-term</td></tr><tr><td>1. Switch the domain manager to a backup workstation. Use either the conman switchmgr command or the Dynamic Workload Console. For more information about both methods, see the switchmgr command in User&#x27;s Guide and Reference.2. Check that the message boxes for the failing domain manager are large enough not to fill up before it is restored. Increase their size if necessary.</td><td>1. Switch the domain manager to a backup workstation. Use either the conman switchmgr command or the Dynamic Workload Console. For more information about both methods, see the switchmgr command in User&#x27;s Guide and Reference.2. Check that the message boxes for the failing domain manager are large enough not to fill up before it is restored. Increase their size if necessary.</td></tr><tr><td rowspan="3"></td><td>3. In the IBM Workload Scheduler database assign the role of domain manager to the backup workstation. This is done by changing the workstation type in the database from MANAGER to FTA on the original domain manager and from FTA to MANAGER on the backup.</td></tr><tr><td>4. Set the workstation running the failing domain manager to ignore, using either the composer mod cpu &lt;workstation_name&gt; command or the Dynamic Workload Console.</td></tr><tr><td>5. Run JnextPlan to generate the new production plan so that the backup master domain manager is removed from the plan.</td></tr><tr><td>When ready to restore the ownership of the domain to the original domain manager:</td><td>When ready to restore the ownership of the domain to the original domain manager:</td></tr></table>

Table 67. Complete procedure for switching a domain manager after an unplanned outage. (continued)  

<table><tr><td colspan="2">Unplanned outage</td></tr><tr><td rowspan="2">3. Optional: 
·A. In the original domain manager, remove the conman start command from the init procedure and delete any existing copies of the Symphony, Sinfonia, and message box files. 
Note: This step is recommended to avoid that any outdated symphony present in the computer is automatically triggered at the first startup. You can add conman start again later. 
B. After an unplanned outage, the fault-tolerant agent needs a new Symphony file. Perform the following steps on the current master domain manager: 
·i. Verify that the current master domain manager is linked to all agents except the old master domain manager. 
·ii. Shut down all IBM® Workload Scheduler processes (unlink from all agents). 
·iii. Rename Sinfonia as Sinfonia.org. 
·iv. Copy Symphony to Sinfonia. 
You now have identical Symphony and Sinfonia files.</td><td>6. Remove the ignore flag from the workstation running the original domain manager.</td></tr><tr><td>7. Run JnextPlan to generate the new production plan so that the backup master domain manager is reinserted in the plan.</td></tr><tr><td>4. Switch from the backup workstation to the domain manager using one of the methods indicated in step 1.</td><td rowspan="2">8. Reassign ownership of the domain to the original domain manager in the IBM Workload Scheduler database. This is done by changing the workstation type in the database from MANAGER to FTA on the original domain manager and from FTA to MANAGER on the backup.</td></tr><tr><td>5. Link the domain manager from the master to download a fresh version of the Symphony file.</td></tr></table>

Table 67. Complete procedure for switching a domain manager after an unplanned outage. (continued)  

<table><tr><td colspan="2">Unplanned outage</td></tr><tr><td rowspan="3"></td><td>9. Optional: In the original domain manager, remove the conman start command from the init procedure and delete any existing copies of the Symphony, Sinfonia, and message box files.
Note: This step is recommended to avoid that any outdated symphony present in the computer is automatically triggered at the first startup. You can add conman start again later.</td></tr><tr><td>10. Switch from the backup workstation to the domain manager using one of the methods indicated in step 1 on page 385.</td></tr><tr><td>11. Link the domain manager from the master to download a fresh version of the Symphony file.</td></tr></table>

# Switching the master to a backup

# About this task

A backup workstation for the master domain manager and another workstation for the dynamic domain manager are an essential asset to ensure business continuity and data integrity in your environment.

There are two ways in which the switchover to a backup master domain manager can occur:

# A manual, planned switchover procedure

You can switch the master domain manager to a backup master domain manager at any time, either for a short term or for a long term (the original master is not expected to return to service before the next new production period turnover), using the switchmgr command.

# An automatic failover process

Starting with version 9.5 Fix Pack 2, you can rely on the automatic failover feature, where, given a list of available backups, the workload is switched over to the backup. See Automatic failover on page 390 for more information.

When selecting a workstation to be a backup, the same rules apply to both the automatic failover and the manual switching of the master. Backup workstations must have compatible operating systems with the master and the backup master domain manager must be installed on a system that is not currently defined in the workload scheduling network. For more information about these topics see Selecting a workstation for the backup master domain manager on page 388 and Changing an agent to become a backup master domain manager on page 388.

In the following topics you can find information about how to enable the automatic failover process, and how to manually switch a master domain manager, and a dynamic domain manager for a Z controller.

If you lose or want to plan to change a master domain manager or dynamic domain manager, the same comments in the section Switching a domain manager on page 381 apply, but in addition, consider the sub-topics in this section.

# Selecting a workstation for the backup master domain manager

It is the normal process to install a backup master domain manager when you set up your scheduling network. However, if you have not done so, and decide later that you need a backup master domain manager, you have two options:

- Install a backup master domain manager on a system that is not currently in the workload scheduling network. For the detailed procedure, see the section about installing the master domain manager and backup master domain manager Planning and Installation Guide.  
- Promote an agent to backup master domain manager. This option is time-consuming and requires you to interrupt your workload scheduling activities, but if you want to do it, follow the procedure described in this section.

Regardless of the option you choose, the following are some prerequisites to consider for the backup workstation:

- Choose compatible operating systems. Since you must transfer files between the master domain manager and its backup, the workstations must have compatible operating systems. Do not combine UNIX™ with Windows™ workstations, and in UNIX™, do not combine big-endian workstations (AIX®) with little-endian workstations (most Intel™-based operating systems, including Windows™ and Linux™).

See the IBM Workload Scheduler Detailed System Requirements for details of the prerequisite requirements of a backup master domain manager.

- Ensure the master domain manager and the backup master domain manager have FullStatus turned on in the workstation definition. See Setting up a backup master domain manager on page 389  
- Copy any necessary files, such as, the security file and localots file, to the backup workstation. See Copying files to use on the backup master domain manager on page 389.

# Changing an agent to become a backup master domain manager

You cannot change an agent to become a backup master domain manager, using a command or procedure that allows continuity of workload scheduling activities.

Instead, if you need to change an agent workstation to become the backup master domain manager, you must interrupt the workload scheduling activities. The procedure is as follows:

1. Check that the workstation satisfies the prerequisites for a backup master domain manager. See IBM Workload Scheduler Detailed System Requirements for more information.  
2. If it does, stop and disable all workload scheduling operations on the workstation  
3. Uninstall the agent, following the instructions in the section about uninstalling agents in Planning and Installation Guide.  
4. Install the backup master domain manager on the system where the agent was installed, following the instructions in the section about installing the master domain manager and backup master domain manager in Planning and Installation Guide.

5. Ensure that the database entry for the workstation is correct for a backup master domain manager. See the section about workstation definition in User's Guide and Reference for information about the workstation definition  
6. Define and start any workload scheduling operations you require on the workstation in its new role.

# Setting up a backup master domain manager

Ensure that the master domain manager and the backup master domain manager have FullStatus turned on in the workstation definition. This is important if you need to resort to long-term recovery, where the backup master domain manager generates a Symphony file (runs JnextPlan). If FullStatus is not turned on, the former master domain manager shows up as a regular fault-tolerant agent after the first occurrence of JnextPlan. During normal operations, the JnextPlan job automatically turns on the FullStatus flag for the master domain manager, if it is not already turned on. When the new master domain manager runs JnextPlan, it does not recognize the former master domain manager as a backup master domain manager unless the flag is enabled. The former master domain manager does not have an accurate Symphony file when the time comes to switch back. For more information about workstation properties, see the section about workstation definition in User's Guide and Reference.

Also ensure that the backup master domain manager is synchronized with respect to time with the master domain manager. The securest way is to use a Network Time Protocol Server to control the time on both systems, with the same repeat interval.

# Copying files to use on the backup master domain manager

To back up the important master domain manager files to the backup master domain manager, use the following procedure:

1. Copy the Security file from the master domain manager to backup domain manager in the following path:

On Windows operating systems

<TWA_home> \TWS

On UNIX operating systems

TWA_DATA_DIR

Add a suffix to the file so that it does not overwrite the Security file on the backup domain manager, for example, Security_from_MDM.

2. Copy all files in the following path:

On Windows operating systems

<TWA_home>/TWS/mozart

On UNIX operating systems

TWA_DATA_DIR/mozart

3. Copy the localopts file (see Setting local options on page 48 for the location). Add a suffix to the file so that it does not overwrite the localopts file on the backup master domain manager; for example, localopts_from_MDM.

This procedure must be performed each production period, or whenever there are significant changes to any objects. It can be incorporated into a script.

In addition to these required files, you might also want to copy the following:

- Any scripts you might have written.  
- Archived Symphony files, for reference.  
- Log files, for reference.

![](images/d9152a40abd4adfea83af8b22b53d1e2c1cdbc4f1a814be0ed5adeeb25b19043.jpg)

Note: Another approach could be to place all of the above files on a separately mountable file system, that could easily be unmounted from the master domain manager and mounted on the backup master domain manager in the event of need. You would almost certainly want to backup these files in addition, to protect against loss of the separately mountable file system.

To prevent the loss of messages caused by a master domain manager error, you can use the fault-tolerant switch-manager facility.

# Automatic failover

Switching a master domain manager to a backup master domain manager.

Recovery is easy when you are prepared for potential problems. If the master domain manager becomes unavailable, to ensure continuous operations, a long-term switchmgr operation is triggered and the workload is automatically switched to an eligible backup master domain manager.

Similarly, the backup event processors automatically detect if the event processor is unavailable, and a long-term switcheventprocessor command is triggered.

This is the default behavior for a complete fresh installation of V9.5 Fix Pack 2 or later, but it can be enabled for back-level environments that are upgraded to V9.5 Fix Pack 2 or later. For more information, see Enabling automatic failover on page 392.

![](images/0eb69450e6abee648f7ab5fd0554fcf4d9f2edc4cd8e172715dbeeef324c6ab4.jpg)

Note: If you perform a fresh installation of a backup master domain manager at the V9.5 Fix Pack level in an existing back-level environment, the automatic failover feature is disabled. To enable it, follow this procedure. The feature is enabled by default for only a complete fresh installation.

You can optionally define potential backups for both the master domain manager and the event processor in two separate lists, adding preferential backups at the top of the lists. The backup engines monitor the behavior of the master domain manager and event processor to detect anomalous behavior and then attempt to recover. Each component plays a role in either detecting a failure or recovering from it:

Each backup master domain manager monitors the status of the active master domain manager.  
- The master domain manager (active or backup) is made to be self-aware. It monitors the status of its fault-tolerant agent to check on the status of processes such as, Batchman, Mailman and Jobman. If at least one of these processes are down, the master domain manager makes 3 attempts to restart them. If the 3 attempts fail, a long-term switchmgr operation is triggered and the workload is automatically switched to an eligible backup master domain manager, while the event processor remains unchanged.

- If the WebSphere Application Server Liberty goes down, the watchdog process attempts to restart it. If the attempt fails, long-term switchmgr and switcheventprocessor commands are triggered, moving both the master domain manager and event processor to their backups.  
- If the active master domain manager cannot be automatically restored within 5 minutes (the threshold after which the master is declared unavailable), then a permanent switch to a backup is automatically triggered by any of the backup candidates when one or more of the following conditions persist:

- The fault-tolerant agent, WebSphere Application Server Liberty, or both are still down.  
- The engine is unable to communicate with the database, for example, due to a network outage.

If you have defined potential backups in a list, and a switch after 5 minutes is not possible with the first backup in the list because it is unavailable, then an attempt is made to contact the remaining backups in the list, following the order specified in the list, until an available backup is found to perform the switch. In this case, 5 minutes pass between each attempt.

The list for potential event processor backups is a separate list from the potential master domain manager backups, because you might have a workstation that can serve as the event manager backup, but you do not want it to act as a potential master domain manager backup. If the event manager fails, but the master domain manager is running fine, then only the event manager switches to a backup manager defined in the list of potential backups. The same happens if the master domain manager fails and the event manager is running fine.

You can track detected failures and the actions taken by checking the messages.log file located in the path:

<TWA_DATA_DIR>/stdlib/logm.log  
$<$  TWA_home>\TWS\stdlib\appserver\engineServer\logs\messages.log

![](images/8b5fa243bde012acbed55b223352bf78ac2cd30557c2a879b7a31a103b380ce0.jpg)

Note: On Linux® and UNIX®, for a fresh installation, an extended agent is installed with the master domain manager which is used to communicate where to run the FINAL job stream, along with its jobs. With an extended agent, $MASTER can be used to indicate that the agent's host workstation is the master domain manager. If the role of the master is switched to a backup, then the new master is represented by $MASTER. This supports both a short-term and long-term switch for the automatic failover feature. If you are upgrading from a version earlier than 9.5 Fix Pack 2, then you must define the extended agent manually.

On Windows™ workstations, the FINAL job stream is not defined on the extended agent, but remains on the master domain manager. The FINAL and FINALPOSTREPORTS job streams and jobs need to be moved from the master to the extended agent workstation. For this reason, only a short-term switch can be performed automatically and the long-term switch must be performed manually as documented in Extended loss or permanent change of master domain manager on page 397 and in Complete procedure for switching a domain manager on page 383. See

![](images/bb4f26ec68e5fbe23f30bf812f48842df3dc2ecedafecdafdc0b0512a3f3e68b.jpg)

also the switchmgr command in the User's Guide and Reference that contains both the command-line syntax, as well as the procedural steps to perform the switch from the Dynamic Workload Console.

# Enabling automatic failover

To enable automatic failover, configure one or more backup engines, and set the related global options (workstationEventMgrListInAutomaticFailover and workstationMasterListInAutomaticFailover) using the optman command, so that when the active master becomes unavailable, a long-term switchmgr operation is triggered.

# Before you begin

Ensure that the master domain manager and the back master domain managers were installed using the same user (UID) and group (GID).

# About this task

If you performed an upgrade from Version 9.5 or 9.5 Fix Pack 1, the automatic failover feature is disabled, but it can be enabled following a few simple steps outlined in this task. Automatic failover is, instead, enabled by default for a fresh installation of Version 9.5 Fix Pack 2 and later, and any backup master domain manager installed and configured with Fix Pack 2 is an eligible backup. If you subsequently disabled this feature, you can use the following procedure to re-enable it. You can also use this procedure to define a list of preferred eligible backups, excluding any backups you do not want to consider as an eligible backup. If an eligible workstation is defined in a folder, use the composer li ws @;showid command to retrieve the ID of the workstation you plan to define as backup. You can also configure a separate list of potential backups for the event processor.

1. Ensure the local option, mm resolve master, in the localizepts file, is set to no on both the master domain manager and on all eligible backup master domain managers.  
2. Optional. Define a list of potential backups for the master domain manager and the event manager.

a. Update the global option, workstationMasterListInAutomaticFailover, on the master domain manager to specify a list of workstations to be considered as eligible backups for the master domain manager. Edit the value of this option by adding a list of workstations, separated by commas, starting with your preferred choices at the top of the list. The list includes the current master domain manager. If no workstations are specified in this list, then the first backup master domain manager to detect that the master is down, performs the switch.  
b. Specify potential backups for the event processor by editing the value for the workstationEventMgrListInAutomaticFailover global option. Add a list of workstations, separated by commas, starting with your preferred choices at the top of the list. The list includes the current event manager workstation.

3. Set the following global options to "yes": enAutomaticFailover | af and enAutomaticFailoverActions | aa using the optmanchg command. For example:

optman chg af=yes

optman chg aa=yes

4. Restart WebSphere Application Server Liberty

![](images/0038e60c6ec16daa51f6de7385798d107ea31fdd62fc6072600b7e817fb03c1f.jpg)

Important: Complete the remaining steps only if they are not already present in your environment.

5. If not already present on the master domain manager, create a new workstation with the following specifications:

Type: Extended Agent  
$\circ$  Access method: unixloc1  
 Host: $MASTER

For example, if you create a workstation named, MDM_XA, with these specifications, the following is the workstation definition:

```txt
CPUNAME MDM_XA
DESCRIPTION "Workload Scheduler Virtual Master"
OS OTHER
NODE mdm_xa TCPADDR 31111
FOR MAESTRO HOST $MASTER ACCESS "unixlocl"
TYPE X-AGENT
AUTOLINK OFF
BEHINDFIREWALL OFF
FULLSTATUS OFF
END
```

6. Set the FINAL and FINALPOSTREPORTS job streams on the master domain manager to "draft". Draft job streams are not added to the preproduction plan.

```txt
composer mod jS=FINAL composer mod js=FINALPOSTREPORTS
```

For example, the following is an extract from the definition for the FINAL job stream:

```txt
SCHEDULE MDM#FINAL   
DESCRIPTION "Added by composer."   
DRAFT   
ON RUNCYCLE RC1 "FREQ  $\equiv$  DAILY;"   
AT 2359   
CARRYFORWARD   
FOLLOWS MDM#FINAL.SWITCHPLAN PREVIOUS :
```

The following example is an extract from the definition for the FINALPOSTREPORTS job stream:

```txt
SCHEDULE MDM#FINALPOSTREPORTS  
DESCRIPTION "Added by composer."  
DRAFT  
ON RUNCYCLE RC1 "FREQ=DAILY;"  
SCHEDTIME 2359  
CARRYFORWARD  
FOLLOWS MDM_XA#FINAL.SWITCHPLAN PREVIOUS:
```

7. If not already present, make the following changes to the Sfinal file:

a. Create a backup of the Sfinal file. For example:

```batch
cp /<TWA_home>/TWS/Sfinal /<TWA_home>/TWS/Sfinal.org
```

b. Add the new extended agent workstation to the FINAL and FINALPOSTREPORTS job stream definitions.

c. Substitute the SCRIPTNAME keyword with DOCOMMAND in all of the jobs defined in the FINAL and FINALPOSTREPORTS job streams.  
d. Ensure the path to the scripts launched by the jobs in the FINAL and FINALPOSTREPORTS job streams use the variable, UNISONHOME.  
e. Submit the composer add sfinal command to generate the FINAL and FINALPOSTREPORTS job streams on the new extended agent workstation if they do not already exist.  
f. Verify that the new extended agent workstation has been added to the Sfinal file. The following example is an extract of the modified Sfinal file containing the addition of the MDM_XA extended agent workstation, the substitution of the SCRIPTNAME keyword with DOCOMMAND in all jobs defined in FINAL and FINALPOSTREPORTS job stream definitions, and the use of the UNISONHOME variable in place of the path to the scripts:

FINAL:

```txt
SCHEDULE MDM_XA#FINAL ON EVERYDAY AT 2359 CARRYFORWARD   
FOLLOWS MDM_XA#FINAL.SWITCHPLAN PREVIOUS   
...   
.   
.   
STARTAPPSERVER DOCOMMAND   
"\$\{UNISONHOME\}/../appservers/tools/startAppServer.sh" STREAMLOGON wa95ids RECOVERY CONTINUE MAKEPLAN DOCOMAND "\$\{UNISONHOME\}/MakePlan" STREAMLOGON wa95ids RCCONDSUCC  $(RC = 0)$  OR  $(RC = 4)$ " FOLLOWS STARTAPPSERVER SWITCHPLAN DOCOMAND "\$\{UNISONHOME\}/SwitchPlan" STREAMLOGON wa95ids FOLLOWS MAKEPLAN   
.   
.   
.   
END
```

# FINALPOSTREPORTS:

```txt
SCHEDULE MDM_XA#FINALPOSTREPORTS ON EVERYDAY SCHEDTIME 2359 CARRYFORWARD   
FOLLOWS MDM_XA#FINAL.SWITCHPLAN PREVIOUS   
...   
...   
... CHECKSYNC DOCOMMAND "$\{\UNISONHOME\}/bin/planman checksync" STREAMLOGON wa95ids RECOVERY CONTINUE CREATEPOSTREPORTS DOCOMMAND "$\{\UNISONHOME\}/CreatePostReports" STREAMLOGON wa95ids RECOVERY CONTINUE
```

```txt
UPDATESTATS DOCOMMAND "${\UNISONHOME}/UpdateStats"  
STREAMLOGON wa95ids  
RECOVERY CONTINUE  
FOLLOWS CHECKSYNC  
...  
...  
...  
END
```

8. Submit the composer add Sfinal command and then verify that the FINAL and FINALPOSTREPORTS job streams and the related jobs, are correctly defined on the extended agent workstation. The following is an example of the correct output:

```txt
...   
...   
...   
/   
-add Sfinal   
AWSJCL003I The command "add" completed successfully on object "jd=MDM_XA#STARTAPPSERVER".   
AWSJCL003I The command "add" completed successfully on object "jd=MDM_XA#MAKEPLAN".   
AWSJCL003I The command "add" completed successfully on object "jd=MDM_XA#SWITCHPLAN".   
AWSJCL003I The command "add" completed successfully on object "js=MDM_XA#FINAL".   
AWSJCL003I The command "add" completed successfully on object "jd=MDM_XA#CHECKSYNC".   
AWSJCL003I The command "add" completed successfully on object "jd=MDM_XA#CREATEPOSTREPORTS".   
AWSJCL003I The command "add" completed successfully on object "jd=MDM_XA#UPDATESTATS".   
AWSJCL003I The command "add" completed successfully on object "js=MDM_XA#FINALPOSTREPORTS".   
AWSBIA090I For file "Sfinal": errors 0, warnings 0.   
AWSBIA288I Total objects updated: 8
```

9. Compare the two copies of the FINAL and FINALPOSTREPORTS job streams and make any necessary changes to those on the extended agent workstation, for example, the job stream submit time, run cycles, or any other custom changes to personalize the schedule.

10. Submit JnextPlan with the -noremove options to update the plan with the new extended agent workstation:

```txt
JnextPlan -for 0000 -noremove
```

11. If JnextPlan runs correctly, proceed to delete the FINAL and FINALPOSTREPORTS job streams previously set to "draft" on the master domain manager.

```txt
composer del FINALPOSTREPORTS composer del FINAL
```

12. Delete the FINAL and FINALPOSTREPORTS job streams from the plan as follows.

```batch
conman "canc FINALPOSTREPORTS" conman "canc FINAL"
```

13. Modify the new job stream definitions for the FINAL and FINALPOSTREPORTS job streams, setting the limit to "0":

```batch
SCHEDULE MDM_XA#FINAL   
DESCRIPTION "Added by composer."   
ON RUNCYCLE RC1 "FREQ  $\equiv$  DAILY;"   
AT 2359   
CARRYFORWARD   
FOLLOWS MDM_XA#FINAL.SWITCHPLAN PREVIOUS   
LIMIT O   
:   
MDM_XA#STARTAPPSERVER
```

14. Submit first the FINAL, and then the FINALPOSTREPORTS job streams into the current plan.

```txt
conman sbs MDM_XA#FINAL conman sbs MDM_XA#FINALPOSTREPORTS
```

15. Verify that the start time and date for the FINAL and FINALPOSTREPORTS job streams are correct by submitting the conman showschedules command.  
16. Reset the value of the limit job stream keyword for the FINAL and FINALPOSTREPORTS job streams, both in the database and in the plan.

```txt
conman "limit MDM_XA#FINAL ;10"  
conman "limit MDM_XA#FINALPOSTREPORTS ;10"
```

Both job streams should be in WAITING (HOLD internal status), awaiting execution time.

17. Archived plans, forecast and trial plans are stored on the master domain manager where the plans run. To make these plans available on the backup master domain manager, either store the plan in a single shared folder, or create a job that synchronizes the plans between the master domain manager and the backup master domain manager.

# What to do next

To enable the new master to access the plans that ran on the original master (the current plan is visible because it is synchronized with the backup), configure a job that copies the plans from the original master to the new master.

After an automatic failover, if you would like to subsequently return service to the original master, you must perform a manual switch. See Manually switching the master on page 396.

# Manually switching the master

A manual switchover from the primary master domain managerto a backup master domain manager is invoked through the switchmgr command. The backup master domain manager becomes the current, active master connected to the IBM® Workload Scheduler database.

There are four main use case scenarios that can prompt the need for switch of the master to a backup:

# Planned outage

The domain manager is replaced with its backup for planned maintenance work (for example, an upgrade of the operating system).

# Unplanned outage

The domain manager is replaced with its backup because of an unexpected failure or malfunction.

# Short-term

The domain manager is expected to return to service before the next new production period turnover (run of the JnextPlan job).

# Long-term

The domain manager is not expected to return to service before the next new production period turnover (run of the JnextPlan job).

# Short-term switch of a master domain manager

Use the procedure described in Simplified procedure for switching a domain manager on page 382 when you have a short-term loss of a master domain manager.

Master domain managers remain switched until you perform another switch manager operation. To return to the original master domain manager, repeat this procedure before the next production period turnover, unless you do not expect the master domain manager to be available for the next production period turnover (final Job Scheduler and JnextPlan job). In this case, use the procedure in the following section.

# Extended loss or permanent change of master domain manager

Use the following procedure to switch to the backup if the original master domain manager is not expected to return to service before the next new production period turnover (final Job Scheduler and JnextPlan job).

On UNIX™ operating systems, use forward slashes in path names.

1. Use the conman stop function to stop IBM Workload Scheduler on the master domain manager and its backup. for more information about the command, see the section about the stop command in User's Guide and Reference.  
2. If you copied the Security file from the master domain manager to the backup master domain manager with a suffix, now delete the Security file on the backup master domain manager and rename the Security file with the suffix as just Security.  
3. If you copied the locallypts file from the master domain manager to the backup master domain manager with a suffix, now merge the locallypts file on the backup master domain manager with the locallypts file from the master domain manager. Look at each property in turn and determine which version you want to keep on what is going to be your new master domain manager. For example, the property thiscpu needs to be the one from the backup master domain manager, but the options for controlling how the processes run can be taken from the master domain manager.  
4. On the backup master domain manager cancel the final Job Scheduler in the Symphony file (it refers to the next production period's JnextPlan on the old master domain manager).  
5. On the backup master domain manager, use composer to modify any important job streams that run on the master domain manager, in particular the final Job Scheduler. For each of these, change the workstation name to the name of the backup.  
6. Change the workstation definition of the master domain manager from manager to fault-tolerant agent.  
7. Change the workstation definition of the backup master domain manager from fault-tolerant agent to manager.

![](images/a779d60f6a23e7d203a4a83666eb14473382093f684e0b1bf10ed125e17a908c.jpg)

Note: These two steps must be done in the order given, as the system will not allow you to have two managers at the same time.

8. On the backup master domain manager, edit the TWA_home/TWS/mozart/globalopts file and change the master option to the name of the backup master domain manager workstation (this is used mainly for reports production)  
9. Use the conman switchmgr function to switch to the backup master domain manager. See Simplified procedure for switching a domain manager on page 382.  
10. Submit a new final Job Scheduler to the new master domain manager (old backup master domain manager).

11. Run JnextPlan -for 0000 on the new master domain manager to generate the new Symphony file.  
12. Remember to log on to the backup master domain manager when opening the Dynamic Workload Console, first defining a new engine to access it.  
13. If the old master domain manager has failed or is being replaced, you can now delete its workstation definition and remove it from the network.

# Switching a master domain manager or dynamic domain manager

Switching a master domain manager or dynamic domain manager affects the running dynamic workload broker server.

The installation of a master domain manager or dynamic domain manager and of its backup workstations includes also the installation of a dynamic workload broker server.

You might have to switch the master domain manager or dynamic domain manager because, for example, the system running the current workstation is down. When a conman switchmgr command is submitted, an automatic process is triggered by which the old server stops the dynamic scheduling services and the new server starts a new instance of the dynamic workload broker server when the older server has completed the switch. This process ensures that there is only one active dynamic workload broker server running at a time.

You can configure this automatic switch broker process on instances at version 9.5 or later, by modifying the following properties contained in the SwitchBroker.properties file located in TWA_DATA_DIR/broker/config/

SwitchBroker.properties:

Table 68. Configurable properties for automatic switch broker process  

<table><tr><td>Property</td><td>Description</td></tr><tr><td>Master.Switch.HostName</td><td>The master domain manager name used to identify the active master.</td></tr><tr><td>Master.Switch.ExpiringTime</td><td>The number of seconds the new master waits before becoming the active master. The default value is 300 seconds.</td></tr><tr><td>Master.Switch.PollingTime</td><td>The time interval, in seconds, between the database checks made by the new master on the status updates of the old master. The default is 5 seconds.</td></tr></table>

When the switchmgr command is submitted, the new master begins monitoring the database (with the frequency specified by Master.Switch.PollingTime), to verify when the state changes for the old master. If there is no response from the old master (because of a crash or because the old master is at a product level version earlier than V9.5) then the new master waits for a maximum of two intervals specified by Master.Switch.PollingTime (10 seconds), and then automatically promotes itself as the new active master. If, instead, a status update is detected in the database while polling, the new master waits the amount of time specified by Master.Switch.ExpiringTime before declaring itself the new active master. As soon as the old master completes the switch procedure, then the new master declares itself as the active master without waiting for the expiry of the Master.Switch.ExpiringTime.

The properties must be modified on both the master domain manager or dynamic domain manager and their backups at version 9.5 or later.

Here is the procedure to follow every time you switch the master domain manager or dynamic domain manager if you run dynamic scheduling in your network:

1. Set the job fence to go priority level. For further details, see the section about the fence command in User's Guide and Reference.  
2. Switch the master domain manager or dynamic domain manager to a backup workstation. Use either the conman switchmgr command or the Dynamic Workload Console. For more information about both methods, see the procedure described under the switchmgr command in User's Guide and Reference.  
3. Once the switch has been performed, restore the job fence to zero. For further details, see the procedure described under the switchmgr command in User's Guide and Reference.

# Switching a dynamic domain manager for a Z controller

As a normal behavior, the dynamic domain manager for a Z controller works by having both the server and processes up and running, while the backup dynamic domain manager for a Z controller works with the processes that are running and the system that is down. You might have to switch the dynamic domain manager for a Z controller to a backup workstation because, for example, the system running the current workstation goes down.

To switch the dynamic domain manager for a Z controller to the backup workstation, perform the following procedure:

1. Stop the server on the dynamic domain manager for a Z controller by issuing the following command:

# On Windows

```txt
stopAppServer.bat
```

# On UNIX

```txt
stopAppServer.sh
```

2. On the backup dynamic domain manager for a Z controller, run the following command:

# On Windows

```batch
startZosDDM.bat -dbUsr db_user -dbPwd db_user pwd
```

# On UNIX

```batch
startZosDDM.sh -dbUsr db_user -dbPwd db_user_pwd
```

where:

# dbUrs db_user

The user that has been granted access to the IBM Z Workload Scheduler tables on the database server.

# dbPwd db_user pwd

The password for the user that has been granted access to the IBM Z Workload Scheduler tables on the database server.

3. On the backup dynamic domain manager for a Z controller, start the server by running the following command:

# On Windows

```batch
startAppServer.bat
```

# On UNIX

```batch
startAppServer.sh
```

# Cloning scheduling definitions from one environment to another

Replicating scheduling definitions from one environment for example, a test environment, to a different one, for example a production environment.

# About this task

This section applies to IBM Workload Scheduler master domain managers and its backup. It documents how to clone IBM Workload Scheduler data from one environment to another.

![](images/68e938b8b9495f5fb6da83d3abbf196abdb0bb2b97dbfc898b3de8d6a94eeeb8.jpg)

Note: This cloning procedure does not clone the following information from the source environment:

The preproduction plan  
- The history of job runs and job statistics  
The audit records  
- The state of running event rule instances. This means that any complex event rules, where part of the rule has been satisfied prior to cloning of the environment, are generated as new rules after the cloning procedure. Even if the subsequent conditions of the event rule are satisfied, the record that the first part of the rule was satisfied is no longer available, so the rule will never be completely satisfied.

With the following steps all scheduling object definitions and global options can be migrated from a source environment named "ENV_1" to a target environment named "ENV_2".

1. In ENV_2, install a fresh instance of an IBM Workload Scheduler version 10.2.5 master domain manager and it point to its database by defining MDM_ENV2 as the master domain manager workstation name. The installation process automatically defines the following workstations in the ENV_2 database:

- MDM_env2 is the master domain manager workstation name.  
MDM_env2_DWB is the broker workstation name.  
$\circ$  MDM_ENV2_1 is the agent workstation name.  
- MASTERAGENTS is the dynamic pool which includes, by default, MDM_ENV2_1 dynamic agent workstation.

2. On the ENV_1 master domain manager, run the dataexport command or script to export all scheduling object definitions and global options from ENV_1. You can find this file in the bin subdirectory of the TWA_home directory.

Run dataexport from a Windows™ or UNIX® command prompt as follows:

```txt
dataexport source_dir export_dir
```

where:

source_dir

The TWS_HOME directory of the ENV_1 instance of IBM Workload Scheduler version 10.2.5.

![](images/9b94e2ef35711ff6a15556f6c2d1bdda73c90de67e6a88551058000abe7f7503.jpg)

Note: The dataexport utility only accepts source_dir values that end in TWS.

export_dir

The directory where the export files are created.

For example:

```batch
dataexport.cmd F:\IWS1025\twsDB2user F:\IWS1025\export
```

The object definitions and the global options are retrieved from the ENV_1 database and placed in the F:\IWS1025\export directory.

3. Verify that the following files were created in export_dir:

acls.def  
- calendars.def  
erules.def  
- folders.def  
globalOptions.def  
- jobs.def

![](images/984fd14486e1725bb112a8c0bc48a915e41247e8be35ebb1055a0194665733cd.jpg)

Note: The record length supported by DB2® is 4095 bytes, but it decreases to 4000 bytes with Oracle. When you migrate your job definitions to Oracle, any job with task string (scripts or commands) exceeding 4000 bytes in length are not migrated. In this case, the data import utility replaces the job definition with a dummy job definition and sets the job priority to 0, guaranteeing that successors are not run.

- parms.def  
o prompts.def  
rcgroups.def  
resources.def  
schedules.def  
sdoms.def  
srols.def  
topology.def  
- users.def (includes encrypted user passwords)  
ovariables.def

4. Open the export_dir\topology.def file and remove the MASTERAGENTS definition to avoid replacing the same workstation definition that was created when you installed a fresh instance of the IBM Workload Scheduler version 10.2.5 master domain manager in ENV_2.

If you plan to dismiss ENV_1 and you want to move the other workstations from ENV_1 to ENV_2, then you do not have to perform any additional steps.

If you plan to install new agents in ENV_2, then it is recommended to install them using the same displayname used by the agent present in ENV_1 so that you do not need to modify the erules.def, jobs.def, resources.def, schedules.def, and users.def files exported in the previous step. If you do not install them using the same displayname, then you must edit these files so that they match the agent displayname present in ENV_2.

5. Edit the export_dir\users.def file to specify the current valid password for the Windows™ users.  
6. To import the object definitions and the global options retrieved from the ENV_1 into the ENV_2 database, copy the files that were created when you ran the dataexport utility to a directory on the ENV_2 master domain manager and run the dataimport command or script to import all scheduling object definitions and global options to the ENV_2 database. You can find this file in the bin subdirectory of the TWA_home directory.

Run dataimport from a Windows™ or UNIX® command prompt as follows:

```python
dataimport source_dir export_dir
```

where:

source_dir

The TWS_HOME directory of the ENV_2 instance of IBM Workload Scheduler version 10.2.5.

export_dir

The directory where you copied the object definitions and the global options retrieved from ENV_1.

For example:

```batch
dataimport.cmd F:\IWS1025\twsDB2user F:\IWS1025\export
```

7. If you want to dismiss the instance of IBM Workload Scheduler installed in ENV_1 and reuse the same agents in ENV_2, stop the IBM Workload Scheduler processes running on the master domain manager in ENV_1 to avoid conflicts.

# Results

You have now completed cloning scheduling definitions from one environment to another.

# Changing key IBM Workload Scheduler passwords

# About this task

When you change passwords for key users in your IBM Workload Scheduler environment, there are various operations to perform, depending on which user's password is being changed, the type of operating system on which it is deployed, and the type of IBM Workload Scheduler node where the password is being changed.

Perform one or more of the following steps depending on the characteristics of your environment and your operating systems:

- Change the user password at the operating system level using native commands.

If you use special characters in the password, ensure you use a "\\" (backslash) before the special character. The following rules apply:

# On Windows™ operating systems:

Passwords for users can include any alphanumeric characters and (!?=^*/~\ $_+,...,@$ -#.

# On UNIX™ and LINUX systems:

Passwords for users can include any alphanumeric characters and (!?=*~_+..

- Change the password for the TWS user by changing the WebSphere Application Server Liberty user password. For more information, see the WebSphere Application Server Liberty documentation, for example securityUtility command. For the detailed procedure, see Changing the WebSphere Application Server Liberty password on page 404.  
- Change the password used by command-line clients, as described in Change password used by command-line clients to access the master domain manager on page 406.  
- Change the password used by fault-tolerant agents, as described in Change password used by fault-tolerant agent systems to access the master domain manager (for conman) on page 406.  
- Change the password for the database user, as described in Changing the properties for the database on page 408.  
- Change the engine connection parameters in the Dynamic Workload Console, as described in Update the engine connection parameters in the GUIs on page 406.  
- On Windows operating systems, change the password of the IBM® Workload Scheduler account in Windows services, as described in Windows - update Windows services on page 407.  
- If you run jobs on Windows operating systems, change the password of the streamlogon user of the jobs, as described in Change the IBM Workload Scheduler user definition on page 407.  
- Run the following commands to ensure the previous steps were completed correctly:

optman ls

composer mo ws=@

For all other users of IBM Workload Scheduler, no action is required if their passwords change.

![](images/976ce92839c687d884c99870033b0677144ab5d93329a1e5ea74105de0abf715.jpg)

Note: After changing any password, restart WebSphere Application Server Liberty.

See the following table to determine if a change of password requires actions to be taken for a role on the different IBM Workload Scheduler components. Look up the role and the component and determine from the corresponding table cell where the changes must be made:

- If the cell contains a "√", make the change on the system where the indicated component is running  
- If the cell contains "MDM", make the change on the master domain manager to which the component belongs

Table 69. If and where password changes are required  

<table><tr><td>Role</td><td>MDM</td><td>BKM</td><td>FTA</td></tr><tr><td>WebSphere Application Server Liberty user</td><td>✓</td><td>✓</td><td></td></tr><tr><td>Database user</td><td>✓</td><td>✓</td><td></td></tr><tr><td>Streamlogon user (Windows®)</td><td>✓</td><td>✓</td><td>MDM</td></tr></table>

For example, if you are the <TWS_user> (the instance owner) of a fault-tolerant agent, you need to implement the password change on the system where the fault-tolerant agent is installed, but if you are also the streamlogon user of jobs running on that system, the changes required for the new password must be applied at the master domain manager to which the fault-tolerant agent belongs.

# Changing the WebSphere Application Server Liberty password

Procedure to modify the WebSphere Application Server Liberty password.

To modify the WebSphere Application Server Liberty password, update the wauser_variables.xml configuration file. This operation changes the password for the TWS user, which is stored in the configuration file. Ensure you also update the password in the useropts file, so that you can continue working with the command-line client. If you have several users using the command-line client, change the password of the TWS user in all useropts files (one for each user). For more information, see Change password used by command-line clients to access the master domain manager on page 406.

1. The location of the file to be modified varies depending on whether you have already customized the template or not, as follows:

If you have no previous customizations defined in the configuration file,

edit the template located in the templates folder.

Templates for the master domain manager are stored in the following paths:

On UNIX operating systems

TWA_home/usr/serverngineServer/configDropins/template

On Windows operating systems

TWA_home\usr\server\engineServer\configDropins\templates

Templates for the Dynamic Workload Console are stored in the following paths:

On UNIX operating systems

DWC_home/usr/servers/dwcServer/configDropins/template

On Windows operating systems

DWC_home\usr\servers\dwcServer\configDropins\templates

If you have previous customizations defined in the configuration file,

edit the file located in the overrides folder, which is the file currently used by WebSphere Application Server Liberty.

The wauser_variables.xml file is located in

On UNIX operating systems

TWA_DATA_DIR/usr/servers/engineServer/configDropins/overrides

On Windows operating systems

TWA_home\usr\servers\engineServer\configDropins\overridden

On UNIX operating systems

DWC_DATA_dir/usr/servers/dwcServer/configDropins/overrides

On Windows operating systems

DWC_home\usr\servers\dwcServer\configDropins\overridden

2. Copy the wauser_variables.xml file to a temporary directory.  
3. Edit the file as necessary, specifying the new password.

The contents of the wauser_variables.xml file is as follows:

```txt
<server description="wauser_var">
    <variable name="user.twsuser.id" value="$(wlpUser)” />
    <variable name="user.twsuser.password" value="$(wlpPassword)” />
</server>
```

where:

user.twsuser.id

Is the WebSphere Application Server Liberty user ID.

user.twsuser.password

Is the new WebSphere Application Server Liberty password.

4. Optionally, create a backup copy of the configuration file in a different directory, if the file is already present.  
5. Copy the wauser_variables.xml file to the overrides folder. Changes are effective immediately.

6. Update the PASSWORD in the useropts file on the following workstations:

on every command-line client that points to your workstation.  
- on every fault-tolerant agent in your environment that has an HTTP/HTTPS connection defined in locallypts that points to your workstation. The HTTP/HTTPS connection is used to submit a predefined job or job stream.  
in the engine connection parameters on every connected Dynamic Workload Console.

If you have more than one instance of IBM Workload Scheduler on a system, you might have implemented separate user options files to make separate connections. In this case, check the useropts key in the localizepts file on each instance to determine the name of the specific useropts file for that instance.

# Change password used by command-line clients to access the master domain manager

# About this task

If you have changed the password of the WebSphere Application Server Liberty user that command-line clients use to connect to the master domain manager, the connection parameters must be updated.

Follow this procedure:

1. Identify all systems that have a command line client remote connection defined with the master domain manager  
2. On these workstations, open the user options files. The user option file is located:

# On Windows operating systems

```txt
C:\Users\<user>\.TWS\useropts_<user>
```

# On Linux operating systems

```txt
/home/<user>/.TWS/useropts_<user>
```

If you have more than one instance of IBM Workload Scheduler on a system, you might have implemented separate user options files to make separate connections. In this case, check the useropts key in the localopts file on each instance to determine the name of the specific useropts file for that instance.

3. For each file, locate the password key (encrypted) and change its value to that of the new password in plain text, enclosed in double quotation marks. The password is saved in clear, but will be encrypted at first logon of the User ID.  
4. Save the files.

# Change password used by fault-tolerant agent systems to access the master domain manager (for conman)

# About this task

If you have changed the password of the WebSphere Application Server Liberty user that is used by fault-tolerant agents with an HTTP or HTTPS connection defined in the local options that points to the master domain manager, the connection parameters must be updated.

Follow this procedure:

1. Identify all fault-tolerant agents with an HTTP or HTTPS connection defined in the local options that points to the master domain manager.  
2. On these workstations, open the user options file <Root_home>/.TWS/useropts  
3. Locate the password key (encrypted) and change its value to that of the new password in plain text, enclosed in double quotation marks. The password is saved in clear, but will be encrypted at first logon of the User ID.  
4. Save the file.

# Update the engine connection parameters in the GUIs

# About this task

If you have changed the password of the WebSphere Application Server Liberty user that is used by the Dynamic Workload Console to connect to the distributed engine, the engine connection parameters must be updated, as follows:

1. On each instance of the Dynamic Workload Console locate the page where you modify the distributed engine connection parameters  
2. Change the password and submit the page.

Windows™ - update Windows™ services

# About this task

On Windows™, the TWS_user account is used to start the following services:

- IBM Token Service for TWS_user  
- IBM Workload Scheduler for TWS_user

The password must be updated in the properties of these services, or they are not able to start at next reboot. This is done as follows:

1. Stop all IBM Workload Scheduler processes. See Unlinking and stopping IBM Workload Scheduler on page 407 for details.  
2. Restart all IBM Workload Scheduler processes using the StartUp command.

# Change the IBM Workload Scheduler user definition

# About this task

If the user ID is used within IBM Workload Scheduler to run jobs, follow this procedure:

1. Run the composer modify user command. The user details of the selected user are written to a temporary file, which is opened. Fore more information, see the topic about the modify command in User's Guide and Reference  
2. Edit the password field so that it contains the new password value delimited by double quotation marks characters (").  
3. Save the file, and the contents are added to the database.  
4. To make the change immediately effective in the current plan, issue the conman altpass command. For more information, see the topic about the altpass command in User's Guide and Reference

# Unlinking and stopping IBM Workload Scheduler

# About this task

Before you perform an upgrade or uninstall, install a fix pack, or perform maintenance activities, ensure that all IBM Workload Scheduler processes and services are stopped. Follow these steps:

1. If you have jobs that are currently running on the workstation, wait for them to finish. To determine which are not finished, check for jobs that are in the exec state. When there are no jobs in this state, and you have allowed sufficient time for all events to be distributed in your network, you can continue with the rest of the procedure.  
2. If the workstation that you want to stop is not the master domain manager, unlink the workstation by issuing the following command from the command line of the master domain manager:

```txt
conman "unlink workstationname;noask"
```

3. Stop WebSphere Application Server Liberty by using the conman stopappserver command (see Starting and stopping the application server and appservman on page 426).  
4. All IBM Workload Scheduler processes on the workstation must then be stopped manually. From the command line, while logged on as the <TWS_user>, enter the following command:

```txt
conman "stop;wait"
```

5. From the command line, stop the netman process as follows:

UNIX®

Run the conman "shut" command.

![](images/4c238534f63535773a7e05cb13925eb044a9e68a72c9ca0ba9d2814397899766.jpg)

Note: Do not use the UNIX® kill command to stop IBM Workload Scheduler processes.

# Windows®

From the IBM Workload Scheduler home directory, run the shutdown.cmd command.

6. To stop dynamic agents, run the ShutDownLwa command.  
7. To stop the SSM agent, perform the following steps:

- On Windows®, stop the service IBM Workload Scheduler SSM Agent (for <<TWS_user>>).  
On UNIX®, run the stopmon command.

# What to do next

To verify if there are services and processes still running:

# UNIX®

Enter the command: ps -u <TWS_user>Verify that the following processes are not running: netman, mailman, batchman, writer, jobman, JOBMAN, stageman, logman, planman, monman, ssmagent.bin, and appservman.

# Windows®

Run Task Manager, and verify that the following processes are not running: netman, mailman, batchman, writer, jobman, stageman, JOBMON, tokensrv, batchup, logman, planman, monman, ssmagent, and appservman.

Also, ensure that no system programs are accessing the directory or its subdirectories, including the command prompt and Windows Explorer.

# Changing the properties for the database

# About this task

When you installed IBM Workload Scheduler, you supplied the database name, the server name, port, the host name of the database server, and other information.

If you need to change any of the database properties such as host name, port, instance owner, or database name, use the datasource_dbVASer.xml template file to reflect these changes in the application server on the master domain manager or on the Dynamic Workload Console.

If you want to change any of these properties, perform the following steps:

1. Change the configuration of the IBM Workload Scheduler application server so that it points correctly to the changed database configuration, as follows:

a. The location of the file to be modified varies depending on whether you have already customized the template or not, as follows:

If you have no previous customizations defined in the configuration file,

edit the template located in the templates folder.

Templates for the master domain manager are stored in the following paths:

On UNIX operating systems

TWA_home/usr/server/engineServer/configDropins/template

On Windows operating systems

TWA_home\usr\server\engineServer\configDropins\templates

Templates for the Dynamic Workload Console are stored in the following paths:

On UNIX operating systems

DWC_home/usr/servers/dwcServer/configDropins/template

On Windows operating systems

DWC_home\usr\servers\dwcServer\configDropins\templates

If you have previous customizations defined in the configuration file,

edit the file located in the overrides folder, which is the file currently used by WebSphere Application Server Liberty.

The wauser_variables.xml file is located in

On UNIX operating systems

TWA_DATA_DIR/usr/servers/engineServer/configDropins/ overrides

On Windows operating systems

TWA_home\usr\servers\engineServer\configDropins\overridden

On UNIX operating systems

DWC_DATA_dir/usr/servers/dwcServer/configDropins/overrides

# On Windows operating systems

DWC_home\usr\servers\dwcServer\configDropins\overridden

b. Copy the datasource_dbvendor.xml file to a temporary location.  
c. Modify the following properties in the file based on the values you changed in your database configuration:

# db.serverName

The name or IP address of the database server

# db.portNumber

The port number of the database server

# db(databaseName

The database name

# db.user

The database instance owner

# db.password

The database user password. You can optionally encrypt the password, as described in the topic about the secure script in IBM Workload Scheduler: Planning and Installation.

# db.driver.path

The path to the JDBC drivers. IBM Workload Scheduler is supplied using the JDBC driver type 4 for DB2® and type 2 for Oracle. However, each can use the other driver type, if necessary. Software Support might ask you to change to this driver. This procedure must only be performed under the control of Software Support.

# db捆绑

The setting for the SSL connection. true indicates that SSL connection is enabled, false indicates that SSL connection is disabled..

d. Browse to the overrides folder:  
e. Create a backup of the datasource_dbVASdor.xml.  
f. Replace the datasource_dbVASdor.xm1 file with the file you edited. The changes are effective immediately.

2. On the master domain manager only, edit the file CLIConfig.properties, in the path TWA_DATA_DIR//broker/config, by updating the value for the property com.ibm.tdbw.dao.rdbms.jdbcPath to reflect the JDBC URL specified. The following is an example of a JDBC value:

database_type: //hostname:port/dbName

3. On the master domain manager only, edit the file DAOCommon.properties, in the path TWA_DATA_DIR//broker/config, as follows:

In the first line specify the rdbmsName for all DBs.  
For Oracle only, change all lines and specify the TWS_Oracle_User.

4. On the master domain manager only, edit the file TWSCfg properties, in the path TWA_DATA_DIR/usr/ servers/engineServer/resources/properties/TwSCfg.properties. If you are using MSSQL change the first line. For Oracle only, change all lines. Consider the following example:

```txt
com.ibm.tws.dao.rdbms.rdbmsName = ORACLE  
com.ibm.tws.dao.rdbms.modelSchema = <TWS_Oracle_User>  
com.ibm.tws.dao.rdbms.eventRuleSchema = <TWS_Oracle_User>  
com.ibm.tws.dao.rdbms.logSchema = <TWS_Oracle_User>
```

# Changing the workstation host name or IP address

When you change the host name, the IP address or both on the workstations of your IBM Workload Scheduler environment to have it function properly, you must report the changed value on:

- The WebSphere Application Server Liberty if the following components changed the host name, the IP address or both:

Master domain manager  
Backup master domain manager  
- Connector or Z connector  
Dynamic Workload Console

For more information, see Reporting the changes in the WebSphere Application Server Liberty configuration file on page 411.

- The following components if the workstation where you installed the RDBMS changed the host name, the IP address or both:

Master domain manager  
Backup master domain manager  
Dynamic domain manager  
- Backup dynamic domain manager

For more information, see Changing the properties for the database on page 408.

- The workstation definitions if you installed the following components:

Master domain manager  
Backup master domain manager  
Dynamic domain manager  
Backup dynamic domain manager  
- Fault-tolerant agent and standard agent  
- Domain manager

For more information, see Reporting the changed host name or IP address in the workstation definition on page 413.

# Reporting the changes in the WebSphere Application Server Liberty configuration file About this task

If the host name or IP address is changed for the following components, then you must report the changed value in the WebSphere Application Server Liberty host_variables.xml configuration file:

- Master domain manager  
- Backup master domain manager  
- Dynamic domain manager  
- Backup dynamic domain manager  
- Dynamic Workload Console

1. Stop the WebSphere Application Server Liberty.  
2. Obtain the changed host name, IP address, or both.  
3. Verify that the value for the properties listed below were changed with the actual values:

Old Hostname  
New Hostname  
The host names for the specific port properties

If these values are different from the actual host name or IP address values, proceed with Step 4 on page 412. If this values are not changed, skip the steps below.

4. Create a back up of and then modify the values in the host_variables.xml file located in

# On UNIX operating systems

```txt
TWA_DATA_DIR/usr/servers/engineServer/configDropins/overrides
```

# On Windows operating systems

```batch
TWA_home\usr\servers\engineServer\configDropins\overdrafts
```

5. Propagate the changes to the interfaces as follows:

# Address of the master domain manager changes

- On each fault-tolerant agent, dynamic agent, and standard agent you configured to connect to the conman command line, update the host parameter present in the "Attributes for CLI connections" section in the localots file. Usually you have the host parameter defined in the localots file of the workstations you use to submit predefined jobs and job streams (sbj and sbs commands).  
- On every command-line client, update the host parameter present in the "Attributes for CLI connections" section in the localopts file.  
- On the Dynamic Workload Console, update the engine connections.  
On all of the server components:

a. Run JnextPlan.  
b. Update the value for the Master.Switch.HostName parameter in the SwitchBroker.properties file located in TWA_DATA_DIR/broker/config/ SwitchBroker.properties.

c. From the broker command line, run exportserverdata to extract a list of URIs containing the old hostname to a text file, then run importserverdata providing the updated file in

input to update the changed host name. For more information about the commands, see the section about using utility commands in the dynamic environment in User's Guide and Reference.

# Address of the Dynamic Workload Console changes

Notify all the users of the new web address.

# Reporting the changed host name or IP address in the workstation definition

# About this task

Run this procedure if you changed the host name or IP address on the following components:

- Master domain manager  
- Backup master domain manager  
- Fault-tolerant agent and standard agent  
- Domain manager

To modify the host name or the IP address on the workstation definition, perform the following steps:

1. Use composer or the Dynamic Workload Console to check the workstation definition stored in the database for the IBM Workload Scheduler instance installed on the workstation where the IP address or the host name changed.  
2. Verify the node attribute contains the new host name or IP address. If this value is changed proceed with Step 3 on page 413. If this value is not changed skip the steps below.  
3. Change the value of the node parameter with the new value.  
4. Refresh the new workstation definition into the plan. Do it immediately if you are changing the host name or the IP address of a master domain manager or a domain manager. If you are changing them on a workstation that is not a master domain manager or a domain manager you can wait the next scheduled plan generation to refresh your workstation definition in the Symphony file. In this case during this production day you cannot run jobs on this workstation. To generate the plan, perform the following steps:

a. Run optman Is and take note of the actual value of the enCarryForward parameter.  
b. If this value is not set to all, run

optmanchgcf=ALL

to set it to all

c. Add the new workstation definition to the plan, by running:

JnextPlan -for 0000

d. Reassign the original value to the enCarryForward parameter.

# Reporting the changed host name or IP address of the dynamic workload broker server About this task

The dynamic workload broker server is a component that IBM Workload Scheduler installs when you install the following components:

- Master domain manager  
- Backup master domain manager  
- Dynamic domain manager  
- Backup dynamic domain manager

If you changed the host name or the IP address on the dynamic workload broker server, or if you installed a new one run the procedure described in Reporting the changes in the WebSphere Application Server Liberty configuration file on page 411.

If you changed the host name or the IP address on a master domain manager or backup master domain manager and you ran the Reporting the changes in the WebSphere Application Server Liberty configuration file on page 411 procedure, skip this section.

If you changed the host name or the IP address on the dynamic domain manager or backup dynamic domain manager you do not need to change the definition of your broker workstation (type broker), because the value of the node attribute is set to the localhost value to allow to switch between the dynamic workload broker server and its backup.

After you ran the procedure, propagate the changes to the dynamic agent and update the ResourceAdvisorURL property in the JobManager.ini file on each agent connected to that dynamic workload broker server, by performing the following steps:

1. Run the following command to stop the agent:

ShutdownLwa

2. Edit the JobManager.ini file and change the host name or the IP address in the ResourceAdvisorURL property.  
3. Run the following command to start the agent:

StartUpLwa

# Perform the following changes:

1. Open the JobDispatcherConfig.properties file and change the value of the JDURL=https://host_name property to reflect the new host name or IP address.  
2. Open the CliConfig.properties file and change the value of the ITDWBServerHost=/host_name property to reflect the new host name or IP address.  
3. Open the ResourceAdvisorConfig.properties file and change the value of the ResourceAdvisorURL=https://host_name property to reflect the new host name or IP address.  
4. From the <TWA_home>/TDWB/bin directory, run the following command:

# On Windows operating systems:

exportserverdata.bat

# On UNIX and Linux operating systems:

exportserverdata.sh

This command extracts a list of URIs (Uniform Resource Identifier) of all the dynamic workload broker instances from the IBM Workload Scheduler database and copies them to a temporary file. By default, the list of URIs is saved to the server.properties file, located in the current directory.

5. Change all the entries that contain the old host name to reflect the new host name.  
6. Place the file back in the database, by running the following command:

On Windows operating systems:

```txt
importserverdata.bat
```

On UNIX and Linux operating systems:

```python
importserverdata.sh
```

7. Stop WebSphere Application Server Liberty, by running the following command:

```txt
stopAppServer
```

8. Start WebSphere Application Server Liberty, by running the following command:

```batch
startAppServer
```

# Reporting the changed host name or IP address of the dynamic agent

# About this task

If you changed the host name or the IP address on the workstation where you installed the dynamic agent, the changes are automatically reported stopping and starting the agent using the following commands:

1. To stop the agent:

```txt
ShutdownLwa
```

2. To start the agent:

```txt
StartUpLwa
```

![](images/0a7489462de18a680c886ec36d44f5e592eef5a36ff0c3182c811847ed8af207.jpg)

Note: Do not modify manually the value of the node parameter in the dynamic agent workstation definition.

# Changing the security settings

This section describes how to modify the security settings of IBM Workload Scheduler.

# About this task

A number of template files are available for customizing various security settings on the application server:

ssl_variables.xml

auth/basicRegistry_config.xml

File-based authentication

auth_IDS_config.xml

IBM® Directory Server

auth_OpenLDAP_config.xml

OpenLDAP

# auth_OpenLDAP_config.xml

Windows Server Active Directory

For the procedure to customize the security settings, see the section about configuring a common LDAP for both the master and the console in Planning and Installation Guide.

For the settings related to SSL, see Configuring SSL attributes on page 325. You can also change other settings, such as the active user registry or the local operating system ID and password.

- For more information about the procedure to make any changes to the WebSphere Application Server Liberty properties, see Configuring IBM Workload Scheduler using templates on page 418.  
To determine which properties are to be changed, see:

- Configuring authentication on page 262, for information about the properties to be changed to modify your user registry configuration for user authentication.  
- Customizing your RDBMS server on page 353, for information about the procedure to be performed when modifying your RDBMS server.  
- Changing the properties for the database on page 408, for information about changing the database properties such as database name, the server name, port, the host name of the database server.  
- Changing key IBM Workload Scheduler passwords on page 402, for information about how to change key passwords.

- To change the text file of the current security properties, perform the following steps:

1. Edit the text file and locate the properties you need to change.  
2. Make any required changes to the properties.

Do not change any other properties.

# Managing the event processor

# About this task

The only maintenance issue for the event processor is the management of the EIF event queue, cache.dat. The event queue is circular, with events being added at the end and removed from the beginning. However, if there is no room to write an event at the end of the queue it is written at the beginning, overwriting the event at the beginning of the queue.

To increase the size of the event processor queue, follow this procedure:

1. At the workstation running the event processor, browse to the following path:

On Windows operating systems

<TWA_home>\TWS\stdlib\appserver\engineServer\temp\TWS\EIFListener

On UNIX operating systems

<TWA_DATA_DIR>/stdlib/appserver/engineServer/temp/TWS/EIFListener

2. Edit the eif.template file and locate the keyword:

BufEvtMaxSize

3. Increase the value of this keyword, according to your requirements.  
4. Stop and restart WebSphere Application Server Liberty using the conman stopappserver and conman startappserver commands (see Starting and stopping the application server and appservman on page 426).

# Automatically initializing IBM Workload Scheduler instances

On UNIX systems, you can automatically initialize IBM Workload Scheduler instances during operating system startup.

# About this task

On UNIX™ systems, you can ensure that your IBM Workload Scheduler instances are automatically initialized during operating system startup.

For AIX® and some Linux™ operating systems that use a traditional init like System V, you can do this by adding an IBM Workload Scheduler service to the init process of your operating system. Use the sample start script iwa_init<installation user> located in TWA_home/TWS/config and add it to the appropriate run level after customizing it as necessary.

For some Linux™ distributions that use systemd as the default initialization system, such as RedHat Enterprise Linux™ v7.0 and SUSE Linux™ Enterprise Server V12, a sample service file, iwa.service, is provided located in the path TWA_home/TWS/config that is already configured to support the automatic initialization of IBM Workload Scheduler instances at startup.

Perform the following steps:

# For UNIX operating systems that use the traditional init system such as System V :

Configure the script and then register the service.

1. Create a copy of the iwa_init `<installation user>` script based on your requirements. Provide the following information, depending on the operating system you use:

# Required-Start

On Linux™ systems, specify the precondition services

# Default-Start

On Linux™ systems, specify the required runlevels. For example, specify runlevels 2, 3, and 5.

2. Browse to the appropriate system-dependent folder, as follows:

# Supported Linux™ operating systems

Save the script in the /etc/init.d folder and register the service using the insserv -v script_name command.

# Supported AIX® operating systems

Save the script to the appropriate rcrunlevel.d folder. Rename the script according to the runlevel script definition. For example, Ssequencenumberservice_name, as in S10iwa_init。<installation user>.

![](images/ff76a2a51f8c5568cd066e6d4601732e6f10ac4d90c210010aee795477a60c85.jpg)

Note: If you run this script on a master domain manager or on a backup master domain manager, the script has no effect on the database.

For more information about the inittab, init.d, insserv, and init commands, see the reference documentation for your operating system.

# For Linux™ distributions that use systemd as the default initialization system:

This procedure uses the iwa.service sample service that is already customized to automatically initialize IBM Workload Scheduler instances at system startup.

1. Copy the sample service provided, iwa.service, located in the path TWA_home/TWS/config to the following path on the Linux $^{\text{TM}}$  system /etc/systemd/system/  
2. To make systemd aware of the service, invoke the systemd daemon-reload command.  
3. Start the service submitting the following command:

systemctl start iwa.service

4. Verify the status by submitting the following command:

systemctl status iwa.service

5. Stop the service by submitting the following command:

systemctl stop iwa.service

6. Finally, enable the service so that it is activated by default when the system boots by submitting the following command:

systemctl enable iwa.service

# Configuring IBM Workload Scheduler using templates

Starting from version 9.5, IBM Workload Scheduler has moved from WebSphere® Application Server to WebSphere Application Server Liberty Base. As a result, the utilities known as wastools have been replaced with a number of templates addressing widely used configurations.

You can now configure WebSphere Application Server Liberty to work with IBM Workload Scheduler using the templates provided or define your custom .xml files containing your own configuration settings. Templates are available for both the master domain manager and the Dynamic Workload Console.

See Table 70: Correspondence between wastools and templates on page 420 to find the mapping between wastools and templates. The table indicates both the file containing the current configuration in use, as well as the template files available to modify the current configuration.

Templates for the master domain manager are stored in the following paths:

# On UNIX operating systems

TWA_home/usr/server/engineServer configDropins/template

# On Windows operating systems

TWA_home\usr\servers\engineServer\configDropins\templates

Templates for the Dynamic Workload Console are stored in the following paths:

# On UNIX operating systems

DWC_home/usr/servers/dwcServer/configDropins/template

# On Windows operating systems

DWC_home\usr\servers\dwcServer\configDropins\templates

When you edit the file with your customized settings for the master domain manager, move it to the following paths:

# On UNIX operating systems

TWA_DATA_DIR/usr/server/engineServer/configDropins/overrides

# On Windows operating systems

TWA_home\usr\servers\engineServer\configDropins\overridden

When you edit the file with your customized settings for the Dynamic Workload Console, move it to the following paths:

# On UNIX operating systems

DWC_DATA_dir/usr/servers/dwcServer/configDropins/overrides

# On Windows operating systems

DWC_home\usr\servers\dwcServer\configDropins\overridden

![](images/bddcdcf80d7eca19a6c93131353ab4d55e864d451f14e65fbead87d90bae9113.jpg)

Note: Do not edit the files in the templates directory because they will be overwritten when upgrading to new version or fix pack.

To configure WebSphere Application Server Liberty to work with IBM Workload Scheduler, use the template files provided in the templates folder or create your custom .xml files containing your configuration settings. WebSphere Application Server Liberty retrieves the .xml files from the overrides folder and applies the configuration settings defined in each file. The file name is irrelevant, because WebSphere Application Server Liberty analyzes each .xml file for its contents.

The template files provided refer to commonly used configurations. If you want to implement different configurations, for example a custom authorization mechanism, you can create a custom .xml file, containing your configuration settings in this section:

```twig
<server description="My custom configuration description"></server>
```

Ensure you remove any obsolete .xml files, to prevent WebSphere Application Server Liberty from parsing unwanted files.

If you use the provided templates, ensure you follow this procedure:

1. Copy the template file from the templates folder to a working folder.  
2. Edit the template file in the working folder with the desired configuration.  
3. Optionally, create a backup copy of the relevant configuration file present in the overrides directory in a different directory. Ensure you do not copy the backup file in the path where the template files are located.  
4. Copy the updated template file to the overrides folder. Maintaining the original folder structure is not required.  
5. Changes are effective immediately.

Table 70. Correspondence between wastools and templates  

<table><tr><td>Function</td><td>Current configuration file in use</td><td>Template file for customization</td><td>wastool</td></tr><tr><td>Datasource settings</td><td>overrides/datasource.xml</td><td>templates/datasources/datasourcevendor.xml</td><td>changeDataSourceProertiesshowDataSourceProperties</td></tr><tr><td>Hostname and port settings</td><td>· overrides/host_vvariables.xml
· overrides/ports_variables.xml</td><td>· Not applicable. The host_variables.xml file is very simple and therefore is located only in the overrides folder.
· templates/ports_variables.xml</td><td>changeHostPropertiesshowHostProperties</td></tr><tr><td>Authentication settings</td><td>overrides/wauser_variables.xml</td><td>Not applicable. The wauser_variables.xml file is very simple and therefore is located only in the overrides folder.</td><td>changePassword</td></tr><tr><td>Trace settings</td><td>Traces are disabled by default, so no file is present in the overrides folder.
Copy the trace.xml file to the overrides folder to enable traces.</td><td>templates/trace.xml</td><td>changeTraceProperties</td></tr><tr><td>z/OS engine settings for the Dynamic Workload Console</td><td>overrides/connectionFactory.xml</td><td>zconnector/connectionFactory.xml</td><td>createZosEngine(Dynamic Workload Console installation only)</td></tr></table>

Table 70. Correspondence between wastools and templates (continued)  

<table><tr><td>Function</td><td>Current configuration file in use</td><td>Template file for customization</td><td>wastool</td></tr><tr><td>SSL connections and certificates</td><td>· overrides/authorization_config.xml
· overrides_SSL_variables.xml</td><td>File-based:
authenticaton.authenticatedRegistry_config.xml
IBM® Directory Server:
authenticaton/auth_ID
S_config.
xml

OpenLDAP:
authenticaton/auth_OpenLDAP_configh.xml

Microsoft Server Active Directory:
authenticaton/auth_AD
_config.xml

OpenID:
authenticaton/openid_connect.xml
ssl_variables.xml</td><td>showSecurityProperties
changeSecurityProperties</td></tr><tr><td>Json Web Token (JWT) management</td><td>overrides/jwt_variables.xml</td><td>Not applicable</td><td>Not applicable</td></tr></table>

Templates are divided into the following directories:

defaults (files used by the installation process)

- ports_config.xml  
- ports_variables.xml

- ssl_config.xml  
- ssl_variables.xml

# overrises (configuration files)

- authentication_config.xml  
- connectionFactory.xml (Dynamic Workload Console installation only)  
- datasource.xml  
- host_variables.xml  
- jvmoptions  
- ports_variables.xml  
- ssl_variables.xml  
- wauser_variables.xml

# templates (templates available for customization)

# authentication

- auth_AD_config.xml  
- auth_basicRegistry_config.xml  
- auth_IDS_config.xml  
- auth_OpenLDAP_config.xml  
- openid_connect.xml

# datasources (one file for each supported database)

- datasource_<databaseVASr>.\xml

# zconnectors (Dynamic Workload Console installation only)

- connectionFactory.xml

- ports_variables.xml  
- ssl_variables.xml  
trace.xml  
- adminCenter.xml (Not recommended for production environment)

![](images/edde08ed9573cc18681f3e53f0a50efd1e67312ef234aa1e50753479b6366a3f.jpg)

Note: Enabling the AdminCenter feature on WebSphere Application Server Liberty could affect the runtime performance of the Application Server. Thus, it is suggested to enable it only if you are planning to use it. For more information about AdminCenter feature, see Administering Liberty using Admin Center.

For information about how to change database properties, see Changing the properties for the database on page 408.

For information about authentication settings, see Configuring authentication on page 262.

For information about configuring a z/OS engine, see the section about defining az/OS engine in the Z connector in IBM Z Workload Scheduler: Planning and Installation.

For information about logs and traces, see the section about logging and tracing in Troubleshooting Guide.

# WebSphere Application Server Liberty tasks

The tasks contained in this chapter might need to be performed for improving WebSphere Application Server Liberty performance.

# Application server - starting and stopping

Use the startAppServer and stopAppServer commands or the equivalent from the Dynamic Workload Console to start or stop the WebSphere Application Server Liberty. For a description of these commands, see IBM Workload Scheduler: User's Guide and Reference.

These commands also stop appservman, the service that monitors and optionally restarts WebSphere Application Server Liberty.

If you do not want to stop appservman, you can issue startAppServer or stopAppServer, supplying the -direct argument. These scripts are located in TWA_home/appserververteools.

The complete syntax of startAppServer and stopAppServer is as follows:

UNIXTM

Start the application server

```txt
./startAppServer.sh [-direct]
```

Stop the application server

```txt
./stopAppServer.sh [-direct]
```

![](images/05d9fa94eaf8e5cfbb9d57b3c947bdbb1204497434ad5fd17c5ec86387233329.jpg)

Note: If your WebSphere Application Server Liberty is installed for the Dynamic Workload Console, use the following syntax:

```txt
./stopAppServer.sh [-direct]  
[-user <user_ID>  
    -password <password>]
```

The user ID and password are optional only if you have specified them in the soap.client props file located in the properties directory of the WebSphere Application Server Liberty profile. Unlike

![](images/26fbbde5542825431cd53705704ca41da55ca290ed0d266600e1fae34b70b944.jpg)

the master domain manager installation, when you install the Dynamic Workload Console the soap.client props file is not automatically customized with these credentials.

# WindowsTM

# Start the application server

```batch
startAppServer.bat [-direct]
```

# Stop the application server

```txt
stopAppServer.bat [-direct [-wlpHome <installation_directory>] [-options <parameters>]]
```

# z/OS

# Start the application server

```txt
./startAppServer.sh [-direct]
```

# Stop the application server

```txt
./stopAppServer.sh [-direct]
```

where the arguments are as follows:

# -direct

Optionally starts or stops the application server without starting or stopping the application server monitor appservman.

For example, you might use this after changing some configuration parameters. By stopping WebSphere Application Server Liberty without stopping appservman, the latter will immediately restart WebSphere Application Server Liberty, using the new configuration properties.

This argument is mandatory on UNIX™ when the product components are not integrated.

# -options parameters

Optionally supplies parameters to the WebSphere Application Server Liberty startServer or stopServer commands. See the WebSphere Application Server Liberty documentation for details.

# -wlpHome installation_directory

Defines the WebSphere Application Server Liberty installation directory, if it is not the default value.

# Application server - automatic restart after failure

If you experience any problems with the application server failing, a service is available that not only monitors its status, but can also restart it automatically in the event of failure. The service is called appservman, and it is enabled and controlled by the local options on the computer where the application server is running.

The following sections describe the service, how it works, and how it is controlled:

- Appservman - how it works on page 425  
- Controlling appservman on page 425  
- Starting and stopping the application server and appservman on page 426  
Monitoring the application server status on page 427  
- Obtaining information about application server failures on page 427  
Events created by appservman on page 427

# Appservman - how it works

Appservman is a service that starts, stops and monitors the application server. It also optionally restarts the application server in the event that the latter fails. Appservman can be controlled not just from nodes running the application server, but also from any other node running conman.

It is launched as a service by netman when starting IBM Workload Scheduler, and it itself then launches the application server. Netman also launches it when the conman startappserver command is run.

Appservman is stopped when IBM Workload Scheduler is shut down. In addition, Netman stops both the application server and appservman when you use the conman stopappserver command, or, on Windows™ only, when you issue the Shutdown -- appsrv command.

While it is running appservman monitors the availability of the application server, sending events that report the status of the application server. If the automatic restart facility is enabled, and the application server fails, the service determines from the restart policy indicated in the localizepts options if it is to restart the application server. If the policy permits, it will restart the application server, and send events to report its actions.

Using the startappserver and stopappserver commands to stop the application server and appservman.

# Controlling appservman

Appservman is controlled by the following local options (in the locallyts file):

# Appserver auto restart

Determines if the automatic restart facility is enabled.

The default is yes. To disable the option set it to no.

# Appserver check interval

Determines how frequently the service checks on the status of the application server. You should not set this value to less than the typical time it takes to start the application server on the computer.

The default is every 3 minutes.

# Appserver min restart time

Determines the minimum time that must elapse between failures of the application server for the automatic restart to work. This option stops appservman from immediately restarting the application server if it fails on initial startup or when being restarted.

The default is 2 minutes.

# Appserver max restarts

Determines the maximum number of times that appservman will automatically restart the application server within a time frame determined by you (Appserver count reset interval).

The default is 5 restarts.

# Appserver count reset interval

Determines the time frame for the maximum number of restarts (Appserver max restarts).

The default is 24 hours.

# How to use the options

The default settings are a good starting point. Follow the indications below if you are not satisfied that the settings are maintaining the correct availability of the application server:

- If the application server is not restarting after failure, check the following:

- That the Appserver auto restart is set to yes.  
- That the Appserver check interval is not set to too high a value. For example, if this value is set to 50 minutes, instead of the default 3, an early failure of the application server might wait 45 minutes before being restarted.  
- That Appserver min restart time is sufficient for the application server to fully restart. If, when the server checks the status of the application server, it finds that the application server is still starting up, in some circumstances it is not able to distinguish the starting-up state from the failed state, will report it as failed, and try and restart it again. With the same result. This will continue until Appserver max restarts is exceeded. If this is the case, make Appserver min restart time larger.

- If the application server is failing infrequently, but after several failures is not restarting, set the Appserver max restarts option to a higher value or the Appserver count reset interval to a lower value, or both. In this case it might be advantageous to study the pattern of failures and tailor these options to give you the required availability

# Starting and stopping the application server and appservman

If you need to stop and restart WebSphere Application Server Liberty, for example to implement a change in the application server configuration, use the following conman commands:

# conman stopappserver[domain!] workstation [;wait]

This command stops the application server and appservman. You can optionally stop the application server on a remote workstation. The optional ;wait parameter tells conman to suspend processing until the command reports that both the application server and the service have stopped.

# conman startappserver[domain!]workstation [;wait]

This command starts the application server and appservman. You can optionally start the application server on a remote workstation. The optional ;wait parameter tells conman to suspend processing until the command reports that both the application server and the service are up and running.

To stop and start the application server without stopping appservman, see Application server - starting and stopping on page 423.

# Monitoring the application server status

To see the current status of the application server at any time view the STATE field in the workstation details.

This field contains a string of characters that provide information about the statuses of objects and processes on the workstation. The state of the application server is a one-character flag in this string, which has one of the following values if the application server is installed:

```txt
[A|R]
```

where:

A

WebSphere Application Server Liberty is running.

R

WebSphere Application Server Liberty is restarting.

If WebSphere Application Server Liberty is down or if it was not installed, neither value of the flag is present in the STATE entry.

# Obtaining information about application server failures

Appservman does not provide information about why the application server has failed. To obtain this information, look in the application server log files (see the IBM Workload Scheduler: Troubleshooting Guide).

# Events created by appservman

Appservman sends an event called ApplicationServerStatusChanged from the TWSObjectsMonitor provider to the configured event monitoring process every time the status of the application server changes.

# Application server - encrypting the profile properties files

For more information about encrypting passwords in WebSphere Application Server Liberty profile properties files, see the related documentation, for example securityUtility command.

This utility requires the JAVA_HOME environment variable to be set. If you do not have Java installed, you can optionally use the Java version provided with the product and available in:

IBM® Workload Scheduler

```txt
<INST_DIR>/TWS/JavaExt/jre/jre
```

Dynamic Workload Console

```txt
<DWC_INST_DIR>/java/jre/bin
```

# Application server - configuration files backup and restore

On UNIX operating systems, all configuration files are stored in the <TWA_DATA_DIR>/usr and <DWC_DATA_dir>/usr.

On Windows operating systems, backup the files in \TWA_home\usr and \DWC_home\usr.

# Application server - changing the host name or TCP/IP ports

To modify the host name of the computer where the application server is installed, or the TCP/IP ports it uses, use the following templates:

host_variables.xml

Specify the hostname in the variable name property.

ports_variable.xml

Edit the following properties as required:

- host.http.port  
- host=https.port  
- host).(bootstrap).port  
- host.bootstrapsport.sec

To disable a port, set its value to -1.

Edit the files as required using the following basic procedure:

1. Copy the template file from the templates folder to a working folder.  
2. Edit the template file in the working folder with the desired configuration.  
3. Optionally, create a backup copy of the relevant configuration file present in the overrides directory in a different directory. Ensure you do not copy the backup file in the path where the template files are located.  
4. Copy the updated template file to the overrides folder. Maintaining the original folder structure is not required.  
5. Changes are effective immediately.

For more information about the procedure, see Configuring IBM Workload Scheduler using templates on page 418. For more information about WebSphere® Liberty configuration, see the related documentation, for example HTTP Endpoint (httpEndpoint) and Configuring an httpEndpoint to use an SSL configuration.

# Application server - changing the trace properties

To modify the trace properties, modify the trace.xml template as necessary.

Templates for the master domain manager are stored in the following paths:

On UNIX operating systems

TWA_home/usr/server/engineServer configDropins/template

# On Windows operating systems

TWA_home\usr\servers\engineServer\configDropins\templates

Templates for the Dynamic Workload Console are stored in the following paths:

# On UNIX operating systems

DWC_home/usr/servers/dwcServer/configDropins/template

# On Windows operating systems

DWC_home\usr\servers\dwcServer\configDropins\templates

When you edit the file with your customized settings for the master domain manager, move it to the following paths:

# On UNIX operating systems

TWA_DATA_DIR/usr/server/engineServer/configDropins/overrides

# On Windows operating systems

TWA_home\usr\servers\engineServer\configDropins\overridden

When you edit the file with your customized settings for the Dynamic Workload Console, move it to the following paths:

# On UNIX operating systems

DWC_DATA_dir/usr/servers/dwcServer/configDropins/overrides

# On Windows operating systems

DWC_home\usr\servers\dwcServer\configDropins\overridden

To modify the trace.xml template, follow this procedure:

1. Copy the template file from the templates folder to a working folder.  
2. Edit the template file in the working folder with the desired configuration.  
3. Optionally, create a backup copy of the relevant configuration file present in the overrides directory in a different directory. Ensure you do not copy the backup file in the path where the template files are located.  
4. Copy the updated template file to the overrides folder. Maintaining the original folder structure is not required.  
5. Changes are effective immediately.

# Chapter 9. Administering an IBM i dynamic environment

On overview on how to administer the IBM Workload Scheduler IBM i dynamic environment.

To begin scheduling jobs with advanced options on IBM i agents, the agents must be configured.

# Configuring the agent on IBM i systems

An overview on how to configure the agent on IBM i systems.

The configuration settings of the agent are contained in the JobManager.ini file and in the JobManagerGW.ini file (for the path of these files, see the section about installation paths in IBM Workload Scheduler: Planning and Installation).

The configuration files are made up of many different sections. Each section name is enclosed between square brackets and each section includes a sequence of variable = value statements.

You can customize properties for the following:

- Log properties  
- Trace properties when the agent is stopped. You can also customize traces when the agent is running using the procedure described in Configuring trace properties when the agent is running on page 78.  
- Native job executor  
- Java™ job executor  
Resource advisor agent  
- System scanner

On IBM i systems, the log messages are written in the following file:

```txt
TWA_DATA_DIR>/stdlib/JM/JoBManager_message.log
```

On IBM i systems, the trace messages are written in the following files:

```txt
<TWA_DATA_DIR>/TWS/stdlist/JM/ITA_trace.log  
<TWA_DATA_DIR>/TWS/stdlist/JM/JobManager_trace.log  
<TWA_DATA_DIR>/TWS/stdlist/JM/javaExecutor0.log
```

Not all the properties in the JobManager.ini file and in the JobManagerGW.ini file can be customized. For a list of the configurable properties, see the following sections:

- Configuring log message properties [JobManager Logging.cclog] on page 75.  
- Configuring trace properties when the agent is stopped [JobManager Logging.cclog] on page 77.  
- Configuring common launchers properties [Launchers] on page 81.  
- Configuring properties of the native job launcher [NativeJobLauncher] on page 83.  
- Configuring properties of the Java job launcher [JavaJobLauncher] on page 86.  
- Configuring properties of the Resource advisor agent [ResourceAdvisorAgent] on page 87.  
- Configuring properties of the System scanner [SystemScanner] on page 89

![](images/4f4d6378fb8038eed8a4ec1cb9c122c2bdacf426b242e93ca717ec4137c218d8.jpg)

Note: In the JobManager.ini file and in the JobManagerGW.ini file you must refer to Java 64 bit version.

# Configuring log message properties [JobManager Logging.cclog]

# About this task

To configure the logs, edit the [JobManager Logging.ccclog] section in the JobManager.ini file. This procedure requires that you stop and restart the IBM Workload Scheduler agent

The section containing the log properties is named:

```json
[JobManager Logging.cblog]
```

You can change the following properties:

JobManager/loggerhd.fileName

The name of the file where messages are to be logged. the default value is

On Windows operating systems

```batch
TWA_home\stdlib\JM\JOBMANAGER-FFDC
```

On UNIX operating systems

```txt
$\S$  (TWA_DATA_DIR)/stdlib/JM/JobManager_message.log
```

JobManager/loggerhd.maxFileBytes

The maximum size that the log file can reach. The default is 1024000 bytes.

JobManager/loggerhd.maxFiles

The maximum number of log files that can be stored. The default is 3.

JobManager/loggerhd.fileEncoding

By default, log files for the agent are coded in UTF-8 format. If you want to produce the log in a different format, add this property and specify the required codepage.

JobManager.loggerfl.level

The amount of information to be provided in the logs. The value ranges from 3000 to 7000. Smaller numbers correspond to more detailed logs. The default is 3000.

JobManager.ddc.maxDiskSpace

Exceeding this maximum disk space, log files collected by the first failure data capture mechanism are removed, beginning with the oldest files first.

JobManager.ddc.baseDir

The directory to which log and trace files collected by the ffdc tool are copied. The default directory is

On Windows operating systems

```txt
TWA_home\stdlib\JM\JobManager_message.log
```

# On UNIX operating systems

$\S$  (TWA_DATA_DIR)/stdlib/JM/JobManager_message.log

# JobManager.ddc.filesToCopy

Log and trace files (JobManager_message.log and JobManager_trace.log) collected by the ffdc tool located in <TWA_home>\TWS\stdlib>JM. The files are available in the following paths:

# On Windows operating systems

- TWA_home/TWS/stdlist/JM/JobManager_message.log  
- TWA_home/TWS/stdlist/JM/JobManager_trace.log

# On UNIX operating systems

$\cdot \S$  (TWA_DATA_DIR)/stdlib/JM/JobManager_message.log  
$\S$  (TWA_DATA_DIR)/stdlib/PM/JobManager_trace.log

When a message is logged (JobManager.ffdc_triggerFilter = JobManager.msgIdFilter) that has an ID that matches the pattern "AWSITA*E" (JobManager.msgIdFilter.msglds = AWSITA*E), which corresponds to all error messages, then the log and trace files (JobManager.ffdc.filesToCopy = "/opt/IBM/TWA_<TWS_user>/TWS/stdlist/JM/JobManager_message.log" "/opt/IBM/TWA_<TWS_user>/TWS/stdlist/JM/JobManager_trace.log") are copied (JobManager.ffdcClassName = ccg_ffdc_filecopy_handler) to the directory JOBMANAGER-FFDC (JobManager.ffdc.baseDir = /opt/IBM/TWA_<TWS_user>/TWS/stdlist/JM/JobMANAGER-FFDC). If the files copied exceed 10 MB (JobManager.ffdc.maxDiskSpace = 10000000), then the oldest files are removed first (JobManager.ffdc.quotaPolicy = QUOTA_AUTODELETE).

After installing the z-centric agent or dynamic agent on Windows 2012, the JobManager_message.log might not be created. In this case, perform the following procedure:

1. Stop the agent.  
2. Create a backup copy of JobManager.ini, and edit the original file by changing the row:

```txt
JobManager/loggerhd.className = ccgMULTIProc_filehandler
```

to

```txt
JobManager/loggerhd.className = ccg_filehandler
```

3. Restart the agent.

# Configuring trace properties when the agent is stopped [JobManager Logging.cclog]

How to configure the trace properties when the agent is stopped.

To configure the trace properties when the agent is stopped, edit the [JobManager Logging] section in the JobManager.ini file and then restart the IBM Workload Scheduler agent.

The section containing the trace properties is named:

[JobManager Logging.cclog]

You can change the following properties:

# JobManager.trhd.fileName

The name of the trace file. the default path is as follows:

# On Windows operating systems

TWA_home/TWS/stdlist/JM/JobManager_trace.log

# On UNIX operating systems

$\S$  (TWA_DATA_DIR)/stdlib/JM/JobManager_trace.log

# JobManager.trhd.maxFileBytes

The maximum size that the trace file can reach. The default is 10240000 bytes.

# JobManager.trhd.maxFiles

The maximum number of trace files that can be stored. The default is 5.

# JobManager.trfl.level

Determines the type of trace messages that are logged. Change this value to trace more or fewer events, as appropriate, or on request from IBM Software Support. Valid values are:

# DEBUG_MAX

Maximum tracing. Every trace message in the code is written to the trace logs.

# INFO

All informational, warning, error and critical trace messages are written to the trace. The default value.

# WARNING

All warning, error and critical trace messages are written to the trace.

# ERROR

All error and critical trace messages are written to the trace.

# CRITICAL

Only messages which cause the agent to stop are written to the trace.

The output trace (JobManager_trace.log) is provided in XML format.

After installing the z-centric agent or dynamic agent on Windows 2012, the JobManager_trace.log might not be created. In this case, perform the following procedure:

1. Stop the agent.  
2. Create a backup copy of JobManager.ini, and edit the original file by changing the row:

JobManager.trhd.className = ccg_multipleproc_filehandler

to

```txt
JobManager.trhd.className = ccg_filehandler
```

3. Restart the agent.

# Configuring trace properties when the agent is running

Use the twstrace command to set the trace on the agent when it is running.

Using the twstrace command, you can perform the following actions on the agent when it is running:

- See command usage and verify version on page 79.  
- Enable or disable trace on page 79.  
- Set the traces to a specific level, specify the number of trace files you want to create, and the maximum size of each trace file. See Set trace information on page 79.  
Show trace information on page 80.  
- Collect trace files, message files, and configuration files in a compressed file using the command line. See Collect trace information on page 80.  
- Collect trace files, message files, and configuration files in a compressed file using the Dynamic Workload Console. See the section about retrieving agent traces from the Dynamic Workload Console in Troubleshooting Guide.

You can also configure the traces when the agent is not running by editing the [JobManager Logging] section in the JobManager.ini file as described in Configuring the agent on page 71. This procedure requires that you stop and restart the agent.

# twstrace command

Use the twstrace command to configure traces, and collect logs, traces, and configuration files (ita.ini and jobManager.ini) for agents. You collect all the information in a compressed file when it is running without stopping and restarting it.

# See command usage and verify version

To see the command usage and options, use the following syntax.

# Syntax

twstrace -u | -v

# Parameters

-u

Shows the command usage.

-V

Shows the command version.

# Enable or disable trace

To set the trace to the maximum or minimum level, use the following syntax.

# Syntax

twstrace -enable | -disable

# Parameters

-enable

Sets the trace to the maximum level. The maximum level is 1000.

-disabled

Sets the trace to the minimum level. The minimum level is 3000.

# Set trace information

To set the trace to a specific level, specify the number of trace files you want to create, and the maximum size the trace files can reach, use the following syntax.

# Syntax

twstrace [-level <level_number>] [-maxFiles <files_number>] [-maxFileBytes <bytes_number>]

# Parameters

-level<level_number>

Sets the trace level. Specify a value in the range from 1000 to 3000, which is also the default value. Note that if you set this parameter to 3000, you have the lowest morbidity level and the fewest trace messages. To have a better trace level, with the most verbose trace messages and the maximum trace level, set it to 1000.

-maxFiles <files_number>

Specify the number of trace files you want to create.

-maxFileBytes <bytes_number>

Set the maximum size in bytes that the trace files can reach. The default is 1024000 bytes.

# Show trace information

To display the current trace level, the number of trace files, and the maximum size the trace files can reach, use the following syntax.

# Syntax

twstrace -level | -maxFiles | -maxFileBytes

# Parameters

-level

See the trace level you set.

-maxFiles

See the number of trace files you create.

-maxFileBytes

See the maximum size you set for each trace file

# Example

# Sample

The example shows the information you receive when you run the following command:

```batch
twstrace -level -maxFiles -maxFileBytes
```

```txt
AWSITA176I The trace properties are: level="1000", max files="3", file size="1024000".
```

# Collect trace information

To collect the trace files, the message files, and the configuration files in a compressed file, use the following syntax.

# Syntax

twstrace -getLogs [-zipFile <compressed_file_name>] [-host <host_name>] [-protocol {http | https} [-port <port_number>] [-iniFile <ini_file_name>]

# Parameters

-zipFile <compressed_file_name>

Specify the name of the compressed file that contains all the information, that is logs, traces, and configuration files (ita.ini and jobManager.ini) for the agent. The default is logs.zip.

-host <host_name>

Specify the host name or the IP address of the agent for which you want to collect the trace. The default is localhost.

-protocol http?https

Specify the protocol of the agent for which you are collecting the trace. The default is the protocol specified in the .ini file of the agent.

-port <port_number>

Specify the port of the agent. The default is the port number of the agent where you are running the command line.

-iniFile <ini_file_name>

Specify the name of the .ini file that contains the SSL configuration of the agent for which you want to collect the traces. If you are collecting the traces for a remote agent for which you customized the security certificates, you must import the certificate on the local agent and specify the name of the .ini file that contains this configuration. To do this, perform the following actions:

1. Extract the certificate from the keystore of the remote agent.  
2. Import the certificate in a local agent keystore. You can create an ad hoc keystore whose name must be TWSClientKeyStore.kdb.  
3. Create an .ini file in which you specify:

0 in the tcp_port property as follows:

```txt
tcp_port=0
```

- The port of the remote agent in the ssl_port property as follows:

```txt
ssl_port=<ssl_port>
```

- The path to the keystore you created in Step 2 on page 437 in the keyrepository_path property as follows:

```xml
key_repository_path=<local_agent_keystore_path>
```

# Configuring common launchers properties [Launchers]

# About this task

In the JobManager.ini file, the section containing the properties common to the different launchers (or executors) is named:

```json
[Launchers]
```

The following properties are available:

# BaseDir

The installation path of the IBM Workload Scheduler agent. Do not modify this value.

# CommandHandlerMinThreads

Indicates the maximum number of commands that can be run on the agent concurrently. Limits to the number of jobs vary depending on the resources of your workstation, however consider that operations on command are usually short. The default is 20. Usually, there is no need to modify this setting, even if you plan a very high workload on the agent. You might want to change it if many commands are run concurrently on the agent, for example, many concurrent requests to retrieve job logs.

# CommandHandlerMaxThreads

Indicates the maximum number of commands that can be run on the agent concurrently. Limits to the number of jobs vary depending on the resources of your workstation, however consider that operations on commander are usually short. The default is 100. Usually, there is no need to modify this setting, even if you plan a very high workload on the agent. You might want to change it if many commands are run concurrently on the agent, for example, many concurrent requests to retrieve job logs.

# CpaHeartBeatTimeSeconds

The polling interval in seconds used to verify if the agent process is still up and running. If the agent process is inactive the product stops also the JobManager process. The default is 30. Modify only if you use dynamic pools with CPU-based requirements or optimization policies. With a lower value, the agent reacts quickly to

CPU modifications, but this might cause unstable values in case of CPU spikes. Lower values causes a higher use of resources on the agent.

# DirectoryPermissions

The access rights assigned to the agent for creating directories when running jobs. The default is 0755.

Supported values are UNIX-format entries in hexadecimal notation.

# DownloadDir

The name of the directory where the fix pack installation package or upgrade elmage for IBM Workload Scheduler fault-tolerant agents or dynamic agents is downloaded during the centralized agent update process. If not specified, the following default directory is used:

# On Windows operating systems:

TWA_home\TWS\stdlib\JM\download

# On UNIX operating systems:

TWA_DATA_DIR/TWS/stdlist/JM/download

The centralized agent update process does not apply to z-centric agents.

# ExecutorsMaxThreads

Specifies the maximum number of jobs the dynamic agent can run concurrently. For example, to allow the dynamic agent to run a maximum of 500 jobs concurrently, set this parameter to 500. The default is 400.

# ExecutorsMinThreads

Specifies the minimum number of jobs the dynamic agent can run concurrently. For example, to allow the dynamic agent to run a minimum of 500 jobs concurrently, set this parameter to 500. The default is 38. Modify if the number of expected concurrent jobs is much higher than 38. The agent dynamically allocates more threads if necessary, until it reaches the value specified in ExecutorsMaxThreads.

# FilePermissions

The access rights assigned to the agent for creating files when running jobs. The default is 0755. Supported values are UNIX-format entries in hexadecimal notation.

# MaxAge

The number of days that job logs are kept (in path TWA_home/TWS/stdlidst/JM) before being deleted. The default is 30. Possible values range from a minimum of 1 day.

# NotifierMaxThreads

Notifier threads are in charge of notifying the dynamic workload broker of each status change in a job. This parameter specifies the maximum number of job status changes that can be notified to the dynamic workload broker.

# NotifierMinThreads

Notifier threads are in charge of notifying the dynamic workload broker of each status change in a job. This parameter specifies the minimum number of job status changes that can be notified to the dynamic workload

broker. The default value is 3. Modify this parameters only in case of unexpected errors and after consulting with software support team.

# SpoolDir

The path to the folder containing the jobstore and outputs. The default is:

# On Windows operating systems

TWA_home/TWS/stdlist/JM

# On UNIX operating systems

$(TWA_DATA_DIR/stdlist/JM

# StackSizeBytes

The size of the operating system stack in bytes. The default is DEFAULT, meaning that the agent uses the default value for the operating system. Do not modify this parameter unless instructed to do so by the software support team. Incorrect values can cause the agent to crash.

# Configuring properties of the native job launcher [NativeJobLauncher]

# About this task

In the JobManager.ini file, the section containing the properties of the native job launcher is named:

[NativeJobLauncher]

You can change the following properties:

# AllowRoot

Applies to UNIX™ systems only. Specifies if the root user can run jobs on the agent. It can be true or false. The default is false. This property does not apply to IBM i, use the AllowQSECOFR option instead

# AllowQECOFR

Applies to IBM i systems only. Specifies if QSECOFR user can run jobs on the agent. It can be true or false. The default is true. Add a line like AllowQSECOFR = false to the JobManager.ini file to deny job execution to QSECOFR.

# CheckExec

If true, before launching the job, the agent checks both the availability and the execution rights of the binary file. The default is true.

# DefaultWorkingDir

Specifies the working directory of native jobs. You can also specify the value for the working directory when creating or editing the job definition in the Graphical Designer. When specified in the Graphical Designer, this value overrides the value specified for the DefaultWorkingDir property. If you do not specify any working directories, the <TWS_home>\bin directory is used.

# JobUnspecifiedInteractive

Applies to Windows™ operating systems only. Specifies if native jobs are to be launched in interactive mode. It can be true or false. The default is false.

# KeepCommandTraces

Set to true to store the traces of the method invocation for actions performed on a job definition, for example, when selecting from a picklist. These files are stored in the path /opt/IBM/TWA<TWS_user>/TWS/ stdlist/JM/r3batch_cmd_exec. The default setting is false.

# KeepJobCommandTraces

Set to true to store the traces of the method invocation for actions performed on a job instance, for example, viewing a spool list. These files are stored in the .zip file of the job instance. The default setting is true.

# LoadProfile

Applies to agents on Windows servers only. Specifies if the user profile is to be loaded. It can be true or false. The default is true.

# MonitorQueueName

Specifies the name of the queue where the IBM i jobs are monitored. If you do not specify this property, the default queue (QBATCH) is used.

# PortMax

The maximum range of the port numbers used by the task launcher to communicate with the Job Manager. The default is 0, meaning that the operating system assigns the port automatically.

# PortMin

The minimum range of the port numbers used by the task launcher to communicate with the Job Manager. The default is 0, meaning that the operating system assigns the port automatically.

# PostJobExecScriptPathName

The fully qualified path of the script file that you want to run when the job completes. By default, this property is not present in the JobManager.ini file. If you do not specify any file path or the script file doesn't exist, no action is taken.

This property applies to dynamic agent and z/OS agent. For details about running a script when a job completes, see User's Guide and Reference.

# PromotedNice

Used in workload service assurance. This property is not supported on the Agent for z/OS.

For UNIX and Linux operating systems only, assigns the priority value to a critical job that needs to be promoted so that the operating system processes it before others. Applies to critical jobs or predecessors that need to be promoted so that they can start at their critical start time.

Boundary values vary depending upon each specific platform, but generally lower values correspond to higher priority levels and vice versa. The default is -1.

# Be aware that:

- The promotion process is effective with negative values only. If you set a positive value, the system runs it with the -1 default value.  
- An out of range value (for example -200), prompts the operating system to automatically promote the jobs with the lowest allowed nice value.  
- Overusing the promotion mechanism (that is, defining an exceedingly high number of jobs as mission critical and setting the highest priority value here) might overload the operating system, negatively impacting the overall performance of the workstation.

# PromotedPriority

Used in workload service assurance. This property is not supported on the Agent for z/OS.

For Windows operating systems only, sets to this value the priority by which the operating system processes a critical job when it is promoted. Applies to critical jobs or predecessors that need to be promoted so that they can start at their critical start time. Valid values are:

High  
- AboveNormal (the default)  
Normal  
BelowNormal  
Low Or Idle

Note that if you a set a lower priority value than the one non-critical jobs might be assigned, no warning is given.

# RequireUserName

When true, requires that you add the user name in the JSDL job definition.

When false, runs with the user name used by job manager, that is:

- TWS_user on UNIX™ and Linux™ systems  
- The local system account on Windows™ systems

The default is false.

# RunExecutablesAsIBMiJobs

If you set this property to true, you can define IBM i jobs as generic jobs without using the XML definition. Generic jobs are automatically converted to IBM i jobs. As a side effect, generic jobs cannot be run when this parameter is enabled (RunExecutablesAsIBMiJobs=true). There is no default value because this property is not listed in the JobManager.ini file after the agent installation.

If you set this property to true, ensure that the user you used to install the agent has been granted the *ALLOBJ special authority.

# RunInteractiveJobOnInvalidSession

Applies only to native and executable jobs starting interactive programs running on dynamic agents installed on Windows operating systems. Interactive programs run only if the job user has an active session open when the job runs. If there is no active session for the job user, the job behavior is defined by this property, as follows. Set the property to true to enable jobs to start interactive programs even if there is no active session for the job user. Set the property to false to prevent jobs from starting interactive programs if there is no active session for the job user.

# ScriptSuffix

The suffix to be used when creating the script files. It is:

. cmd

For Windows

.sh

For UNIX

# verboseTracing

Enables verbose tracing. It is set to true by default.

# Configuring properties of the Java™ job launcher [JavaJobLauncher]

# About this task

In the JobManager.ini file, the section containing the properties of the Java™ job launcher is named:

[JavaJobLoader]

You can change the following property:

# JVMOptions

The options to provide to the Java™ Virtual Machine used to start job types with advanced options. Supported keywords for establishing a secure connection are:

- https @@proxyHost  
- https.protoPort

Supported keywords for establishing a non-secure connection are:

Dhttp-proxyHost  
Dhttp-proxyPort

For example, to set job types with advanced options, based on the default JVM http protocol handler, to the unauthenticated proxy server called with name myproxyserver.mycompany.com, define the following option:

JVMOptions = -Dhttp-proxyHost=myproxyserver.mycompany.com -Dhttp-proxyPort=80

# Configuring properties of the Resource advisor agent [ResourceAdvisorAgent]

# About this task

In the JobManager.ini and JobManagerGW.ini files, the section containing the properties of the Resource advisor agent is named:

[ResourceAdvisorAgent]

You can change the following properties:

# BackupResourceAdvisorUrls

The list of URLs returned by the IBM Workload Scheduler master in a distributed environment or by the dynamic domain manager either in a z/OS or in a distributed environment. The agent uses this list to connect to the master or dynamic domain manager.

# CPUScannerPeriodSeconds

The time interval that the Resource advisor agent collects resource information about the local CPU. The default value is every 10 seconds.

# FullyQualifiedHostname

The fully qualified host name of the agent. It is configured automatically at installation time and is used to connect with the master in a distributed environment or with the dynamic domain manager in a z/OS or in a distributed environment. Edit only if the host name is changed after installation.

# NotifyToResourceAdvisorPeriodSeconds

The time interval that the Resource advisor agent forwards the collected resource information to the Resource advisor. The default value is every 119 seconds.

# ResourceAdvisorUrl

# JobManager.ini

The URL of the master in a distributed environment, or of the dynamic domain manager in a z/OS or in a distributed environment, that is hosting the agent. This URL is used until the server replies with the list of its URLs. The value is https:// $\mathbb{S}(\text{tdwb_server}):$ $\mathbb{S}(\text{tdwb_port})/$  JobManagerRESTWeb/JobScheduler/resource, where:

# $(tdwb_server)$

is the fully qualified host name of the master in a distributed environment or of the dynamic domain manager either in a z/OS or in a distributed environment.

#  $(tdwb_port)

is the port number of the master in a distributed environment or of the dynamic domain manager either in a z/OS or in a distributed environment.

It is configured automatically at installation time. Edit only if the host name or the port number are changed after installation, or if you do not use secure connection (set to http). If you set the port number to zero, the resource advisor agent does

not start. The port is set to zero if at installation time you specify that you will not be using the master in a distributed environment or the dynamic domain manager either in a z/OS or in a distributed environment.

In a distributed environment, if -gateway is set to either local or remote, then this is the URL of the dynamic agent workstation where the gateway resides and through which the dynamic agents communicate. The value is https://\ $(tdwb_server):\$  (tdwb_port)/ita/JobManagerGW/ JobManagerRESTWeb/JobScheduler/resource, where:

# $(tdwb_server)$

The fully qualified host name of the dynamic agent workstation where the gateway resides and through which the dynamic agent communicates with the dynamic workload broker.

#  $(tdwb_port)

The port number of the dynamic agent workstation where the gateway resides and through which the dynamic agent communicates with the dynamic workload broker.

# JobManagerGW.ini

In a distributed environment, if -gateway is set to local, then ResourceAdvisorUrl is the URL of the master or dynamic domain manager. The value is https://\(\mathbb{S}\) (tdwb_server): \)\mathbb{S}\) (tdwb_port)/JobManagerRESTWeb/JobScheduler/resource, where:

# $(tdwb_server)$

The fully qualified host name of the master or dynamic domain manager.

#  $(tdwb_port)

The port number of the master or dynamic domain manager.

# ScannerPeriodSeconds

The time interval that the Resource advisor agent collects information about all the resources in the local system other than CPU resources. The default value is every 120 seconds.

The resource advisor agent, intermittently scans the resources of the machine (computer system, operating system, file systems and networks) and periodically sends an update of their status to the master or dynamic domain manager either in a z/OS or in a distributed environment.

The CPU is scanned every CPUScannerPeriodSeconds seconds, while all the other resources are scanned every ScannerPeriodSeconds seconds. As soon as one of the scans shows a significant change in the status of a resource, the resources are synchronized with the master in a distributed environment or the dynamic domain manager either in a z/OS or in a distributed environment. The following is the policy followed by the agent to tell if a resource attribute has significantly changed:

- A resource is added or deleted  
- A string attribute changes its value

- A CPU value changes by more than DeltaForCPU  
- A file system value changes by more than DeltaForDiskMB megabytes  
- A Memory value changes by more than DeltaForMemoryMB megabytes

If there are no significant changes, the resources are synchronized with the IBM Workload Scheduler master in a distributed environment or with the dynamic domain manager either in a z/OS or in a distributed environment every NotifyToResourceAdvisorPeriodSeconds seconds.

# Configuring properties of the System scanner [SystemScanner]

# About this task

In the JobManager.ini file, the section containing the properties of the System scanner is named:

[SystemScanner]

You can change the following properties:

# CPUSamples

The number of samples used to calculate the average CPU usage. The default value is 3.

# DeltaForCPU

The change in CPU usage considered to be significant when it becomes higher than this percentage (for example, DeltaForCPU is 20 if the CPU usage changes from 10 percent to 30 percent). The default value is 20 percent.

# DeltaForDiskMB

The change in use of all file system resources that is considered significant when it becomes higher than this value. The default value is 100 MB.

# DeltaForMemoryMB

The change in use of all system memory that is considered significant when it becomes higher than this value. The default value is 100 MB.

# Configuring to schedule job types with advanced options

# About this task

You can define job types with advanced options by using the related configuration files. The options you define in the configuration files apply to all job types with advanced options of the same type. You can override these options when defining the job by using the Dynamic Workload Console or, if you are in a distributed environment, the composer command.

Configuration files are available on each dynamic agent in TWA_home/TWS/JavaExtcfg for the following job types with advanced options:

Table 71. Configuration files for job types with advanced options  

<table><tr><td>Job type</td><td>File name</td><td>Keyword</td></tr><tr><td>·Database job type
·MSSQL Job</td><td>DatabaseJobExecutor.properties</td><td>Use the jdbcDriversPath keyword to specify the path to the JDBC drivers. Define the keyword so that it points to the JDBC jar files directory, for example:
jdbcDriversPath=c:\mydir\jars\jdbc
The JDBC jar files must be located in the specified directory or its subdirectories. Ensure you have list permissions on the directory and its sub directories.
Note: For the MSSQL database, use version 4 of the JDBC drivers.</td></tr><tr><td>Java™ job type</td><td>JavaJobExecutor.properties</td><td>Use the jarPath keyword to specify the path to the directory where the jar files are stored. This includes all jar files stored in the specified directory and all sub directories.</td></tr><tr><td>J2EE job type</td><td>J2EEJobExecutorConfig.properties</td><td>For more information about the J2EE job type, see the topic about configuring to schedule J2EE jobs in the IBM Workload Scheduler: Administration Guide.</td></tr></table>

# Chapter 10. Performance

This chapter provides information about issues that impact performance. Use this information both to prevent problems occurring and to help resolve problems that occur.

# Network traffic

A full description of how a IBM Workload Scheduler network is structured, and how the different nodes communicate, is provided at the beginning of Network administration on page 274. In particular, see Optimizing the network on page 289, which explains how to design and operate your IBM Workload Scheduler network to maximize performance.

# Tracing

The performance of any workstation can be impacted by the level of tracing it has to perform.

The Troubleshooting Guide has a chapter which explains the diagnostic tools that are available.

The performance might also be impacted by the tracing activities on WebSphere Application Server Liberty.

# Logging

The performance of any workstation can be impacted by the way the IBM Workload Scheduler logging mechanism uses memory. The default settings applied in this version are designed to ensure the maximum performance. However, because these defaults are different from the defaults in earlier versions, if you are experiencing performance problems, it is advisable to check that these settings have not been in some way overwritten by the previous values. In the diagnostic tools chapter of IBM Workload Scheduler: Troubleshooting Guide, there is a section about CCLog, which, apart from discussing how to customize CCLog, also describes how to check the CCLog processing defaults.

# Symphony file sizing

To calculate the size of the Symphony file and understand its impact on performance, see Avoiding full file systems on page 334.

# Tuning a UNIX™ domain manager to handle large numbers of fault-tolerant agents

The performance of domain managers on UNIX™ is impacted if they are overloaded with jobs. Improvements can be obtained by modifying the kernel parameters. The precise settings differ according to operating system, and you might need to test different settings to obtain optimum performance.

The following is an example of the kernel settings for Linux (kernel t3.10.0-514.e17.x86_64) to handle 500000 jobs per day workload:

data seg size=unlimited  
scheduling priority=0  
file size=unlimited

```txt
pending signals=124946  
max locked memory=64  
max memory size=unlimited  
open files=105000  
pipe size=8  
POSIX message queues=819200  
real-time priority=0  
stack size=10240  
cpu time=unlimited  
max user processes=16384  
virtual memory=unlimited  
file locks=unlimited
```

# Tuning job processing on a workstation

This section explains how to tune selected options in the IBM Workload Scheduler `localargs` file to improve IBM Workload Scheduler performance. These options control the period between successive instances of an activity. Table 72: Options for tuning job processing on a workstation on page 448 shows the activities to be tuned, the corresponding option that can be set in the `localargs` file, and how the changed value impacts performance.

Table 72. Options for tuning job processing on a workstation  

<table><tr><td>Activity</td><td>Option</td><td>Impact on performance</td></tr><tr><td>batchman periodically scans the Symphony file for jobs ready to be processed.</td><td>bm look</td><td rowspan="3">In all these cases, a shorter time means more frequent scans, using more cpu resources, and impacting other processes that are running. However, it also means that for all activities waiting time is kept to a minimum. If throughput is important and the workstation has plenty of memory, try shortening the times.</td></tr><tr><td>jobman accesses the Courier.msg file to see if there are jobs that need to be launched.</td><td>jm read</td></tr><tr><td>After having launched a job jobman checks periodically for job completion status.</td><td>jm look</td></tr><tr><td>mailman looks periodically in the Mailbox.msg for completed jobs.</td><td>mm read</td><td rowspan="2">A longer period between successive activities means jobs take longer to run, because there are longer waits for each activity. However, the reduced frequency of the scans means that more memory is available for jobs because less is being used by these monitoring activities.</td></tr><tr><td>batchman checks periodically in Intercom.msg for jobs that are complete so that it can update the Symphony file.</td><td>bm read</td></tr><tr><td></td><td></td><td>Consider the meaning of the various options. If your objective is to run the jobs as quickly as possible, but you are not concerned about how quickly the information about completed jobs is distributed, you could reduce the wait periods for bm look and jm read, but increase the periods for the others.</td></tr><tr><td></td><td></td><td>Alternatively, to speed up the overall job processing time (from initial job launch to the update with the</td></tr></table>

Table 72. Options for tuning job processing on a workstation (continued)  

<table><tr><td>Activity</td><td>Option</td><td>Impact on performance</td></tr><tr><td></td><td></td><td>completion status), you can tune bm look, jm look, and mm read.</td></tr></table>

If you decide to tune these settings do the following:

- Test the result in a test system before applying changes in your production environment. To get worthwhile results, the test environment must have the same characteristics as the production environment.  
- Modify only the parameters that are necessary. It is better to modify one at a time and thoroughly test the change in performance, rather than changing all at once.  
- Make a backup copy of the locally files to ensure you can revert to the default options if necessary.

Stop and start the agent to activate changes applied to the localopts file.

# Tuning plan replication

Tuning plan replication involves configuring specific settings to optimize the process of replicating plan data into the database. Plan replication ensures quick and reliable access to plan data stored in the database. Its main objective is to provide quick response times and increased overall performance. Sometimes, if this synchronization process is not configured appropriately for the size of your workload, you might notice some discrepancies in your environment, such as job status misalignment between the command line (conman) and the monitoring results obtained in the Dynamic Workload Console.

There are a few simple settings you can configure to optimize performance:

# Configure the cache size

Add the following properties to the TwSConfig.properties file located in the following paths:

# On Windows operating systems

```txt
<TWA_home>\usr\server\engineServer\resources\properties
```

# On UNIX operating systems

```txt
<TWA_DATA_DIR>/usr/server/engineServer/resources.properties
```

```txt
Custom property which defines the number of threads and queues needed to handle the plan updates com.ibm.tws.planner.monitor.subProcessors=10
```

```txt
Custom property which optimizes the DB access for file dependency status update com.ibm.tws.planner.monitor.filecachesize=40000
```

```txt
#Customer property which optimizes the DB access for job and job stream status update
com.ibm.tws.planner|monitor.cachesize=40000
```

In addition, follow the steps to increase the heap size settings (initialHeapSize = 2048 and maximumHeapSize = 4096) of the application server on the master domain manager as documented in the Administration Guide.

# Tuning the database

Tuning the database requires specific steps which vary depending on the database. To find detailed and specific information consult the relevant product documentation.

# Optimizing the replication of the Symphony file in the database

Tuning DB2 database configuration parameters to improve performance when the Symphony file is replicated in the database.

In a IBM Workload Scheduler environment where more than 200,000 jobs are scheduled to be submitted, there are several DB2 database configuration parameters than can be tuned to improve performance when the Symphony plan is replicated in the IBM Workload Scheduler database.

The following are the suggested values for a plan with more than 200,000 jobs:

```c
LOGBUFSZ = 2150  
DBHEAP = AUTOMATIC (or greater than LOGBUFSZ)  
LOGFILSIZ = 3000  
LOGPRIMARY = 200  
LOGSECOND = 40  
PAGE_AGE_TRGT_MCR = 120
```

In addition, increase the number of pages (NPAGES) of the TWS_PLN BuffaloPOOL parameter to 182000 and the TWS BuffaloPOOL parameter to 50000 by using the ALTER BuffaloPOOL command.

Before changing any of these values, refer to the information about tuning a DB2 database in the relevant product documentation in IBM Documentation.

# Too many manual job submissions

IBM Workload Scheduler is designed for maximum efficiency when handling jobs submitted using a scheduled plan.

Consequently, it is less adapted to processing manually submitted jobs. Thus, performance can be improved by reducing the number of manually submitted jobs.

# Too many file dependency checks

Each file dependency check has an impact on performance. If you design a plan that is constantly checking many file dependencies, you reduce the performance of the workstation where these jobs are being run.

If multiple "opens? files are being used as a dependency, use the "-a? (and) option. For example, to check if three home directories /tom, /dick, and /harry exist, before launching my job issue the following:

```batch
job2 opens "/users" (-d %p/tom -a -d %p/dick -a -d %p/harry)
```

This checks for all three directories at the same time, instead of looking for each directory separately.

Other factors that impact performance when evaluating file dependencies are the bm check parameters in the locallypts file. These are documented in the Locaopts summary section in the Administration Guide.

![](images/c3415f0afc68c8e72f436b26825d74b0a93d5aaaff268ee7f19896d0eb8e5c50.jpg)

Note: In case of file dependencies applied to dynamic agent, it is suggested to keep ratio number of file dependencies/bm check file less than 0.7

# Network configuration availability

After a system reboot, network services might be slow to start and if the agent starts when network services are not yet ready, the agent cannot work properly.

To prevent this problem, the agent waits sixty seconds and then retries to retrieve the network configuration. The agent repeats this operation for 5 times, that is, it waits for a total of 5 minutes for the network configuration to become available. If all attempts fail, the agent stops working.

You can configure the number of times the agent waits for network configuration availability in the ITA section of the ita.ini file, as follows:

1. Browse to the path where the ita.ini file is located:

On UNIX™ operating systems

TWA_DATA_DIR/ITA/cpa/ita/ita.ini

On Windows™ operating systems

TWA_homeTWS\ITA\cpa\config\ita.ini

2. Edit the setting for the net_conf_wait parameter defining the number of times the agent retries to retrieve the network configuration, waiting sixty seconds between each attempt. If the number of attempts you have defined expires without the agent being able to retrieve the network configuration, the agent stops working.

# Workload spreading

Whatever jobs you have to schedule, try and spread them out through the production period so that there is no concentration in any one moment. Try also to avoid scheduling activities during times when normal user traffic in the network is very heavy, for example during the morning when users commence working and deal with accumulated emails.

Failure to do this might cause a bottleneck at the Mailbox.msg queue, which causes delays in updating the Symphony file, which in turn creates delays in the availability of job statuses to conman, the Dynamic Workload Console.

# Improving job-processing performance

The processing and monitoring of jobs on a workstation is controlled primarily by various parameters in the localopts file and the global options maintained by optman. These parameters are described in the IBM Workload Scheduler: Planning and Installation Guide.

If you are experiencing problems of performance when processing and monitoring jobs, contact IBM Software Support for advice about how to tune these parameters in your particular environment to improve performance.

# Mailbox caching - advantages and disadvantages

Mailman uses a parameter in the localizepts file to decide whether to cache mailbox messages: mm cache mailbox. This section explains the advantages and disadvantages of the on and off settings of this parameter.

# Setting the mm cache mailbox parameter to no

This means that mailman has to make a separate read action for each message before processing it, and then a separate delete action after successfully processing the message. The I/O activity in performing these activities one message at a time is proportionally high for the amount of data being read. This has an impact on performance. On the other hand, the processing is simple, in that each message is read, processed, and then removed from the mailbox. Any failure of the system at any point means that at most one message is replayed and no data is lost.

# Setting the mm cache mailbox parameter to yes (default)

This means that mailman reads a block of messages into cache memory, processes all of the messages, and then deletes all of them from the mailbox. The advantage in I/O time is clear; reading and deleting a sequential set of messages in one action is a much more efficient use of I/O time, than reading and deleting them one-by-one, meaning improved performance.

However, if there is a failure of mailman or the operating system, the cache is lost. On restarting, mailman rereads the set of messages that were previously in cache, some of which might already have been processed. For example, if mailman reads a block of 32 messages into cache and has processed 30 of them when a problem occurs, when mailman is restarted it rereads those 32 records and has to process 30 duplicates before being able to continue where it stopped.

Most events deal with job state changes, and these events can be repeated without creating any problems, and the critical events mechanism is able to deal with the others. However, there is an impact on performance while this recovery processing is going on, and if the in-built mechanisms cannot handle the message duplication, a more serious error might occur, ultimately involving the full or partial loss of the mailbox contents.

The number of messages being read in one action is configurable, using the parameter mm cache size. The default value for this parameter is 32 messages, and the maximum is 512. Setting this parameter to a value higher than the default increases performance during correct working, but decreases the performance in the event of a failure, for the reasons stated above. In addition, the additional cache means that the memory required by the IBM Workload Scheduler engine also increases. If you have a workstation with limited memory, or memory-heavy applications running, it might be counterproductive to increase the mailbox cache because the operating system might have to start paging the cache memory.

In conclusion, the default setting maximizes performance; only if you start losing events should you set it to no.

# Setting the synch level parameter

This section describes the impact of the different settings of the synch level parameter in the localopts file. The synch level parameter only impacts  $\mathsf{UNIX}^{\mathsf{TM}}$  environments.

The I/O activity performed by the IBM Workload Scheduler engine in managing plans, job streams, and jobs, consists in reading from and writing to the Symphony file and the event files (Mailbox.msg, Intercom.msg, and Courier.msg). When IBM Workload Scheduler writes to these files it has more than a straightforward write operation to perform. For example, when it writes to the Mailbox.msg file it performs the actions described in the following pseudo code:

```tcl
TWS_write_event_lock { Lock Mailbox to write } TWS_write_event_update { Check Available Space Write Header Write Record Update Write Pointer Unlock Mailbox }
```

Each action requires one or more write accesses to the disk. The way these actions are performed with the different synch level options is as follows:

synch level = high

Each write operation on the event files is immediately physically written to disk. This has a heavy impact on performance caused by the high I/O dependency.

synch level = medium

Each write event is considered as a single operation. For example, while TWS_write_event_lock contains only one action, TWS_write_event_update comprises five actions. With synch level at medium, the five actions in this write event would be completed in one physical disk access, thus drastically reducing the I/O overhead.

synch level  $=$  low(default)

The operating system decides how and when to synchronize the data to disk. The impact of this option is more difficult to assess, because the rules are different for each operating system and file system.

# The fault-tolerant switch manager - impact on performance

This section describes the impact that the enablement of the fault-tolerant switch manager feature has on the performance of the general architecture and the individual system. The fault-tolerant switch manager is enabled by setting the enSwfaultTol global option to yes. When it is set, the master domain manager distributes messages to all fault-tolerant agents with FullStatus set to yes. This option has not dynamic capabilities and is not designed to work with broker agents.

Enabling this option impacts the following:

Network traffic  
- Disk space

![](images/8af51817a3512c92e84537a2358d14b5e25087540357dfe7828efa7b5c1fe46e.jpg)

Note: The fault-tolerant switch manager facility is only available if all of the workstations in the domain are at version 8.2, fix pack level 4, or higher.

# Network Traffic

Network traffic is unchanged under normal conditions, but is increased during the replay phase, according to your choice and only under special conditions.

The replay phase is an essential part of the processing performed by the switchmgr command. It occurs when the new domain manager processes its Symphony file against its copies of the messages received, as it attempts to update its copy of the Symphony file.

Under normal conditions, the outbound reliability does not create any additional network traffic, because the messages are only stored for an eventual replay operation. The multiple inbound connections do not generate additional traffic because the traffic that was previously copied by the domain manager to the FullStatus member is now copied to the FullStatus members directly by the fault-tolerant agents.

During the replay phase, the connection protocol initiated by mailman on the backup domain manager includes a new phase for the replay of messages not sent by the failed domain manager. The impact of the message replay might be important, depending on the number of messages "trapped" in the old domain manager.

# Disk Space

There are two places within the network where disk space use increases following the activation of the additional fault tolerance.

These places are as follows:

- On the single fault-tolerant agent. Here, in addition to the tomaster.msg queue, new queues are created for the other FullStatus fault-tolerant agents. These queues need not be considered, because the impact on a single agent is small.  
- On the FullStatus fault-tolerant agents acting as backup domain managers. Here new ftbox message files are created. Upward traffic to the upper domain manager is in ftbox/ftup.msg and downward traffic to the lower domain manager is in ftbox/ftdown.msg.

# Scalability

In an environment with large numbers of scheduling objects, the following impacts are felt:

- Impact on JnextPlan on page 455  
- Impact on reporting on page 455  
- Impact on event rule deployment on page 456

The resolution for these problems often includes making the following changes:

- Increasing application server heap size on page 456  
- Increasing maximum DB2 log capacity on page 457

# Impact on JnextPlan

The main impact on performance caused by a large network of workstations running many jobs over a production period of many days, is on JnextPlan. The key factor is the number of job stream instances that JnextPlan needs to handle. JnextPlan has to process each of these instances, and the time it takes to do so is a factor that can only be reduced by ensuring that the master domain manager and the database are on the most powerful computers possible, and that the communication, whether in local or remote, between the master domain manager and the database is maximized.

However, there are some specific measures that need to be taken as the number of jobs or job stream instances increases:

# Number of jobs in the plan exceeds 40 000

In this event you need to increase the Java™ heap size used by the application server. The default is 512 MB, and you should at least double the heap size when job numbers exceed this level. Follow the procedure in Increasing application server heap size on page 456.

# You have a large number of job stream instances in the plan

# DB2®

The default DB2® transaction log files cannot handle more than the transactions generated by about 180 000 job stream instances. You need to change the parameters that control the log file sizes or the numbers of log files that can be created, or both. Follow the procedure in Increasing maximum DB2 log capacity on page 457.

# Oracle

The number of transactions that can be managed by the Oracle log files depends on the way the Oracle database is configured. See the Oracle documentation for more details.

![](images/b649737b1a04f309a2d9f751ca9ad1d3d33456cdb3c5ac1e4ad2b8acda364de3.jpg)

Note: If circumstances change and the number of job stream instances handled by JnextPlan falls below about 180 000, consider resetting the log and application server heap size settings to their default values, to avoid performance problems.

# Impact on reporting

When a report is being processed, extra memory is required to handle large numbers of scheduling objects. The critical point is approximately 70 000 objects. This problem can be handled by increasing the Java™ heap size used by the application server. Follow the procedure in Increasing application server heap size on page 456.

# Impact on event rule deployment

When deploying large numbers of event rules, extra memory is required. The critical point is approximately 8000 rules. This problem can be handled by increasing the  $\mathrm{Java}^{\mathrm{TM}}$  heap size used by the application server. Follow the procedure in Increasing application server heap size on page 456.

# Increasing application server heap size

Follow this procedure to increase the Java™ heap size:

1. Log on to the computer where IBM Workload Scheduler is installed as the following user:

On Windows™ operating systems:

Any user in the Administrators group.

On UNIX™ operating systems:

root

2. Stop the WebSphere Application Server Liberty either by using the conman stopappserver command (see Starting and stopping the application server and appservman on page 426) or by running:

On Windows™ operating systems:

<TWA_home>\server_wauser\appservertools\stopAppServer.bat

On UNIX™ operating systems:

<TWA_home>/server_wauser/appleservertools/stopAppServer.sh

3. Open the following file:

On Windows™ operating systems:

<TWA_home>\server_wauser\usr\servers\engineServer\configDropins\overridden  
\jvmoptions

On UNIX™ operating systems:

<TWA_DATA_DIR>/server_wauser/usr/servers/engineServer/configDropins/ overrides/jvmoptions

4. Edit it as follows:

```txt
-Xms4096m  
-Xmx4096m  
-Xgcpolicy:gencon  
#nursery mem size  
-Xmn1024m
```

![](images/2eff0d70a78c4d7cd8cc65f77c3e6f6c2dce6a5c309b1b829d639e7008f8d118.jpg)

Note: In case of high workload (more than 200000 jobs/day) use 6144 as heap size and 1536 as nursery mem size. The above suggested settings must be applied when the RAM configuration value twice the value of the heap size.

5. Save the file jvm.option  
6. Start the WebSphere Application Server Liberty, either by using the conman startappserver command (see Starting and stopping the application server and appservman on page 426) or by running

Windows operating systems:

<TWA_home>\server_wauser\appservertools\stopAppServer.bat

UNIX operating systems:

<TWA_home>/server_wauser/appleservertools/stopAppServer.sh

# Increasing maximum DB2® log capacity

The IBM Workload Scheduler DB2® database uses a transaction log the maximum size of which is fundamentally important for the successful running of JnextPlan on very large databases.

The default log consists of 40 primary log files, which are always present, and 20 secondary log files, created on demand. Each file is about 4 MB in size, so the maximum log capacity using all of the "secondary" log files as well as the primary files is  $(40 + 20) \times 4\mathrm{MB} = 240\mathrm{MB}$ .

The log space used by JnextPlan is dependent on the size of the preproduction plan. Approximately every 1000 job stream instances generate transactions that occupy 1 MB of space in the log file. Thus, the log files by default have a maximum theoretical capacity of 240 000 job stream instances. However, in practice, you should allow for at least  $25\%$  more space than this algorithm indicates, so the capacity of the default log files is around 180 000 job stream instances.

If JnextPlan has neared or exceeded that level, you must make more log space available to DB2®.

In addition to performing the above calculation, you can also determine the log space actually used by a specific instance of JnextPlan and base your log size requirement on that figure.

# Determining actual DB2® log file usage

The following is the procedure to verify how much space was used by a successful instance of the JnextPlan command:

1. After JnextPlan has run, log on to the computer where the IBM Workload Scheduler DB2® server is installed, as the DB2® instance owner (UNIX™) or DB2® Administrator (Windows™).  
2. Open a DB2® command line window or shell, as follows:

UNIXTM

Follow these steps:

a. Issue the command su - db2inst1, or change to the subdirectory sqllib of the home directory of the owner of the DB2® instance (by default db2inst1)  
b. Launch the command ./db2profile

# WindowsTM

Select from the Start menu, Programs  $\rightarrow$  IBM DB2  $\rightarrow$  Command Line Tools  $\rightarrow$  Command Window

3. Run the following command:

```batch
db2 "get snapshot for database on TWS" > snapdb.txt
```

where "TWS" must be changed to the actual database name if different

4. Open the snapdb.txt file and look for a section like this:

```txt
Log space available to the database (Bytes) = 244315359  
Log space used by the database (Bytes) = 484641  
Maximum secondary log space used (Bytes) = 0  
Maximum total log space used (Bytes) = 581636  
Secondary logs allocated currently = 0
```

The value shown in "Maximum total log space used" is the actual space used for the DB2® logs. This space should be allocated to DB2® using primary log files only: therefore, you should change the number of primary log files and their size as necessary to meet this requirement as a minimum.

In addition, you are recommended to allocate a secondary log space to DB2®. A good choice for the secondary log files is half the number allocated for the primary files.

The snapshot command described in step 3 on page 458 can be run at any time to keep track of the current usage of the DB2® log space, without a noticeable impact on performance. All metrics shown are useful to monitor the current allocation of DB2® primary and secondary logs at any time, and to determine any required changes.

# Procedure for changing the maximum DB2® log capacity

Do this as follows:

1. Log on to the computer where the IBM Workload Scheduler DB2® server is installed, as the DB2® instance owner (UNIX™) or DB2® Administrator (Windows™).  
2. Open a DB2® command line window or shell, as follows:

# UNIXTM

Follow these steps:

a. Issue the command su - db2inst1, or change to the subdirectory sq1lib of the home directory of the owner of the DB2® instance (by default db2inst1)  
b. Launch the command ./.db2profile

# WindowsTM

Select from the Start menu, Programs  $\rightarrow$  IBM DB2  $\rightarrow$  Command Line Tools  $\rightarrow$  Command Window

3. Run the following commands:

```txt
db2 update dbcfg for <database_name> using LOGFILSIZ <log_file_size> db2 update dbcfg for <database_name> using LOGPRIMARY <primary_log_files> db2 update dbcfg for <database_name> using LOGSECOND <secondary_log_files>
```

where:

# <database_name>

The name of the database:

If you are running this from the computer where the DB2® server is installed, the installed default name is TWS. Supply this value unless you have changed it.  
- You are not recommended to run this procedure from the computer where the DB2® client is installed, but if you do so, the installed default name is TWS_DB. Supply this value unless you have changed it.

# <log_file_size>

The log file size in 4 KB pages. The default is 1000 (hence the default log file size of 4MB). Look in the DB2® documentation for details of the implications of choosing a larger or a smaller log file size. The maximum value is 262 144 (making the maximum log file size about 1 GB).

# <primary_log_files>

The number of primary log files. The default is 40. The total maximum number of log files that DB2® can handle (primary and secondary) is 256. Thus, there is a maximum limit of 256 GB for the log, or approximately 256 million Job Scheduler instances! (maximum 256 files x 1 GB maximum file size)

# <secondary_log_files>

The number of secondary log files. The default is 20. If there is enough free space on the file system, these additional log files are dynamically allocated by DB2® as needed (with a small impact on the performance of JnextPlan). Because these are only created if required, it is preferable to increase the number of secondary files, rather than the primary files. Typically, you allocate  $50\%$  of the primary log file value.

In making the calculation to allocate the log files, allow at least  $25\%$  more space than you think you require, to avoid that any slight miscalculation causes JnextPlan to fail.

Example: if you have determined from the procedure described in Determining actual DB2 log file usage on page 457 that JnextPlan has a current use of 320 MB, you could calculate as follows:

a. Increase 320 MB by  $25\%$ , giving 400 MB  
b. Determine if you want more log files, or bigger log files, or both, by reference to the DB2® documentation. For example, you could choose to allocate 40 files with a size of 10 MB, 80 files with a size of 5 MB, or 100 files with a size of 4 MB. For the sake of this example, assume you have chosen 80 files with a size of 5 MB, so your LOGPRIMARY value will be 80.  
c. Determine the log file size in 4 KB pages to give a log file size of 5 MB - your LOGFILSIZ value will thus be 1250.  
d. Determine how many secondary log files are required. If you follow the  $50\%$  guideline you will need a LOGSECOND value of 40.

4. Log on to the computer where IBM Workload Scheduler is installed as the following user:

UNIXTM

root

Windows™

Any user in the Administrators group.

5. Access the directory: <TWS Installation_PATH>\server<wauser>appservertools  
6. Stop the WebSphere Application Server Liberty using the conman stopappserver command (see Starting and stopping the application server and appservman on page 426)

7. On the computer where the DB2® server is installed, stop and start DB2®, as follows:

a. Ensure that no other applications are using this instance of DB2®, or if they are that they can be stopped.  
b. Issue the following command:

db2stop

c. Issue the following command:

db2start

![](images/ee756de1c81b84c7b5da06602bee4a60c5b7fce7f7f590def26f548d98c2130d.jpg)

Note: It is strongly recommended that you stop and start DB2®. If this is a problem for you, you must at least disconnect all applications from the DB2® instance and reconnect them. DB2® will apply the new parameters when you reconnect. If necessary, use the following command to force the disconnection of all open connections:

db2 "force application all"

8. Start the WebSphere Application Server Liberty using the conman startappserver command (see Starting and stopping the application server and appservman on page 426)

# Oracle tablespace size

Oracle (RDBMS) is divided in tablespaces which are an allocation of space where datafiles are stored.

The number of transactions that can be managed by the Oracle log files depends on the way the Oracle database is configured, thus it is important to allocate an appropriate table size to avoid issues on performance.

For example, considering a workload of 500000 jobs per day, 80GB of .dbf file size is recommended.

# Multiple Dynamic Workload Console production plan reports

From the Dynamic Workload Console you can launch production plan reports. These are heavy users of CPU time, and if they are requested for the entire plan, they can also take some considerable time to produce. If several are running at once, they can have a noticeable impact on the performance of the master domain manager.

If you notice a degradation of performance, you can determine if there are any reports running by checking for the report work files, as follows;

1. Navigate to the operating system's temporary directory  
2. Look for files that have the following file name template:

```txt
TWS-sequential_number-extr
```

Each report currently in progress has one of these work files open. The files are removed when the report is completed.

3. Check the dates of these files, and consider only recent files (if a report fails during production at any time, its file remains in the temporary directory until the next reboot of the master domain manager or you run an operating system cleanup process that discards all files in the temporary directory).

There is no direct action to take, as you must wait until the report completes for the performance to recover.

However, if you note that large numbers of reports are being issued, it might indicate the following scenario:

1. A user issues a report request, expecting it to be available immediately  
2. When the report does not appear immediately, the user things it has hung, closes and reopens the browser, and reissues the report. The closing of the browser does not stop the report production.  
3. The user might repeat this action several times.

In this case, you can take action to remind the user that the production of large reports can be time-consuming, and that it always better to wait.

# Dynamic Workload Console - adjusting session timeout settings

# About this task

The value assigned to the session timeout settings defines after how many minutes a user is automatically logged out from the WebSphere Application Server Liberty. If you plan to perform long running operations, or to have many users connected concurrently to the Dynamic Workload Console, or expect to have low performance on the system where the Dynamic Workload Console is installed, you might want to edit these values: httpSession invalidationTimeout="5h" and ltpa expiration="1440".

Perform these steps to change the values assigned to the timeout settings:

1. Stop WebSphere Application Server Liberty:

UNIXTM

./stopAppServer.sh [-direct]

WindowsTM

stopAppServer.bat [-direct]

For more information about stopping WebSphere Application Server Liberty, see Application server - starting and stopping on page 423.

2. Create a .xml file with this content (i.e. timeout_config.xml):

```asp
<server description="http_timeout_config">
    <httpSession invalidationTimeout="5h" invalidateOnUnauthorizedSessionRequestException="false"/>
    <ltpa expiration="1440"/>
</server>
```

3. Save the file in the following path: <DATA_DIR>/usr/dwcServer/configDropins/overrides  
4. Start WebSphere Application Server Liberty:

UNIXTM

```txt
./startAppServer.sh [-direct]  
Windows™  
startAppServer.bat [-direct]
```

![](images/7405f3474c2b7b0c11a7c56198f281508dd5046f6c5d6fb6f4fc399aa219f5ba.jpg)

Note: The desired time must be indicated in minutes

For more information, please refer to the WebSphere Application Server Liberty documentation at the following links https://www.ibm.com/support/knowledgecenter/en/SSEQTP-liberty/com.ibm.websphere.liberty.autogen.base.doc/ ae/rwlp_config_httpSession.html. and https://www.ibm.com/support/knowledgecenter/en/SSEQTP-liberty/ com.ibm.websphere.liberty.autogen.base.doc/ae/rwlp_config_ltpa.html

# Dynamic Workload Console - Increasing application server heap size

Follow this procedure to increase the Java™ heap size:

1. Log on to the computer where Dynamic Workload Console is installed as the following user:

Windows™ operating systems:

Any user in the Administrators group.

UNIX™ operating systems:

root

2. Stop the WebSphere Application Server Liberty by running:

Windows™ operating systems:

DWC_home\appservertools\stopAppServer.bat

UNIX™ operating systems:

DWC_home/appservers/tools/stopAppServer.sh

3. Open the following file:

Windows operating systems:

DWC_DATA_dir\usr\server\dwcServer\configDropins\overdrafts\jvmoptions

UNIX operating systems:

DWC_DATA_dir/usr/servers/dwcServer/configDropins/overrides/jvm(options

# 4. Here is an example:

```txt
-Xms4096m  
-Xmx4096m  
-Xgcpolicy:gencon  
#nursery mem size  
-Xmn1024m
```

![](images/7464d9e10b9235b9569c705d7bd31f1a847e8c945156795262ffbe486667bb88.jpg)

Note: In case of high workload (more than 50 concurrent users) use 6144 as heap size and 1536 as nursery mem size. The above suggested settings must be applied when the RAM configuration value twice the value of the heap size.

5. Save the file jvm.option  
6. Start the WebSphere Application Server Liberty, by running

Windows operating systems:

DWC_home\appservertools\startAppServer.bat

UNIX operating systems:

DWC_home/appserverstools/startAppServer.sh

# Dynamic Workload Console graphical views

When viewing graphical views in a supported web browser, especially when there are hundreds of objects, including dependencies, it is recommended that you use either Google Chrome or Mozilla Firefox to guarantee the best possible performance. This applies to the following graphical views:

- Job Stream Graphical View (both model and plan)  
Plan View  
- Preproduction Plan View

# Using Google Chrome might reduce the Dynamic Workload Console performance

Due to Google Chrome cache static resources restrictions, when using the Dynamic Workload Console with default certificates, the performance could be reduced.

To avoid impact on the performance, use custom certificates or a different browser.

# Chapter 11. Availability

This section describes factors that might affect the availability of IBM Workload Scheduler on a workstation. It covers the following topics:

- Resolving user ID account on Windows operating systems on page 464  
Using a temporary directory on UNIX on page 465

# Resolving user ID account on Windows® operating systems

# About this task

IBM Workload Scheduler needs to resolve the user ID account on Windows® operating systems to verify the security information.

Windows® users can be classified as domain users or local users. Domain users are defined in the domain controller, while local users are defined in the workstations of the network.

For a domain user, IBM Workload Scheduler requests the primary domain controller (or any domain controller for Windows® 2000 or 2003 Active Directory), to identify an available domain controller. It then uses this domain controller identity to type out the structure for the user.

For a local user, IBM Workload Scheduler makes a request to the local workstation. Generally, IBM Workload Scheduler specifies two cases: one for the IBM Workload Scheduler user and one for the streamlogon user.

The following is a list of steps that IBM Workload Scheduler performs to authenticate Windows® users, and the APIs involved:

1. IBM Workload Scheduler looks up the user in the reference domain. For the domain user, the reference domain is the name of the Windows® network. For the local user, it is the name of the local workstation.

API: LookupAccountName.

2. If the user is a domain user, IBM Workload Scheduler asks the primary domain controller for any domain controller that is available to resolve the account for the user in the reference domain.

API: NetGetAnyDCName for Windows® or DsGetDcName for Windows® 2000 or 2003.

3. IBM Workload Scheduler requests the domain controller (or the local workstation if the user is local) for information about the user.

API:NetUserInfo.

![](images/e231864e8de0fae9a45edba1ba44c3b47ccb0152eac75bc68079774b52e21770.jpg)

Note: On Windows® 2000 and 2003, the permissions for this API are contained in the BUILTIN\ "Pre-Windows

2000 compatible access" group.

# Using a temporary directory on UNIX™

When performing IBM Workload Scheduler operations on UNIX™, temporary files are written to the temporary directory on the local workstation. Ensure that the <TWS_user> running operations has read and write access to this directory.

# Chapter 12. License Management in IBM License Metric Tool

According to your IBM Workload Scheduler license, IBM® License Metric Tool helps you maintain your license compliance. By using License Metric Tool, you can generate reports that summarize your license consumption. The generated reports are maintained on the License Metric Tool server and should be periodically reviewed and signed, creating a history for audit purposes in the process. If you are contacted by a third-party software compliance auditor who plans to visit your enterprise to carry out a software audit, ensure that all reports are up-to-date and signed, and then supply copies of reports that cover the time periods that the auditor requests.

The following IBM Workload Scheduler license models are available to customers:

- Processor Value Unit license model on page 466  
- Per Job license model on page 470  
- Using per job queries when upgrading from a version earlier than 9.4 Fix Pack 2 on page 476

To install and configure IBM® License Metric Tool, see the product documentation at https://www.ibm.com/docs/en/licenses-metric-tool

# Processor Value Unit license model

# About this task

IBM® License Metric Tool generates reports to help you maintain compliance with your Processor Value Unit (PVU) subcapacity license terms. License Metric Tool can calculate PVU consumption only when software identification tags exist and are activated by the customer. The optman global optionlicenseType must be set to perServer (default value) to activate Processor Value Unit consumption tracking. You can also set the optman global option licenseType to byWorkstation to specify that the licensing type (either perServer or perJob) is specified at creation time for each workstation.

License Metric Tool automatically detects the following IBM Workload Scheduler 10.2.5 chargeable components that are part of the product:

Table 73. Chargeable software components automatically detected by License Metric Tool

Chargeable Software Components

IBM Z Workload Scheduler Agent V10.2.5

To detect and count remote nodes that are managed by IBM Workload Scheduler chargeable components, you must manually deploy software tags because no product code is present on those nodes.

The following IBM Workload Scheduler Version 10.2.5 chargeable components require manual deployment of software tags:

Table 74. Chargeable software components that require software tag deployment on managed nodes

Chargeable Software Components

Assigned Software tags

IBM Workload Scheduler for IBM

ibm.com_IBM_Workload_Scheduler_for_IBMApplications-10.2.5.swwdtag

Applications 10.2.5

![](images/c854aa82dae2db2af3860c1cd88eb5e0ad1f0a371169712ac95a2be814f4cec5.jpg)

Note: The IBM Workload Scheduler for IBM Applications license can be used for all the IBM Workload Scheduler access methods and application plug-ins available on the Automation Hub, except a list of plug-ins that support only the Per Job license model, see table Table 3 on page 469 for the complete list.

Complete the following procedure to manually deploy dedicated software tags on each managed node and calculate PVU consumption:

1. Identify the remote nodes that are managed by each of your chargeable components. For example, the remote nodes that are managed by the application server that you are connecting to, with IBM Workload Scheduler plug-in for IBM InfoSphere DataStage.  
2. Extract assigned software tags from the ILMT_IWS_for_Aplications_and(agentless.zip file that is included in your Agent installation media.  
3. Place the assigned software tag anywhere on the managed node.  
4. Wait for the next software scan in License Metric Tool to have the chargeable software components reported.  
5. It is recommended that you check whether License Metric Tool reporting matches with currently managed nodes before signing each License Metric Tool report.

![](images/ce419e934728c40af0f39417779c93c8e05e265caa4e3adc61598d59e033fbe2.jpg)

Note: if you cannot deploy the ibm.com_IBM_Workload_Scheduler_for_IBM_Aplications-10.2.5.swwdtag license tag on the node, then this license metric cannot be used, and you need to use the Per job license model.

Each single agent, which contributes to the license usage of the product, is installed with multiple tags, as follows:

- IWS Agent  
- IWS Dynamic agent  
- IWS Fault Tolerant Agent

All these three tags represent an IBM® Workload Scheduler agent and need to be bundled to IBM® Workload Scheduler in IBM License Metric Tool. For more information about bundling to a product, see the related documentation, for example Automatic bundling.

The master domain manager centrally maintains the history of the plug-in jobs that you run in your environment. The history can be used:

- During audits to verify which systems are actually managed by IBM Workload Scheduler.  
- To check periodically the result of your License Metric Tool reporting.  
- To verify your PVU license entitlement.

An SQL query is provided to access the history in the database. You can run the query either from the command-line interface of your database or by creating your custom SQL report tasks from the Dynamic Workload Console as described in Dynamic Workload Console User's Guide.

For each job definition in the database, the SQL query returns the:

1. Type of the plug-in job.  
2. Name of the workstation on which the job is defined.  
3. Name of the job.  
4. XML file containing the name of the remote server on which the job ran. If the XML file does not contain the name of the remote server, you can find it in the plug-in properties file in the TWS/JavaExtcfg agent folder.

- For DB2, IDS, MSSQL database types:

```sql
SELECT JOD_TASK_TYPE as Job_type, WF.FOL_PATH as Workstation_folder_name, WKC_NAME as Workstation_name, JF.FOL_PATH as Job_folder_name, JOD_NAME as Job_name,  
JOD_TASK_STRING as Job-definition  
FROM (((MDL.JOD_JOBDefinitions J inner join MDL.FOLFolders JF on J.FOL_ID = JF.FOL_ID)  
inner join MDL.WKC_WORKSTATION_CLASSES W on J.WKC_ID = W.WKC_ID)  
inner join MDL.FOLFolders WF on W.FOL_ID = WF.FOL_ID)  
WHERE JOD_BY_JSDL='Y' and UPPER(JOD_TASK_TYPE) NOT IN ('EXECABLE', 'DISTRIBUTEDSHADOWJOB', 'ZSHADOWJOB')  
ORDER BY JOD_TASK_TYPE, WKC_NAME, JOD_NAME
```

- For Oracle database type:

```sql
SELECT JOD_TASK_TYPE as Job_type, WF.FOL_PATH as Workstation_folder_name, WKC_NAME as Workstation_name, JF.FOL_PATH as Job_folder_name, JOD_NAME as Job_name, JOD_TASK_STRING as Job_definition  
FROM (((twsuser.JOD_JOBDefinitions J inner join twsuser.FOLFolders JF on J.FOL_ID=JF.FOL_ID) inner join twsuser.WKC_WORKSTATION_CLASSES W on J.WKC_ID=W.WKC_ID) inner join twsuser.FOLFolders WF on W.FOL_ID=WF.FOL_ID) WHERE JOD_BY_JSDL='Y' and UPPER(JOD_TASK_TYPE) NOT IN ('EXECUTABLE', 'DISTRIBUTEDSHADOWJOB', 'ZSHADOWJOB')  
ORDER BY JOD_TASK_TYPE, WKC_NAME, JOD_NAME
```

where twsuser is the name of the IBM Workload Scheduler schema.

The following example shows the query output for a Datasstage job type:

```xml
datasetage NY_1 DS_JOB <?xml version="1.0" encoding="UTF-8"?>
<jsdl:jobDefinition xmlns:jsdl="http://www.ibm.com/xmlns/prod/scheduling/1.0/jsdl"
xmlns:jsdldatasetage="http://www.ibm.com/xmlns/prod/scheduling/1.0/jsdldatasetage"
name="DATASTAGE">
<jsdl:application name="datastage">
<jsdldatasetage:datasetage>
<jsdldatasetage:DataStageParameters>
<jsdldatasetage:DataStagePanel>
```

Table 75. IBM Workload Scheduler chargeable access methods and application plug-ins  
```xml
<jsdldatasetLogon> <jsdldatasetDomain>ncxx4175.romelab.it.ibm.com:9080</jsdldatasetDomain> <jsdldatasetServer>ncxx4175</jsdldatasetServer> <jsdldatasetUserName>isadmin</jsdldatasetUserName> <jsdldatasetpassword> {aes}ScWNLDAHuN9X5sbtvAVky3RVd7g0kJqNerDbFbpwrDg= </jsdldatasetpassword> </jsdldatasetLogon> <jsdldatasetJobDefinitionGroup> <jsdldatasetProjectNameGroup> <jsdldatasetProjectName>tws4apps</jsdldatasetTaskName> </jsdldatasetTaskNameGroup> <jsdldatasetJobNameButtonGroup> <jsdldatasetJobNameRadioButton> <jsdldatasetJobName>dsj01_succ</jsdldatasetTaskName> </jsdldatasetTaskNameRadioButton> </jsdldatasetTaskNameButtonGroup> <jsdldatasetFileRemotePath/> </jsdldatasetTaskDefinitionGroup> <jsdldatasetJobExecutionGroup/> </jsdldatasetDataStagePanel> <jsdldatasetOptionsPanel> <jsdldatasetJobOptionsGroup> <jsdldatasetWarningLimitButtonGroup> <jsdldatasetNoWarningLimitButton/> </jsdldatasetWarningLimitButtonGroup> <jsdldatasetRowLimitButtonGroup> <jsdldatasetNoRowLimitButton/> </jsdldatasetRowLimitButtonGroup> <jsdldatasetOperationalMetadataGroup> <jsdldatasetUseDefault/> </jsdldatasetOperationalMetadataGroup> </jsdldatasetJobOptionsGroup> </jsdldatasetOptionsPanel> </jsdldatasetDataStageParameters> </jsdldatasetDatastage> </jsdlapplication> </jsdl:jobDefinition>
```

IBM Workload Scheduler access methods and application plug-ins

Salesforce

SAP Hana cloud platform Application lifecycle

SAP Hana Extended Application Services (XS)

Provisioning

IBM Cloud

Microsoft Azure

Amazon EC2

Google Deployment Manager

Table 75. IBM Workload Scheduler chargeable access methods and application plug-ins

(continued)

IBM Workload Scheduler access methods and application plug-ins

Azure Resource Manager

AWS Cloud formation

Kubernetes Batch Jobs

AWS SNS

AWS SQS

AWS Lambda

Google Cloud Storage

Google Dataflow

Google Cloud Functions

Azure DataLake Storage

Azure Data Bricks

Automation Anywhere Bot Runner

Automation Anywhere Bot Trader

Blue Prism

Chef Bootstrap

Chef Runlist

Ansible

UDeploy Code

HCL Launch

Hadoop Distributed File system

Apache Spark

Oracle UCM

Hadoop MapReduce

Oozie

Cloudant

# Per Job license model

About this task

To generate a report that summarizes your monthly per-job license usage, you can generate a license metric tag file (SLMTag). The SLM tag that is generated applies the 10 monthly jobs pricing method where, the job count increments by 1 for every 10 successfully executed jobs you run and 1 job is counted when you run anywhere from 1 to 10 jobs. For example, if you run 34 jobs, 4 licenses are counted.

In the optman global options, use thelicenseType keyword to define the pricing model. If you set the licenseType keyword to byWorkstation, you can then define the pricing model to be applied for each single workstation at creation time, specifying either perServer or perJob. If you select the perServer setting in optman, see Processor Value Unit license model on page 466 for more information about tracking license consumption.

The queries listed below apply when you select either the byWorkstation or perJob pricing models in optman to return the license consumption tracking. If you select the byWorkstation value, the queries listed below return the number of records with license type  $= \mathbf{J}$  generated by successful jobs on workstations which are set to license type  $=$  perJob.

You can optionally retrieve consumption information for a subset of workstations. To obtain this information, remove the comment before the lines:

```sql
-- "((Actual_workstation_name_in_run = 'WKS_NAME1' AND
-- ACTUAL_WKSFolders_NAME_IN Runs = '/FOL_WKS1/') OR
-- (Actual_workstation_name_in_run = 'WKS_NAME2' AND
-- ACTUAL_WKSFolders_NAME_IN Runs = '/FOL_WKS2/')) and"
```

remove the double dashes  $(-)$ , and replace the '/FOL_WKS1/','WKS_NAMEE1','/FOL_WKS2/','WKS_NAME2' strings with your folder and workstation couples.

The master domain manager centrally maintains the history of the jobs that you run in your environment. By using the optman global option, statsHistory, you can set the number of days for which you maintain the history of the jobs. To track your monthly per-job license usage, set the value of statsHistory to 400 (which is the default value). For more information about statsHistory, see Global options - detailed description on page 27.

For the SQL statement to generate the SLMTag file, see the following samples:

- For DB2 database type:

```sql
SELECT'<SchemaVersion>2.1.1</SchemaVersion>
<SoftwareIdentity>
<Name>IBM Workload Automation</Name>
<PersistentId>3303c35cbc08435080502d621d5cdbff</PersistentId>
<InstanceId>/opt/IBM/TWA</InstanceId>
</SoftwareIdentity>' as xml from sysibm.sysdummy1
UNION
SELECT xml.metrics as xml
FROM (SELECTCONCAT('<Metric logTime="',CONCAT(current_date,CONCAT('T',CONCAT(replace(current_time,'.',':'),CONCAT(+00:00))'
Type>10_MONTHLY_JOBS</Type>
<Value>' ,CONCAT(JobNbr,CONCAT('/</Value>
<Period><StartTime>' ,CONCAT(Year,CONCAT(-,'',CONCAT
(trim(VARCHAR_FORMAT(Month,'00')) ,CONCAT(-01T00:00:01+00:00</StartTime>
<EndTime>' ,CONCAT(Year,CONCAT(-,'',CONCAT trimmed(VARCHAR_format(
Month,'00')) ,CONCAT(-,' ,CONCAT LAST_DAY,'T23:59:00+00:00</EndTime>
</Period></Metric'))))))))))) as xml.metrics
```

- For Oracle database type:  
```sql
FROM (SELECT Year, Month,   
CASE   
when Month  $= 2$  then '28'   
when Month  $= 4$  then '30'   
when Month  $= 6$  then '30'   
when Month  $= 9$  then '30'   
when Month  $= 11$  then '30'   
else '31'   
end as LAST_DAY,   
 $(\mathrm{COUNT}(\star) + 9) / 10$  AS JobNbr,   
current date as current_date,   
current time as current_time   
from (SELECT unique year(Job_run_date_time) AS Year,   
month(Job_run_date_time)AS Month, day(Job_run_date_time) AS day,   
JOB_STREAM_WKS_FOL_NAME, JOB_STREAM_WKS_NAME_INRuns, JOB_STREAMFolders_NAME, JOB_STREAM_NAME_IN Runs,   
JOB_NAME_IN Runs FROM MDL.JOB_HISTORY_V   
WHERE Job_status  $\equiv$  S' and Workstationlicense_type  $\equiv$  J' and   
-- ((Actual_workstation_name_in_run  $=$  'WKS_NAME1' AND   
-- ACTUAL_WKSFolders_NAME_IN Runs  $=$  '/FOL_WKS1/) OR   
-- (Actual_workstation_name_in_run  $=$  'WKS_NAME2' AND   
-- ACTUAL_WKSFolders_NAME_IN Runs  $=$  '/FOL_WKS2/) and   
(ACTUAL_WKSFolders_NAME_IN Runs, Actual_workstation_name_in_run) not in   
(select FOL_PATH,WKS_NAME from MDL.WKS_WORKSTATIONS W JOIN MDL.FOLFolders   
F ON W.FOL_ID  $\equiv$  f.FOL_ID where W.WKS_agent_TYPE  $\equiv$  'E'))   
GROUP BY Year,Month))   
ORDER BY xml desc
```

```sql
SELECT'<SchemaVersion>2.1.1</SchemaVersion>
<SoftwareIdentity>
<Name>IBM Workload Automation</Name>
<PersistentId>3303c35cbc08435080502d621d5cdbff</PersistentId>
<InstanceId>/opt/IBM/TWA</InstanceId>
</SoftwareIdentity>' as xml from dual
UNION
SELECT xml.metrics as xml
FROM (SELECT'<Metric logTime="'' || cdate || 'T' || ctime || '+00:00" >
Type>10_MONTHLY_JOBS</Type>
<Value>' || JobNbr '' </Value>
<Period>
<StartTime>' || Year ''-' || trim(TO_CHAR(Month,'00')) |
'-01T00:00:01+00:00</StartTime>
<EndTime>' || Year ''-' || trim(TO_CHAR(Month,'00')) | | '-'
| | LAST_DAY | | 'T23:59:00+00:00'
</EndTime></Period>' as xml.metrics
FROM (SELECT Year, Month,
CASE
when Month = 2 then '28'
when Month = 4 then '30'
when Month = 6 then '30'
when Month = 9 then '30'
when Month = 11 then '30'
else '31'
end as LAST_DAY,
CAST((COUNT(*) + 9) / 10 AS INT) AS JobNbr,
TO_CHAR(SYSDATE, 'YYYY-MM-DD') as cdate,
TO_CHAR(SYSDATE, 'HH24:MI:SS') as ctime
from (
SELECT unique EXTRACT(year FROM Job_run_date_time) AS Year,
```

- For IDS database type:  
```sql
EXTRACT(month FROM Job_run_date_time) AS Month,  
EXTRACT(day FROM Job_run_date_time) AS Day,  
JOB_STREAM_WKS_FOL_NAME,  
JOB_STREAM_WKS_NAME_IN Runs,  
JOB_STREAM鞘DER_NAME,  
JOB_STREAM_NAME_IN Runs,  
JOB_NAME_IN Runs  
FROM JOB_HISTORY_V  
WHERE Job_status='S' and Workstationlicense_type='J' and  
-- ((Actual_workstation_name_in_run = 'WKS_NAME1' AND  
-- ACTUAL_WKS鞘DER_NAME_IN Runs = '/FOL_WKS1/') OR  
-- (Actual_workstation_name_in_run = 'WKS_NAME2' AND ACTUAL_WKS鞘DER_NAME_IN Runs = '/FOL_WKS2/')) and  
(Actual_WKS鞘DER_NAME_IN Runs, Actual_workstation_name_in_run) not in  
(select FOL_PATH, WKS_NAME from WKS_WORKSTATIONS W JOIN FOL鞘DERS F ON  
W.FOL_ID=f.FOL_ID where W.WKS_AGENT_TYPE='E'))  
GROUP BY Year, Month))  
ORDER BY xml desc
```

```sql
SELECT'<SchemaVersion>2.1.1</SchemaVersion><SoftwareIdentity>' as xml FROM   
Workload   
Automation</Name><PersistentId>3303c35cbc08435080502d621d5cdbff</Persistent   
Id><InstanceId>/opt/IBM/TWA</InstanceId></softwareIdentity>' as xml FROM   
SYSTABLES   
UNION   
SELECT xml_metricas xml FROM (SELECTCONCAT('<Metric logTime  $\equiv$  ',CONCAT(current_date,CONCAT('T',CONCAT (current_time,CONCAT(+00:00)> <Type>10_MONTHLY_JOBS</Type><Value>'CONCAT(r round(JobNbr,0),CONCAT('/Value><Period><StartTime>'CONCAT(Year,CONCAT（'-'，CONCAT(Month,CONCAT(-01T00:00:01+00:00</StartTime><EndTime> '，CONCAT(Year,CONCAT(-,'，CONCAT(Month,CONCAT(-,'，CONCAT(LAST_DAY,'T23:59:00+00:00</EndTime> </Period></Metric')))))))))） as xml_metric   
FROM (SELECT Year, replace(TO_CHAR(Month,'\*\*'),\*\,'0') AS Month,   
CASE   
when Month  $= 2$  then '28'   
when Month  $= 4$  then '30'   
when Month  $= 6$  then '30'   
when Month  $= 9$  then '30'   
when Month  $= 11$  then '30'   
else '31'   
end as LAST_DAY,   
(COUNT(\*)+9)/10 AS JobNbr,   
TO_CHAR today,'%Y-%m-%d') as current_date,   
TO_CHAR(extend(current, hour to second), '%H:%M:%S') as current_time   
FROM (SELECT unique year(Job_run_date_time) AS Year,   
month(Job_run_date_time) AS Month, day(Job_run_date_time) AS day,   
JOB_STREAM_WKS_FOL_NAME, JOB_STREAM_WKS_NAME_IN Runs,   
JOB_STREAM鞘DER_NAME, JOB_STREAM_NAME_IN Runs,   
JOB_NAME_IN Runs   
FROM MDL.JOB_HISTORY_V   
WHERE Job_status='S' and Workstationlicense_type='J' and --((Actual_workstation_name_in_run = 'WKS_NAME1' AND -- ACTUAL_WKS鞘DER_NAME_IN Runs ='/FOL_WKS1/' ) OR -- (Actual_workstation_name_in_run = 'WKS_NAME2' AND ACTUAL_WKS鞘DER_NAME_IN Runs ='/FOL_WKS2/')) and not exists(select 1 from MDL.WKS_WORKSTATIONS W JOIN MDL.FOL鞘DERS F ON W.FOL_ID=F.FOL_ID where W.WKS_agent_TYPE='E' AND Actual_wks_folder_name_in_run = F.FOL_PATH AND Actual_workstation_name_in_run = W.WKS_NAME))   
GROUP BY Year,Month))   
ORDER BY xml desc
```

# - For MSSQL database type:

```sql
SELECT'<SchemaVersion>2.1.1</SchemaVersion>
<SoftwareIdentity>
<Name>IBM Workload Automation</Name>
<PersistentId>3303c35cbc08435080502d621d5cdbff</PersistentId>
<InstanceId>/opt/IBM/TWA</InstanceId>
</SoftwareIdentity>' as xml
UNION
SELECT b.xml.metrics as xml
FROM (SELECT'<Metric logTime>' + CONVERT(nvarchar(19), adatetime, 126) +
'+' + 00:00')
Type>10_MONTHLY_JOBS</Type>
<Value>' + CONVERT(varchar(10), a.JobNbr) + '/Value'<Period>
<StartTime>' + CONVERT(varchar(10), aYEAR) + '-' + RIGHT('00' + 
CONVERT(varchar(2),
a.Month), 2) + '-01T00:00:01+00:00</StartTime>
<EndTime>' + CONVERT(varchar(10), a.Year) + '-' + RIGHT('00' + 
CONVERT(varchar(2),
a.Month), 2) + '-' + a.LAST_DAY + 'T23:59:00+00:00</EndTime>
</Period></Metric>' as xml.metrics
FROM (SELECT Year, Month,
CASE
when Month = 2 then '28'
when Month = 4 then '30'
when Month = 6 then '30'
when Month = 9 then '30'
when Month = 11 then '30'
else '31'
end as LAST_DAY,
(COUNT(*)+9)/10 AS JobNbr, SYSDATETIME() as datetime,
CONVERT (date, SYSDATETIME()) as cdate,
CONVERT (time, SYSDATETIME()) as ctime
FROM (SELECT distinct year(Job_run_date_time) AS Year,
month(Job_run_date_time) AS Month, day(Job_run_date_time) AS day,
JobStream_wks_fol_name, JobStream_wks_name_in_run,
JobStream_folder_name, JobStream_name_in_run,
Job_name_in_run
FROM MDL.JOB_HISTORY_V
WHERE Job_status='S' and Workstationlicense_type='J' and
--((Actual_workstation_name_in_run = 'WKS_NAME1' AND
-- Actual_wks_folder_name_in_run = '/FOL_WKS1/')) OR
-- (Actual_workstation_name_in_run = 'WKS_NAME2' AND Actual_wks_folder_name_in_run = '/FOL_WKS2/')) AND
not exists (select 1 from MDL.WKS_WORKSTATIONS W JOIN MDL.FOL_FOLDERS F ON
W.FOL_ID=F.FOL_ID where W.WKS_AGENT_TYPE='E' AND
Actual_wks_folder_name_in_run = F.FOL_PATH AND
Actual_workstation_name_in_run = W.WKS_NAMEA)) r
GROUP BY Year, Month) a) b
ORDER BY xml desc
```

The following example shows a license metric tag file with the 10 monthly jobs that ran in your environment:

```xml
<SchemaVersion>2.1.1</SchemaVersion> <SoftwareIdentity> <Name>IBM Workload Scheduler</Name> <PersistentId>3303c35cbc08435080502d621d5cdbff</PersistentId> </InstanceId>/opt/IBM/TWA</InstanceId> </SoftwareIdentity> <Metric logTime="2019-04-09T16:07:20+00:00"> <Type>10_MONTHLY_JOBS</Type> </Value>2</Value> <Period><StartTime>2019-03-01T00:00:01+00:00</StartTime>
```

```xml
<EndTime>2019-03-31T23:59:00+00:00</EndTime></Period> </Metric> <Metric logTime="2019-04-09T16:07:20+00:00"> <Type>10_MONTHLY_JOBS</Type> <Value>22</Value> <Period><StartTime>2019-02-01T00:00:01+00:00</StartTime> <EndTime>2019-02-28T23:59:00+00:00</EndTime></Period> </Metric>
```

# Queries to verify the number of jobs you run every month

# About this task

An SQL query is provided that accesses the job history in the database to verify the number of jobs that you run every month in your environment. The job runs calculated with this query are not grouped in groups of 10 as with the previous queries, but are instead, the total number of jobs that ran.

You can run the SQL query either from the command-line interface of your database, or by creating your custom SQL report tasks from the Dynamic Workload Console, as described in the related section in Dynamic Workload Console User's Guide.

- For DB2 database type:

```sql
SELECT Year, Month, count(\* AS JobNbr from (SELECT unique year(Job_run_date_time) AS Year, month(Job_run_date_time) AS Month, day(Job_run_date_time) AS day, JOB_STREAM_WKS_FOL_NAME, JOB_STREAM_WKS_NAME_IN Runs, JOB_STREAMFolders_NAME, JOB_STREAM_NAME_IN Runs, JOB_NAME_IN Runs FROM MDL.JOB_HISTORY_V WHERE Job_status='S' and Workstationlicense_type='J' and --((Actual_workstation_name_in_run = 'WKS_NAME1' AND -- ACTUAL_WKSFolders_NAME_IN Runs = '/FOL_WKS1/') OR -- (Actual_workstation_name_in_run = 'WKS_NAME2' AND -- ACTUAL_WKSFolders_NAME_IN Runs = '/FOL_WKS2/')) and (Actual_WKSFolders_NAME_IN Runs, Actual_workstation_name_in_run) not in (select FOL_PATH, WKS_NAME from MDL.WKS_WORKSTATIONS W JOIN MDL.FOLFolders F ON W.FOL_ID=f.FOL_ID where W.WKS_agent_TYPE='E')) GROUP BY Year, Month
```

- For ORACLE database type:

```sql
SELECT Year, Month, cast (count (*) AS INT) AS JobNbr from (SELECT unique EXTRACT(year FROM Job_run_date_time) AS Year, EXTRACT(month FROM Job_run_date_time) AS Month, EXTRACT(day FROM Job_run_date_time) AS Day, JOB_STREAM_WKS_FOL_NAME, JOB_STREAM_WKS_NAME_IN Runs, JOB_STREAMFolders_NAME, JOB_STREAM_NAME_IN Runs, JOB_NAME_IN Runs FROM JOB_HISTORY_V WHERE Job_status='S' and Workstationlicense_type='J' and --((Actual_workstation_name_in_run = 'WKS_NAME1' AND -- ACTUAL_WKSFolders_NAME_IN Runs = '/FOL_WKS1/') OR -- (Actual_workstation_name_in_run = 'WKS_NAME2' AND
```

```sql
-- ACTUAL_WKSFolders_NAME_IN Runs = '/FOL_WKS2/') and  
(Actual_WKSFolders_NAME_IN Runs, Actual_workstation_name_in_run) not in  
(select FOL_PATH, WKS_NAME from WKS_WORKSTATIONS W JOIN FOLFolders F ON  
W.FOL_ID=f.FOL_ID where W.WKS_AGENT_TYPE='E'))  
GROUP BY Year, Month
```

- For MSSQL, Azure SQL, and Google Cloud SQL for SQL server database types:

```sql
SELECT Year, Month, count(*) AS JobNbr from (SELECT distinct year(Job_run_date_time) AS Year, month(Job_run_date_time) AS Month, day(Job_run_date_time) AS day, Job stream_wks_fol_name, Job stream_wks_name_in_run, Job stream_folder_name, Job stream_name_in_run, Job_name_in_run FROM MDL.JOB_HISTORY_V WHERE Job_status='S' and Workstationlicense_type='J' and --((Actual_workstation_name_in_run = 'WKS_NAME1' AND -- Actual_wks_folder_name_in_run = '/FOL_WKS1/') OR -- (Actual_workstation_name_in_run = 'WKS_NAME2' AND -- Actual_wks_folder_name_in_run = '/FOL_WKS2/')) AND not exists (select 1 from MDL.WKS_WORKSTATIONS W JOIN MDL.FOL_FOLDERS F ON W.FOL_ID=F.FOL_ID where W.WKS_agent_TYPE='E' AND Actual_wks_folder_name_in_run = F.FOL_PATH AND Actual_workstation_name_in_run = W.WKS_NAME)) r GROUP BY Year, Month
```

![](images/38ac2c9f6a72c51e351558c20d2358f0d88eafe9efa468da4bd57e14546bcac9.jpg)

# Note:

- All jobs processed or managed by IBM® Workload Scheduler are counted, but the same job counts once if repeated more than once during the same day. To meet this requirement and be considered as the same job, jobs must contain the same jobstream_workstation_name, jobstream_name and job_name strings and not run on a remote engine.  
- The SQL queries select only jobs that run successfully. The SQL queries do not count shadow jobs, jobs that run on agent for z/OS, and rerun jobs.

# Using per job queries when upgrading from a version earlier than 9.4 Fix Pack 2

# About this task

If you are upgrading from a version earlier than 9.4 FP2, then follow the steps listed below before you run the queries listed in Per Job license model on page 470:

1. Upgrade all components in your environment to version 9.4, Fix Pack 2 or later.  
2. Depending on your database, run one of the statements listed below as many times as necessary until the History table is entirely updated. Several runs might be necessary.  
3. Run the queries listed in Per Job license model on page 470.

If you are using a DB2 database, run the following statement:

```sql
UPDATE ( SELECT * FROM MDL.JHR_JOB_HISTORY Runs WHERE WKC licenses_TYPE = '-FETCH FIRST 10000 ROWS ONLY) SET WKC licenses_TYPE = 'J'
```

If you are using an Oracle database, run the following statement:

```sql
UPDATE JHR_JOB_HISTORY Runs
set WKC licenses_TYPE = 'J'
where WKC licenses_TYPE = '-' and rownum <= 10000
```

If you are using an IDS database, run the following statement:

```sql
UPDATE MDL.JHR_JOB_HISTORY Runs SET WKC licenses_TYPE = 'J' WHERE JOB_ID IN (SELECT JOB_ID FROM (SELECT FIRST 10000 JOB_ID FROM MDL.JHR_JOB_HISTORY Runs WHERE WKC licenses_TYPE = '-')
```

If you are using an MSSQL database, run the following statement:

```txt
UPDATE TOP (10000) MDL.JHR_JOB_HISTORY Runs set WKC licenses_TYPE = 'J' where WKC licenses_TYPE = '-'
```

# Notices

This document provides information about copyright, trademarks, terms and conditions for product documentation.

© Copyright IBM Corporation 1993, 2016 / © Copyright HCL Technologies Limited 2016, 2025

This information was developed for products and services offered in the US. This material might be available from IBM in other languages. However, you may be required to own a copy of the product or product version in that language in order to access it.

IBM may not offer the products, services, or features discussed in this document in other countries. Consult your local IBM representative for information on the products and services currently available in your area. Any reference to an IBM product, program, or service is not intended to state or imply that only that IBM product, program, or service may be used. Any functionally equivalent product, program, or service that does not infringe any IBM intellectual property right may be used instead. However, it is the user's responsibility to evaluate and verify the operation of any non-IBM product, program, or service.

IBM may have patents or pending patent applications covering subject matter described in this document. The furnishing of this document does not grant you any license to these patents. You can send license inquiries, in writing, to:

IBM Director of Licensing

IBM Corporation

North Castle Drive, MD-NC119

Armonk, NY 10504-1785

US

For license inquiries regarding double-byte character set (DBCS) information, contact the IBM Intellectual Property Department in your country or send inquiries, in writing, to:

Intellectual Property Licensing

Legal and Intellectual Property Law

IBM Japan Ltd.

19-21, Nihonbashi-Hakozakicho, Chuo-ku

Tokyo 103-8510, Japan

INTERNATIONAL BUSINESS CORPORATION PROVIDES THIS PUBLICATION "AS IS" WITHOUT WARRANTY OF ANY KIND, Either EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTYES OF NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Some jurisdictions do not allow disclaimer of express or implied warranties in certain transactions, therefore, this statement may not apply to you.

This information could include technical inaccuracies or typographical errors. Changes are periodically made to the information herein; these changes will be incorporated in new editions of the publication. IBM may make improvements and/or changes in the product(s) and/or the program(s) described in this publication at any time without notice.

Any references in this information to non-IBM websites are provided for convenience only and do not in any manner serve as an endorsement of those websites. The materials at those websites are not part of the materials for this IBM product and use of those websites is at your own risk.

IBM may use or distribute any of the information you provide in any way it believes appropriate without incurring any obligation to you.

Licensees of this program who wish to have information about it for the purpose of enabling: (i) the exchange of information between independently created programs and other programs (including this one) and (ii) the mutual use of the information which has been exchanged, should contact:

IBM Director of Licensing

IBM Corporation

North Castle Drive, MD-NC119

Armonk, NY 10504-1785

US

Such information may be available, subject to appropriate terms and conditions, including in some cases, payment of a fee.

The licensed program described in this document and all licensed material available for it are provided by IBM under terms of the IBM Customer Agreement, IBM International Program License Agreement or any equivalent agreement between us.

The performance data discussed herein is presented as derived under specific operating conditions. Actual results may vary.

Information concerning non-IBM products was obtained from the suppliers of those products, their published announcements or other publicly available sources. IBM has not tested those products and cannot confirm the accuracy of performance, compatibility or any other claims related to non-IBM products. Questions on the capabilities of non-IBM products should be addressed to the suppliers of those products.

This information is for planning purposes only. The information herein is subject to change before the products described become available.

This information contains examples of data and reports used in daily business operations. To illustrate them as completely as possible, the examples include the names of individuals, companies, brands, and products. All of these names are fictitious and any similarity to actual people or business enterprises is entirely coincidental.

# COPYRIGHT LICENSE:

This information contains sample application programs in source language, which illustrate programming techniques on various operating platforms. You may copy, modify, and distribute these sample programs in any form without payment to IBM, for the purposes of developing, using, marketing or distributing application programs conforming to the application programming interface for the operating platform for which the sample programs are written. These examples have not been thoroughly tested under all conditions. IBM, therefore, cannot guarantee or imply reliability, serviceability, or function of these programs. The sample programs are provided "AS IS", without warranty of any kind. IBM shall not be liable for any damages arising out of your use of the sample programs.

© (HCL Technologies Limited) (2025).

Portions of this code are derived from IBM Corp. Sample Programs.

Copyright IBM Corp. 2016

# Trademarks

IBM, the IBM logo, and ibm.com are trademarks or registered trademarks of International Business Machines Corp., registered in many jurisdictions worldwide. Other product and service names might be trademarks of IBM® or other companies. A current list of IBM® trademarks is available on the web at "Copyright and trademark information" at www.ibm.com/legal/copytrade.shtml.

Adobe™, the Adobe™ logo, PostScript™, and the PostScript™ logo are either registered trademarks or trademarks of Adobe™ Systems Incorporated in the United States, and/or other countries.

IT Infrastructure Library™ is a Registered Trade Mark of AXELOS Limited.

Linear Tape-Open™, LTO™, the LTO™ Logo, Ultrium™, and the Ultrium™ logo are trademarks of HP, IBM® Corp. and Quantum in the U.S. and other countries.

Intel™, Intel™ logo, Intel Inside™, Intel Inside™ logo, Intel Centrino™, Intel Centrino™ logo, Celeron™, Intel Xeon™, Intel SpeedStep™, Itanium™, and Pentium™ are trademarks or registered trademarks of Intel™ Corporation or its subsidiaries in the United States and other countries.

Linux™ is a registered trademark of Linus Torvalds in the United States, other countries, or both.

Microsoft™, Windows™, Windows NT™, and the Windows™ logo are trademarks of Microsoft™ Corporation in the United States, other countries, or both.

![](images/32a8ad3a4c5f1a5aabcbabe9e2f1222b109b32a593b03dcda881de668d6b85ab.jpg)

Java

COMPATIBLE Java™ and all Java-based trademarks and logos are trademarks or registered trademarks of Oracle and/or its affiliates.

Cell Broadband Engine™ is a trademark of Sony Computer Entertainment, Inc. in the United States, other countries, or both and is used under license therefrom.

ITIL™ is a Registered Trade Mark of AXEOS Limited.

UNIX™ is a registered trademark of The Open Group in the United States and other countries.

# Terms and conditions for product documentation

Permissions for the use of these publications are granted subject to the following terms and conditions.

# Applicability

These terms and conditions are in addition to any terms of use for the IBM website.

# Personal use

You may reproduce these publications for your personal, noncommercial use provided that all proprietary notices are preserved. You may not distribute, display or make derivative work of these publications, or any portion thereof, without the express consent of IBM.

# Commercial use

You may reproduce, distribute and display these publications solely within your enterprise provided that all proprietary notices are preserved. You may not make derivative works of these publications, or reproduce, distribute or display these publications or any portion thereof outside your enterprise, without the express consent of IBM.

# Rights

Except as expressly granted in this permission, no other permissions, licenses or rights are granted, either express or implied, to the publications or any information, data, software or other intellectual property contained therein.

IBM reserves the right to withdraw the permissions granted herein whenever, in its discretion, the use of the publications is detrimental to its interest or, as determined by IBM, the above instructions are not being properly followed.

You may not download, export or re-export this information except in full compliance with all applicable laws and regulations, including all United States export laws and regulations.

IBM MAKES NO GUARANTEE ABOUT THE CONTENT OF THESE PUBLICATIONS. THE PUBLICATIONS ARE PROVIDED "AS-IS" AND WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING BUT NOT LIMITED TO IMPLIED WARRANTIES OF MERCHANTABILITY, NON-INFRINGEMENT, AND FITNESS FOR A PARTICULAR PURPOSE.

# Index

# Special Characters

. jobmanrc 305

.rhost, file 305

<TWS_user>

changing password 402

owning processes 285

required security access for

workload service assurance

251

$MASTER variable, resolve in mailman, local

option 59

# Numerics

2001, service in

NetConf

file

301

2002, service in

NetConf

file

301

2003, service in

NetConf

file

301

2004, service in

NetConf

file

301

2005, service in

NetConf

file

301

2006, service in

NetConf

file

301

2007, service in

NetConf

file

30

2008, service in

NetConf

file

301

2009, service in

NetConf

file

301

2010, service in

NetConf

file

301

2011, service in

NetConf

file

301

2012, service in

NetConf

file

301

2013, service in

NetConf

file

301

2014, service in

NetConf

file

301

2015, service in

NetConf

file

301

2016, service in

NetConf

file

301

2017, service in

NetConf

file

301

2018, service in

NetConf

file

301

2021, service in

NetConf

file

301

2022, service in

NetConf

file

301

2023, service in

NetConf

file

301

2501, service in

NetConf

file

301

2502, service in

NetConf

file

301

2503, service in

NetConf

file

301

# A

aa, global option 32

accepted license

Processor Value Unit license model 466

access control list

security 180

access control list definition

security access control list 187

access method for

dynamic agent

overview 303

access method for extended agent

overview 303

access method on fault-tolerant agent, UNIX

local 305

access method, UNIX

remote 305

access, remote, for command-line,

configuring 123

accessibility xi

action, object type, defining access 233

actions on security objects

specifying actions on security objects 194

Active directory

LDAP configuration 269

Active Directory, authentication 262

active-active

configuration 127

Add User, global option 31, 31

adding

security role 185

Administering agents on AS/400 430

Administering agents on i5/OS 430

Administering agents on IBM i 430, 430

Administering IBMi agents 430

Administering IBMi jobs 430

Administering jobs on AS/400 430

Administering jobs on i5/OS 430

administrative tasks 380

DB2 346

Oracle 352

af, global option 31

agent 388

agent configuration

JobManager.ini file 71

maintenance 101

agent log and trace files

twstrace syntax 78,434

agent logs encoding 75, 431

agent logs setting 75, 431

agent network configuration 451

agent process

monitoring 287

agent traces

modifying 78, 434

viewing settings 78, 434

agent working directory

JobManager.ini file 71

agents

critical, positioning 289

ah, global option 28

al, global option 27

altpass, command 402

APARIJ35597451

application server 427

administrative tasks 380

automatic restart 424

configuration backup and restore 428

configuration files: backup and restore 428

encrypting profile properties 427

host name, modify 428

increase heap size 456, 462

monitor 424

security settings, modify 415

TCP/IP ports, modify 428

ApplicationServerStatusChanged event 427

approachingLateOffset, global option 27

appserver

auto restart, local option 52

check interval, local option 53

count reset interval, local option 53

max restarts, local option 53

min restart time, local option 53

appserverbox

monitoring 293

appservman 424

local options 425

not stopping while stopping the

WebSphere Application Server Liberty

423

run from conman, process 302

appservman process

monitoring 287

archive settings for job data

configuring 107

archived files 340

archived plans list

modifying number 168

archived plans number

displayed in Monitor Workload view 168

as, global option 28

at dependency, job streams without,

preventing from starting, global option 37

attributes 225

au, global option 31, 31

auditing

empty. behavior, global option 33

audit

database and plan 364

directory

as log file location 344

header format 366

log format 367

overview 363

plan, enabling, global option 36

audit management

audit history maintenance, global option 28

audit store type, global option 28

database, enabling, global option 33

specify cleanup frequency, global option 41

audit trails

maintaining 363, 364

auditHistory, global option 28

auditing

enabling 364

Self-Service Catalog 167

Self-ServiceDashboards167

storinginfoinafile364

storinginfo in both db and file 364

storinginfoindb364

auditing data permanence

auditHistory global option 364

auditing db info

enDbAudit 364

auditing enabling

auditStore global option 364

auditing facilities 363

auditing plan info

enPlanAudit 364

auditStore, global option 28

authentication

Active Directory 262

basic user registry 262

IBM Directory Server 262

IBM Tivoli Directory Server 265

LDAP 262

Microsoft Active Directory 268

OpenID Connect 272

authentication on SMTP connection, use, global option 45

authentication, configuring 262

auto link flag 276

auto restart, appservman 425

automatic failover

enabling 392

automatic failover actions, global option 32

automatic failover, global option 31

automatic maintenance, DB2

running manually 348

automatic restart of application server 424

automatically grant logon as batch, global

option 36

autostart monman, local option 53

availability 464

average run time calculation, weighting factor,

global option 41

# B

backing up

log files 333

backup

application server configuration 428, 428

backup

master domain manager

331

log files 331

to offline storage 331

backup domain manager

definition 275

domain manager

backup definition 275

performance 453

switching 382, 383

backup event manager, global option 34

backup master domain manager

backing up files to 331

configuring 389

copying files to 389

definition 275

extended loss of 397

from an agent 388

permanent change 397

selecting 388

setting up 389

switching 397

backup master domain manager

configuration

109

backup master, global option 34

backupConfig, used to backup application

server configuration 428

baseRecPrompt, global option 29

baseRecPropmt, additional prompts global

option 39

basicURL136

basic user registry 262

configuration 149

batchman

deadline, minimum wait to check , local

option 53

dependency status, wait to check, local

option 53

file, minimum wait to check , local option 53

intercom.msg file, maximum wait to read,

local option 54

processes 284

production control file, minimum wait to

update, local option 54

starting 285

statistics reporting, enable, local option 54

status messages, send to standard list,

local option 54

tuning 448

until time, maximum wait to report expiry

of, local option 53

batchman process

monitoring 287

beacon 159

behind firewall

extended agent 278

behindfirewall option 277

bindUser, global option 29

bm check deadline, local option 53

bm check file, local option 53

bm check status, local option 53

bm check until, local option 53

bm look, local option 54

bm read, local option 54

bm status, local option 54

bm verbose, local option 54

bp, global option 29

broker backup configuration 398

broker configuration

modifying 109

broker configuration data 398

broker failover 398

broker server configuration

modifying 109

broker switch 398

BrokerWorkstation.properties

dynamic workload broker

workstation configuration

109

bu, global option 29

# C

CA 318

cache.dat, increasing size of 416

caching mailbox 452

calendar, object type, defining access 230,

234, 235

calendars, enabling the copying of into

Symphony, global option 40

can be event processor, local option 54

caonly, SSL auth mode, local option 62

carry forward internetwork dependencies,

global option 33

carry forward resource quantities, global

option 33

carry forward, global option 32

carryStates, global option 29

CCLog

shared memory management 447

cd, global option 47

centralized security 210

centralized security, global option 32

Certificate Authority 311, 313

certificate renewal 321

certificate rotation 321

certificates 311, 311, 311, 313, 314, 317, 318

320

renewing 321

rotating 321

Certman

311, 311, 313, 314, 317, 318, 320

cf, global option 32

change default directory

change default directory when using the

centralized agent update, local option 56

changeHostProperties script 428

changeSecurityProperties script 415

changing

IP address or host name on the

dynamic agent

415

IP address or host name on the

dynamic workload broker

server

413

WebSphere Application Server Liberty

file

411

workstation definition 413

workstation host name or IP address 411

changing an agent to backup

master domain manager

388

check interval, appservman 425

check status of remote job, process start 302

checkevtptroc, run from conman on a client, process 302

checks, file dependency, impacting

performance 450

ci, global option 33

clbox

monitoring 293

CLI

default workstation when using, local option 56

host name when connecting from, local option 57

is installed as, local option 57

OpenSSL certificate file when using SSL

with server, local option 55

OpenSSL cipher class, local option 54

OpenSSL trusted certificate directory when using SSL with server, local option 55

OpenSSL, enabling SSL server

authentication, local option 55

port, local option 61

protocol, local option 61

proxy port, local option 61

proxy, local option 61

timeout, local option 66

useroptsfile,localoption66

CLI SSL cipher suites, local option 54

cli ssl cipher, local option 54

cli ssI server auth, local option 55

cli ssl server certificate, local option 55

cli ssl trusted dir, local option 55

Cloud & Smarter Infrastructure technical

training xi

cn, global option 30

command line client

configuring remote access 123

command line reporting

configuration 374

Oracle database configuration 374

Oracle JDBC drivers 374

command-line prompt

composer 55

conman 56

commands

console 133

dumpsec 208

evtsize 298

makesec 209

StartUp 286

commands and scripts

jobmanrc 305

altpass 402

appservman 424

backupConfig 428

changeHostProperties 428

changeSecurityProperties 415

dbexpand, impact on audit log file 369

dbreorg 349

dbrunstats 348

fault-tolerant agent access method on UNIX local 305

jobmanrc 305

link 276

makesec, impact on audit log file 369

restoreConfig 428

rmstdlist 340

startappserver 424, 426

startAppServer 423

StartUp 285

stopappserver 424, 426

stopAppServer 423

UNIX local

fault-tolerant agent access method

on 305

unlink

usage 276

communications in the network 276

companyName, global option 30

composer

defining access for working with

objects 230

prompt, local option 55

configuration

basic user registry 149

Dynamic Workload Console

145

for LDAP 149

for single sign-on 149

ldap user registry 146

templates 418

user 146

user's portfolio 146

configuration file, netman 301

configuration files

application server, backup and restore 428

backing up 331

configuring 311

archive settings for job data 107

authentication 262

gateway 278

global resource matching 105

heartbeat signal 105

high availability 127

J2EE communication channel 113

J2EE jobs 113

maximum number of results for global

resource matching 105

time interval for job allocation to

resources 105

time interval for notifications on

resources 105

time interval for retrying failed

operations 107

WebSphere

Application Server

113

configuring reports

Oracle database 175

configuring role-based security

role-based security 180, 186

conman

defining access for working with

objects 230

log type 367

prompt, local option 56

running appservman 302

running checkevtptroc on a client 302

running deployconf 302

running startappserver 302

running startevtproc 302

running stopappserver 302

running stopevtptroc 302

running stopevtptroc on a client 302

running stopmon 301

running switchevtptroc 301

starting the find and return of a stdlist

file 301

connection failed, wait to retry in netman, local

option 60

connection parameters

configuring 123

connectivity, impact on network 289

console command 133

console manager, start process 302

console messages and prompts 132

continue keyword 257

copying files to backup

master domain manager

389

count reset interval, appservman 426

courier

monitoring 293

courier.msg file, wait to read in jobman, local

option 59

cpu, object type, defining access 230

cpu, SSL auth mode, local option 62

create

security domains 184

create an SAP connection 154

critical agents, positioning 289

critical job

riskConfidence, global option 44

critical path processing, enabling, global

option 39

cross dependencies notification

timeout 43

cs, global option 29

current folder

local option 56

setting 56

customization 13

customizing

news notification beacon 159

customizing certificates

MDM and dynamic agent

321

CyberArk

certificate management 97

p12 certificates 97

perm certificates 97

secure communication 97

using CyberArk certificates 97

using your certificates 97

CyberArk integration

agent configuration 91

configuration 71

profile configuration 91

CyberArk parameters

configuration 92

CyberArk setup 92

CyberArk.ini

configuration 92

# D

DA certificates

rotating 321

da, global option 33

data flows, planning for 291

data maintenance 331

data volumes, impact on network 289

database

back up

to backup

master domain manager

331

to offline storage 331

changing instance owner 353

collecting job metrics 378

log type 367

moving 354

plan replication 449

relocating to a different host 353

reorganization 333

upgrading version 353

database and plan audit 364

database audit enabling, global option 33

database change

configuring with

master domain manager

354

configuring with

master domain manager

with pools

358

database customization 353

database driver

changing 408

database host name

changing 408

database instance owner

changing 408

database job

configuring 120, 445

database migration 354

database migration procedure

master domain manager

354

master domain manager

with pools

358

database migration with pools 358

database name

changing 408

database objects

Security access control list definition 187

Security domain definition 188

Security role definition 191

database password

changing 408

database port

changing 408

database properties

changing 408

database SSL connection

changing 408

database with pools

moving 358

date format, local option 56

DB2

administrative tasks 346

automatic maintenance

running manually 348

changing database user password 402

collecting job metrics 378

increase maximum log capacity 457, 460

monitoring the lock list memory 350

passwords not used by TWS, changing 347

reorganization 333

reorganizedatabase349

tools, locating 347

tuning 450

user permissions for running the tools 347

DB2 for zOS

collecting job metrics 379

DB2 tools

dbgrant 346

dbeorg 346

dbrunstats 346

dbexpand, command, impact on audit log

file 369

dbreorg, DB2 tool 349

dbrunstats, DB2 tool 348

deadline, minimum wait to check , local

batchman option 53

deadlineOffset, global option 30

default ws, local option 56

defining

database objects

Security access control list 187

Security domain 188

Security role 191

definition

workstation changing 413

delete 320

delete folder

global option 40

delete prompt

global option 40

delete resource

global option 40

dependency checks, file, impacting

performance 450

dependency status, batchman wait to check,

local option 53

deploymentFrequency, global option 31

dephyconf, run from conman, process 302

df, global option 31

direct scheduling

J2EE jobs 112

director

audit 344

logs 340

methods 345

schedForecast 344

schedlog 342

schedTrial 344

tmp, as location for temporary files 345

traces 341

directory

change default when using the centralized

agent update, local option 56

disabling

news notification beacon 159

disk full

monitoring 335

disk space

maintaining enough available space 334

monitoring 335

used by backup

domain manager

impacting performance

454

disk usage

monitoring 335

do, global option 30

domain

definition 275

master, definition 275

parent, definition 275

structure of, impact on critical agents 289

domain manager

data flows 291

definition 275

failure 381

IP address validation 309

log file maintenance 340

loss of 381

mitigating loss of 381

network planning, role of 289

optimizing for critical activities 289

positioning for critical activities 289

role of in network planning 289

running without 381

switching 382, 383

temporary files 345

without 381

domain user, resolving account in

Windows 464

download directory, local option 56

download scripts from z/OS

master domain manager

, starting process

301

DsGetDcName, API used to resolve Windows

user ID account 464

dumpsec command 208

duplicatesecuritydomains185

duplicatesecurityrole186

duration, job, long, threshold, global option 42

dynamic agent 275

changing IP address or host name 415

gateway configuration 278

overview 303

dynamic agent certificates

rotatir

dynamic agent

configuration

109, 109

dynamic agents

jobs cannot launch 307

dynamic domain manager

configuring the

dynamic workload broker

server

102

maintaining the

dynamic workload broker

server

103

dynamic domain manager

configuration

109

dynamic scheduling 275

dynamic workload broker security

dynamic workload broker

security roles and users and groups

121, 121

dynamic workload broker

server

changing IP address or host name 413

changing URI data 103

configuring 102

exportserverdata 103

http communication 104

https communication 104

importserverdata103

maintaining 103

unsecure communication 104

dynamic workload broker

server on

dynamic domain manager

configuring 102

maintaining 103

dynamic workload broker

server on

master domain manager

configuring 102

maintaining 103

dynamic workload broker

users and roles

mapping security roles in

WebSphere Application Server Liberty

121

modifying 121

dynamic workload broker

workstation configuration

modifying 109

Dynamic Workload Console 136

accessibility xi

authentication method 145

best browser to view graphical views 463

Chrome 463

configuration 136, 136, 145

configure to view reports 175

defining access for working with

objects 230

launch in context 136

local OS method 145

modifying 145

multiple production plan reports, affecting

performance 460

PAM authentication method 145

Dynamic Workload Console configuration templates 418

Dynamic Workload Console

global settings

155

Dynamic Workload Console

customizing

155

dynamic workstations 275

# E

ed, global option 34, 35

education xi

ee, global option 39

ef, global option 39

eh, global option 35

EIF event queue, increasing size of 416

empty auditing, global option 33

empty job streams, global option 34

enable list security check 35

enable support for objects in folders

folder support 37

security file 37

enable the role based security model 37

enabling

SSL communication 325

enAddUser, global option 31, 31

enAutomaticFailover

global option 23

enAutomaticFailover, global option 31

enAutomaticFailoverActions

global option 23

enAutomaticFailoverActions, global option 32

enCarryForward, global option 32

enCentSec, global option 32

enCFinterNetworkDeps, global option 33

enCFResourceQuantity, global option 33

encrypting 427

encrypting application server profile

properties 427

encryption in motion 109

encryption settings 134

enDbAudit, global option 33

enDbGetOpsAudit, global option 33

enEmptySchedulesAreSucc, global option 34

enEventDrivenWorkloadAutomation, global option 34

enEventDrivenWorkloadAutomationProxy,

global option 35

enEventProcessorHttpsProtocol, global

option 35

enForecastStartTime, global option 35

engine

administrative tasks 380

enLegacyStartOfDayEvaluation, global

option 35

enListSecChk, global option 35

enLogonBatch, global option 36

enPlanAudit, global option 36

enPreventStart, global option 37

enRetainNameOnRerunFrom, global option 37

enRoleBasedSecurityFileCreation, global

option 37

enSecFileExtendedFields 37

enSSLFullConnection, global option 38

enStartCondSuccOnDeadline, global option 38

enSwfaultTol, global option 38

Enterprise Workload Manager

resource assignment 107

resource optimization 107

resource weight 107

retry on failure 107

enTimeZone, global option 38

enWhatIfAnalysis, global option 38

enWorkloadServiceAssurance, global

option 39

error messages

IP address validation 308

es, global option 33, 34

event processor

managing 416

event processor HTTPS protocol, global

option 35

event processor, enabling workstation to be,

local option 54

event rule management

IBM Z Workload Scheduler

connector remote server name

, global option 47

IBM Z Workload Scheduler

connector server name

, global option 47

IBM Z Workload Scheduler

connector server port

global option 48

IBM Z Workload Scheduler

connector user name

, global option 48

IBM Z Workload Scheduler

connector user password

global option 48

log history maintenance, global option 28,

41

mail sender name, global option 42

SMTP

port, global option 45

server name, global option 45

use authentication, global option 45

use SSL, global option 45

use TLS, global option 45

user name, global option 45

user password, global option 45

specify cleanup frequency, global option 41

event-driven workload automation

enablement, global option 34

event-driven workload automation proxy

enablement, global option 35

event, ApplicationServerStatusChanged 427

event, object type, defining access 237

eventProcessorEIFPort, global option 39

eventProcessorEIFSsIPort, global option 39

eventrule, object type, defining access 230

evtsize command 298

exportserverdata103

extended agent

behind firewall278

definition 275

jobs cannot launch 307

overview 303

extract 314

extract certificates 314

extRecPrompt, global option 39

# F

failover

automatic 392

failure of

domain manager

381

master domain manager

387

fault tolerant switch manager, enabling, global

option 38

fault-tolerant agent

backing up to, when used as backup

master domain manager

331

changing to

backup master domain manager

388

definition 275

fault-tolerant agent instances

automatic initialization 417

fault-tolerant switch manager

,impact on performance

453

fc, global option 39

fd, global option 40

feed 159

file dependency checks impacting

performance 450

file proxy

high availability 110

load balancer 110

file start condition, defining job name, global

option 39

file trigger, defining job name, global option 39

file, object type, defining access 237

files

.rhost 305

avoiding full file systems 334

batchman minimum wait to check , local

optic

configuration

backing up 331

forecast plan logs 344

host.equiv 305

job output, archived 342

JobManager.ini 278

JobManagerGW.ini 87,443

localopts 48

log files

backing up 331

maintaining file system 334

NetConf

301

Security

backing up 331

Symphony

archived 342

IP address validation 307

maximum number of records 303

overview 276

scanning by batchman 284

trial plan logs 344

useropts 70

fileStartConditionJobName, global option 39

filling mailboxes

monitoring 293

filling message queues

monitoring 293

final job stream, launch time, global option 46

FIPS

local option 63

FIPS compliance, local option 63

firewall bypass, starting 301

firewall support 277

flows, data, planning for 291

folder

access 239

setting the current

56

folder delete

global option 40

folder, object type, defining access

230, 238

folderDays

global option 40

forecast plan logs 344

forecast start time enablement, global

options 35

format, audit log files 367

ftdown message queue, in backup

domain manager

454

ftup message queue, in backup

domain manager

454

full file systems, avoiding 334

FullStatus

mode, setting

284

# G

gateway

configuration 278

configure 87, 443

generate 311, 313

generate certificates 311, 313

getaddrinfo() system call 307, 307

Give access

Give access to user or group 180

global option descriptions

approachingLateOffset 27

auditHistory 28

auditStore 28

automatic failover 31

automatic failover actions 32

baseRecPrompt 29

bindUser 29

carryforward31,31,32

carryStates 29

companyName 30

deadlineOffset 30

deploymentFrequency 31

enCentSec 32

enCFinterNetworkDeps 33

enCFResourceQuantity 33

enDbAudit 33

enDbGetOpsAudit 33

enEmptySchedsAreSucc 34

enEventDrivenWorkloadAutomation 34

enEventDrivenWorkloadAutomationProxy 35

enEventProcessorHttpsProtocol 35

enForecastStartTime 35

enLegacyStartOfDayEvaluation 35

enListSecChk 35

enLogonBatch 36

enPlanAudit 36

enPreventStart 37

enRetainNameOnRerunFrom 37

enRoleBasedSecurityFileCreation 37

enSecFileExtendedFields 37

enSSLFullConnection 38

enStartCondSuccOnDeadline 38

enSwfaultTol 38

enTimeZone 38

enWhatIfAnalysis 38

enWorkloadServiceAssurance 39

event manager backup 34

eventProcessorEIFPort 39

eventProcessorEIFSsIPort 39

extRecPrompt 39

fileStartConditionJobName 39

folderDays 40

ignoreCals 40

licenseType 40

logCleanupFrequency 41

logHistory 41

logmanMinMaxPolicy 41

logmanSmoothPolicy 41

longDurationThreshold 42

mailSenderName 42

master backups 34

maxLen 42

minLen 43

nn 44

np 44

nt 43

nu 44

promotionOffset 43

resubmitJobName 43

resubmitJobUserName 44

riskConfidence 44

smtpServerName 45

smtpServerPort 45

smtpUserName 45

smtpUserPassword 45

smtpUseSSL 45

smtpUseTLS 45

startConditionDeadlineOffset 47

startOfDay 46

statsHistory 46

untilDays 47

useAuthentication 45

workstationLimit 47

zOSRemoteServerName 47

zOSServerName 47

zOSServerPort 48

zOSUserName48

zOSUserPassword 48

global options

enAutomaticFailover 23

enAutomaticFailoverActions 23

workstationEventMgrListInAutomaticFailover 23

workstationMasterListInAutomaticFailover 24

global resource matching

configuring 105

global settings

customizing 155

graphical views, browser 463

# H

header format, audit log records 366

header, log type 367

heap size, application server, increase 456, 462

heartbeat signal

configuring 105

high availability

configuration 127

file proxy 110

history, job statistics, global option 46

host name

application server, modify 428

changing on the

dynamic agent

415

changing on the

dynamic workload broker

server

413

impact of changing 309

host name or IP address

changing 411

changing

WebSphere Application Server Liberty

41

host, for extended agents, definition 276

host, when connecting from

command line client

,local option

57

host.equiv, file 305

HTTPS protocol for event processor, global

option 35

# 1

IBM Directory Server, authentication 262

IBM Tivoli Directory Server 265

IBM Workload Scheduler

roles 146

IBM Workload Scheduler agent

log configuration 75, 431

trace configuration 77, 432

IBM Workload Scheduler

instances

automatic initialization 417

IBM Workload Scheduler

service

417

IBMWAS61Service425

ic, global option 40

ignoreCals, global option 40

ILMT

IBM License Metric Tool 466, 466

import 318

import certificates 318

importserverdata 103

incoming message cache

enable in mailman, local option 59

resize in mailman, local option 59

indirect scheduling

J2EE jobs 112

instance initialization 417

instances

automatic initialization 417

intercom

monitoring 293

intercom.msg file, batchman maximum wait to

read, local option 54

internal Symphony table, determining the size

of 302

IP address

changing on the

dynamic agent

415

changing on the

dynamic workload broker server

413

impact of changing 309

support for V6 307

validation 307

is remote cli, local option 57

# J

J2EE communication channel

configuring 113

J2EE job

configuring 120,445

J2EE jobs

configuration for 112

configuring 113

direct scheduling 112

enabling 113

indirect scheduling 112

JMS 112

security settings 112

supported operations 112

WebSphere

Application Server

settings

112

J2EE jobs on agent

configuration 113, 115, 116

J2EEJobExecutorConfig.properties

configuring 113

Java heap size, application server,

increase 456, 462

Java job

configuring 120, 445

Java job configuration

JobManager.ini file 71

Java Virtual Machine options 86, 442

jm file no root, local option 56

jm job table size, local option 57

jm load user profile, local option 57

jm look, local option 57

jm nice, local option 57

jm no root, local option 58

jm promoted nice, local option 58

jm promoted priority, local option 58

jm read, local option 59

JMS

J2EE jobs 112

JnextPlan

when setting up a domain manager 389

JnextPlan

, avoiding lock list memory problmes

50

job executors

configuring 120, 445

Java options 86, 442

job management tasks wait in jobman, local

option 57

job metrics

collecting 378

SQL queries 378

job output files, archived 342

job plug-ins

configuring 120, 445

Java options 86, 442

job status change notification

timeout 43

job streams

empty. behavior, global option 34

more than 180 000, impacting DB2 log

files 454

without at dependency, preventing from

starting, global option 37

without jobs. behavior, global option 33, 34

job submissions, manual, impacting

performance 450

job table, size of in jobman, local option 57

job times, minimum and maximum, logging

and reporting, global option 41

Job types with advanced options

authorization for running 230

configuration files 120, 445

configuring 120, 445

cpu access 230

customizing 120, 445

defining access 230

defining authorization 230

Java options 86, 442

job types with advanced options

configuration files

location 120, 445

job, object type, defining access 230, 241

JobDispatcherConfig.properties

job age in archive database 107

job age in database 107

jobman

tuning 448

jobman and JOBMAN 56

courier.msg file, wait to read, local

option 59

job management tasks wait, local option 57

launching by batchman 284

nice value to apply to critical UNIX or Linux

jobs, local option 58

nice value to apply to UNIX or Linux jobs,

local option 57

priority value to apply to critical Windows

jobs, local option 58

root jobs, enabling the launch of, local

option 58

size of job table, local option 57

starting 285

user profile to apply on a fault-tolerant

agent, local option 57

jobman process

monitoring 287

JobManager.ini

files 278

jobmanrc 305

jobs

failing to launch on

dynamic agents

307

failing to launch on extended agent 307

improving processing performance 451

late, when becoming, global option 27

long duration threshold, global option 42

more than 40 000, impacting Java heap

size 454

promotion of critical, eligibility for, global

option 43

retaining name on rerun, global option 37

statistics history, global option 46

JVM options 86,442

# K

Kerberos

configuring 98

Kerberos Authentication Protocol 98

key rotation 134

keystore 314

# L

late jobs, when becoming, global option 27

launch in context 136

Dynamic Workload Console 136

lb, global option 36

lc, global option 41

Id, global option 42

LDAP

authentication 262

configuration 149

LDAP servers

IBM Tivoli Directory Server (IDS) 266

Microsoft Active Directory 269

ldap user registry

configuration 146

le, global option 35

lh, global option 41

license

license management 466

per Job license model 470, 476

Per Job pricing 470

Processor Value Unit license model 466

Processor Value Unit pricing 466

version 9.4, Fix pack 2 476

license management

per Job license model 470

per Job statements 476

license metric tool

specify In, global option 40

license metrics

license metric tool 466

license type

specify license type, global option 40

licenseType, global option 40

link command, using 276

link flag, auto 276

link to non-responding workstation, wait to

retry in mailman, local option 59

linking

concept 276

Linux

jobs, nice value to apply when critical, local

option 58

jobs, nice value to apply, local option 57

list permission

enable option 35

Im, global option 41

In, global option 40

load balancer

configuration 127

local option

current folder setting 56

local option descriptions

appserver auto restart 52

appserver check interval 53

appserver count reset interval 53

appserver max restarts 53

appserver min restart time 53

autostart monman 53

bm check file 53, 53

bm check status 53

bm check until 53

bm look 54

bm read 54

bm stats 54

bm verbose 54

can be event processor 54

caonly 62

change default directory 56

cli ssl cipher 54

CLI SSL cipher suites 54

cli ssl server auth 55

cli ssl server certificate 55

cli ssl trusted dir 55

composer prompt 55

conman prompt 56

cpu 62

date format 56

default ws 56

fips compliance 63

host 57

is remote cli 57

jm file no root 56

jm job table size 57

jm load user profile 57

Jm look 57

jm nice 57

jm no root 58

jm promoted nice 58

jm promoted priority 58

jm read 59

merge stdlists 59

mm cache mailbox 59

mm cache size 59

mm resolve master 59

mm response 59

mm retry link 59

mm sound off 60

mm symphony download timeout 60

mm unlink 60

nm mortal 60

nm port 60

nm read 60

nm retry 60

nm SSL full port 60

nm SSL port 61

port 61

protocol 61

proxy 61

proxy port 61

restricted stdlists 61

SSL auth mode 62

SSL auth string 62

SSL CA certificate 62

SSL certificate 63

SSL certificate type 63

SSL cipher suites 63, 95

SSL config file 63, 95

SSL encryption cipher 63, 95

SSL key 63

SSL key pwd 63

SSL random seed 64

SSL version 55, 64, 94

stlist width 64

string 62

switch sym prompt 65

sync level 65

syslog local 65

tcp connect timeout 65

tcp timeout 65

this cpu 65

timeout 66

unison network directory 66

useropts 66

wr enable compression 66

wr read 66

wr unlink 66

local options

file example 48

file template 48

setting 48

setting sysloglocal 132

syntax 48

local security 206

local UNIX

access method 304

local user, resolving account in Windows 464

localopts

nm ipvalidate 307

option for setting synch level 453

options for caching mailbox messages 452

options used for tuning 448

parameters for tuning mailman

servers 300, 300

tuning for job-processing performance 451

used for appservman 425

localoptsfile48

lock list memory, DB2, monitoring 350

LOCKLIST, DB2 configuration parameter 350

log capacity, DB2, increase 457, 460

log configuration

IBM Workload Scheduler agent

75,431

log files

audit

format 367

backing up 333

backup 331

improving performance 340

maintenance 101, 340

reducing space 340

logCleanupFrequency, global option 41

LOGFILSIZ, DB2 parameter 458

logging,impact on performance 447

logging.properties

configuring 115

logHistory, global option 41

logmanMinMaxPolicy, global option 41

logmanSmoothPolicy, global option 41

logon as batch, granting automatically, global

option 36

LOGPRIMARY, DB2 parameter 458

logs

agent encoding 75, 431

logs directory, as log file location 340

LOGSECOND, DB2 parameter 458

longDurationThreshold, global option 42

LookupAccountName, API used to resolve

Windows user ID account 464

loss of

domain manager

381

master domain manager

387

It, global option 41

LTPA keys

sharing 149

# M

newsletter

monitoring 293

郵箱 caching 452

newsletter files

setting size 298

newsletter full

monitoring 293

mailboxes

monitoring 293

mailman

$MASTER variable, resolve, local option 59

caching 452

determining the size of its internal

Symphony table 302

incoming message cache

enable, local option 59

resize, local option 59

link to non-responding workstation, wait to

retry, local option 59

processes timing out 276

servers

configuring to maximize critical

activities 289

tuning 300

starting 285, 301

starting with demgr parameter 301

tellop command, respond to, local

option 60, 60

tuning 448

unlink non-responding workstation, wait to,

local option 60

workstation not responding, wait to report,

local option 59

mailman process

monitoring 287

mailSenderName, global option 42

maintenance

agent configuration 101

DB2, automatic

running manually 348

makesec

impact on audit log file 369

log type 368

makesec command 209

manage access 182

Manage access control list

access control list 182

manage sap connections 154

managing

settings repository 174

manual job submissions impacting

performance 450

master domain manager

backing up to backup

master domain manager

331

configuring the

dynamic workload broker

serve

102

connecting to new database 354

database migration 354

definition 275

extended loss of 397

failure 387

loss of 387

maintaining the

dynamic workload broker

server

103

mitigating loss of 387

new database 354

permanent change 397

running without 387

switching 397

without 387

master domain manager

configuration

109

master domain manager

with pools

connecting to new database 358

database migration 358

new database 358

master domain, definition 275

master instances

automatic initialization 417

max restarts, appservman 426

maximum and minimum job times, logging

and reporting, global option 41

maximum number of concurrent job log

requests

Broker.jobLog.corePoolSize 109

maximum number of results for global

resource matching

configuring 105

maximum records in Symphony file 303

maxLen, global option 42

MAXLOCKS, DB2 configuration parameter 350

MDM certificates

rotating 321

mdm configuration

templates 418

members

workstationclassdefinition189,191

memory

management by logging processes

impacting performance 447

merge stdlists, local option 59

message boxes encryption 134

message caching 452

message level 133

message queues

dm.msg 291

ftdown, in backup

domain manager

454

ftup, in backup

domain manager

454

in backup

domain manager

454

monitoring 293

methods directory, as log file location 345

Microsoft Active Directory 268

min restart time, appservman 425

minimum and maximum job times, logging

and reporting, global option 41

minLen, global option 43

mitigating loss of

domain manager

381

master domain manager

387

ml, global option 43

mm cache mailbox, local option 59

mm cache size, local option 59

mm resolve master, local option 59

mm response, local option 59

mm retry link, local option 59

mm sound off, local option 60

mm symphony download timeout, local

option 60

mm unlink, local option 60

Mm_unlink, localopts parameter 300

modifying

agent traces 78,434

monbox

monitoring 293

moncmd

monitoring 293

monman

autostart, local option 53

starting process 301

monman process

monitoring 287

moving databases with pools 358

moving from Db2 to PostgreSQL 358

ms, global option 42

# N

native job configuration

JobManager.ini file 71

NetConf

, file

301

NetGetAnyDCName, API used to resolve

Windows user ID account 464

netmar

configuration file 301

connection failed, wait to retry, local

option 60

IP address validation 307

port, local option 60

quit when child processes stopped, local

option 60

SSL full port, local option 60

SSL port, local option 61

starting 285

stop and start commands, wait to check

for, local option 60

support for Internet Protocol version 6 307

netman process

monitoring 287

NetUserInfo, API used to resolve Windows

user ID account 464

network

capacity 289

changes,impact of 309

communications 276

gateway configuration 278

impact of changes 309

IP address validation 307

linking 276

message queues, planning for 291

monitoring for unlinked workstations 276

operation 284

optimizing 289

overview 274

processes 285

structure, impact on critical agents 289

support for Internet Protocol version 6 307

traffic caused by backup

domain manager

impacting performance

454

unlinking 276

network traffic 447

new database

connecting to

masterdomainmanager

354

connecting to

master domain manager

with pools

358

new executors

authorization for running 230

defining access 230

defining authorization 230

news notification beacon

customize 159

disabling 159

nice value to apply to critical UNIX or Linux

jobs in jobman, local option 58

nice value to apply to UNIX or Linux jobs in

jobman, local option 57

nm ipvalidate, localopts parameter 307

nm mortal, local option 60

nm port, local option 60

nm read, local option 60

nm retry, local option 60

nm SSL full port, local option 60

nm SSL port, local option 61

nn, global option 44

nodename validation 307

normal run time calculation, weighting factor,

global option 41

notification

news

disabling 159

enabling 159

notificationTimeout, global option 43

np, global option 44

nt, global option 43

nu, global option 44

# 0

object attribute values 225

specifying object attribute values 201

object attributes

attributes for object types 200

object types, defining access to composer

actions 230

od, global option 38

offline storage, used for backup and

restore 331

OpenID Connect 272

opens, file dependency 304

OpenSSL

ca certificate file, local option 62

certificate file, local option 63

certificate type, local option 63

cipher class, local option 54

cipher suites, local option 63, 63, 95, 95

CLI cipher suites, local option 54, 54

enabling SSL server authentication, local

option 55

server certificate when using command-line

client, local option 55

SSL config file, local option 63, 95

SSL encryption cipher, local option 63, 95

SSL key file, local option 63

SSL key password file, local option 63

SSL random seed, local option 64

trusted directory when using command-line

client, local option 55

Oracle

administrative tasks 352

changing user password 402

collecting job metrics 379

reorganization 333

tuning 450

Oracle database

configuring reports 175

Oracle JDBC drivers

URL configuration 175

overview

access method for

dynamic agent

303

access method for extended agent 303

dynamic agent

303

extended agent 303

# P

pa, global option 36

parameter

ResourceAdvisorURL 278

parameter, object type, defining access 245

parent domain, definition 275

parms, log type 368

password for SMTP connection, global

option 45

password management

agent configuration 90, 91

profile configuration 90, 91

password resolver

agent configuration 90, 91

profile configuration 90, 91

password solver

agent configuration 90, 91

profile configuration 90, 91

password storage

agent configuration 90, 91

profile configuration 90, 91

password vault

agent configuration 90, 91

profile configuration 90, 91

password vault integration

configuration 71

passwords

other DB2, changing 347

TWS_user, changing 402

performance 447

browser 463

fault-tolerant switch manager

453

file dependency checks, too many 450

graphical views in browser 463

impacted by multiple TDWC production

plan reports 460

job submissions, manual, too many 450

job-processing, improving 451

network 289

too many file dependency checks 450

too many manual job submissions 450

tuning database configuration

parameters 450

tuning job processing on a workstation 448

tuning on UNIX 447

workload spreading 451

permissions, user

for running DB2 tools 347

plan auditing, enabling, global option 36

plan replication

tuning 449

Plan View

auto refresh

Plan View 159

Show Plan View

auto refresh 159

plan, log type 368

plan, preproduction, maximum length, global

option 42

plan, preproduction, minimum length, global

option 43

planning to minimize network message

quences 291

po, global option 43

pobox

monitoring 293

port

SMTP server, global option 45

SSL full, used by netman, local option 60

SSL, used by netman, local option 61

port for

command line client

, local option

61

port number, event processor, global

option 39, 39

port, for netman, local option 60

predecessors, hide

What-if Analysis view 169

preproduction plan, maximum length, global

option 42

preproduction plan, minimum length, global

option 43

preventing job streams without at dependency

from starting, global option 37

pricing

license metrics 466, 470

priority value to apply to critical Windows jobs

in jobman, local option 58

process messages 132

process prompts 132

processes status

monitoring 287

production control file, batchman minimum

wait to update, local option 54

production plan reports, TDWC, affecting

performance 460

production, managing on extended agents 307

profile properties 427

promoting to

backup master domain manager

388

promotion of critical jobs, eligibility for, global

option 43

promotionOffset, global option 43

prompt, object type, defining access 230, 245

prompts, additional, global option 39

protocol, local option 61

proxy port, local option 61

proxy, local option 61

ps, global option 37

# Q

quit netman when child processes stopped,

local option 60

# R

r3batch extended agent, interaction process

start 302

rc, global option 44

release, log type 368

remote access for command-line,

configuring 123

remote job, check status of, process start 302

remote UNIX

access method 304

remove alias from certificates 320

remove security domains

edit security domains 185

remove security role

edit security role 186

reorganizDB2database349

reorganizing database 333

replicate plan data

database 449

tuning 449

report, object type, defining access 246

reports configuring

Oracle database 175

reports, configuring

Dynamic Workload Console

to view

175

rerun jobs, retaining name, global option 37

resource advisor agent 398

Resource advisor agent

JobManager.ini file 71

resource quantities carried forward, global

option 33

resource, object type, defining access 230, 246

ResourceAdvisorURL

parameter 278

restart, automatic, of application server 424

restore

application server configuration 428

restore of application server configuration 428

restore, from offline storage 331

restoreConfig, used to restore application

server configuration 428

restricted stdlists, local option 61

resubmitJobName, defining job name, global

option 43

resubmitJobName, global option 43

resubmitJobUserName, defining job name,

global option 44

resubmitJobUserName, global option 44

rights, user

for running DB2 tools 347

riskConfidence, defining job risk, global

option 44

riskConfidence, global option 44

rj, global option 43

rmstdlist command

used for archiving log files 340

role based security model

enable the role based security model,

global option 37

role-based security model

security 179

roles

for Workload Scheduler 147

root jobs, enabling the launch of in jobman,

local option 58

root user, changing password 402

rq, global option 33

rr, global option 37

rs, global option 37

run cycle group, object type, defining

access 230, 247

run time (average) calculation, weighting

factor, global option 41

running without

domain manager

381

master domain manager

387

rw, global option 44

# s

sample audit log entries 371

SAP connection 154

sc, global option 35

scalability 454

schedlog directory, as log file location 342

schedule, object type, defining access 230,

248

scheduling definitions

replicating 400

scheduling events, communications 276

sd, global option 46

secure 311

secure communication 311, 311, 311, 313

314, 317, 318, 320

in job definitions 98

secureaddr

workstation definition 325

security

centralized 210

information, verifying in Windows 464

local 206

overview 205

specifying accesses 228

specifying object types 221

specifying objects 223

specifying user attributes 214

template file 211

security access control list

security access control list definition 187

Security access control list definition 187

security check when listing, global option 35

security domain 181

security domain definition 189

security domain definition

security domain 189

Security domain definition 188

security domains

create 184

security file

enabling centralized security, global

option 32

security file, template 211

security role

adding 185

security role definition 191

security role definition

security role 191

Security role definition 191

security roles

security 185

security settings, application server,

modify 415

Security, file

backing up 331

securitylevel 325

workstation definition 325

Self-Service Catalog

auditing 167

single sign-on 149

Self-ServiceDashboards

auditing 167

Self-Service Monitoring

single sign-on 149

sender name, mail, event rule management,

global option 42

server

monitoring 293

server configuration

ResourceAdvisorConfig.properties file 105

servers

mailman

configuring to maximize critical

activities 289

tuning 300

servicenowUrl, global option 44

servicenowUserName, global option 44

servicenowUserPassword, global option 44

services

IBMWAS61Service 425

stopping 407

services (Windows)

changing password 402

stopping 407

Workload Scheduler, configuring in

NetConf

file

301

setting the local options 48

setting the user options 70

settings

agent traces 78, 434

settings repository

managing 174

sf, global optic

sh, global option 46

single sign-on 265, 268, 272

basic registry 149

configuration 149

Dynamic Workload Console 149

LDAP registry 149

Self-Service Catalog 149

Self-Service Monitoring 149

Single Sing-On 150, 150, 151, 151

configuring 150, 151

Dynamic Workload Console

150, 151

master domain manager

150, 151

size of core services and job log requests

Broker.jobLog.corePoolSize 109

sizing the internal Symphony table 302

SMTP

authentication on connection, use, global

option 45

port, global option 45

server name, global option 45

SSL on connection, use, global option 45

TLS on connection, use, global option 45

user name for connection, global option 45

user password for connection, global

option 45

smtpServerName, global option 45

smtpServerPort, global option 45

smtpUseAuthentication, global option 45

smtpUserName, global option 45

smtpUserPassword, global option 45

smtpUseSSL, global option 45

smtpUseTLS, global option 45

sn, global option 45

soap.client props

configuring 116

sp, global option 45

SQL queries for job metrics 378

DB2 378

DB2 for zOS 379

Oracle 379

SSL

authentication mode, local option 62

authentication string, local option 62

full connection enablement, global

option 38

full port, used by netman, local option 60

OpenSSL CA certificate file, local option 62

OpenSSL certificate file for

communications with command-line client,

local option 55

OpenSSL certificate file, local option 63

OpenSSL certificate type, local option 63

OpenSSL cipher class when using

command-line client, local option 54

OpenSSL trusted certificate directory for

communications with command-line client,

local option 55

OpenSSL, enabling server authentication

for

command line client

,local option

55

OpenSSL, SSL encryption cipher, local

option 63, 95

OpenSSL, SSL key file, local option 63

OpenSSL, SSL key password file, local

option 63

OpenSSL, SSL random seed, local option 64

port, used by netman, local option 61

SSL config file, local option 63, 95

SSL attributes

configuring 325

SSL auth mode, local option 62

SSL auth string, local option 62

SSL CA certificate, local option 62

SSL certificate type, local option 63

SSL certificate, local option 63

SSL cipher suites, local option 63, 95

SSL communication

enabling 325

SSL config file, local option 63, 95

SSL encryption cipher, local option 63, 95

SSL key pwd, local option 63

SSL key, local option 63

SSL on SMTP connection, use, global

option 45

SSL random seed, local option 64

SSL version

enabling using local option 55, 64, 94

SSL version, local option 55, 64, 94

SSO

configuration 149

Dynamic Workload Console 149

Self-Service Catalog 149

Self-Service Monitoring 149

st, global option 35

stageman, log type 368

standard agent instance

automatic initialization 417

standard agent, definition 275

start condition

deadline behavior, global option 38

start

dynamic workload broker

398

start-of-plan-period

initialization, communications 276

startappserver 424, 426

run from conman, process 302

startAppServer command 423

startConditionDeadlineOffset, defining, global

option 47

startConditionDeadlineOffset, global option 47

startevtptroc, run from conman, process 302

starting

WebSphere Application Server Liberty

423

startOfDay, global option 46

startOfDay, how evaluated in time zones,

global option 35

StartUp

used for starting netman 285

StartUp command 286

startZosDDM 399

statistics reporting by batchman, enable, local

option 54

statsHistory, global option 46

status

application server 427

status messages, batchman send to standard

list, local option 54

stdlist directory

information about extended agent jobs 304

stlist width, local option 64

stdlist, merge console messages into, local

option 59

stop and start commands, wait to check for in

netman, local option 60

stop

dynamic workload broker

398

stopappserver 424, 426

run from conman, process 302

stopAppServer command 423

stopevptroc, run from conman on a client,

process 302

stopevtptroc, run from conman, process 302

stopmon, run from conman, process 301

stopping

services 407

stopping services 407

stopping

WebSphere Application Server Liberty

23

stopping workstations hierarchically, starting

process 301

streamlogon, user 464

string, SSL auth mode, local option 62

structure of network, impact on critical

agents 289

submitting too many jobs manually, impact on

performance 450

sw, global option 38

switch

dynamic workload broker

instances

398

switch manager, fault tolerant, enabling, global

option 38

switch sym prompt, local option 65

switchevtptroc, run from conman, process 301

switching a domain manager

planned, unplanned outage 383

short-term, long-term outage 383

switching a domain manager, short-term 382

switching a

master domain manager

long-term 397

short-term 397

switching backup dynamic domain manager

z controller 399

switching databases with pools 358

switching extended agents

$manager keyword 219

$master keyword 219

switching from Db2 to PostgreSQL 358

switching standard agents

$manager keyword 219

$master keyword 219

switching the dynamic domain manager

broker instance switch 398

z controller 399

switching the

dynamic workload broker

398

switching the master domain manager

broker instance switch 398

switching the mdm

automatic 392

switchmgr

automatic 392, 392

starting normal process 301

starting process so that links are not

started until event received 301

symphony encryption 134

Symphony file

archived 342

enabling the copying of calendars into,

global option 40

fileStartConditionJobName, global

option 39

IP address validation 307

maximum number of records 303

monitoring space used 334

overview 276

resubmitJobName, global option 43

resubmitJobUserName, global option 44

scanning by batchman 284

startConditionDeadlineOffset, global

option 47

support for Internet Protocol version 6 307

Symphony file download timeout, local

option 60

Symphony table, internal, determining the size

of 302

sync level, local option 65

synch level option, setting 453

syslog 132

syslog local, local option 65

sysloglocal options

LOG_ERR132

LOG_INFO 132

LOG_NOTICE 132

LOG WARNING 132

System scanner

JobManager.ini file 71

# T

task executors

configuring 120, 445

tcp connect timeout, local option 65

tcp timeout, local option 65

tcp timeout, localopts parameter 300

TCP/IP ports, application server, modify 428

TdwcGlobalSettings.xml.template file 155

technical training xi

tellop command, respond to in mailman, local

option 60

temporary files 345

this cpu, local option 65

threshold, long job duration, global option 42

time interval for job allocation to resources

configuring 105

time interval for notifications on resources

configuring 105

time interval for retrying failed operations

configuring 107

time zone feature, enabling, global option 38

time zones

evaluating startOfDay, global option 35

timeout, local option 66

tl, global option 45

TLS on SMTP connection, use, global

option 45

tmp directory, as location for temporary

files 345

tomaster

monitoring 293

tomaster.msg message queue

in backup

domain manager

454

tools

database and plan 364

trace and log files agent

agent twstrace syntax 78, 434

trace configuration

IBM Workload Scheduler agent

77,432

trace.xml, application server utility 428

traces directory, as trace file location 341

tracing 447

traffic caused by backup

domain manager

impacting performance

454

training

technical xi

tree structure, impact on critical agents 289

trial plan logs 344

trigger

workflow triggering 39, 43, 47

troubleshooting

data flows 291

message queues 291

ts, global option 32

tuning

database 450, 450

job processing on a workstation 448

localopts file, for job-processing

performance 451

mailman servers 300

plan replication 449

UNIX operating systems 447

TWS disk space

monitoring 335

TWS processes status

monitoring 287

TWSObjectsMonitor events,

ApplicationServerStatusChanged 427

twstrace syntax

agent log and trace files 78, 434

tz, global option 38

# U

ua, global option 45

ud, global option 47

un, global option 45

unison network directory, local option 66

UNIX

access method 304

changing passwords on 402

configuration for IP address validation 308

jobs, nice value to apply when critical, local

option 58

jobs, nice value to apply, local option 57

local UNIX access method 304

remote UNIX access method 304

temporary directory, on UNIX, access

rights 465

tuning 447

unixlocl, access method on fault-tolerant

agent 305

unixrsh, access method 305

unixssh, access method 305

unlink non-responding workstation, wait to in

mailman, local option 60

unlink, command

usage 276

unlinking

concept 276

workstations 407

unlinking workstations 407

until time, batchman maximum wait to report

expiry of, local option 53

untilDays, global option 47, 47

up, global option 45

us, global option 45

used disk space

monitoring 335

user

configuration 146

portfolio 146

user authentication

in job definitions 98

user name for SMTP connection, global

option 45

user options

setting 70

syntax 70

user password for SMTP connection, global

option 45

user permissions

for running DB2 tools 347

user profile to apply on a fault-tolerant agent in

jobman, local option 57

user security

commands

dumpsec 208

makesec 209

local security 206

security file

access capabilities 229

modifying 207

sample 252

syntax 211

user qualification 218

variable:

wildcards 214

security files 206

setting 178

userobj, object type, defining access 230, 249

useroptsfile70

useropts,local option 66

users

domain, resolving account in Windows 464

local, resolving account in Windows 464

streamlogon 464

utilities

defining access for working with

objects 230

trace.xml 428

utility commands

setting mailbox file size 298

starting up netman 286

# V

validating IP address 307

validity 317

values 225

variable table, object type, defining access 230

variables

$MASTER, resolve, local option 59

variable, object type, defining access 250

verify 317

verify certificates 317

version 9.4, Fix pack 2

upgrading 476

view access 181

View access for security domain

view access 181

View access for users or groups

view access control list 181

viewing

agent traces 78,434

volumes, data, impact on network 289

# W

wa, global option 39

warning messages

IP address validation 308

wastools replacement 418

we, global option 34

WebSphere

Application Server

configuring 113

WebSphere Application Server Liberty

changing user password 402

starting and stopping 423

WebSphere Application Server Liberty

file

changing host name or IP address 411

WebSphere Application Server Liberty

, starting

426

WebSphere Application Server Liberty

, stopping

426

weighting factor for calculating average run

time, global option 41

What-if Analysis

hide predecessors 169

What-if Analysis, enabling, global option 38

wi, global option 38

Windows

changing passwords on 402

jobs, nice value to apply when critical, local

option 58

resolving user ID account 464

Windows OS

special characters, handling 127

without

domain manager

381

master domain manager

387

wl, global option 47

wm, global option 34

working directory

folder 56

workload

spreading to improve performance 451

workload applications, object type, defining

access 251

workload automation, event-driven,

enablement, global option 34

workload automation, event-driven, proxy,

enablement, global option 35

workload service assurance

approaching late offset, global option 27

deadline offset, global option 30

jobs eligible for promotion, global option 43

nice value to apply to critical UNIX or Linux

jobs in jobman, local option 58

priority value to apply to critical Windows

jobs in jobman, local option 58

required security access for

<TWS_user>

251

workload service assurance, enabling, global

option 39

workstation

application server status 427

changing host name or IP address 411

dynamic agent 275

Tuning job processing on 448

workstation class definition

members 189, 191

workstation definition 325

changing 413

secureaddr 325

workstation not responding, wait to report in

mailman, local option 59

workstationEventMgrListInAutomaticFailover

global option 23

workstationEventMgrListInAutomaticFailover,

global option 34

workstationLimit, global option 47

workstationMasterListInAutomaticFailover

global option 24

workstationMasterListInAutomaticFailover,

global option 34

workstations

default when using the

command line client

,local option

56

enabling to be event processor, local

option 54

unlinking 407

wr enable compression, local option 66

wr read, local option 66

wr unlink, local option 66

Wr_unlink, localopts parameter 300

writer

starting 285

starting, for incoming mailman

messages 301

stopping, for incoming mailman

messages 301

# X

xl, global option 42

xp, global option 39

# Z

zOSRemoteServerName, global option 47

zOSServerName, global option 47

zOSServerPort, global option 48

zOSUserName, global option 48

zOSUserPassword, global option 48

zp, global option 48

zr, global option 47

zs, global option 47

zu, global option 48

zw, global option 48
